(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(n){function e(e){for(var r,s,i=e[0],l=e[1],c=e[2],d=0,u=[];d<i.length;d++)s=i[d],Object.prototype.hasOwnProperty.call(o,s)&&o[s]&&u.push(o[s][0]),o[s]=0;for(r in l)Object.prototype.hasOwnProperty.call(l,r)&&(n[r]=l[r]);for(p&&p(e);u.length;)u.shift()();return a.push.apply(a,c||[]),t()}function t(){for(var n,e=0;e<a.length;e++){for(var t=a[e],r=!0,i=1;i<t.length;i++){var l=t[i];0!==o[l]&&(r=!1)}r&&(a.splice(e--,1),n=s(s.s=t[0]))}return n}var r={},o={1:0},a=[];function s(e){if(r[e])return r[e].exports;var t=r[e]={i:e,l:!1,exports:{}};return n[e].call(t.exports,t,t.exports,s),t.l=!0,t.exports}s.e=function(n){var e=[],t=o[n];if(0!==t)if(t)e.push(t[2]);else{var r=new Promise((function(e,r){t=o[n]=[e,r]}));e.push(t[2]=r);var a,i=document.createElement("script");i.charset="utf-8",i.timeout=120,s.nc&&i.setAttribute("nonce",s.nc),i.src=function(n){return s.p+"assets/js/"+({}[n]||n)+"."+{2:"ebc69a32",3:"25c614f0",4:"542e9b82",5:"4bcce552",6:"d41e8bf9",7:"e928a25b",8:"ddf992e7",9:"faedc087",10:"6c4c4ab9",11:"679678d6",12:"deaf25f7",13:"985315df",14:"7787d897",15:"635b8f55",16:"a7f9bb48",17:"1832ebcb",18:"ac9e3253",19:"3e4bc6eb",20:"984e29ec",21:"3f37f8b8",22:"30ee1728",23:"489c8b6d",24:"65478516",25:"440f402d",26:"1815479a",27:"f5b8cee5",28:"9a6cf032",29:"ce8ffc27",30:"f24cccf9",31:"a6875203",32:"17e4d471",33:"fac1c69e",34:"2b94da57",35:"6079a664",36:"1f99cd1d",37:"c91aaa19",38:"31561a65",39:"71c38fd3",40:"a76c135b",41:"e97e6cb7",42:"b808ef8f",43:"5b2a9968",44:"355b1d3b",45:"9c528887",46:"8d3eedb6",47:"8c3bbdb6",48:"66c350b9",49:"2fd99115",50:"17339639",51:"5e628842",52:"d592fe39",53:"c5dc4be4",54:"f9ec091c",55:"abf342d9",56:"5c78476c",57:"182af18e",58:"cc39e610",59:"6f032d18",60:"6b5f548a",61:"02e1a9f1",62:"50f82996",63:"71f391ec",64:"1f0993d0",65:"7448d827",66:"468ff5f8",67:"5c9486d0",68:"241d98b1",69:"72d856a7",70:"7d934840",71:"6a0d9ea4",72:"dc50c87a",73:"aa1c1691",74:"c5253135",75:"6ff54b05",76:"8bafff13",77:"40b68e0e",78:"8c8cb816",79:"f2b49dc2",80:"84394ab3",81:"dffe7377",82:"07a12478",83:"20894a19",84:"9536d25d",85:"79f06ebd",86:"e50e665c",87:"95d14ae9",88:"2cef63e5",89:"53c53bc6",90:"32c61d53",91:"f9b662b0",92:"410fa25c",93:"27703c41",94:"2d354f23",95:"a70b147a",96:"adb90937",97:"7d717f87",98:"2fb32ed1",99:"78399d6c",100:"14ecf654",101:"ef2677ae",102:"a2e87932",103:"6b933b04",104:"a2aaa7ca",105:"eae2ecc4",106:"a57cd4d0",107:"73811f03",108:"2e5bd9d4",109:"92b57358",110:"90f10894",111:"508768cb",112:"d14993ff",113:"0994f3b9",114:"13df2932",115:"fcdb35e7",116:"3b137288"}[n]+".js"}(n);var l=new Error;a=function(e){i.onerror=i.onload=null,clearTimeout(c);var t=o[n];if(0!==t){if(t){var r=e&&("load"===e.type?"missing":e.type),a=e&&e.target&&e.target.src;l.message="Loading chunk "+n+" failed.\n("+r+": "+a+")",l.name="ChunkLoadError",l.type=r,l.request=a,t[1](l)}o[n]=void 0}};var c=setTimeout((function(){a({type:"timeout",target:i})}),12e4);i.onerror=i.onload=a,document.head.appendChild(i)}return Promise.all(e)},s.m=n,s.c=r,s.d=function(n,e,t){s.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:t})},s.r=function(n){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})},s.t=function(n,e){if(1&e&&(n=s(n)),8&e)return n;if(4&e&&"object"==typeof n&&n&&n.__esModule)return n;var t=Object.create(null);if(s.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:n}),2&e&&"string"!=typeof n)for(var r in n)s.d(t,r,function(e){return n[e]}.bind(null,r));return t},s.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return s.d(e,"a",e),e},s.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},s.p="/",s.oe=function(n){throw console.error(n),n};var i=window.webpackJsonp=window.webpackJsonp||[],l=i.push.bind(i);i.push=e,i=i.slice();for(var c=0;c<i.length;c++)e(i[c]);var p=l;a.push([129,0]),t()}([function(n,e,t){"use strict";var r=function(n){return n&&n.Math===Math&&n};n.exports=r("object"==typeof globalThis&&globalThis)||r("object"==typeof window&&window)||r("object"==typeof self&&self)||r("object"==typeof global&&global)||r("object"==typeof this&&this)||function(){return this}()||Function("return this")()},function(n,e,t){"use strict";n.exports=function(n){try{return!!n()}catch(n){return!0}}},function(n,e,t){"use strict";var r="object"==typeof document&&document.all;n.exports=void 0===r&&void 0!==r?function(n){return"function"==typeof n||n===r}:function(n){return"function"==typeof n}},function(n,e,t){"use strict";var r=t(13),o=t(0),a=t(144),s=t(4),i=t(2),l=t(87),c=t(146),p=t(147),d=t(1),u=t(11),m=t(18),g=t(88).IteratorPrototype,f=t(6),h=t(24),v=m("toStringTag"),b=TypeError,_=o.Iterator,y=h||!i(_)||_.prototype!==g||!d((function(){_({})})),k=function(){if(a(this,g),l(this)===g)throw new b("Abstract class Iterator not directly constructable")},w=function(n,e){f?c(g,n,{configurable:!0,get:function(){return e},set:function(e){if(s(this),this===g)throw new b("You can't redefine this property");u(this,n)?this[n]=e:p(this,n,e)}}):g[n]=e};u(g,v)||w(v,"Iterator"),!y&&u(g,"constructor")&&g.constructor!==Object||w("constructor",k),k.prototype=g,r({global:!0,constructor:!0,forced:y},{Iterator:k})},function(n,e,t){"use strict";var r=t(9),o=String,a=TypeError;n.exports=function(n){if(r(n))return n;throw new a(o(n)+" is not an object")}},function(n,e,t){"use strict";function r(n,e,t,r,o,a,s,i){var l,c="function"==typeof n?n.options:n;if(e&&(c.render=e,c.staticRenderFns=t,c._compiled=!0),r&&(c.functional=!0),a&&(c._scopeId="data-v-"+a),s?(l=function(n){(n=n||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(n=__VUE_SSR_CONTEXT__),o&&o.call(this,n),n&&n._registeredComponents&&n._registeredComponents.add(s)},c._ssrRegister=l):o&&(l=i?function(){o.call(this,(c.functional?this.parent:this).$root.$options.shadowRoot)}:o),l)if(c.functional){c._injectStyles=l;var p=c.render;c.render=function(n,e){return l.call(e),p(n,e)}}else{var d=c.beforeCreate;c.beforeCreate=d?[].concat(d,l):[l]}return{exports:n,options:c}}t.d(e,"a",(function(){return r}))},function(n,e,t){"use strict";var r=t(1);n.exports=!r((function(){return 7!==Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(n,e,t){"use strict";var r=t(32),o=Function.prototype,a=o.call,s=r&&o.bind.bind(a,a);n.exports=r?s:function(n){return function(){return a.apply(n,arguments)}}},function(n,e,t){"use strict";var r=t(32),o=Function.prototype.call;n.exports=r?o.bind(o):function(){return o.apply(o,arguments)}},function(n,e,t){"use strict";var r=t(2);n.exports=function(n){return"object"==typeof n?null!==n:r(n)}},function(n,e,t){"use strict";var r=t(2),o=t(49),a=TypeError;n.exports=function(n){if(r(n))return n;throw new a(o(n)+" is not a function")}},function(n,e,t){"use strict";var r=t(7),o=t(38),a=r({}.hasOwnProperty);n.exports=Object.hasOwn||function(n,e){return a(o(n),e)}},function(n,e){var t=Array.isArray;n.exports=t},function(n,e,t){"use strict";var r=t(0),o=t(69).f,a=t(25),s=t(52),i=t(51),l=t(84),c=t(143);n.exports=function(n,e){var t,p,d,u,m,g=n.target,f=n.global,h=n.stat;if(t=f?r:h?r[g]||i(g,{}):r[g]&&r[g].prototype)for(p in e){if(u=e[p],d=n.dontCallGetSet?(m=o(t,p))&&m.value:t[p],!c(f?p:g+(h?".":"#")+p,n.forced)&&void 0!==d){if(typeof u==typeof d)continue;l(u,d)}(n.sham||d&&d.sham)&&a(u,"sham",!0),s(t,p,u,n)}}},function(n,e,t){"use strict";var r=t(8),o=t(4),a=t(37);n.exports=function(n,e,t){var s,i;o(n);try{if(!(s=a(n,"return"))){if("throw"===e)throw t;return t}s=r(s,n)}catch(n){i=!0,s=n}if("throw"===e)throw t;if(i)throw s;return o(s),t}},function(n,e,t){var r=t(99),o="object"==typeof self&&self&&self.Object===Object&&self,a=r||o||Function("return this")();n.exports=a},function(n,e,t){"use strict";var r=t(13),o=t(8),a=t(10),s=t(4),i=t(28),l=t(90),c=t(91),p=t(24),d=t(14),u=t(92),m=t(29),g=!p&&!u("filter",(function(){})),f=!p&&!g&&m("filter",TypeError),h=p||g||f,v=l((function(){for(var n,e,t=this.iterator,r=this.predicate,a=this.next;;){if(n=s(o(a,t)),this.done=!!n.done)return;if(e=n.value,c(t,r,[e,this.counter++],!0))return e}}));r({target:"Iterator",proto:!0,real:!0,forced:h},{filter:function(n){s(this);try{a(n)}catch(n){d(this,"throw",n)}return f?o(f,this,n):new v(i(this),{predicate:n})}})},function(n,e,t){"use strict";var r=t(13),o=t(8),a=t(56),s=t(10),i=t(4),l=t(28),c=t(14),p=t(29)("forEach",TypeError);r({target:"Iterator",proto:!0,real:!0,forced:p},{forEach:function(n){i(this);try{s(n)}catch(n){c(this,"throw",n)}if(p)return o(p,this,n);var e=l(this),t=0;a(e,(function(e){n(e,t++)}),{IS_RECORD:!0})}})},function(n,e,t){"use strict";var r=t(0),o=t(77),a=t(11),s=t(78),i=t(74),l=t(73),c=r.Symbol,p=o("wks"),d=l?c.for||c:c&&c.withoutSetter||s;n.exports=function(n){return a(p,n)||(p[n]=i&&a(c,n)?c[n]:d("Symbol."+n)),p[n]}},function(n,e,t){"use strict";var r=t(6),o=t(79),a=t(81),s=t(4),i=t(71),l=TypeError,c=Object.defineProperty,p=Object.getOwnPropertyDescriptor;e.f=r?a?function(n,e,t){if(s(n),e=i(e),s(t),"function"==typeof n&&"prototype"===e&&"value"in t&&"writable"in t&&!t.writable){var r=p(n,e);r&&r.writable&&(n[e]=t.value,t={configurable:"configurable"in t?t.configurable:r.configurable,enumerable:"enumerable"in t?t.enumerable:r.enumerable,writable:!1})}return c(n,e,t)}:c:function(n,e,t){if(s(n),e=i(e),s(t),o)try{return c(n,e,t)}catch(n){}if("get"in t||"set"in t)throw new l("Accessors not supported");return"value"in t&&(n[e]=t.value),n}},function(n,e,t){var r=t(199),o=t(202);n.exports=function(n,e){var t=o(n,e);return r(t)?t:void 0}},function(n,e,t){"use strict";t.d(e,"e",(function(){return r})),t.d(e,"b",(function(){return a})),t.d(e,"j",(function(){return s})),t.d(e,"g",(function(){return l})),t.d(e,"h",(function(){return c})),t.d(e,"i",(function(){return p})),t.d(e,"c",(function(){return d})),t.d(e,"f",(function(){return u})),t.d(e,"l",(function(){return m})),t.d(e,"m",(function(){return g})),t.d(e,"d",(function(){return h})),t.d(e,"k",(function(){return v})),t.d(e,"n",(function(){return b})),t.d(e,"a",(function(){return y}));t(31),t(3),t(16),t(17),t(22);const r=/#.*$/,o=/\.(md|html)$/,a=/\/$/,s=/^[a-z]+:/i;function i(n){return decodeURI(n).replace(r,"").replace(o,"")}function l(n){return s.test(n)}function c(n){return/^mailto:/.test(n)}function p(n){return/^tel:/.test(n)}function d(n){if(l(n))return n;if(!n)return"404";const e=n.match(r),t=e?e[0]:"",o=i(n);return a.test(o)?n:o+".html"+t}function u(n,e){const t=n.hash,o=function(n){const e=n&&n.match(r);if(e)return e[0]}(e);if(o&&t!==o)return!1;return i(n.path)===i(e)}function m(n,e,t){if(l(e))return{type:"external",path:e};t&&(e=function(n,e,t){const r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;const o=e.split("/");t&&o[o.length-1]||o.pop();const a=n.replace(/^\//,"").split("/");for(let n=0;n<a.length;n++){const e=a[n];".."===e?o.pop():"."!==e&&o.push(e)}""!==o[0]&&o.unshift("");return o.join("/")}(e,t));const r=i(e);for(let e=0;e<n.length;e++)if(i(n[e].regularPath)===r)return Object.assign({},n[e],{type:"page",path:d(n[e].path)});return console.error(`[vuepress] No matching page found for sidebar item "${e}"`),{}}function g(n,e,t,r){const{pages:o,themeConfig:a}=t,s=r&&a.locales&&a.locales[r]||a;if("auto"===(n.frontmatter.sidebar||s.sidebar||a.sidebar))return f(n);const i=s.sidebar||a.sidebar;if(i){const{base:t,config:r}=function(n,e){if(Array.isArray(e))return{base:"/",config:e};for(const r in e)if(0===(t=n,/(\.html|\/)$/.test(t)?t:t+"/").indexOf(encodeURI(r)))return{base:r,config:e[r]};var t;return{}}(e,i);return"auto"===r?f(n):r?r.map(n=>function n(e,t,r,o=1){if("string"==typeof e)return m(t,e,r);if(Array.isArray(e))return Object.assign(m(t,e[0],r),{title:e[1]});{o>3&&console.error("[vuepress] detected a too deep nested sidebar group.");const a=e.children||[];return 0===a.length&&e.path?Object.assign(m(t,e.path,r),{title:e.title}):{type:"group",path:e.path,title:e.title,sidebarDepth:e.sidebarDepth,initialOpenGroupIndex:e.initialOpenGroupIndex,children:a.map(e=>n(e,t,r,o+1)),collapsable:!1!==e.collapsable}}}(n,o,t)):[]}return[]}function f(n){const e=h(n.headers||[]);return[{type:"group",collapsable:!1,title:n.title,path:null,children:e.map(e=>({type:"auto",title:e.title,basePath:n.path,path:n.path+"#"+e.slug,children:e.children||[]}))}]}function h(n){let e;return(n=n.map(n=>Object.assign({},n))).forEach(n=>{2===n.level?e=n:e&&(e.children||(e.children=[])).push(n)}),n.filter(n=>2===n.level)}function v(n){return Object.assign(n,{type:n.items&&n.items.length?"links":"link"})}function b(n){return Object.prototype.toString.call(n).match(/\[object (.*?)\]/)[1].toLowerCase()}function _(n){let e=n.frontmatter.date||n.lastUpdated||new Date,t=new Date(e);return"Invalid Date"==t&&e&&(t=new Date(e.replace(/-/g,"/"))),t.getTime()}function y(n,e){return _(e)-_(n)}},function(n,e,t){"use strict";var r=t(13),o=t(8),a=t(10),s=t(4),i=t(28),l=t(90),c=t(91),p=t(14),d=t(92),u=t(29),m=t(24),g=!m&&!d("map",(function(){})),f=!m&&!g&&u("map",TypeError),h=m||g||f,v=l((function(){var n=this.iterator,e=s(o(this.next,n));if(!(this.done=!!e.done))return c(n,this.mapper,[e.value,this.counter++],!0)}));r({target:"Iterator",proto:!0,real:!0,forced:h},{map:function(n){s(this);try{a(n)}catch(n){p(this,"throw",n)}return f?o(f,this,n):new v(i(this),{mapper:n})}})},function(n,e){n.exports=function(n){return null!=n&&"object"==typeof n}},function(n,e,t){"use strict";n.exports=!1},function(n,e,t){"use strict";var r=t(6),o=t(19),a=t(33);n.exports=r?function(n,e,t){return o.f(n,e,a(1,t))}:function(n,e,t){return n[e]=t,n}},function(n,e,t){var r=t(30),o=t(184),a=t(185),s=r?r.toStringTag:void 0;n.exports=function(n){return null==n?void 0===n?"[object Undefined]":"[object Null]":s&&s in Object(n)?o(n):a(n)}},function(n,e,t){"use strict";var r=t(7),o=r({}.toString),a=r("".slice);n.exports=function(n){return a(o(n),8,-1)}},function(n,e,t){"use strict";n.exports=function(n){return{iterator:n,next:n.next,done:!1}}},function(n,e,t){"use strict";var r=t(0);n.exports=function(n,e){var t=r.Iterator,o=t&&t.prototype,a=o&&o[n],s=!1;if(a)try{a.call({next:function(){return{done:!0}},return:function(){s=!0}},-1)}catch(n){n instanceof e||(s=!1)}if(!s)return a}},function(n,e,t){var r=t(15).Symbol;n.exports=r},function(n,e,t){"use strict";var r=t(13),o=t(38),a=t(39),s=t(178),i=t(180);r({target:"Array",proto:!0,arity:1,forced:t(1)((function(){return 4294967297!==[].push.call({length:4294967296},1)}))||!function(){try{Object.defineProperty([],"length",{writable:!1}).push()}catch(n){return n instanceof TypeError}}()},{push:function(n){var e=o(this),t=a(e),r=arguments.length;i(t+r);for(var l=0;l<r;l++)e[t]=arguments[l],t++;return s(e,t),t}})},function(n,e,t){"use strict";var r=t(1);n.exports=!r((function(){var n=function(){}.bind();return"function"!=typeof n||n.hasOwnProperty("prototype")}))},function(n,e,t){"use strict";n.exports=function(n,e){return{enumerable:!(1&n),configurable:!(2&n),writable:!(4&n),value:e}}},function(n,e,t){"use strict";var r=t(70),o=t(47);n.exports=function(n){return r(o(n))}},function(n,e,t){"use strict";var r=t(0),o=t(2),a=function(n){return o(n)?n:void 0};n.exports=function(n,e){return arguments.length<2?a(r[n]):r[n]&&r[n][e]}},function(n,e,t){"use strict";var r=t(7);n.exports=r({}.isPrototypeOf)},function(n,e,t){"use strict";var r=t(10),o=t(48);n.exports=function(n,e){var t=n[e];return o(t)?void 0:r(t)}},function(n,e,t){"use strict";var r=t(47),o=Object;n.exports=function(n){return o(r(n))}},function(n,e,t){"use strict";var r=t(141);n.exports=function(n){return r(n.length)}},function(n,e,t){var r=t(189),o=t(190),a=t(191),s=t(192),i=t(193);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=o,l.prototype.get=a,l.prototype.has=s,l.prototype.set=i,n.exports=l},function(n,e,t){var r=t(101);n.exports=function(n,e){for(var t=n.length;t--;)if(r(n[t][0],e))return t;return-1}},function(n,e,t){var r=t(20)(Object,"create");n.exports=r},function(n,e,t){var r=t(211);n.exports=function(n,e){var t=n.__data__;return r(e)?t["string"==typeof e?"string":"hash"]:t.map}},function(n,e,t){var r=t(64);n.exports=function(n){if("string"==typeof n||r(n))return n;var e=n+"";return"0"==e&&1/n==-1/0?"-0":e}},function(n,e,t){var r,o;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(o="function"==typeof(r=function(){var n,e,t={version:"0.2.0"},r=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function o(n,e,t){return n<e?e:n>t?t:n}function a(n){return 100*(-1+n)}t.configure=function(n){var e,t;for(e in n)void 0!==(t=n[e])&&n.hasOwnProperty(e)&&(r[e]=t);return this},t.status=null,t.set=function(n){var e=t.isStarted();n=o(n,r.minimum,1),t.status=1===n?null:n;var l=t.render(!e),c=l.querySelector(r.barSelector),p=r.speed,d=r.easing;return l.offsetWidth,s((function(e){""===r.positionUsing&&(r.positionUsing=t.getPositioningCSS()),i(c,function(n,e,t){var o;return(o="translate3d"===r.positionUsing?{transform:"translate3d("+a(n)+"%,0,0)"}:"translate"===r.positionUsing?{transform:"translate("+a(n)+"%,0)"}:{"margin-left":a(n)+"%"}).transition="all "+e+"ms "+t,o}(n,p,d)),1===n?(i(l,{transition:"none",opacity:1}),l.offsetWidth,setTimeout((function(){i(l,{transition:"all "+p+"ms linear",opacity:0}),setTimeout((function(){t.remove(),e()}),p)}),p)):setTimeout(e,p)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var n=function(){setTimeout((function(){t.status&&(t.trickle(),n())}),r.trickleSpeed)};return r.trickle&&n(),this},t.done=function(n){return n||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(n){var e=t.status;return e?("number"!=typeof n&&(n=(1-e)*o(Math.random()*e,.1,.95)),e=o(e+n,0,.994),t.set(e)):t.start()},t.trickle=function(){return t.inc(Math.random()*r.trickleRate)},n=0,e=0,t.promise=function(r){return r&&"resolved"!==r.state()?(0===e&&t.start(),n++,e++,r.always((function(){0==--e?(n=0,t.done()):t.set((n-e)/n)})),this):this},t.render=function(n){if(t.isRendered())return document.getElementById("nprogress");c(document.documentElement,"nprogress-busy");var e=document.createElement("div");e.id="nprogress",e.innerHTML=r.template;var o,s=e.querySelector(r.barSelector),l=n?"-100":a(t.status||0),p=document.querySelector(r.parent);return i(s,{transition:"all 0 linear",transform:"translate3d("+l+"%,0,0)"}),r.showSpinner||(o=e.querySelector(r.spinnerSelector))&&u(o),p!=document.body&&c(p,"nprogress-custom-parent"),p.appendChild(e),e},t.remove=function(){p(document.documentElement,"nprogress-busy"),p(document.querySelector(r.parent),"nprogress-custom-parent");var n=document.getElementById("nprogress");n&&u(n)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var n=document.body.style,e="WebkitTransform"in n?"Webkit":"MozTransform"in n?"Moz":"msTransform"in n?"ms":"OTransform"in n?"O":"";return e+"Perspective"in n?"translate3d":e+"Transform"in n?"translate":"margin"};var s=function(){var n=[];function e(){var t=n.shift();t&&t(e)}return function(t){n.push(t),1==n.length&&e()}}(),i=function(){var n=["Webkit","O","Moz","ms"],e={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(n,e){return e.toUpperCase()})),e[t]||(e[t]=function(e){var t=document.body.style;if(e in t)return e;for(var r,o=n.length,a=e.charAt(0).toUpperCase()+e.slice(1);o--;)if((r=n[o]+a)in t)return r;return e}(t))}function r(n,e,r){e=t(e),n.style[e]=r}return function(n,e){var t,o,a=arguments;if(2==a.length)for(t in e)void 0!==(o=e[t])&&e.hasOwnProperty(t)&&r(n,t,o);else r(n,a[1],a[2])}}();function l(n,e){return("string"==typeof n?n:d(n)).indexOf(" "+e+" ")>=0}function c(n,e){var t=d(n),r=t+e;l(t,e)||(n.className=r.substring(1))}function p(n,e){var t,r=d(n);l(n,e)&&(t=r.replace(" "+e+" "," "),n.className=t.substring(1,t.length-1))}function d(n){return(" "+(n.className||"")+" ").replace(/\s+/gi," ")}function u(n){n&&n.parentNode&&n.parentNode.removeChild(n)}return t})?r.call(e,t,e,n):r)||(n.exports=o)},function(n){n.exports=JSON.parse('{"_from":"vuepress-plugin-comment-plus@^1.1.0","_id":"vuepress-plugin-comment-plus@1.1.0","_inBundle":false,"_integrity":"sha512-pYlsRuF3PA9KSfUrZ2NukDM2K8y8sNsTozKbOj+xuNKxshKrodo3//LdBhjNyerfJVg5+okq+qoC3/nDH4aHpg==","_location":"/vuepress-plugin-comment-plus","_phantomChildren":{},"_requested":{"type":"range","registry":true,"raw":"vuepress-plugin-comment-plus@^1.1.0","name":"vuepress-plugin-comment-plus","escapedName":"vuepress-plugin-comment-plus","rawSpec":"^1.1.0","saveSpec":null,"fetchSpec":"^1.1.0"},"_requiredBy":["#DEV:/"],"_resolved":"https://registry.npmjs.org/vuepress-plugin-comment-plus/-/vuepress-plugin-comment-plus-1.1.0.tgz","_shasum":"bf44d81db4ffe12c3b72a9d999c2d9b7117c746a","_spec":"vuepress-plugin-comment-plus@^1.1.0","_where":"/home/runner/work/tenqaz.github.io/tenqaz.github.io","author":{"name":"dongyuanxin"},"bugs":{"url":"https://github.com/SivanLaai/vuepress-plugin-comment-plus/issues"},"bundleDependencies":false,"dependencies":{"@waline/client":"^1.3.3","ejs":"^2.6.1","gitalk":"^1.5.0","gitalk-fix":"^1.5.2","i":"^0.3.6","npm":"^6.9.0","valine":"^1.3.9"},"deprecated":false,"description":"Comment plugin in vuepress, such as Gitalk, Valine...","homepage":"https://github.com/SivanLaai/vuepress-plugin-comment-plus#readme","keywords":["vuepress","comment","plugin","vue","gitalk","valine","waline"],"license":"MIT","main":"index.js","name":"vuepress-plugin-comment-plus","repository":{"type":"git","url":"git+ssh://git@github.com/SivanLaai/vuepress-plugin-comment-plus.git"},"scripts":{"test":"echo \\"Error: no test specified\\" && exit 1"},"version":"1.1.0"}')},function(n,e,t){"use strict";var r=t(48),o=TypeError;n.exports=function(n){if(r(n))throw new o("Can't call method on "+n);return n}},function(n,e,t){"use strict";n.exports=function(n){return null==n}},function(n,e,t){"use strict";var r=String;n.exports=function(n){try{return r(n)}catch(n){return"Object"}}},function(n,e,t){"use strict";var r=t(24),o=t(0),a=t(51),s=n.exports=o["__core-js_shared__"]||a("__core-js_shared__",{});(s.versions||(s.versions=[])).push({version:"3.45.1",mode:r?"pure":"global",copyright:"© 2014-2025 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.45.1/LICENSE",source:"https://github.com/zloirock/core-js"})},function(n,e,t){"use strict";var r=t(0),o=Object.defineProperty;n.exports=function(n,e){try{o(r,n,{value:e,configurable:!0,writable:!0})}catch(t){r[n]=e}return e}},function(n,e,t){"use strict";var r=t(2),o=t(19),a=t(82),s=t(51);n.exports=function(n,e,t,i){i||(i={});var l=i.enumerable,c=void 0!==i.name?i.name:e;if(r(t)&&a(t,c,i),i.global)l?n[e]=t:s(e,t);else{try{i.unsafe?n[e]&&(l=!0):delete n[e]}catch(n){}l?n[e]=t:o.f(n,e,{value:t,enumerable:!1,configurable:!i.nonConfigurable,writable:!i.nonWritable})}return n}},function(n,e,t){"use strict";var r=t(77),o=t(78),a=r("keys");n.exports=function(n){return a[n]||(a[n]=o(n))}},function(n,e,t){"use strict";n.exports={}},function(n,e,t){"use strict";n.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(n,e,t){"use strict";var r=t(159),o=t(8),a=t(4),s=t(49),i=t(161),l=t(39),c=t(36),p=t(162),d=t(94),u=t(14),m=TypeError,g=function(n,e){this.stopped=n,this.result=e},f=g.prototype;n.exports=function(n,e,t){var h,v,b,_,y,k,w,E=t&&t.that,x=!(!t||!t.AS_ENTRIES),A=!(!t||!t.IS_RECORD),B=!(!t||!t.IS_ITERATOR),z=!(!t||!t.INTERRUPTED),j=r(e,E),T=function(n){return h&&u(h,"normal"),new g(!0,n)},C=function(n){return x?(a(n),z?j(n[0],n[1],T):j(n[0],n[1])):z?j(n,T):j(n)};if(A)h=n.iterator;else if(B)h=n;else{if(!(v=d(n)))throw new m(s(n)+" is not iterable");if(i(v)){for(b=0,_=l(n);_>b;b++)if((y=C(n[b]))&&c(f,y))return y;return new g(!1)}h=p(n,v)}for(k=A?n.next:h.next;!(w=o(k,h)).done;){try{y=C(w.value)}catch(n){u(h,"throw",n)}if("object"==typeof y&&y&&c(f,y))return y}return new g(!1)}},function(n,e,t){var r=t(183),o=t(23),a=Object.prototype,s=a.hasOwnProperty,i=a.propertyIsEnumerable,l=r(function(){return arguments}())?r:function(n){return o(n)&&s.call(n,"callee")&&!i.call(n,"callee")};n.exports=l},function(n,e,t){var r=t(20)(t(15),"Map");n.exports=r},function(n,e){n.exports=function(n){var e=typeof n;return null!=n&&("object"==e||"function"==e)}},function(n,e,t){var r=t(203),o=t(210),a=t(212),s=t(213),i=t(214);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=o,l.prototype.get=a,l.prototype.has=s,l.prototype.set=i,n.exports=l},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n){t[++e]=n})),t}},function(n,e){n.exports=function(n){return"number"==typeof n&&n>-1&&n%1==0&&n<=9007199254740991}},function(n,e,t){var r=t(12),o=t(64),a=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,s=/^\w*$/;n.exports=function(n,e){if(r(n))return!1;var t=typeof n;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=n&&!o(n))||(s.test(n)||!a.test(n)||null!=e&&n in Object(e))}},function(n,e,t){var r=t(26),o=t(23);n.exports=function(n){return"symbol"==typeof n||o(n)&&"[object Symbol]"==r(n)}},function(n,e){n.exports=function(n){return n}},function(n,e,t){"use strict";var r=t(13),o=t(8),a=t(56),s=t(10),i=t(4),l=t(28),c=t(14),p=t(29)("some",TypeError);r({target:"Iterator",proto:!0,real:!0,forced:p},{some:function(n){i(this);try{s(n)}catch(n){c(this,"throw",n)}if(p)return o(p,this,n);var e=l(this),t=0;return a(e,(function(e,r){if(n(e,t++))return r()}),{IS_RECORD:!0,INTERRUPTED:!0}).stopped}})},function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},function(n,e){var t=/^\s+|\s+$/g,r=/^[-+]0x[0-9a-f]+$/i,o=/^0b[01]+$/i,a=/^0o[0-7]+$/i,s=parseInt,i="object"==typeof global&&global&&global.Object===Object&&global,l="object"==typeof self&&self&&self.Object===Object&&self,c=i||l||Function("return this")(),p=Object.prototype.toString,d=Math.max,u=Math.min,m=function(){return c.Date.now()};function g(n){var e=typeof n;return!!n&&("object"==e||"function"==e)}function f(n){if("number"==typeof n)return n;if(function(n){return"symbol"==typeof n||function(n){return!!n&&"object"==typeof n}(n)&&"[object Symbol]"==p.call(n)}(n))return NaN;if(g(n)){var e="function"==typeof n.valueOf?n.valueOf():n;n=g(e)?e+"":e}if("string"!=typeof n)return 0===n?n:+n;n=n.replace(t,"");var i=o.test(n);return i||a.test(n)?s(n.slice(2),i?2:8):r.test(n)?NaN:+n}n.exports=function(n,e,t){var r,o,a,s,i,l,c=0,p=!1,h=!1,v=!0;if("function"!=typeof n)throw new TypeError("Expected a function");function b(e){var t=r,a=o;return r=o=void 0,c=e,s=n.apply(a,t)}function _(n){return c=n,i=setTimeout(k,e),p?b(n):s}function y(n){var t=n-l;return void 0===l||t>=e||t<0||h&&n-c>=a}function k(){var n=m();if(y(n))return w(n);i=setTimeout(k,function(n){var t=e-(n-l);return h?u(t,a-(n-c)):t}(n))}function w(n){return i=void 0,v&&r?b(n):(r=o=void 0,s)}function E(){var n=m(),t=y(n);if(r=arguments,o=this,l=n,t){if(void 0===i)return _(l);if(h)return i=setTimeout(k,e),b(l)}return void 0===i&&(i=setTimeout(k,e)),s}return e=f(e)||0,g(t)&&(p=!!t.leading,a=(h="maxWait"in t)?d(f(t.maxWait)||0,e):a,v="trailing"in t?!!t.trailing:v),E.cancel=function(){void 0!==i&&clearTimeout(i),c=0,r=l=o=i=void 0},E.flush=function(){return void 0===i?s:w(m())},E}},function(n,e,t){"use strict";var r=t(6),o=t(8),a=t(130),s=t(33),i=t(34),l=t(71),c=t(11),p=t(79),d=Object.getOwnPropertyDescriptor;e.f=r?d:function(n,e){if(n=i(n),e=l(e),p)try{return d(n,e)}catch(n){}if(c(n,e))return s(!o(a.f,n,e),n[e])}},function(n,e,t){"use strict";var r=t(7),o=t(1),a=t(27),s=Object,i=r("".split);n.exports=o((function(){return!s("z").propertyIsEnumerable(0)}))?function(n){return"String"===a(n)?i(n,""):s(n)}:s},function(n,e,t){"use strict";var r=t(131),o=t(72);n.exports=function(n){var e=r(n,"string");return o(e)?e:e+""}},function(n,e,t){"use strict";var r=t(35),o=t(2),a=t(36),s=t(73),i=Object;n.exports=s?function(n){return"symbol"==typeof n}:function(n){var e=r("Symbol");return o(e)&&a(e.prototype,i(n))}},function(n,e,t){"use strict";var r=t(74);n.exports=r&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(n,e,t){"use strict";var r=t(75),o=t(1),a=t(0).String;n.exports=!!Object.getOwnPropertySymbols&&!o((function(){var n=Symbol("symbol detection");return!a(n)||!(Object(n)instanceof Symbol)||!Symbol.sham&&r&&r<41}))},function(n,e,t){"use strict";var r,o,a=t(0),s=t(76),i=a.process,l=a.Deno,c=i&&i.versions||l&&l.version,p=c&&c.v8;p&&(o=(r=p.split("."))[0]>0&&r[0]<4?1:+(r[0]+r[1])),!o&&s&&(!(r=s.match(/Edge\/(\d+)/))||r[1]>=74)&&(r=s.match(/Chrome\/(\d+)/))&&(o=+r[1]),n.exports=o},function(n,e,t){"use strict";var r=t(0).navigator,o=r&&r.userAgent;n.exports=o?String(o):""},function(n,e,t){"use strict";var r=t(50);n.exports=function(n,e){return r[n]||(r[n]=e||{})}},function(n,e,t){"use strict";var r=t(7),o=0,a=Math.random(),s=r(1.1.toString);n.exports=function(n){return"Symbol("+(void 0===n?"":n)+")_"+s(++o+a,36)}},function(n,e,t){"use strict";var r=t(6),o=t(1),a=t(80);n.exports=!r&&!o((function(){return 7!==Object.defineProperty(a("div"),"a",{get:function(){return 7}}).a}))},function(n,e,t){"use strict";var r=t(0),o=t(9),a=r.document,s=o(a)&&o(a.createElement);n.exports=function(n){return s?a.createElement(n):{}}},function(n,e,t){"use strict";var r=t(6),o=t(1);n.exports=r&&o((function(){return 42!==Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(n,e,t){"use strict";var r=t(7),o=t(1),a=t(2),s=t(11),i=t(6),l=t(133).CONFIGURABLE,c=t(134),p=t(83),d=p.enforce,u=p.get,m=String,g=Object.defineProperty,f=r("".slice),h=r("".replace),v=r([].join),b=i&&!o((function(){return 8!==g((function(){}),"length",{value:8}).length})),_=String(String).split("String"),y=n.exports=function(n,e,t){"Symbol("===f(m(e),0,7)&&(e="["+h(m(e),/^Symbol\(([^)]*)\).*$/,"$1")+"]"),t&&t.getter&&(e="get "+e),t&&t.setter&&(e="set "+e),(!s(n,"name")||l&&n.name!==e)&&(i?g(n,"name",{value:e,configurable:!0}):n.name=e),b&&t&&s(t,"arity")&&n.length!==t.arity&&g(n,"length",{value:t.arity});try{t&&s(t,"constructor")&&t.constructor?i&&g(n,"prototype",{writable:!1}):n.prototype&&(n.prototype=void 0)}catch(n){}var r=d(n);return s(r,"source")||(r.source=v(_,"string"==typeof e?e:"")),n};Function.prototype.toString=y((function(){return a(this)&&u(this).source||c(this)}),"toString")},function(n,e,t){"use strict";var r,o,a,s=t(135),i=t(0),l=t(9),c=t(25),p=t(11),d=t(50),u=t(53),m=t(54),g=i.TypeError,f=i.WeakMap;if(s||d.state){var h=d.state||(d.state=new f);h.get=h.get,h.has=h.has,h.set=h.set,r=function(n,e){if(h.has(n))throw new g("Object already initialized");return e.facade=n,h.set(n,e),e},o=function(n){return h.get(n)||{}},a=function(n){return h.has(n)}}else{var v=u("state");m[v]=!0,r=function(n,e){if(p(n,v))throw new g("Object already initialized");return e.facade=n,c(n,v,e),e},o=function(n){return p(n,v)?n[v]:{}},a=function(n){return p(n,v)}}n.exports={set:r,get:o,has:a,enforce:function(n){return a(n)?o(n):r(n,{})},getterFor:function(n){return function(e){var t;if(!l(e)||(t=o(e)).type!==n)throw new g("Incompatible receiver, "+n+" required");return t}}}},function(n,e,t){"use strict";var r=t(11),o=t(136),a=t(69),s=t(19);n.exports=function(n,e,t){for(var i=o(e),l=s.f,c=a.f,p=0;p<i.length;p++){var d=i[p];r(n,d)||t&&r(t,d)||l(n,d,c(e,d))}}},function(n,e,t){"use strict";var r=t(7),o=t(11),a=t(34),s=t(138).indexOf,i=t(54),l=r([].push);n.exports=function(n,e){var t,r=a(n),c=0,p=[];for(t in r)!o(i,t)&&o(r,t)&&l(p,t);for(;e.length>c;)o(r,t=e[c++])&&(~s(p,t)||l(p,t));return p}},function(n,e,t){"use strict";var r=t(140);n.exports=function(n){var e=+n;return e!=e||0===e?0:r(e)}},function(n,e,t){"use strict";var r=t(11),o=t(2),a=t(38),s=t(53),i=t(145),l=s("IE_PROTO"),c=Object,p=c.prototype;n.exports=i?c.getPrototypeOf:function(n){var e=a(n);if(r(e,l))return e[l];var t=e.constructor;return o(t)&&e instanceof t?t.prototype:e instanceof c?p:null}},function(n,e,t){"use strict";var r,o,a,s=t(1),i=t(2),l=t(9),c=t(89),p=t(87),d=t(52),u=t(18),m=t(24),g=u("iterator"),f=!1;[].keys&&("next"in(a=[].keys())?(o=p(p(a)))!==Object.prototype&&(r=o):f=!0),!l(r)||s((function(){var n={};return r[g].call(n)!==n}))?r={}:m&&(r=c(r)),i(r[g])||d(r,g,(function(){return this})),n.exports={IteratorPrototype:r,BUGGY_SAFARI_ITERATORS:f}},function(n,e,t){"use strict";var r,o=t(4),a=t(148),s=t(55),i=t(54),l=t(150),c=t(80),p=t(53),d=p("IE_PROTO"),u=function(){},m=function(n){return"<script>"+n+"<\/script>"},g=function(n){n.write(m("")),n.close();var e=n.parentWindow.Object;return n=null,e},f=function(){try{r=new ActiveXObject("htmlfile")}catch(n){}var n,e;f="undefined"!=typeof document?document.domain&&r?g(r):((e=c("iframe")).style.display="none",l.appendChild(e),e.src=String("javascript:"),(n=e.contentWindow.document).open(),n.write(m("document.F=Object")),n.close(),n.F):g(r);for(var t=s.length;t--;)delete f.prototype[s[t]];return f()};i[d]=!0,n.exports=Object.create||function(n,e){var t;return null!==n?(u.prototype=o(n),t=new u,u.prototype=null,t[d]=n):t=f(),void 0===e?t:a.f(t,e)}},function(n,e,t){"use strict";var r=t(8),o=t(89),a=t(25),s=t(151),i=t(18),l=t(83),c=t(37),p=t(88).IteratorPrototype,d=t(152),u=t(14),m=t(153),g=i("toStringTag"),f=l.set,h=function(n){var e=l.getterFor(n?"WrapForValidIterator":"IteratorHelper");return s(o(p),{next:function(){var t=e(this);if(n)return t.nextHandler();if(t.done)return d(void 0,!0);try{var r=t.nextHandler();return t.returnHandlerResult?r:d(r,t.done)}catch(n){throw t.done=!0,n}},return:function(){var t=e(this),o=t.iterator;if(t.done=!0,n){var a=c(o,"return");return a?r(a,o):d(void 0,!0)}if(t.inner)try{u(t.inner.iterator,"normal")}catch(n){return u(o,"throw",n)}if(t.openIters)try{m(t.openIters,"normal")}catch(n){return u(o,"throw",n)}return o&&u(o,"normal"),d(void 0,!0)}})},v=h(!0),b=h(!1);a(b,g,"Iterator Helper"),n.exports=function(n,e,t){var r=function(r,o){o?(o.iterator=r.iterator,o.next=r.next):o=r,o.type=e?"WrapForValidIterator":"IteratorHelper",o.returnHandlerResult=!!t,o.nextHandler=n,o.counter=0,o.done=!1,f(this,o)};return r.prototype=e?v:b,r}},function(n,e,t){"use strict";var r=t(4),o=t(14);n.exports=function(n,e,t,a){try{return a?e(r(t)[0],t[1]):e(t)}catch(e){o(n,"throw",e)}}},function(n,e,t){"use strict";n.exports=function(n,e){var t="function"==typeof Iterator&&Iterator.prototype[n];if(t)try{t.call({next:null},e).next()}catch(n){return!0}}},function(n,e,t){"use strict";n.exports={}},function(n,e,t){"use strict";var r=t(95),o=t(37),a=t(48),s=t(93),i=t(18)("iterator");n.exports=function(n){if(!a(n))return o(n,i)||o(n,"@@iterator")||s[r(n)]}},function(n,e,t){"use strict";var r=t(163),o=t(2),a=t(27),s=t(18)("toStringTag"),i=Object,l="Arguments"===a(function(){return arguments}());n.exports=r?a:function(n){var e,t,r;return void 0===n?"Undefined":null===n?"Null":"string"==typeof(t=function(n,e){try{return n[e]}catch(n){}}(e=i(n),s))?t:l?a(e):"Object"===(r=a(e))&&o(e.callee)?"Arguments":r}},function(n,e,t){"use strict";var r=t(32),o=Function.prototype,a=o.apply,s=o.call;n.exports="object"==typeof Reflect&&Reflect.apply||(r?s.bind(a):function(){return s.apply(a,arguments)})},function(n,e,t){"use strict";var r=t(167),o=t(9),a=t(47),s=t(168);n.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var n,e=!1,t={};try{(n=r(Object.prototype,"__proto__","set"))(t,[]),e=t instanceof Array}catch(n){}return function(t,r){return a(t),s(r),o(t)?(e?n(t,r):t.__proto__=r,t):t}}():void 0)},function(n,e){n.exports=function(n,e){for(var t=-1,r=e.length,o=n.length;++t<r;)n[o+t]=e[t];return n}},function(n,e){var t="object"==typeof global&&global&&global.Object===Object&&global;n.exports=t},function(n,e,t){var r=t(40),o=t(194),a=t(195),s=t(196),i=t(197),l=t(198);function c(n){var e=this.__data__=new r(n);this.size=e.size}c.prototype.clear=o,c.prototype.delete=a,c.prototype.get=s,c.prototype.has=i,c.prototype.set=l,n.exports=c},function(n,e){n.exports=function(n,e){return n===e||n!=n&&e!=e}},function(n,e,t){var r=t(26),o=t(59);n.exports=function(n){if(!o(n))return!1;var e=r(n);return"[object Function]"==e||"[object GeneratorFunction]"==e||"[object AsyncFunction]"==e||"[object Proxy]"==e}},function(n,e){var t=Function.prototype.toString;n.exports=function(n){if(null!=n){try{return t.call(n)}catch(n){}try{return n+""}catch(n){}}return""}},function(n,e,t){var r=t(215),o=t(23);n.exports=function n(e,t,a,s,i){return e===t||(null==e||null==t||!o(e)&&!o(t)?e!=e&&t!=t:r(e,t,a,s,n,i))}},function(n,e,t){var r=t(106),o=t(218),a=t(107);n.exports=function(n,e,t,s,i,l){var c=1&t,p=n.length,d=e.length;if(p!=d&&!(c&&d>p))return!1;var u=l.get(n),m=l.get(e);if(u&&m)return u==e&&m==n;var g=-1,f=!0,h=2&t?new r:void 0;for(l.set(n,e),l.set(e,n);++g<p;){var v=n[g],b=e[g];if(s)var _=c?s(b,v,g,e,n,l):s(v,b,g,n,e,l);if(void 0!==_){if(_)continue;f=!1;break}if(h){if(!o(e,(function(n,e){if(!a(h,e)&&(v===n||i(v,n,t,s,l)))return h.push(e)}))){f=!1;break}}else if(v!==b&&!i(v,b,t,s,l)){f=!1;break}}return l.delete(n),l.delete(e),f}},function(n,e,t){var r=t(60),o=t(216),a=t(217);function s(n){var e=-1,t=null==n?0:n.length;for(this.__data__=new r;++e<t;)this.add(n[e])}s.prototype.add=s.prototype.push=o,s.prototype.has=a,n.exports=s},function(n,e){n.exports=function(n,e){return n.has(e)}},function(n,e,t){var r=t(228),o=t(234),a=t(112);n.exports=function(n){return a(n)?r(n):o(n)}},function(n,e,t){(function(n){var r=t(15),o=t(230),a=e&&!e.nodeType&&e,s=a&&"object"==typeof n&&n&&!n.nodeType&&n,i=s&&s.exports===a?r.Buffer:void 0,l=(i?i.isBuffer:void 0)||o;n.exports=l}).call(this,t(67)(n))},function(n,e){var t=/^(?:0|[1-9]\d*)$/;n.exports=function(n,e){var r=typeof n;return!!(e=null==e?9007199254740991:e)&&("number"==r||"symbol"!=r&&t.test(n))&&n>-1&&n%1==0&&n<e}},function(n,e,t){var r=t(231),o=t(232),a=t(233),s=a&&a.isTypedArray,i=s?o(s):r;n.exports=i},function(n,e,t){var r=t(102),o=t(62);n.exports=function(n){return null!=n&&o(n.length)&&!r(n)}},function(n,e,t){var r=t(20)(t(15),"Set");n.exports=r},function(n,e,t){var r=t(59);n.exports=function(n){return n==n&&!r(n)}},function(n,e){n.exports=function(n,e){return function(t){return null!=t&&(t[n]===e&&(void 0!==e||n in Object(t)))}}},function(n,e,t){var r=t(117),o=t(44);n.exports=function(n,e){for(var t=0,a=(e=r(e,n)).length;null!=n&&t<a;)n=n[o(e[t++])];return t&&t==a?n:void 0}},function(n,e,t){var r=t(12),o=t(63),a=t(245),s=t(248);n.exports=function(n,e){return r(n)?n:o(n,e)?[n]:a(s(n))}},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(181),o=t(186),a=t(257),s=t(265),i=t(274),l=t(128),c=a((function(n){var e=l(n);return i(e)&&(e=void 0),s(r(n,1,i,!0),o(e,2))}));n.exports=c},function(n,e,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var r=/["'&<>]/;n.exports=function(n){var e,t=""+n,o=r.exec(t);if(!o)return t;var a="",s=0,i=0;for(s=o.index;s<t.length;s++){switch(t.charCodeAt(s)){case 34:e="&quot;";break;case 38:e="&amp;";break;case 39:e="&#39;";break;case 60:e="&lt;";break;case 62:e="&gt;";break;default:continue}i!==s&&(a+=t.substring(i,s)),i=s+1,a+=e}return i!==s?a+t.substring(i,s):a}},function(n,e,t){"use strict";
/**
 * @file Embedded JavaScript templating engine. {@link http://ejs.co}
 * @author Matthew Eernisse <mde@fleegix.org>
 * @author Tiancheng "Timothy" Gu <timothygu99@gmail.com>
 * @project EJS
 * @license {@link http://www.apache.org/licenses/LICENSE-2.0 Apache License, Version 2.0}
 */var r=t(281),o=t(282),a=t(283),s=!1,i=t(284).version,l=["delimiter","scope","context","debug","compileDebug","client","_with","rmWhitespace","strict","filename","async"],c=l.concat("cache"),p=/^\uFEFF/,d=/^[a-zA-Z_$][0-9a-zA-Z_$]*$/;function u(n,t){var o;if(t.some((function(t){return o=e.resolveInclude(n,t,!0),r.existsSync(o)})))return o}function m(n,t){var r,o=n.filename,a=arguments.length>1;if(n.cache){if(!o)throw new Error("cache option requires a filename");if(r=e.cache.get(o))return r;a||(t=f(o).toString().replace(p,""))}else if(!a){if(!o)throw new Error("Internal EJS error: no file name or template provided");t=f(o).toString().replace(p,"")}return r=e.compile(t,n),n.cache&&e.cache.set(o,r),r}function g(n,t,r){var o;if(!r){if("function"==typeof e.promiseImpl)return new e.promiseImpl((function(e,r){try{e(o=m(n)(t))}catch(n){r(n)}}));throw new Error("Please provide a callback function")}try{o=m(n)(t)}catch(n){return r(n)}r(null,o)}function f(n){return e.fileLoader(n)}function h(n,t){var o=a.shallowCopy(a.createNullProtoObjWherePossible(),t);if(o.filename=function(n,t){var o,a,s=t.views,i=/^[A-Za-z]+:\\|^\//.exec(n);if(i&&i.length)n=n.replace(/^\/*/,""),o=Array.isArray(t.root)?u(n,t.root):e.resolveInclude(n,t.root||"/",!0);else if(t.filename&&(a=e.resolveInclude(n,t.filename),r.existsSync(a)&&(o=a)),!o&&Array.isArray(s)&&(o=u(n,s)),!o&&"function"!=typeof t.includer)throw new Error('Could not find the include file "'+t.escapeFunction(n)+'"');return o}(n,o),"function"==typeof t.includer){var s=t.includer(n,o.filename);if(s&&(s.filename&&(o.filename=s.filename),s.template))return m(o,s.template)}return m(o)}function v(n,e,t,r,o){var a=e.split("\n"),s=Math.max(r-3,0),i=Math.min(a.length,r+3),l=o(t),c=a.slice(s,i).map((function(n,e){var t=e+s+1;return(t==r?" >> ":"    ")+t+"| "+n})).join("\n");throw n.path=l,n.message=(l||"ejs")+":"+r+"\n"+c+"\n\n"+n.message,n}function b(n){return n.replace(/;(\s*$)/,"$1")}function _(n,t){var r=a.hasOwnOnlyObject(t),o=a.createNullProtoObjWherePossible();this.templateText=n,this.mode=null,this.truncate=!1,this.currentLine=1,this.source="",o.client=r.client||!1,o.escapeFunction=r.escape||r.escapeFunction||a.escapeXML,o.compileDebug=!1!==r.compileDebug,o.debug=!!r.debug,o.filename=r.filename,o.openDelimiter=r.openDelimiter||e.openDelimiter||"<",o.closeDelimiter=r.closeDelimiter||e.closeDelimiter||">",o.delimiter=r.delimiter||e.delimiter||"%",o.strict=r.strict||!1,o.context=r.context,o.cache=r.cache||!1,o.rmWhitespace=r.rmWhitespace,o.root=r.root,o.includer=r.includer,o.outputFunctionName=r.outputFunctionName,o.localsName=r.localsName||e.localsName||"locals",o.views=r.views,o.async=r.async,o.destructuredLocals=r.destructuredLocals,o.legacyInclude=void 0===r.legacyInclude||!!r.legacyInclude,o.strict?o._with=!1:o._with=void 0===r._with||r._with,this.opts=o,this.regex=this.createRegex()}e.cache=a.cache,e.fileLoader=r.readFileSync,e.localsName="locals",e.promiseImpl=new Function("return this;")().Promise,e.resolveInclude=function(n,e,t){var r=o.dirname,a=o.extname,s=(0,o.resolve)(t?e:r(e),n);return a(n)||(s+=".ejs"),s},e.compile=function(n,e){return e&&e.scope&&(s||(console.warn("`scope` option is deprecated and will be removed in EJS 3"),s=!0),e.context||(e.context=e.scope),delete e.scope),new _(n,e).compile()},e.render=function(n,e,t){var r=e||a.createNullProtoObjWherePossible(),o=t||a.createNullProtoObjWherePossible();return 2==arguments.length&&a.shallowCopyFromList(o,r,l),m(o,n)(r)},e.renderFile=function(){var n,e,t,r=Array.prototype.slice.call(arguments),o=r.shift(),s={filename:o};return"function"==typeof arguments[arguments.length-1]&&(n=r.pop()),r.length?(e=r.shift(),r.length?a.shallowCopy(s,r.pop()):(e.settings&&(e.settings.views&&(s.views=e.settings.views),e.settings["view cache"]&&(s.cache=!0),(t=e.settings["view options"])&&a.shallowCopy(s,t)),a.shallowCopyFromList(s,e,c)),s.filename=o):e=a.createNullProtoObjWherePossible(),g(s,e,n)},e.Template=_,e.clearCache=function(){e.cache.reset()},_.modes={EVAL:"eval",ESCAPED:"escaped",RAW:"raw",COMMENT:"comment",LITERAL:"literal"},_.prototype={createRegex:function(){var n="(<%%|%%>|<%=|<%-|<%_|<%#|<%|%>|-%>|_%>)",e=a.escapeRegExpChars(this.opts.delimiter),t=a.escapeRegExpChars(this.opts.openDelimiter),r=a.escapeRegExpChars(this.opts.closeDelimiter);return n=n.replace(/%/g,e).replace(/</g,t).replace(/>/g,r),new RegExp(n)},compile:function(){var n,e,t,r=this.opts,s="",i="",l=r.escapeFunction,c=r.filename?JSON.stringify(r.filename):"undefined";if(!this.source){if(this.generateSource(),s+='  var __output = "";\n  function __append(s) { if (s !== undefined && s !== null) __output += s }\n',r.outputFunctionName){if(!d.test(r.outputFunctionName))throw new Error("outputFunctionName is not a valid JS identifier.");s+="  var "+r.outputFunctionName+" = __append;\n"}if(r.localsName&&!d.test(r.localsName))throw new Error("localsName is not a valid JS identifier.");if(r.destructuredLocals&&r.destructuredLocals.length){for(var p="  var __locals = ("+r.localsName+" || {}),\n",u=0;u<r.destructuredLocals.length;u++){var m=r.destructuredLocals[u];if(!d.test(m))throw new Error("destructuredLocals["+u+"] is not a valid JS identifier.");u>0&&(p+=",\n  "),p+=m+" = __locals."+m}s+=p+";\n"}!1!==r._with&&(s+="  with ("+r.localsName+" || {}) {\n",i+="  }\n"),i+="  return __output;\n",this.source=s+this.source+i}n=r.compileDebug?"var __line = 1\n  , __lines = "+JSON.stringify(this.templateText)+"\n  , __filename = "+c+";\ntry {\n"+this.source+"} catch (e) {\n  rethrow(e, __lines, __filename, __line, escapeFn);\n}\n":this.source,r.client&&(n="escapeFn = escapeFn || "+l.toString()+";\n"+n,r.compileDebug&&(n="rethrow = rethrow || "+v.toString()+";\n"+n)),r.strict&&(n='"use strict";\n'+n),r.debug&&console.log(n),r.compileDebug&&r.filename&&(n=n+"\n//# sourceURL="+c+"\n");try{if(r.async)try{t=new Function("return (async function(){}).constructor;")()}catch(n){throw n instanceof SyntaxError?new Error("This environment does not support async/await"):n}else t=Function;e=new t(r.localsName+", escapeFn, include, rethrow",n)}catch(n){throw n instanceof SyntaxError&&(r.filename&&(n.message+=" in "+r.filename),n.message+=" while compiling ejs\n\n",n.message+="If the above error is not helpful, you may want to try EJS-Lint:\n",n.message+="https://github.com/RyanZim/EJS-Lint",r.async||(n.message+="\n",n.message+="Or, if you meant to create an async function, pass `async: true` as an option.")),n}var g=r.client?e:function(n){return e.apply(r.context,[n||a.createNullProtoObjWherePossible(),l,function(e,t){var o=a.shallowCopy(a.createNullProtoObjWherePossible(),n);return t&&(o=a.shallowCopy(o,t)),h(e,r)(o)},v])};if(r.filename&&"function"==typeof Object.defineProperty){var f=r.filename,b=o.basename(f,o.extname(f));try{Object.defineProperty(g,"name",{value:b,writable:!1,enumerable:!1,configurable:!0})}catch(n){}}return g},generateSource:function(){this.opts.rmWhitespace&&(this.templateText=this.templateText.replace(/[\r\n]+/g,"\n").replace(/^\s+|\s+$/gm,"")),this.templateText=this.templateText.replace(/[ \t]*<%_/gm,"<%_").replace(/_%>[ \t]*/gm,"_%>");var n=this,e=this.parseTemplateText(),t=this.opts.delimiter,r=this.opts.openDelimiter,o=this.opts.closeDelimiter;e&&e.length&&e.forEach((function(a,s){var i;if(0===a.indexOf(r+t)&&0!==a.indexOf(r+t+t)&&(i=e[s+2])!=t+o&&i!="-"+t+o&&i!="_"+t+o)throw new Error('Could not find matching close tag for "'+a+'".');n.scanLine(a)}))},parseTemplateText:function(){for(var n,e=this.templateText,t=this.regex,r=t.exec(e),o=[];r;)0!==(n=r.index)&&(o.push(e.substring(0,n)),e=e.slice(n)),o.push(r[0]),e=e.slice(r[0].length),r=t.exec(e);return e&&o.push(e),o},_addOutput:function(n){if(this.truncate&&(n=n.replace(/^(?:\r\n|\r|\n)/,""),this.truncate=!1),!n)return n;n=(n=(n=(n=n.replace(/\\/g,"\\\\")).replace(/\n/g,"\\n")).replace(/\r/g,"\\r")).replace(/"/g,'\\"'),this.source+='    ; __append("'+n+'")\n'},scanLine:function(n){var e,t=this.opts.delimiter,r=this.opts.openDelimiter,o=this.opts.closeDelimiter;switch(e=n.split("\n").length-1,n){case r+t:case r+t+"_":this.mode=_.modes.EVAL;break;case r+t+"=":this.mode=_.modes.ESCAPED;break;case r+t+"-":this.mode=_.modes.RAW;break;case r+t+"#":this.mode=_.modes.COMMENT;break;case r+t+t:this.mode=_.modes.LITERAL,this.source+='    ; __append("'+n.replace(r+t+t,r+t)+'")\n';break;case t+t+o:this.mode=_.modes.LITERAL,this.source+='    ; __append("'+n.replace(t+t+o,t+o)+'")\n';break;case t+o:case"-"+t+o:case"_"+t+o:this.mode==_.modes.LITERAL&&this._addOutput(n),this.mode=null,this.truncate=0===n.indexOf("-")||0===n.indexOf("_");break;default:if(this.mode){switch(this.mode){case _.modes.EVAL:case _.modes.ESCAPED:case _.modes.RAW:n.lastIndexOf("//")>n.lastIndexOf("\n")&&(n+="\n")}switch(this.mode){case _.modes.EVAL:this.source+="    ; "+n+"\n";break;case _.modes.ESCAPED:this.source+="    ; __append(escapeFn("+b(n)+"))\n";break;case _.modes.RAW:this.source+="    ; __append("+b(n)+")\n";break;case _.modes.COMMENT:break;case _.modes.LITERAL:this._addOutput(n)}}else this._addOutput(n)}this.opts.compileDebug&&e&&(this.currentLine+=e,this.source+="    ; __line = "+this.currentLine+"\n")}},e.escapeXML=a.escapeXML,e.__express=e.renderFile,e.VERSION=i,e.name="ejs","undefined"!=typeof window&&(window.ejs=e)},function(n,e,t){"use strict";t.r(e);var r={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},o=(t(277),t(5)),a=Object(o.a)(r,(function(){return(0,this._self._c)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"4f1e9d0c",null);e.default=a.exports},function(n,e,t){"use strict";t.r(e);t(3),t(16),t(17),t(22);var r={name:"CodeGroup",data:()=>({codeTabs:[],activeCodeTabIndex:-1}),watch:{activeCodeTabIndex(n){this.codeTabs.forEach(n=>{n.elm.classList.remove("theme-code-block__active")}),this.codeTabs[n].elm.classList.add("theme-code-block__active")}},mounted(){this.codeTabs=(this.$slots.default||[]).filter(n=>Boolean(n.componentOptions)).map((n,e)=>(""===n.componentOptions.propsData.active&&(this.activeCodeTabIndex=e),{title:n.componentOptions.propsData.title,elm:n.elm})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab(n){this.activeCodeTabIndex=n}}},o=(t(278),t(5)),a=Object(o.a)(r,(function(){var n=this,e=n._self._c;return e("div",{staticClass:"theme-code-group"},[e("div",{staticClass:"theme-code-group__nav"},[e("ul",{staticClass:"theme-code-group__ul"},n._l(n.codeTabs,(function(t,r){return e("li",{key:t.title,staticClass:"theme-code-group__li"},[e("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":r===n.activeCodeTabIndex},on:{click:function(e){return n.changeCodeTab(r)}}},[n._v("\n            "+n._s(t.title)+"\n          ")])])})),0)]),n._v(" "),n._t("default"),n._v(" "),n.codeTabs.length<1?e("pre",{staticClass:"pre-blank"},[n._v("// Make sure to add code blocks to your code group")]):n._e()],2)}),[],!1,null,"2f5f1757",null);e.default=a.exports},function(n,e){n.exports=function(n){var e=null==n?0:n.length;return e?n[e-1]:void 0}},function(n,e,t){n.exports=t(288)},function(n,e,t){"use strict";var r={}.propertyIsEnumerable,o=Object.getOwnPropertyDescriptor,a=o&&!r.call({1:2},1);e.f=a?function(n){var e=o(this,n);return!!e&&e.enumerable}:r},function(n,e,t){"use strict";var r=t(8),o=t(9),a=t(72),s=t(37),i=t(132),l=t(18),c=TypeError,p=l("toPrimitive");n.exports=function(n,e){if(!o(n)||a(n))return n;var t,l=s(n,p);if(l){if(void 0===e&&(e="default"),t=r(l,n,e),!o(t)||a(t))return t;throw new c("Can't convert object to primitive value")}return void 0===e&&(e="number"),i(n,e)}},function(n,e,t){"use strict";var r=t(8),o=t(2),a=t(9),s=TypeError;n.exports=function(n,e){var t,i;if("string"===e&&o(t=n.toString)&&!a(i=r(t,n)))return i;if(o(t=n.valueOf)&&!a(i=r(t,n)))return i;if("string"!==e&&o(t=n.toString)&&!a(i=r(t,n)))return i;throw new s("Can't convert object to primitive value")}},function(n,e,t){"use strict";var r=t(6),o=t(11),a=Function.prototype,s=r&&Object.getOwnPropertyDescriptor,i=o(a,"name"),l=i&&"something"===function(){}.name,c=i&&(!r||r&&s(a,"name").configurable);n.exports={EXISTS:i,PROPER:l,CONFIGURABLE:c}},function(n,e,t){"use strict";var r=t(7),o=t(2),a=t(50),s=r(Function.toString);o(a.inspectSource)||(a.inspectSource=function(n){return s(n)}),n.exports=a.inspectSource},function(n,e,t){"use strict";var r=t(0),o=t(2),a=r.WeakMap;n.exports=o(a)&&/native code/.test(String(a))},function(n,e,t){"use strict";var r=t(35),o=t(7),a=t(137),s=t(142),i=t(4),l=o([].concat);n.exports=r("Reflect","ownKeys")||function(n){var e=a.f(i(n)),t=s.f;return t?l(e,t(n)):e}},function(n,e,t){"use strict";var r=t(85),o=t(55).concat("length","prototype");e.f=Object.getOwnPropertyNames||function(n){return r(n,o)}},function(n,e,t){"use strict";var r=t(34),o=t(139),a=t(39),s=function(n){return function(e,t,s){var i=r(e),l=a(i);if(0===l)return!n&&-1;var c,p=o(s,l);if(n&&t!=t){for(;l>p;)if((c=i[p++])!=c)return!0}else for(;l>p;p++)if((n||p in i)&&i[p]===t)return n||p||0;return!n&&-1}};n.exports={includes:s(!0),indexOf:s(!1)}},function(n,e,t){"use strict";var r=t(86),o=Math.max,a=Math.min;n.exports=function(n,e){var t=r(n);return t<0?o(t+e,0):a(t,e)}},function(n,e,t){"use strict";var r=Math.ceil,o=Math.floor;n.exports=Math.trunc||function(n){var e=+n;return(e>0?o:r)(e)}},function(n,e,t){"use strict";var r=t(86),o=Math.min;n.exports=function(n){var e=r(n);return e>0?o(e,9007199254740991):0}},function(n,e,t){"use strict";e.f=Object.getOwnPropertySymbols},function(n,e,t){"use strict";var r=t(1),o=t(2),a=/#|\.prototype\./,s=function(n,e){var t=l[i(n)];return t===p||t!==c&&(o(e)?r(e):!!e)},i=s.normalize=function(n){return String(n).replace(a,".").toLowerCase()},l=s.data={},c=s.NATIVE="N",p=s.POLYFILL="P";n.exports=s},function(n,e,t){"use strict";var r=t(36),o=TypeError;n.exports=function(n,e){if(r(e,n))return n;throw new o("Incorrect invocation")}},function(n,e,t){"use strict";var r=t(1);n.exports=!r((function(){function n(){}return n.prototype.constructor=null,Object.getPrototypeOf(new n)!==n.prototype}))},function(n,e,t){"use strict";var r=t(82),o=t(19);n.exports=function(n,e,t){return t.get&&r(t.get,e,{getter:!0}),t.set&&r(t.set,e,{setter:!0}),o.f(n,e,t)}},function(n,e,t){"use strict";var r=t(6),o=t(19),a=t(33);n.exports=function(n,e,t){r?o.f(n,e,a(0,t)):n[e]=t}},function(n,e,t){"use strict";var r=t(6),o=t(81),a=t(19),s=t(4),i=t(34),l=t(149);e.f=r&&!o?Object.defineProperties:function(n,e){s(n);for(var t,r=i(e),o=l(e),c=o.length,p=0;c>p;)a.f(n,t=o[p++],r[t]);return n}},function(n,e,t){"use strict";var r=t(85),o=t(55);n.exports=Object.keys||function(n){return r(n,o)}},function(n,e,t){"use strict";var r=t(35);n.exports=r("document","documentElement")},function(n,e,t){"use strict";var r=t(52);n.exports=function(n,e,t){for(var o in e)r(n,o,e[o],t);return n}},function(n,e,t){"use strict";n.exports=function(n,e){return{value:n,done:e}}},function(n,e,t){"use strict";var r=t(14);n.exports=function(n,e,t){for(var o=n.length-1;o>=0;o--)if(void 0!==n[o])try{t=r(n[o].iterator,e,t)}catch(n){e="throw",t=n}if("throw"===e)throw t;return t}},function(n,e,t){"use strict";var r=t(13),o=t(155).left,a=t(156),s=t(75);r({target:"Array",proto:!0,forced:!t(157)&&s>79&&s<83||!a("reduce")},{reduce:function(n){var e=arguments.length;return o(this,n,e,e>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r=t(10),o=t(38),a=t(70),s=t(39),i=TypeError,l="Reduce of empty array with no initial value",c=function(n){return function(e,t,c,p){var d=o(e),u=a(d),m=s(d);if(r(t),0===m&&c<2)throw new i(l);var g=n?m-1:0,f=n?-1:1;if(c<2)for(;;){if(g in u){p=u[g],g+=f;break}if(g+=f,n?g<0:m<=g)throw new i(l)}for(;n?g>=0:m>g;g+=f)g in u&&(p=t(p,u[g],g,d));return p}};n.exports={left:c(!1),right:c(!0)}},function(n,e,t){"use strict";var r=t(1);n.exports=function(n,e){var t=[][n];return!!t&&r((function(){t.call(null,e||function(){return 1},1)}))}},function(n,e,t){"use strict";var r=t(158);n.exports="NODE"===r},function(n,e,t){"use strict";var r=t(0),o=t(76),a=t(27),s=function(n){return o.slice(0,n.length)===n};n.exports=s("Bun/")?"BUN":s("Cloudflare-Workers")?"CLOUDFLARE":s("Deno/")?"DENO":s("Node.js/")?"NODE":r.Bun&&"string"==typeof Bun.version?"BUN":r.Deno&&"object"==typeof Deno.version?"DENO":"process"===a(r.process)?"NODE":r.window&&r.document?"BROWSER":"REST"},function(n,e,t){"use strict";var r=t(160),o=t(10),a=t(32),s=r(r.bind);n.exports=function(n,e){return o(n),void 0===e?n:a?s(n,e):function(){return n.apply(e,arguments)}}},function(n,e,t){"use strict";var r=t(27),o=t(7);n.exports=function(n){if("Function"===r(n))return o(n)}},function(n,e,t){"use strict";var r=t(18),o=t(93),a=r("iterator"),s=Array.prototype;n.exports=function(n){return void 0!==n&&(o.Array===n||s[a]===n)}},function(n,e,t){"use strict";var r=t(8),o=t(10),a=t(4),s=t(49),i=t(94),l=TypeError;n.exports=function(n,e){var t=arguments.length<2?i(n):e;if(o(t))return a(r(t,n));throw new l(s(n)+" is not iterable")}},function(n,e,t){"use strict";var r={};r[t(18)("toStringTag")]="z",n.exports="[object z]"===String(r)},function(n,e,t){"use strict";var r=t(13),o=t(56),a=t(10),s=t(4),i=t(28),l=t(14),c=t(29),p=t(96),d=t(1),u=TypeError,m=d((function(){[].keys().reduce((function(){}),void 0)})),g=!m&&c("reduce",u);r({target:"Iterator",proto:!0,real:!0,forced:m||g},{reduce:function(n){s(this);try{a(n)}catch(n){l(this,"throw",n)}var e=arguments.length<2,t=e?void 0:arguments[1];if(g)return p(g,this,e?[n]:[n,t]);var r=i(this),c=0;if(o(r,(function(r){e?(e=!1,t=r):t=n(t,r,c),c++}),{IS_RECORD:!0}),e)throw new u("Reduce of empty iterator with no initial value");return t}})},function(n,e,t){"use strict";var r=t(13),o=t(0),a=t(96),s=t(166),i=o.WebAssembly,l=7!==new Error("e",{cause:7}).cause,c=function(n,e){var t={};t[n]=s(n,e,l),r({global:!0,constructor:!0,arity:1,forced:l},t)},p=function(n,e){if(i&&i[n]){var t={};t[n]=s("WebAssembly."+n,e,l),r({target:"WebAssembly",stat:!0,constructor:!0,arity:1,forced:l},t)}};c("Error",(function(n){return function(e){return a(n,this,arguments)}})),c("EvalError",(function(n){return function(e){return a(n,this,arguments)}})),c("RangeError",(function(n){return function(e){return a(n,this,arguments)}})),c("ReferenceError",(function(n){return function(e){return a(n,this,arguments)}})),c("SyntaxError",(function(n){return function(e){return a(n,this,arguments)}})),c("TypeError",(function(n){return function(e){return a(n,this,arguments)}})),c("URIError",(function(n){return function(e){return a(n,this,arguments)}})),p("CompileError",(function(n){return function(e){return a(n,this,arguments)}})),p("LinkError",(function(n){return function(e){return a(n,this,arguments)}})),p("RuntimeError",(function(n){return function(e){return a(n,this,arguments)}}))},function(n,e,t){"use strict";var r=t(35),o=t(11),a=t(25),s=t(36),i=t(97),l=t(84),c=t(170),p=t(171),d=t(172),u=t(174),m=t(175),g=t(6),f=t(24);n.exports=function(n,e,t,h){var v=h?2:1,b=n.split("."),_=b[b.length-1],y=r.apply(null,b);if(y){var k=y.prototype;if(!f&&o(k,"cause")&&delete k.cause,!t)return y;var w=r("Error"),E=e((function(n,e){var t=d(h?e:n,void 0),r=h?new y(n):new y;return void 0!==t&&a(r,"message",t),m(r,E,r.stack,2),this&&s(k,this)&&p(r,this,E),arguments.length>v&&u(r,arguments[v]),r}));if(E.prototype=k,"Error"!==_?i?i(E,w):l(E,w,{name:!0}):g&&"stackTraceLimit"in y&&(c(E,y,"stackTraceLimit"),c(E,y,"prepareStackTrace")),l(E,y),!f)try{k.name!==_&&a(k,"name",_),k.constructor=E}catch(n){}return E}}},function(n,e,t){"use strict";var r=t(7),o=t(10);n.exports=function(n,e,t){try{return r(o(Object.getOwnPropertyDescriptor(n,e)[t]))}catch(n){}}},function(n,e,t){"use strict";var r=t(169),o=String,a=TypeError;n.exports=function(n){if(r(n))return n;throw new a("Can't set "+o(n)+" as a prototype")}},function(n,e,t){"use strict";var r=t(9);n.exports=function(n){return r(n)||null===n}},function(n,e,t){"use strict";var r=t(19).f;n.exports=function(n,e,t){t in n||r(n,t,{configurable:!0,get:function(){return e[t]},set:function(n){e[t]=n}})}},function(n,e,t){"use strict";var r=t(2),o=t(9),a=t(97);n.exports=function(n,e,t){var s,i;return a&&r(s=e.constructor)&&s!==t&&o(i=s.prototype)&&i!==t.prototype&&a(n,i),n}},function(n,e,t){"use strict";var r=t(173);n.exports=function(n,e){return void 0===n?arguments.length<2?"":e:r(n)}},function(n,e,t){"use strict";var r=t(95),o=String;n.exports=function(n){if("Symbol"===r(n))throw new TypeError("Cannot convert a Symbol value to a string");return o(n)}},function(n,e,t){"use strict";var r=t(9),o=t(25);n.exports=function(n,e){r(e)&&"cause"in e&&o(n,"cause",e.cause)}},function(n,e,t){"use strict";var r=t(25),o=t(176),a=t(177),s=Error.captureStackTrace;n.exports=function(n,e,t,i){a&&(s?s(n,e):r(n,"stack",o(t,i)))}},function(n,e,t){"use strict";var r=t(7),o=Error,a=r("".replace),s=String(new o("zxcasd").stack),i=/\n\s*at [^:]*:[^\n]*/,l=i.test(s);n.exports=function(n,e){if(l&&"string"==typeof n&&!o.prepareStackTrace)for(;e--;)n=a(n,i,"");return n}},function(n,e,t){"use strict";var r=t(1),o=t(33);n.exports=!r((function(){var n=new Error("a");return!("stack"in n)||(Object.defineProperty(n,"stack",o(1,7)),7!==n.stack)}))},function(n,e,t){"use strict";var r=t(6),o=t(179),a=TypeError,s=Object.getOwnPropertyDescriptor,i=r&&!function(){if(void 0!==this)return!0;try{Object.defineProperty([],"length",{writable:!1}).length=1}catch(n){return n instanceof TypeError}}();n.exports=i?function(n,e){if(o(n)&&!s(n,"length").writable)throw new a("Cannot set read only .length");return n.length=e}:function(n,e){return n.length=e}},function(n,e,t){"use strict";var r=t(27);n.exports=Array.isArray||function(n){return"Array"===r(n)}},function(n,e,t){"use strict";var r=TypeError;n.exports=function(n){if(n>9007199254740991)throw r("Maximum allowed index exceeded");return n}},function(n,e,t){var r=t(98),o=t(182);n.exports=function n(e,t,a,s,i){var l=-1,c=e.length;for(a||(a=o),i||(i=[]);++l<c;){var p=e[l];t>0&&a(p)?t>1?n(p,t-1,a,s,i):r(i,p):s||(i[i.length]=p)}return i}},function(n,e,t){var r=t(30),o=t(57),a=t(12),s=r?r.isConcatSpreadable:void 0;n.exports=function(n){return a(n)||o(n)||!!(s&&n&&n[s])}},function(n,e,t){var r=t(26),o=t(23);n.exports=function(n){return o(n)&&"[object Arguments]"==r(n)}},function(n,e,t){var r=t(30),o=Object.prototype,a=o.hasOwnProperty,s=o.toString,i=r?r.toStringTag:void 0;n.exports=function(n){var e=a.call(n,i),t=n[i];try{n[i]=void 0;var r=!0}catch(n){}var o=s.call(n);return r&&(e?n[i]=t:delete n[i]),o}},function(n,e){var t=Object.prototype.toString;n.exports=function(n){return t.call(n)}},function(n,e,t){var r=t(187),o=t(243),a=t(65),s=t(12),i=t(254);n.exports=function(n){return"function"==typeof n?n:null==n?a:"object"==typeof n?s(n)?o(n[0],n[1]):r(n):i(n)}},function(n,e,t){var r=t(188),o=t(242),a=t(115);n.exports=function(n){var e=o(n);return 1==e.length&&e[0][2]?a(e[0][0],e[0][1]):function(t){return t===n||r(t,n,e)}}},function(n,e,t){var r=t(100),o=t(104);n.exports=function(n,e,t,a){var s=t.length,i=s,l=!a;if(null==n)return!i;for(n=Object(n);s--;){var c=t[s];if(l&&c[2]?c[1]!==n[c[0]]:!(c[0]in n))return!1}for(;++s<i;){var p=(c=t[s])[0],d=n[p],u=c[1];if(l&&c[2]){if(void 0===d&&!(p in n))return!1}else{var m=new r;if(a)var g=a(d,u,p,n,e,m);if(!(void 0===g?o(u,d,3,a,m):g))return!1}}return!0}},function(n,e){n.exports=function(){this.__data__=[],this.size=0}},function(n,e,t){var r=t(41),o=Array.prototype.splice;n.exports=function(n){var e=this.__data__,t=r(e,n);return!(t<0)&&(t==e.length-1?e.pop():o.call(e,t,1),--this.size,!0)}},function(n,e,t){var r=t(41);n.exports=function(n){var e=this.__data__,t=r(e,n);return t<0?void 0:e[t][1]}},function(n,e,t){var r=t(41);n.exports=function(n){return r(this.__data__,n)>-1}},function(n,e,t){var r=t(41);n.exports=function(n,e){var t=this.__data__,o=r(t,n);return o<0?(++this.size,t.push([n,e])):t[o][1]=e,this}},function(n,e,t){var r=t(40);n.exports=function(){this.__data__=new r,this.size=0}},function(n,e){n.exports=function(n){var e=this.__data__,t=e.delete(n);return this.size=e.size,t}},function(n,e){n.exports=function(n){return this.__data__.get(n)}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e,t){var r=t(40),o=t(58),a=t(60);n.exports=function(n,e){var t=this.__data__;if(t instanceof r){var s=t.__data__;if(!o||s.length<199)return s.push([n,e]),this.size=++t.size,this;t=this.__data__=new a(s)}return t.set(n,e),this.size=t.size,this}},function(n,e,t){var r=t(102),o=t(200),a=t(59),s=t(103),i=/^\[object .+?Constructor\]$/,l=Function.prototype,c=Object.prototype,p=l.toString,d=c.hasOwnProperty,u=RegExp("^"+p.call(d).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");n.exports=function(n){return!(!a(n)||o(n))&&(r(n)?u:i).test(s(n))}},function(n,e,t){var r,o=t(201),a=(r=/[^.]+$/.exec(o&&o.keys&&o.keys.IE_PROTO||""))?"Symbol(src)_1."+r:"";n.exports=function(n){return!!a&&a in n}},function(n,e,t){var r=t(15)["__core-js_shared__"];n.exports=r},function(n,e){n.exports=function(n,e){return null==n?void 0:n[e]}},function(n,e,t){var r=t(204),o=t(40),a=t(58);n.exports=function(){this.size=0,this.__data__={hash:new r,map:new(a||o),string:new r}}},function(n,e,t){var r=t(205),o=t(206),a=t(207),s=t(208),i=t(209);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=o,l.prototype.get=a,l.prototype.has=s,l.prototype.set=i,n.exports=l},function(n,e,t){var r=t(42);n.exports=function(){this.__data__=r?r(null):{},this.size=0}},function(n,e){n.exports=function(n){var e=this.has(n)&&delete this.__data__[n];return this.size-=e?1:0,e}},function(n,e,t){var r=t(42),o=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;if(r){var t=e[n];return"__lodash_hash_undefined__"===t?void 0:t}return o.call(e,n)?e[n]:void 0}},function(n,e,t){var r=t(42),o=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;return r?void 0!==e[n]:o.call(e,n)}},function(n,e,t){var r=t(42);n.exports=function(n,e){var t=this.__data__;return this.size+=this.has(n)?0:1,t[n]=r&&void 0===e?"__lodash_hash_undefined__":e,this}},function(n,e,t){var r=t(43);n.exports=function(n){var e=r(this,n).delete(n);return this.size-=e?1:0,e}},function(n,e){n.exports=function(n){var e=typeof n;return"string"==e||"number"==e||"symbol"==e||"boolean"==e?"__proto__"!==n:null===n}},function(n,e,t){var r=t(43);n.exports=function(n){return r(this,n).get(n)}},function(n,e,t){var r=t(43);n.exports=function(n){return r(this,n).has(n)}},function(n,e,t){var r=t(43);n.exports=function(n,e){var t=r(this,n),o=t.size;return t.set(n,e),this.size+=t.size==o?0:1,this}},function(n,e,t){var r=t(100),o=t(105),a=t(219),s=t(222),i=t(238),l=t(12),c=t(109),p=t(111),d="[object Object]",u=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,m,g,f){var h=l(n),v=l(e),b=h?"[object Array]":i(n),_=v?"[object Array]":i(e),y=(b="[object Arguments]"==b?d:b)==d,k=(_="[object Arguments]"==_?d:_)==d,w=b==_;if(w&&c(n)){if(!c(e))return!1;h=!0,y=!1}if(w&&!y)return f||(f=new r),h||p(n)?o(n,e,t,m,g,f):a(n,e,b,t,m,g,f);if(!(1&t)){var E=y&&u.call(n,"__wrapped__"),x=k&&u.call(e,"__wrapped__");if(E||x){var A=E?n.value():n,B=x?e.value():e;return f||(f=new r),g(A,B,t,m,f)}}return!!w&&(f||(f=new r),s(n,e,t,m,g,f))}},function(n,e){n.exports=function(n){return this.__data__.set(n,"__lodash_hash_undefined__"),this}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length;++t<r;)if(e(n[t],t,n))return!0;return!1}},function(n,e,t){var r=t(30),o=t(220),a=t(101),s=t(105),i=t(221),l=t(61),c=r?r.prototype:void 0,p=c?c.valueOf:void 0;n.exports=function(n,e,t,r,c,d,u){switch(t){case"[object DataView]":if(n.byteLength!=e.byteLength||n.byteOffset!=e.byteOffset)return!1;n=n.buffer,e=e.buffer;case"[object ArrayBuffer]":return!(n.byteLength!=e.byteLength||!d(new o(n),new o(e)));case"[object Boolean]":case"[object Date]":case"[object Number]":return a(+n,+e);case"[object Error]":return n.name==e.name&&n.message==e.message;case"[object RegExp]":case"[object String]":return n==e+"";case"[object Map]":var m=i;case"[object Set]":var g=1&r;if(m||(m=l),n.size!=e.size&&!g)return!1;var f=u.get(n);if(f)return f==e;r|=2,u.set(n,e);var h=s(m(n),m(e),r,c,d,u);return u.delete(n),h;case"[object Symbol]":if(p)return p.call(n)==p.call(e)}return!1}},function(n,e,t){var r=t(15).Uint8Array;n.exports=r},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n,r){t[++e]=[r,n]})),t}},function(n,e,t){var r=t(223),o=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,a,s,i){var l=1&t,c=r(n),p=c.length;if(p!=r(e).length&&!l)return!1;for(var d=p;d--;){var u=c[d];if(!(l?u in e:o.call(e,u)))return!1}var m=i.get(n),g=i.get(e);if(m&&g)return m==e&&g==n;var f=!0;i.set(n,e),i.set(e,n);for(var h=l;++d<p;){var v=n[u=c[d]],b=e[u];if(a)var _=l?a(b,v,u,e,n,i):a(v,b,u,n,e,i);if(!(void 0===_?v===b||s(v,b,t,a,i):_)){f=!1;break}h||(h="constructor"==u)}if(f&&!h){var y=n.constructor,k=e.constructor;y==k||!("constructor"in n)||!("constructor"in e)||"function"==typeof y&&y instanceof y&&"function"==typeof k&&k instanceof k||(f=!1)}return i.delete(n),i.delete(e),f}},function(n,e,t){var r=t(224),o=t(225),a=t(108);n.exports=function(n){return r(n,a,o)}},function(n,e,t){var r=t(98),o=t(12);n.exports=function(n,e,t){var a=e(n);return o(n)?a:r(a,t(n))}},function(n,e,t){var r=t(226),o=t(227),a=Object.prototype.propertyIsEnumerable,s=Object.getOwnPropertySymbols,i=s?function(n){return null==n?[]:(n=Object(n),r(s(n),(function(e){return a.call(n,e)})))}:o;n.exports=i},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,o=0,a=[];++t<r;){var s=n[t];e(s,t,n)&&(a[o++]=s)}return a}},function(n,e){n.exports=function(){return[]}},function(n,e,t){var r=t(229),o=t(57),a=t(12),s=t(109),i=t(110),l=t(111),c=Object.prototype.hasOwnProperty;n.exports=function(n,e){var t=a(n),p=!t&&o(n),d=!t&&!p&&s(n),u=!t&&!p&&!d&&l(n),m=t||p||d||u,g=m?r(n.length,String):[],f=g.length;for(var h in n)!e&&!c.call(n,h)||m&&("length"==h||d&&("offset"==h||"parent"==h)||u&&("buffer"==h||"byteLength"==h||"byteOffset"==h)||i(h,f))||g.push(h);return g}},function(n,e){n.exports=function(n,e){for(var t=-1,r=Array(n);++t<n;)r[t]=e(t);return r}},function(n,e){n.exports=function(){return!1}},function(n,e,t){var r=t(26),o=t(62),a=t(23),s={};s["[object Float32Array]"]=s["[object Float64Array]"]=s["[object Int8Array]"]=s["[object Int16Array]"]=s["[object Int32Array]"]=s["[object Uint8Array]"]=s["[object Uint8ClampedArray]"]=s["[object Uint16Array]"]=s["[object Uint32Array]"]=!0,s["[object Arguments]"]=s["[object Array]"]=s["[object ArrayBuffer]"]=s["[object Boolean]"]=s["[object DataView]"]=s["[object Date]"]=s["[object Error]"]=s["[object Function]"]=s["[object Map]"]=s["[object Number]"]=s["[object Object]"]=s["[object RegExp]"]=s["[object Set]"]=s["[object String]"]=s["[object WeakMap]"]=!1,n.exports=function(n){return a(n)&&o(n.length)&&!!s[r(n)]}},function(n,e){n.exports=function(n){return function(e){return n(e)}}},function(n,e,t){(function(n){var r=t(99),o=e&&!e.nodeType&&e,a=o&&"object"==typeof n&&n&&!n.nodeType&&n,s=a&&a.exports===o&&r.process,i=function(){try{var n=a&&a.require&&a.require("util").types;return n||s&&s.binding&&s.binding("util")}catch(n){}}();n.exports=i}).call(this,t(67)(n))},function(n,e,t){var r=t(235),o=t(236),a=Object.prototype.hasOwnProperty;n.exports=function(n){if(!r(n))return o(n);var e=[];for(var t in Object(n))a.call(n,t)&&"constructor"!=t&&e.push(t);return e}},function(n,e){var t=Object.prototype;n.exports=function(n){var e=n&&n.constructor;return n===("function"==typeof e&&e.prototype||t)}},function(n,e,t){var r=t(237)(Object.keys,Object);n.exports=r},function(n,e){n.exports=function(n,e){return function(t){return n(e(t))}}},function(n,e,t){var r=t(239),o=t(58),a=t(240),s=t(113),i=t(241),l=t(26),c=t(103),p=c(r),d=c(o),u=c(a),m=c(s),g=c(i),f=l;(r&&"[object DataView]"!=f(new r(new ArrayBuffer(1)))||o&&"[object Map]"!=f(new o)||a&&"[object Promise]"!=f(a.resolve())||s&&"[object Set]"!=f(new s)||i&&"[object WeakMap]"!=f(new i))&&(f=function(n){var e=l(n),t="[object Object]"==e?n.constructor:void 0,r=t?c(t):"";if(r)switch(r){case p:return"[object DataView]";case d:return"[object Map]";case u:return"[object Promise]";case m:return"[object Set]";case g:return"[object WeakMap]"}return e}),n.exports=f},function(n,e,t){var r=t(20)(t(15),"DataView");n.exports=r},function(n,e,t){var r=t(20)(t(15),"Promise");n.exports=r},function(n,e,t){var r=t(20)(t(15),"WeakMap");n.exports=r},function(n,e,t){var r=t(114),o=t(108);n.exports=function(n){for(var e=o(n),t=e.length;t--;){var a=e[t],s=n[a];e[t]=[a,s,r(s)]}return e}},function(n,e,t){var r=t(104),o=t(244),a=t(251),s=t(63),i=t(114),l=t(115),c=t(44);n.exports=function(n,e){return s(n)&&i(e)?l(c(n),e):function(t){var s=o(t,n);return void 0===s&&s===e?a(t,n):r(e,s,3)}}},function(n,e,t){var r=t(116);n.exports=function(n,e,t){var o=null==n?void 0:r(n,e);return void 0===o?t:o}},function(n,e,t){var r=t(246),o=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,a=/\\(\\)?/g,s=r((function(n){var e=[];return 46===n.charCodeAt(0)&&e.push(""),n.replace(o,(function(n,t,r,o){e.push(r?o.replace(a,"$1"):t||n)})),e}));n.exports=s},function(n,e,t){var r=t(247);n.exports=function(n){var e=r(n,(function(n){return 500===t.size&&t.clear(),n})),t=e.cache;return e}},function(n,e,t){var r=t(60);function o(n,e){if("function"!=typeof n||null!=e&&"function"!=typeof e)throw new TypeError("Expected a function");var t=function(){var r=arguments,o=e?e.apply(this,r):r[0],a=t.cache;if(a.has(o))return a.get(o);var s=n.apply(this,r);return t.cache=a.set(o,s)||a,s};return t.cache=new(o.Cache||r),t}o.Cache=r,n.exports=o},function(n,e,t){var r=t(249);n.exports=function(n){return null==n?"":r(n)}},function(n,e,t){var r=t(30),o=t(250),a=t(12),s=t(64),i=r?r.prototype:void 0,l=i?i.toString:void 0;n.exports=function n(e){if("string"==typeof e)return e;if(a(e))return o(e,n)+"";if(s(e))return l?l.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,o=Array(r);++t<r;)o[t]=e(n[t],t,n);return o}},function(n,e,t){var r=t(252),o=t(253);n.exports=function(n,e){return null!=n&&o(n,e,r)}},function(n,e){n.exports=function(n,e){return null!=n&&e in Object(n)}},function(n,e,t){var r=t(117),o=t(57),a=t(12),s=t(110),i=t(62),l=t(44);n.exports=function(n,e,t){for(var c=-1,p=(e=r(e,n)).length,d=!1;++c<p;){var u=l(e[c]);if(!(d=null!=n&&t(n,u)))break;n=n[u]}return d||++c!=p?d:!!(p=null==n?0:n.length)&&i(p)&&s(u,p)&&(a(n)||o(n))}},function(n,e,t){var r=t(255),o=t(256),a=t(63),s=t(44);n.exports=function(n){return a(n)?r(s(n)):o(n)}},function(n,e){n.exports=function(n){return function(e){return null==e?void 0:e[n]}}},function(n,e,t){var r=t(116);n.exports=function(n){return function(e){return r(e,n)}}},function(n,e,t){var r=t(65),o=t(258),a=t(260);n.exports=function(n,e){return a(o(n,e,r),n+"")}},function(n,e,t){var r=t(259),o=Math.max;n.exports=function(n,e,t){return e=o(void 0===e?n.length-1:e,0),function(){for(var a=arguments,s=-1,i=o(a.length-e,0),l=Array(i);++s<i;)l[s]=a[e+s];s=-1;for(var c=Array(e+1);++s<e;)c[s]=a[s];return c[e]=t(l),r(n,this,c)}}},function(n,e){n.exports=function(n,e,t){switch(t.length){case 0:return n.call(e);case 1:return n.call(e,t[0]);case 2:return n.call(e,t[0],t[1]);case 3:return n.call(e,t[0],t[1],t[2])}return n.apply(e,t)}},function(n,e,t){var r=t(261),o=t(264)(r);n.exports=o},function(n,e,t){var r=t(262),o=t(263),a=t(65),s=o?function(n,e){return o(n,"toString",{configurable:!0,enumerable:!1,value:r(e),writable:!0})}:a;n.exports=s},function(n,e){n.exports=function(n){return function(){return n}}},function(n,e,t){var r=t(20),o=function(){try{var n=r(Object,"defineProperty");return n({},"",{}),n}catch(n){}}();n.exports=o},function(n,e){var t=Date.now;n.exports=function(n){var e=0,r=0;return function(){var o=t(),a=16-(o-r);if(r=o,a>0){if(++e>=800)return arguments[0]}else e=0;return n.apply(void 0,arguments)}}},function(n,e,t){var r=t(106),o=t(266),a=t(271),s=t(107),i=t(272),l=t(61);n.exports=function(n,e,t){var c=-1,p=o,d=n.length,u=!0,m=[],g=m;if(t)u=!1,p=a;else if(d>=200){var f=e?null:i(n);if(f)return l(f);u=!1,p=s,g=new r}else g=e?[]:m;n:for(;++c<d;){var h=n[c],v=e?e(h):h;if(h=t||0!==h?h:0,u&&v==v){for(var b=g.length;b--;)if(g[b]===v)continue n;e&&g.push(v),m.push(h)}else p(g,v,t)||(g!==m&&g.push(v),m.push(h))}return m}},function(n,e,t){var r=t(267);n.exports=function(n,e){return!!(null==n?0:n.length)&&r(n,e,0)>-1}},function(n,e,t){var r=t(268),o=t(269),a=t(270);n.exports=function(n,e,t){return e==e?a(n,e,t):r(n,o,t)}},function(n,e){n.exports=function(n,e,t,r){for(var o=n.length,a=t+(r?1:-1);r?a--:++a<o;)if(e(n[a],a,n))return a;return-1}},function(n,e){n.exports=function(n){return n!=n}},function(n,e){n.exports=function(n,e,t){for(var r=t-1,o=n.length;++r<o;)if(n[r]===e)return r;return-1}},function(n,e){n.exports=function(n,e,t){for(var r=-1,o=null==n?0:n.length;++r<o;)if(t(e,n[r]))return!0;return!1}},function(n,e,t){var r=t(113),o=t(273),a=t(61),s=r&&1/a(new r([,-0]))[1]==1/0?function(n){return new r(n)}:o;n.exports=s},function(n,e){n.exports=function(){}},function(n,e,t){var r=t(112),o=t(23);n.exports=function(n){return o(n)&&r(n)}},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(118)},function(n,e,t){"use strict";t(119)},function(n,e,t){},function(n,e,t){},function(n,e){},function(n,e){function t(n,e){for(var t=0,r=n.length-1;r>=0;r--){var o=n[r];"."===o?n.splice(r,1):".."===o?(n.splice(r,1),t++):t&&(n.splice(r,1),t--)}if(e)for(;t--;t)n.unshift("..");return n}function r(n,e){if(n.filter)return n.filter(e);for(var t=[],r=0;r<n.length;r++)e(n[r],r,n)&&t.push(n[r]);return t}e.resolve=function(){for(var n="",e=!1,o=arguments.length-1;o>=-1&&!e;o--){var a=o>=0?arguments[o]:process.cwd();if("string"!=typeof a)throw new TypeError("Arguments to path.resolve must be strings");a&&(n=a+"/"+n,e="/"===a.charAt(0))}return(e?"/":"")+(n=t(r(n.split("/"),(function(n){return!!n})),!e).join("/"))||"."},e.normalize=function(n){var a=e.isAbsolute(n),s="/"===o(n,-1);return(n=t(r(n.split("/"),(function(n){return!!n})),!a).join("/"))||a||(n="."),n&&s&&(n+="/"),(a?"/":"")+n},e.isAbsolute=function(n){return"/"===n.charAt(0)},e.join=function(){var n=Array.prototype.slice.call(arguments,0);return e.normalize(r(n,(function(n,e){if("string"!=typeof n)throw new TypeError("Arguments to path.join must be strings");return n})).join("/"))},e.relative=function(n,t){function r(n){for(var e=0;e<n.length&&""===n[e];e++);for(var t=n.length-1;t>=0&&""===n[t];t--);return e>t?[]:n.slice(e,t-e+1)}n=e.resolve(n).substr(1),t=e.resolve(t).substr(1);for(var o=r(n.split("/")),a=r(t.split("/")),s=Math.min(o.length,a.length),i=s,l=0;l<s;l++)if(o[l]!==a[l]){i=l;break}var c=[];for(l=i;l<o.length;l++)c.push("..");return(c=c.concat(a.slice(i))).join("/")},e.sep="/",e.delimiter=":",e.dirname=function(n){if("string"!=typeof n&&(n+=""),0===n.length)return".";for(var e=n.charCodeAt(0),t=47===e,r=-1,o=!0,a=n.length-1;a>=1;--a)if(47===(e=n.charCodeAt(a))){if(!o){r=a;break}}else o=!1;return-1===r?t?"/":".":t&&1===r?"/":n.slice(0,r)},e.basename=function(n,e){var t=function(n){"string"!=typeof n&&(n+="");var e,t=0,r=-1,o=!0;for(e=n.length-1;e>=0;--e)if(47===n.charCodeAt(e)){if(!o){t=e+1;break}}else-1===r&&(o=!1,r=e+1);return-1===r?"":n.slice(t,r)}(n);return e&&t.substr(-1*e.length)===e&&(t=t.substr(0,t.length-e.length)),t},e.extname=function(n){"string"!=typeof n&&(n+="");for(var e=-1,t=0,r=-1,o=!0,a=0,s=n.length-1;s>=0;--s){var i=n.charCodeAt(s);if(47!==i)-1===r&&(o=!1,r=s+1),46===i?-1===e?e=s:1!==a&&(a=1):-1!==e&&(a=-1);else if(!o){t=s+1;break}}return-1===e||-1===r||0===a||1===a&&e===r-1&&e===t+1?"":n.slice(e,r)};var o="b"==="ab".substr(-1)?function(n,e,t){return n.substr(e,t)}:function(n,e,t){return e<0&&(e=n.length+e),n.substr(e,t)}},function(n,e,t){"use strict";var r=/[|\\{}()[\]^$+*?.]/g,o=Object.prototype.hasOwnProperty,a=function(n,e){return o.apply(n,[e])};e.escapeRegExpChars=function(n){return n?String(n).replace(r,"\\$&"):""};var s={"&":"&amp;","<":"&lt;",">":"&gt;",'"':"&#34;","'":"&#39;"},i=/[&<>'"]/g;function l(n){return s[n]||n}function c(){return Function.prototype.toString.call(this)+';\nvar _ENCODE_HTML_RULES = {\n      "&": "&amp;"\n    , "<": "&lt;"\n    , ">": "&gt;"\n    , \'"\': "&#34;"\n    , "\'": "&#39;"\n    }\n  , _MATCH_HTML = /[&<>\'"]/g;\nfunction encode_char(c) {\n  return _ENCODE_HTML_RULES[c] || c;\n};\n'}e.escapeXML=function(n){return null==n?"":String(n).replace(i,l)};try{"function"==typeof Object.defineProperty?Object.defineProperty(e.escapeXML,"toString",{value:c}):e.escapeXML.toString=c}catch(n){console.warn("Unable to set escapeXML.toString (is the Function prototype frozen?)")}e.shallowCopy=function(n,e){if(e=e||{},null!=n)for(var t in e)a(e,t)&&"__proto__"!==t&&"constructor"!==t&&(n[t]=e[t]);return n},e.shallowCopyFromList=function(n,e,t){if(t=t||[],e=e||{},null!=n)for(var r=0;r<t.length;r++){var o=t[r];if(void 0!==e[o]){if(!a(e,o))continue;if("__proto__"===o||"constructor"===o)continue;n[o]=e[o]}}return n},e.cache={_data:{},set:function(n,e){this._data[n]=e},get:function(n){return this._data[n]},remove:function(n){delete this._data[n]},reset:function(){this._data={}}},e.hyphenToCamel=function(n){return n.replace(/-[a-z]/g,(function(n){return n[1].toUpperCase()}))},e.createNullProtoObjWherePossible="function"==typeof Object.create?function(){return Object.create(null)}:{__proto__:null}instanceof Object?function(){return{}}:function(){return{__proto__:null}},e.hasOwnOnlyObject=function(n){var t=e.createNullProtoObjWherePossible();for(var r in n)a(n,r)&&(t[r]=n[r]);return t}},function(n){n.exports=JSON.parse('{"_from":"ejs@^3.1.8","_id":"ejs@3.1.10","_inBundle":false,"_integrity":"sha512-UeJmFfOrAQS8OJWPZ4qtgHyWExa088/MtK5UEyoJGFH67cDEXkZSviOiKRCZ4Xij0zxI3JECgYs3oKx+AizQBA==","_location":"/ejs","_phantomChildren":{},"_requested":{"type":"range","registry":true,"raw":"ejs@^3.1.8","name":"ejs","escapedName":"ejs","rawSpec":"^3.1.8","saveSpec":null,"fetchSpec":"^3.1.8"},"_requiredBy":["/vuepress-plugin-vssue-global"],"_resolved":"https://registry.npmjs.org/ejs/-/ejs-3.1.10.tgz","_shasum":"69ab8358b14e896f80cc39e62087b88500c3ac3b","_spec":"ejs@^3.1.8","_where":"/home/runner/work/tenqaz.github.io/tenqaz.github.io/node_modules/vuepress-plugin-vssue-global","author":{"name":"Matthew Eernisse","email":"mde@fleegix.org","url":"http://fleegix.org"},"bin":{"ejs":"bin/cli.js"},"bugs":{"url":"https://github.com/mde/ejs/issues"},"bundleDependencies":false,"dependencies":{"jake":"^10.8.5"},"deprecated":false,"description":"Embedded JavaScript templates","devDependencies":{"browserify":"^16.5.1","eslint":"^6.8.0","git-directory-deploy":"^1.5.1","jsdoc":"^4.0.2","lru-cache":"^4.0.1","mocha":"^10.2.0","uglify-js":"^3.3.16"},"engines":{"node":">=0.10.0"},"homepage":"https://github.com/mde/ejs","jsdelivr":"ejs.min.js","keywords":["template","engine","ejs"],"license":"Apache-2.0","main":"./lib/ejs.js","name":"ejs","repository":{"type":"git","url":"git://github.com/mde/ejs.git"},"scripts":{"test":"npx jake test"},"unpkg":"ejs.min.js","version":"3.1.10"}')},function(n,e,t){"use strict";t(120)},function(n,e,t){"use strict";t(121)},function(n,e,t){"use strict";t(122)},function(n,e,t){"use strict";t.r(e);t(3),t(16),t(22);var r=Object.freeze({}),o=Array.isArray;function a(n){return null==n}function s(n){return null!=n}function i(n){return!0===n}function l(n){return"string"==typeof n||"number"==typeof n||"symbol"==typeof n||"boolean"==typeof n}function c(n){return"function"==typeof n}function p(n){return null!==n&&"object"==typeof n}var d=Object.prototype.toString;function u(n){return"[object Object]"===d.call(n)}function m(n){return"[object RegExp]"===d.call(n)}function g(n){var e=parseFloat(String(n));return e>=0&&Math.floor(e)===e&&isFinite(n)}function f(n){return s(n)&&"function"==typeof n.then&&"function"==typeof n.catch}function h(n){return null==n?"":Array.isArray(n)||u(n)&&n.toString===d?JSON.stringify(n,v,2):String(n)}function v(n,e){return e&&e.__v_isRef?e.value:e}function b(n){var e=parseFloat(n);return isNaN(e)?n:e}function _(n,e){for(var t=Object.create(null),r=n.split(","),o=0;o<r.length;o++)t[r[o]]=!0;return e?function(n){return t[n.toLowerCase()]}:function(n){return t[n]}}_("slot,component",!0);var y=_("key,ref,slot,slot-scope,is");function k(n,e){var t=n.length;if(t){if(e===n[t-1])return void(n.length=t-1);var r=n.indexOf(e);if(r>-1)return n.splice(r,1)}}var w=Object.prototype.hasOwnProperty;function E(n,e){return w.call(n,e)}function x(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var A=/-(\w)/g,B=x((function(n){return n.replace(A,(function(n,e){return e?e.toUpperCase():""}))})),z=x((function(n){return n.charAt(0).toUpperCase()+n.slice(1)})),j=/\B([A-Z])/g,T=x((function(n){return n.replace(j,"-$1").toLowerCase()}));var C=Function.prototype.bind?function(n,e){return n.bind(e)}:function(n,e){function t(t){var r=arguments.length;return r?r>1?n.apply(e,arguments):n.call(e,t):n.call(e)}return t._length=n.length,t};function S(n,e){e=e||0;for(var t=n.length-e,r=new Array(t);t--;)r[t]=n[t+e];return r}function P(n,e){for(var t in e)n[t]=e[t];return n}function I(n){for(var e={},t=0;t<n.length;t++)n[t]&&P(e,n[t]);return e}function q(n,e,t){}var D=function(n,e,t){return!1},N=function(n){return n};function O(n,e){if(n===e)return!0;var t=p(n),r=p(e);if(!t||!r)return!t&&!r&&String(n)===String(e);try{var o=Array.isArray(n),a=Array.isArray(e);if(o&&a)return n.length===e.length&&n.every((function(n,t){return O(n,e[t])}));if(n instanceof Date&&e instanceof Date)return n.getTime()===e.getTime();if(o||a)return!1;var s=Object.keys(n),i=Object.keys(e);return s.length===i.length&&s.every((function(t){return O(n[t],e[t])}))}catch(n){return!1}}function R(n,e){for(var t=0;t<n.length;t++)if(O(n[t],e))return t;return-1}function F(n){var e=!1;return function(){e||(e=!0,n.apply(this,arguments))}}function L(n,e){return n===e?0===n&&1/n!=1/e:n==n||e==e}var U=["component","directive","filter"],M=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch","renderTracked","renderTriggered"],G={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:D,isReservedAttr:D,isUnknownElement:D,getTagNamespace:q,parsePlatformTagName:N,mustUseProp:D,async:!0,_lifecycleHooks:M},V=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function $(n){var e=(n+"").charCodeAt(0);return 36===e||95===e}function W(n,e,t,r){Object.defineProperty(n,e,{value:t,enumerable:!!r,writable:!0,configurable:!0})}var H=new RegExp("[^".concat(V.source,".$_\\d]"));var Z="__proto__"in{},K="undefined"!=typeof window,X=K&&window.navigator.userAgent.toLowerCase(),J=X&&/msie|trident/.test(X),Y=X&&X.indexOf("msie 9.0")>0,Q=X&&X.indexOf("edge/")>0;X&&X.indexOf("android");var nn=X&&/iphone|ipad|ipod|ios/.test(X);X&&/chrome\/\d+/.test(X),X&&/phantomjs/.test(X);var en,tn=X&&X.match(/firefox\/(\d+)/),rn={}.watch,on=!1;if(K)try{var an={};Object.defineProperty(an,"passive",{get:function(){on=!0}}),window.addEventListener("test-passive",null,an)}catch(n){}var sn=function(){return void 0===en&&(en=!K&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),en},ln=K&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function cn(n){return"function"==typeof n&&/native code/.test(n.toString())}var pn,dn="undefined"!=typeof Symbol&&cn(Symbol)&&"undefined"!=typeof Reflect&&cn(Reflect.ownKeys);pn="undefined"!=typeof Set&&cn(Set)?Set:function(){function n(){this.set=Object.create(null)}return n.prototype.has=function(n){return!0===this.set[n]},n.prototype.add=function(n){this.set[n]=!0},n.prototype.clear=function(){this.set=Object.create(null)},n}();var un=null;function mn(n){void 0===n&&(n=null),n||un&&un._scope.off(),un=n,n&&n._scope.on()}var gn=function(){function n(n,e,t,r,o,a,s,i){this.tag=n,this.data=e,this.children=t,this.text=r,this.elm=o,this.ns=void 0,this.context=a,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=e&&e.key,this.componentOptions=s,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=i,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1}return Object.defineProperty(n.prototype,"child",{get:function(){return this.componentInstance},enumerable:!1,configurable:!0}),n}(),fn=function(n){void 0===n&&(n="");var e=new gn;return e.text=n,e.isComment=!0,e};function hn(n){return new gn(void 0,void 0,void 0,String(n))}function vn(n){var e=new gn(n.tag,n.data,n.children&&n.children.slice(),n.text,n.elm,n.context,n.componentOptions,n.asyncFactory);return e.ns=n.ns,e.isStatic=n.isStatic,e.key=n.key,e.isComment=n.isComment,e.fnContext=n.fnContext,e.fnOptions=n.fnOptions,e.fnScopeId=n.fnScopeId,e.asyncMeta=n.asyncMeta,e.isCloned=!0,e}"function"==typeof SuppressedError&&SuppressedError;var bn=0,_n=[],yn=function(){function n(){this._pending=!1,this.id=bn++,this.subs=[]}return n.prototype.addSub=function(n){this.subs.push(n)},n.prototype.removeSub=function(n){this.subs[this.subs.indexOf(n)]=null,this._pending||(this._pending=!0,_n.push(this))},n.prototype.depend=function(e){n.target&&n.target.addDep(this)},n.prototype.notify=function(n){var e=this.subs.filter((function(n){return n}));for(var t=0,r=e.length;t<r;t++){0,e[t].update()}},n}();yn.target=null;var kn=[];function wn(n){kn.push(n),yn.target=n}function En(){kn.pop(),yn.target=kn[kn.length-1]}var xn=Array.prototype,An=Object.create(xn);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(n){var e=xn[n];W(An,n,(function(){for(var t=[],r=0;r<arguments.length;r++)t[r]=arguments[r];var o,a=e.apply(this,t),s=this.__ob__;switch(n){case"push":case"unshift":o=t;break;case"splice":o=t.slice(2)}return o&&s.observeArray(o),s.dep.notify(),a}))}));var Bn=Object.getOwnPropertyNames(An),zn={},jn=!0;function Tn(n){jn=n}var Cn={notify:q,depend:q,addSub:q,removeSub:q},Sn=function(){function n(n,e,t){if(void 0===e&&(e=!1),void 0===t&&(t=!1),this.value=n,this.shallow=e,this.mock=t,this.dep=t?Cn:new yn,this.vmCount=0,W(n,"__ob__",this),o(n)){if(!t)if(Z)n.__proto__=An;else for(var r=0,a=Bn.length;r<a;r++){W(n,i=Bn[r],An[i])}e||this.observeArray(n)}else{var s=Object.keys(n);for(r=0;r<s.length;r++){var i;In(n,i=s[r],zn,void 0,e,t)}}}return n.prototype.observeArray=function(n){for(var e=0,t=n.length;e<t;e++)Pn(n[e],!1,this.mock)},n}();function Pn(n,e,t){return n&&E(n,"__ob__")&&n.__ob__ instanceof Sn?n.__ob__:!jn||!t&&sn()||!o(n)&&!u(n)||!Object.isExtensible(n)||n.__v_skip||Ln(n)||n instanceof gn?void 0:new Sn(n,e,t)}function In(n,e,t,r,a,s,i){void 0===i&&(i=!1);var l=new yn,c=Object.getOwnPropertyDescriptor(n,e);if(!c||!1!==c.configurable){var p=c&&c.get,d=c&&c.set;p&&!d||t!==zn&&2!==arguments.length||(t=n[e]);var u=a?t&&t.__ob__:Pn(t,!1,s);return Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){var e=p?p.call(n):t;return yn.target&&(l.depend(),u&&(u.dep.depend(),o(e)&&Nn(e))),Ln(e)&&!a?e.value:e},set:function(e){var r=p?p.call(n):t;if(L(r,e)){if(d)d.call(n,e);else{if(p)return;if(!a&&Ln(r)&&!Ln(e))return void(r.value=e);t=e}u=a?e&&e.__ob__:Pn(e,!1,s),l.notify()}}}),l}}function qn(n,e,t){if(!Fn(n)){var r=n.__ob__;return o(n)&&g(e)?(n.length=Math.max(n.length,e),n.splice(e,1,t),r&&!r.shallow&&r.mock&&Pn(t,!1,!0),t):e in n&&!(e in Object.prototype)?(n[e]=t,t):n._isVue||r&&r.vmCount?t:r?(In(r.value,e,t,void 0,r.shallow,r.mock),r.dep.notify(),t):(n[e]=t,t)}}function Dn(n,e){if(o(n)&&g(e))n.splice(e,1);else{var t=n.__ob__;n._isVue||t&&t.vmCount||Fn(n)||E(n,e)&&(delete n[e],t&&t.dep.notify())}}function Nn(n){for(var e=void 0,t=0,r=n.length;t<r;t++)(e=n[t])&&e.__ob__&&e.__ob__.dep.depend(),o(e)&&Nn(e)}function On(n){return Rn(n,!0),W(n,"__v_isShallow",!0),n}function Rn(n,e){if(!Fn(n)){Pn(n,e,sn());0}}function Fn(n){return!(!n||!n.__v_isReadonly)}function Ln(n){return!(!n||!0!==n.__v_isRef)}function Un(n,e,t){Object.defineProperty(n,t,{enumerable:!0,configurable:!0,get:function(){var n=e[t];if(Ln(n))return n.value;var r=n&&n.__ob__;return r&&r.dep.depend(),n},set:function(n){var r=e[t];Ln(r)&&!Ln(n)?r.value=n:e[t]=n}})}"".concat("watcher"," callback"),"".concat("watcher"," getter"),"".concat("watcher"," cleanup");var Mn;var Gn=function(){function n(n){void 0===n&&(n=!1),this.detached=n,this.active=!0,this.effects=[],this.cleanups=[],this.parent=Mn,!n&&Mn&&(this.index=(Mn.scopes||(Mn.scopes=[])).push(this)-1)}return n.prototype.run=function(n){if(this.active){var e=Mn;try{return Mn=this,n()}finally{Mn=e}}else 0},n.prototype.on=function(){Mn=this},n.prototype.off=function(){Mn=this.parent},n.prototype.stop=function(n){if(this.active){var e=void 0,t=void 0;for(e=0,t=this.effects.length;e<t;e++)this.effects[e].teardown();for(e=0,t=this.cleanups.length;e<t;e++)this.cleanups[e]();if(this.scopes)for(e=0,t=this.scopes.length;e<t;e++)this.scopes[e].stop(!0);if(!this.detached&&this.parent&&!n){var r=this.parent.scopes.pop();r&&r!==this&&(this.parent.scopes[this.index]=r,r.index=this.index)}this.parent=void 0,this.active=!1}},n}();function Vn(n){var e=n._provided,t=n.$parent&&n.$parent._provided;return t===e?n._provided=Object.create(t):e}var $n=x((function(n){var e="&"===n.charAt(0),t="~"===(n=e?n.slice(1):n).charAt(0),r="!"===(n=t?n.slice(1):n).charAt(0);return{name:n=r?n.slice(1):n,once:t,capture:r,passive:e}}));function Wn(n,e){function t(){var n=t.fns;if(!o(n))return je(n,null,arguments,e,"v-on handler");for(var r=n.slice(),a=0;a<r.length;a++)je(r[a],null,arguments,e,"v-on handler")}return t.fns=n,t}function Hn(n,e,t,r,o,s){var l,c,p,d;for(l in n)c=n[l],p=e[l],d=$n(l),a(c)||(a(p)?(a(c.fns)&&(c=n[l]=Wn(c,s)),i(d.once)&&(c=n[l]=o(d.name,c,d.capture)),t(d.name,c,d.capture,d.passive,d.params)):c!==p&&(p.fns=c,n[l]=p));for(l in e)a(n[l])&&r((d=$n(l)).name,e[l],d.capture)}function Zn(n,e,t){var r;n instanceof gn&&(n=n.data.hook||(n.data.hook={}));var o=n[e];function l(){t.apply(this,arguments),k(r.fns,l)}a(o)?r=Wn([l]):s(o.fns)&&i(o.merged)?(r=o).fns.push(l):r=Wn([o,l]),r.merged=!0,n[e]=r}function Kn(n,e,t,r,o){if(s(e)){if(E(e,t))return n[t]=e[t],o||delete e[t],!0;if(E(e,r))return n[t]=e[r],o||delete e[r],!0}return!1}function Xn(n){return l(n)?[hn(n)]:o(n)?function n(e,t){var r,c,p,d,u=[];for(r=0;r<e.length;r++)a(c=e[r])||"boolean"==typeof c||(p=u.length-1,d=u[p],o(c)?c.length>0&&(Jn((c=n(c,"".concat(t||"","_").concat(r)))[0])&&Jn(d)&&(u[p]=hn(d.text+c[0].text),c.shift()),u.push.apply(u,c)):l(c)?Jn(d)?u[p]=hn(d.text+c):""!==c&&u.push(hn(c)):Jn(c)&&Jn(d)?u[p]=hn(d.text+c.text):(i(e._isVList)&&s(c.tag)&&a(c.key)&&s(t)&&(c.key="__vlist".concat(t,"_").concat(r,"__")),u.push(c)));return u}(n):void 0}function Jn(n){return s(n)&&s(n.text)&&!1===n.isComment}function Yn(n,e){var t,r,a,i,l=null;if(o(n)||"string"==typeof n)for(l=new Array(n.length),t=0,r=n.length;t<r;t++)l[t]=e(n[t],t);else if("number"==typeof n)for(l=new Array(n),t=0;t<n;t++)l[t]=e(t+1,t);else if(p(n))if(dn&&n[Symbol.iterator]){l=[];for(var c=n[Symbol.iterator](),d=c.next();!d.done;)l.push(e(d.value,l.length)),d=c.next()}else for(a=Object.keys(n),l=new Array(a.length),t=0,r=a.length;t<r;t++)i=a[t],l[t]=e(n[i],i,t);return s(l)||(l=[]),l._isVList=!0,l}function Qn(n,e,t,r){var o,a=this.$scopedSlots[n];a?(t=t||{},r&&(t=P(P({},r),t)),o=a(t)||(c(e)?e():e)):o=this.$slots[n]||(c(e)?e():e);var s=t&&t.slot;return s?this.$createElement("template",{slot:s},o):o}function ne(n){return St(this.$options,"filters",n,!0)||N}function ee(n,e){return o(n)?-1===n.indexOf(e):n!==e}function te(n,e,t,r,o){var a=G.keyCodes[e]||t;return o&&r&&!G.keyCodes[e]?ee(o,r):a?ee(a,n):r?T(r)!==e:void 0===n}function re(n,e,t,r,a){if(t)if(p(t)){o(t)&&(t=I(t));var s=void 0,i=function(o){if("class"===o||"style"===o||y(o))s=n;else{var i=n.attrs&&n.attrs.type;s=r||G.mustUseProp(e,i,o)?n.domProps||(n.domProps={}):n.attrs||(n.attrs={})}var l=B(o),c=T(o);l in s||c in s||(s[o]=t[o],a&&((n.on||(n.on={}))["update:".concat(o)]=function(n){t[o]=n}))};for(var l in t)i(l)}else;return n}function oe(n,e){var t=this._staticTrees||(this._staticTrees=[]),r=t[n];return r&&!e||se(r=t[n]=this.$options.staticRenderFns[n].call(this._renderProxy,this._c,this),"__static__".concat(n),!1),r}function ae(n,e,t){return se(n,"__once__".concat(e).concat(t?"_".concat(t):""),!0),n}function se(n,e,t){if(o(n))for(var r=0;r<n.length;r++)n[r]&&"string"!=typeof n[r]&&ie(n[r],"".concat(e,"_").concat(r),t);else ie(n,e,t)}function ie(n,e,t){n.isStatic=!0,n.key=e,n.isOnce=t}function le(n,e){if(e)if(u(e)){var t=n.on=n.on?P({},n.on):{};for(var r in e){var o=t[r],a=e[r];t[r]=o?[].concat(o,a):a}}else;return n}function ce(n,e,t,r){e=e||{$stable:!t};for(var a=0;a<n.length;a++){var s=n[a];o(s)?ce(s,e,t):s&&(s.proxy&&(s.fn.proxy=!0),e[s.key]=s.fn)}return r&&(e.$key=r),e}function pe(n,e){for(var t=0;t<e.length;t+=2){var r=e[t];"string"==typeof r&&r&&(n[e[t]]=e[t+1])}return n}function de(n,e){return"string"==typeof n?e+n:n}function ue(n){n._o=ae,n._n=b,n._s=h,n._l=Yn,n._t=Qn,n._q=O,n._i=R,n._m=oe,n._f=ne,n._k=te,n._b=re,n._v=hn,n._e=fn,n._u=ce,n._g=le,n._d=pe,n._p=de}function me(n,e){if(!n||!n.length)return{};for(var t={},r=0,o=n.length;r<o;r++){var a=n[r],s=a.data;if(s&&s.attrs&&s.attrs.slot&&delete s.attrs.slot,a.context!==e&&a.fnContext!==e||!s||null==s.slot)(t.default||(t.default=[])).push(a);else{var i=s.slot,l=t[i]||(t[i]=[]);"template"===a.tag?l.push.apply(l,a.children||[]):l.push(a)}}for(var c in t)t[c].every(ge)&&delete t[c];return t}function ge(n){return n.isComment&&!n.asyncFactory||" "===n.text}function fe(n){return n.isComment&&n.asyncFactory}function he(n,e,t,o){var a,s=Object.keys(t).length>0,i=e?!!e.$stable:!s,l=e&&e.$key;if(e){if(e._normalized)return e._normalized;if(i&&o&&o!==r&&l===o.$key&&!s&&!o.$hasNormal)return o;for(var c in a={},e)e[c]&&"$"!==c[0]&&(a[c]=ve(n,t,c,e[c]))}else a={};for(var p in t)p in a||(a[p]=be(t,p));return e&&Object.isExtensible(e)&&(e._normalized=a),W(a,"$stable",i),W(a,"$key",l),W(a,"$hasNormal",s),a}function ve(n,e,t,r){var a=function(){var e=un;mn(n);var t=arguments.length?r.apply(null,arguments):r({}),a=(t=t&&"object"==typeof t&&!o(t)?[t]:Xn(t))&&t[0];return mn(e),t&&(!a||1===t.length&&a.isComment&&!fe(a))?void 0:t};return r.proxy&&Object.defineProperty(e,t,{get:a,enumerable:!0,configurable:!0}),a}function be(n,e){return function(){return n[e]}}function _e(n){return{get attrs(){if(!n._attrsProxy){var e=n._attrsProxy={};W(e,"_v_attr_proxy",!0),ye(e,n.$attrs,r,n,"$attrs")}return n._attrsProxy},get listeners(){n._listenersProxy||ye(n._listenersProxy={},n.$listeners,r,n,"$listeners");return n._listenersProxy},get slots(){return function(n){n._slotsProxy||we(n._slotsProxy={},n.$scopedSlots);return n._slotsProxy}(n)},emit:C(n.$emit,n),expose:function(e){e&&Object.keys(e).forEach((function(t){return Un(n,e,t)}))}}}function ye(n,e,t,r,o){var a=!1;for(var s in e)s in n?e[s]!==t[s]&&(a=!0):(a=!0,ke(n,s,r,o));for(var s in n)s in e||(a=!0,delete n[s]);return a}function ke(n,e,t,r){Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){return t[r][e]}})}function we(n,e){for(var t in e)n[t]=e[t];for(var t in n)t in e||delete n[t]}var Ee=null;function xe(n,e){return(n.__esModule||dn&&"Module"===n[Symbol.toStringTag])&&(n=n.default),p(n)?e.extend(n):n}function Ae(n){if(o(n))for(var e=0;e<n.length;e++){var t=n[e];if(s(t)&&(s(t.componentOptions)||fe(t)))return t}}function Be(n,e,t,r,d,u){return(o(t)||l(t))&&(d=r,r=t,t=void 0),i(u)&&(d=2),function(n,e,t,r,l){if(s(t)&&s(t.__ob__))return fn();s(t)&&s(t.is)&&(e=t.is);if(!e)return fn();0;o(r)&&c(r[0])&&((t=t||{}).scopedSlots={default:r[0]},r.length=0);2===l?r=Xn(r):1===l&&(r=function(n){for(var e=0;e<n.length;e++)if(o(n[e]))return Array.prototype.concat.apply([],n);return n}(r));var d,u;if("string"==typeof e){var m=void 0;u=n.$vnode&&n.$vnode.ns||G.getTagNamespace(e),d=G.isReservedTag(e)?new gn(G.parsePlatformTagName(e),t,r,void 0,void 0,n):t&&t.pre||!s(m=St(n.$options,"components",e))?new gn(e,t,r,void 0,void 0,n):kt(m,t,n,r,e)}else d=kt(e,t,n,r);return o(d)?d:s(d)?(s(u)&&function n(e,t,r){e.ns=t,"foreignObject"===e.tag&&(t=void 0,r=!0);if(s(e.children))for(var o=0,l=e.children.length;o<l;o++){var c=e.children[o];s(c.tag)&&(a(c.ns)||i(r)&&"svg"!==c.tag)&&n(c,t,r)}}(d,u),s(t)&&function(n){p(n.style)&&Ge(n.style);p(n.class)&&Ge(n.class)}(t),d):fn()}(n,e,t,r,d)}function ze(n,e,t){wn();try{if(e)for(var r=e;r=r.$parent;){var o=r.$options.errorCaptured;if(o)for(var a=0;a<o.length;a++)try{if(!1===o[a].call(r,n,e,t))return}catch(n){Te(n,r,"errorCaptured hook")}}Te(n,e,t)}finally{En()}}function je(n,e,t,r,o){var a;try{(a=t?n.apply(e,t):n.call(e))&&!a._isVue&&f(a)&&!a._handled&&(a.catch((function(n){return ze(n,r,o+" (Promise/async)")})),a._handled=!0)}catch(n){ze(n,r,o)}return a}function Te(n,e,t){if(G.errorHandler)try{return G.errorHandler.call(null,n,e,t)}catch(e){e!==n&&Ce(e,null,"config.errorHandler")}Ce(n,e,t)}function Ce(n,e,t){if(!K||"undefined"==typeof console)throw n;console.error(n)}var Se,Pe=!1,Ie=[],qe=!1;function De(){qe=!1;var n=Ie.slice(0);Ie.length=0;for(var e=0;e<n.length;e++)n[e]()}if("undefined"!=typeof Promise&&cn(Promise)){var Ne=Promise.resolve();Se=function(){Ne.then(De),nn&&setTimeout(q)},Pe=!0}else if(J||"undefined"==typeof MutationObserver||!cn(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())Se="undefined"!=typeof setImmediate&&cn(setImmediate)?function(){setImmediate(De)}:function(){setTimeout(De,0)};else{var Oe=1,Re=new MutationObserver(De),Fe=document.createTextNode(String(Oe));Re.observe(Fe,{characterData:!0}),Se=function(){Oe=(Oe+1)%2,Fe.data=String(Oe)},Pe=!0}function Le(n,e){var t;if(Ie.push((function(){if(n)try{n.call(e)}catch(n){ze(n,e,"nextTick")}else t&&t(e)})),qe||(qe=!0,Se()),!n&&"undefined"!=typeof Promise)return new Promise((function(n){t=n}))}function Ue(n){return function(e,t){if(void 0===t&&(t=un),t)return function(n,e,t){var r=n.$options;r[e]=zt(r[e],t)}(t,n,e)}}Ue("beforeMount"),Ue("mounted"),Ue("beforeUpdate"),Ue("updated"),Ue("beforeDestroy"),Ue("destroyed"),Ue("activated"),Ue("deactivated"),Ue("serverPrefetch"),Ue("renderTracked"),Ue("renderTriggered"),Ue("errorCaptured");var Me=new pn;function Ge(n){return function n(e,t){var r,a,s=o(e);if(!s&&!p(e)||e.__v_skip||Object.isFrozen(e)||e instanceof gn)return;if(e.__ob__){var i=e.__ob__.dep.id;if(t.has(i))return;t.add(i)}if(s)for(r=e.length;r--;)n(e[r],t);else if(Ln(e))n(e.value,t);else for(a=Object.keys(e),r=a.length;r--;)n(e[a[r]],t)}(n,Me),Me.clear(),n}var Ve,$e=0,We=function(){function n(n,e,t,r,o){var a,s;a=this,void 0===(s=Mn&&!Mn._vm?Mn:n?n._scope:void 0)&&(s=Mn),s&&s.active&&s.effects.push(a),(this.vm=n)&&o&&(n._watcher=this),r?(this.deep=!!r.deep,this.user=!!r.user,this.lazy=!!r.lazy,this.sync=!!r.sync,this.before=r.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++$e,this.active=!0,this.post=!1,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new pn,this.newDepIds=new pn,this.expression="",c(e)?this.getter=e:(this.getter=function(n){if(!H.test(n)){var e=n.split(".");return function(n){for(var t=0;t<e.length;t++){if(!n)return;n=n[e[t]]}return n}}}(e),this.getter||(this.getter=q)),this.value=this.lazy?void 0:this.get()}return n.prototype.get=function(){var n;wn(this);var e=this.vm;try{n=this.getter.call(e,e)}catch(n){if(!this.user)throw n;ze(n,e,'getter for watcher "'.concat(this.expression,'"'))}finally{this.deep&&Ge(n),En(),this.cleanupDeps()}return n},n.prototype.addDep=function(n){var e=n.id;this.newDepIds.has(e)||(this.newDepIds.add(e),this.newDeps.push(n),this.depIds.has(e)||n.addSub(this))},n.prototype.cleanupDeps=function(){for(var n=this.deps.length;n--;){var e=this.deps[n];this.newDepIds.has(e.id)||e.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},n.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():mt(this)},n.prototype.run=function(){if(this.active){var n=this.get();if(n!==this.value||p(n)||this.deep){var e=this.value;if(this.value=n,this.user){var t='callback for watcher "'.concat(this.expression,'"');je(this.cb,this.vm,[n,e],this.vm,t)}else this.cb.call(this.vm,n,e)}}},n.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},n.prototype.depend=function(){for(var n=this.deps.length;n--;)this.deps[n].depend()},n.prototype.teardown=function(){if(this.vm&&!this.vm._isBeingDestroyed&&k(this.vm._scope.effects,this),this.active){for(var n=this.deps.length;n--;)this.deps[n].removeSub(this);this.active=!1,this.onStop&&this.onStop()}},n}();function He(n,e){Ve.$on(n,e)}function Ze(n,e){Ve.$off(n,e)}function Ke(n,e){var t=Ve;return function r(){var o=e.apply(null,arguments);null!==o&&t.$off(n,r)}}function Xe(n,e,t){Ve=n,Hn(e,t||{},He,Ze,Ke,n),Ve=void 0}var Je=null;function Ye(n){var e=Je;return Je=n,function(){Je=e}}function Qe(n){for(;n&&(n=n.$parent);)if(n._inactive)return!0;return!1}function nt(n,e){if(e){if(n._directInactive=!1,Qe(n))return}else if(n._directInactive)return;if(n._inactive||null===n._inactive){n._inactive=!1;for(var t=0;t<n.$children.length;t++)nt(n.$children[t]);et(n,"activated")}}function et(n,e,t,r){void 0===r&&(r=!0),wn();var o=un,a=Mn;r&&mn(n);var s=n.$options[e],i="".concat(e," hook");if(s)for(var l=0,c=s.length;l<c;l++)je(s[l],n,t||null,n,i);n._hasHookEvent&&n.$emit("hook:"+e),r&&(mn(o),a&&a.on()),En()}var tt=[],rt=[],ot={},at=!1,st=!1,it=0;var lt=0,ct=Date.now;if(K&&!J){var pt=window.performance;pt&&"function"==typeof pt.now&&ct()>document.createEvent("Event").timeStamp&&(ct=function(){return pt.now()})}var dt=function(n,e){if(n.post){if(!e.post)return 1}else if(e.post)return-1;return n.id-e.id};function ut(){var n,e;for(lt=ct(),st=!0,tt.sort(dt),it=0;it<tt.length;it++)(n=tt[it]).before&&n.before(),e=n.id,ot[e]=null,n.run();var t=rt.slice(),r=tt.slice();it=tt.length=rt.length=0,ot={},at=st=!1,function(n){for(var e=0;e<n.length;e++)n[e]._inactive=!0,nt(n[e],!0)}(t),function(n){var e=n.length;for(;e--;){var t=n[e],r=t.vm;r&&r._watcher===t&&r._isMounted&&!r._isDestroyed&&et(r,"updated")}}(r),function(){for(var n=0;n<_n.length;n++){var e=_n[n];e.subs=e.subs.filter((function(n){return n})),e._pending=!1}_n.length=0}(),ln&&G.devtools&&ln.emit("flush")}function mt(n){var e=n.id;if(null==ot[e]&&(n!==yn.target||!n.noRecurse)){if(ot[e]=!0,st){for(var t=tt.length-1;t>it&&tt[t].id>n.id;)t--;tt.splice(t+1,0,n)}else tt.push(n);at||(at=!0,Le(ut))}}function gt(n,e){if(n){for(var t=Object.create(null),r=dn?Reflect.ownKeys(n):Object.keys(n),o=0;o<r.length;o++){var a=r[o];if("__ob__"!==a){var s=n[a].from;if(s in e._provided)t[a]=e._provided[s];else if("default"in n[a]){var i=n[a].default;t[a]=c(i)?i.call(e):i}else 0}}return t}}function ft(n,e,t,a,s){var l,c=this,p=s.options;E(a,"_uid")?(l=Object.create(a))._original=a:(l=a,a=a._original);var d=i(p._compiled),u=!d;this.data=n,this.props=e,this.children=t,this.parent=a,this.listeners=n.on||r,this.injections=gt(p.inject,a),this.slots=function(){return c.$slots||he(a,n.scopedSlots,c.$slots=me(t,a)),c.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return he(a,n.scopedSlots,this.slots())}}),d&&(this.$options=p,this.$slots=this.slots(),this.$scopedSlots=he(a,n.scopedSlots,this.$slots)),p._scopeId?this._c=function(n,e,t,r){var s=Be(l,n,e,t,r,u);return s&&!o(s)&&(s.fnScopeId=p._scopeId,s.fnContext=a),s}:this._c=function(n,e,t,r){return Be(l,n,e,t,r,u)}}function ht(n,e,t,r,o){var a=vn(n);return a.fnContext=t,a.fnOptions=r,e.slot&&((a.data||(a.data={})).slot=e.slot),a}function vt(n,e){for(var t in e)n[B(t)]=e[t]}function bt(n){return n.name||n.__name||n._componentTag}ue(ft.prototype);var _t={init:function(n,e){if(n.componentInstance&&!n.componentInstance._isDestroyed&&n.data.keepAlive){var t=n;_t.prepatch(t,t)}else{(n.componentInstance=function(n,e){var t={_isComponent:!0,_parentVnode:n,parent:e},r=n.data.inlineTemplate;s(r)&&(t.render=r.render,t.staticRenderFns=r.staticRenderFns);return new n.componentOptions.Ctor(t)}(n,Je)).$mount(e?n.elm:void 0,e)}},prepatch:function(n,e){var t=e.componentOptions;!function(n,e,t,o,a){var s=o.data.scopedSlots,i=n.$scopedSlots,l=!!(s&&!s.$stable||i!==r&&!i.$stable||s&&n.$scopedSlots.$key!==s.$key||!s&&n.$scopedSlots.$key),c=!!(a||n.$options._renderChildren||l),p=n.$vnode;n.$options._parentVnode=o,n.$vnode=o,n._vnode&&(n._vnode.parent=o),n.$options._renderChildren=a;var d=o.data.attrs||r;n._attrsProxy&&ye(n._attrsProxy,d,p.data&&p.data.attrs||r,n,"$attrs")&&(c=!0),n.$attrs=d,t=t||r;var u=n.$options._parentListeners;if(n._listenersProxy&&ye(n._listenersProxy,t,u||r,n,"$listeners"),n.$listeners=n.$options._parentListeners=t,Xe(n,t,u),e&&n.$options.props){Tn(!1);for(var m=n._props,g=n.$options._propKeys||[],f=0;f<g.length;f++){var h=g[f],v=n.$options.props;m[h]=Pt(h,v,e,n)}Tn(!0),n.$options.propsData=e}c&&(n.$slots=me(a,o.context),n.$forceUpdate())}(e.componentInstance=n.componentInstance,t.propsData,t.listeners,e,t.children)},insert:function(n){var e,t=n.context,r=n.componentInstance;r._isMounted||(r._isMounted=!0,et(r,"mounted")),n.data.keepAlive&&(t._isMounted?((e=r)._inactive=!1,rt.push(e)):nt(r,!0))},destroy:function(n){var e=n.componentInstance;e._isDestroyed||(n.data.keepAlive?function n(e,t){if(!(t&&(e._directInactive=!0,Qe(e))||e._inactive)){e._inactive=!0;for(var r=0;r<e.$children.length;r++)n(e.$children[r]);et(e,"deactivated")}}(e,!0):e.$destroy())}},yt=Object.keys(_t);function kt(n,e,t,l,c){if(!a(n)){var d=t.$options._base;if(p(n)&&(n=d.extend(n)),"function"==typeof n){var u;if(a(n.cid)&&void 0===(n=function(n,e){if(i(n.error)&&s(n.errorComp))return n.errorComp;if(s(n.resolved))return n.resolved;var t=Ee;if(t&&s(n.owners)&&-1===n.owners.indexOf(t)&&n.owners.push(t),i(n.loading)&&s(n.loadingComp))return n.loadingComp;if(t&&!s(n.owners)){var r=n.owners=[t],o=!0,l=null,c=null;t.$on("hook:destroyed",(function(){return k(r,t)}));var d=function(n){for(var e=0,t=r.length;e<t;e++)r[e].$forceUpdate();n&&(r.length=0,null!==l&&(clearTimeout(l),l=null),null!==c&&(clearTimeout(c),c=null))},u=F((function(t){n.resolved=xe(t,e),o?r.length=0:d(!0)})),m=F((function(e){s(n.errorComp)&&(n.error=!0,d(!0))})),g=n(u,m);return p(g)&&(f(g)?a(n.resolved)&&g.then(u,m):f(g.component)&&(g.component.then(u,m),s(g.error)&&(n.errorComp=xe(g.error,e)),s(g.loading)&&(n.loadingComp=xe(g.loading,e),0===g.delay?n.loading=!0:l=setTimeout((function(){l=null,a(n.resolved)&&a(n.error)&&(n.loading=!0,d(!1))}),g.delay||200)),s(g.timeout)&&(c=setTimeout((function(){c=null,a(n.resolved)&&m(null)}),g.timeout)))),o=!1,n.loading?n.loadingComp:n.resolved}}(u=n,d)))return function(n,e,t,r,o){var a=fn();return a.asyncFactory=n,a.asyncMeta={data:e,context:t,children:r,tag:o},a}(u,e,t,l,c);e=e||{},Wt(n),s(e.model)&&function(n,e){var t=n.model&&n.model.prop||"value",r=n.model&&n.model.event||"input";(e.attrs||(e.attrs={}))[t]=e.model.value;var a=e.on||(e.on={}),i=a[r],l=e.model.callback;s(i)?(o(i)?-1===i.indexOf(l):i!==l)&&(a[r]=[l].concat(i)):a[r]=l}(n.options,e);var m=function(n,e,t){var r=e.options.props;if(!a(r)){var o={},i=n.attrs,l=n.props;if(s(i)||s(l))for(var c in r){var p=T(c);Kn(o,l,c,p,!0)||Kn(o,i,c,p,!1)}return o}}(e,n);if(i(n.options.functional))return function(n,e,t,a,i){var l=n.options,c={},p=l.props;if(s(p))for(var d in p)c[d]=Pt(d,p,e||r);else s(t.attrs)&&vt(c,t.attrs),s(t.props)&&vt(c,t.props);var u=new ft(t,c,i,a,n),m=l.render.call(null,u._c,u);if(m instanceof gn)return ht(m,t,u.parent,l,u);if(o(m)){for(var g=Xn(m)||[],f=new Array(g.length),h=0;h<g.length;h++)f[h]=ht(g[h],t,u.parent,l,u);return f}}(n,m,e,t,l);var g=e.on;if(e.on=e.nativeOn,i(n.options.abstract)){var h=e.slot;e={},h&&(e.slot=h)}!function(n){for(var e=n.hook||(n.hook={}),t=0;t<yt.length;t++){var r=yt[t],o=e[r],a=_t[r];o===a||o&&o._merged||(e[r]=o?wt(a,o):a)}}(e);var v=bt(n.options)||c;return new gn("vue-component-".concat(n.cid).concat(v?"-".concat(v):""),e,void 0,void 0,void 0,t,{Ctor:n,propsData:m,listeners:g,tag:c,children:l},u)}}}function wt(n,e){var t=function(t,r){n(t,r),e(t,r)};return t._merged=!0,t}var Et=q,xt=G.optionMergeStrategies;function At(n,e,t){if(void 0===t&&(t=!0),!e)return n;for(var r,o,a,s=dn?Reflect.ownKeys(e):Object.keys(e),i=0;i<s.length;i++)"__ob__"!==(r=s[i])&&(o=n[r],a=e[r],t&&E(n,r)?o!==a&&u(o)&&u(a)&&At(o,a):qn(n,r,a));return n}function Bt(n,e,t){return t?function(){var r=c(e)?e.call(t,t):e,o=c(n)?n.call(t,t):n;return r?At(r,o):o}:e?n?function(){return At(c(e)?e.call(this,this):e,c(n)?n.call(this,this):n)}:e:n}function zt(n,e){var t=e?n?n.concat(e):o(e)?e:[e]:n;return t?function(n){for(var e=[],t=0;t<n.length;t++)-1===e.indexOf(n[t])&&e.push(n[t]);return e}(t):t}function jt(n,e,t,r){var o=Object.create(n||null);return e?P(o,e):o}xt.data=function(n,e,t){return t?Bt(n,e,t):e&&"function"!=typeof e?n:Bt(n,e)},M.forEach((function(n){xt[n]=zt})),U.forEach((function(n){xt[n+"s"]=jt})),xt.watch=function(n,e,t,r){if(n===rn&&(n=void 0),e===rn&&(e=void 0),!e)return Object.create(n||null);if(!n)return e;var a={};for(var s in P(a,n),e){var i=a[s],l=e[s];i&&!o(i)&&(i=[i]),a[s]=i?i.concat(l):o(l)?l:[l]}return a},xt.props=xt.methods=xt.inject=xt.computed=function(n,e,t,r){if(!n)return e;var o=Object.create(null);return P(o,n),e&&P(o,e),o},xt.provide=function(n,e){return n?function(){var t=Object.create(null);return At(t,c(n)?n.call(this):n),e&&At(t,c(e)?e.call(this):e,!1),t}:e};var Tt=function(n,e){return void 0===e?n:e};function Ct(n,e,t){if(c(e)&&(e=e.options),function(n,e){var t=n.props;if(t){var r,a,s={};if(o(t))for(r=t.length;r--;)"string"==typeof(a=t[r])&&(s[B(a)]={type:null});else if(u(t))for(var i in t)a=t[i],s[B(i)]=u(a)?a:{type:a};else 0;n.props=s}}(e),function(n,e){var t=n.inject;if(t){var r=n.inject={};if(o(t))for(var a=0;a<t.length;a++)r[t[a]]={from:t[a]};else if(u(t))for(var s in t){var i=t[s];r[s]=u(i)?P({from:s},i):{from:i}}else 0}}(e),function(n){var e=n.directives;if(e)for(var t in e){var r=e[t];c(r)&&(e[t]={bind:r,update:r})}}(e),!e._base&&(e.extends&&(n=Ct(n,e.extends,t)),e.mixins))for(var r=0,a=e.mixins.length;r<a;r++)n=Ct(n,e.mixins[r],t);var s,i={};for(s in n)l(s);for(s in e)E(n,s)||l(s);function l(r){var o=xt[r]||Tt;i[r]=o(n[r],e[r],t,r)}return i}function St(n,e,t,r){if("string"==typeof t){var o=n[e];if(E(o,t))return o[t];var a=B(t);if(E(o,a))return o[a];var s=z(a);return E(o,s)?o[s]:o[t]||o[a]||o[s]}}function Pt(n,e,t,r){var o=e[n],a=!E(t,n),s=t[n],i=Nt(Boolean,o.type);if(i>-1)if(a&&!E(o,"default"))s=!1;else if(""===s||s===T(n)){var l=Nt(String,o.type);(l<0||i<l)&&(s=!0)}if(void 0===s){s=function(n,e,t){if(!E(e,"default"))return;var r=e.default;0;if(n&&n.$options.propsData&&void 0===n.$options.propsData[t]&&void 0!==n._props[t])return n._props[t];return c(r)&&"Function"!==qt(e.type)?r.call(n):r}(r,o,n);var p=jn;Tn(!0),Pn(s),Tn(p)}return s}var It=/^\s*function (\w+)/;function qt(n){var e=n&&n.toString().match(It);return e?e[1]:""}function Dt(n,e){return qt(n)===qt(e)}function Nt(n,e){if(!o(e))return Dt(e,n)?0:-1;for(var t=0,r=e.length;t<r;t++)if(Dt(e[t],n))return t;return-1}var Ot={enumerable:!0,configurable:!0,get:q,set:q};function Rt(n,e,t){Ot.get=function(){return this[e][t]},Ot.set=function(n){this[e][t]=n},Object.defineProperty(n,t,Ot)}function Ft(n){var e=n.$options;if(e.props&&function(n,e){var t=n.$options.propsData||{},r=n._props=On({}),o=n.$options._propKeys=[];n.$parent&&Tn(!1);var a=function(a){o.push(a);var s=Pt(a,e,t,n);In(r,a,s,void 0,!0),a in n||Rt(n,"_props",a)};for(var s in e)a(s);Tn(!0)}(n,e.props),function(n){var e=n.$options,t=e.setup;if(t){var r=n._setupContext=_e(n);mn(n),wn();var o=je(t,null,[n._props||On({}),r],n,"setup");if(En(),mn(),c(o))e.render=o;else if(p(o))if(n._setupState=o,o.__sfc){var a=n._setupProxy={};for(var s in o)"__sfc"!==s&&Un(a,o,s)}else for(var s in o)$(s)||Un(n,o,s);else 0}}(n),e.methods&&function(n,e){n.$options.props;for(var t in e)n[t]="function"!=typeof e[t]?q:C(e[t],n)}(n,e.methods),e.data)!function(n){var e=n.$options.data;u(e=n._data=c(e)?function(n,e){wn();try{return n.call(e,e)}catch(n){return ze(n,e,"data()"),{}}finally{En()}}(e,n):e||{})||(e={});var t=Object.keys(e),r=n.$options.props,o=(n.$options.methods,t.length);for(;o--;){var a=t[o];0,r&&E(r,a)||$(a)||Rt(n,"_data",a)}var s=Pn(e);s&&s.vmCount++}(n);else{var t=Pn(n._data={});t&&t.vmCount++}e.computed&&function(n,e){var t=n._computedWatchers=Object.create(null),r=sn();for(var o in e){var a=e[o],s=c(a)?a:a.get;0,r||(t[o]=new We(n,s||q,q,Lt)),o in n||Ut(n,o,a)}}(n,e.computed),e.watch&&e.watch!==rn&&function(n,e){for(var t in e){var r=e[t];if(o(r))for(var a=0;a<r.length;a++)Vt(n,t,r[a]);else Vt(n,t,r)}}(n,e.watch)}var Lt={lazy:!0};function Ut(n,e,t){var r=!sn();c(t)?(Ot.get=r?Mt(e):Gt(t),Ot.set=q):(Ot.get=t.get?r&&!1!==t.cache?Mt(e):Gt(t.get):q,Ot.set=t.set||q),Object.defineProperty(n,e,Ot)}function Mt(n){return function(){var e=this._computedWatchers&&this._computedWatchers[n];if(e)return e.dirty&&e.evaluate(),yn.target&&e.depend(),e.value}}function Gt(n){return function(){return n.call(this,this)}}function Vt(n,e,t,r){return u(t)&&(r=t,t=t.handler),"string"==typeof t&&(t=n[t]),n.$watch(e,t,r)}var $t=0;function Wt(n){var e=n.options;if(n.super){var t=Wt(n.super);if(t!==n.superOptions){n.superOptions=t;var r=function(n){var e,t=n.options,r=n.sealedOptions;for(var o in t)t[o]!==r[o]&&(e||(e={}),e[o]=t[o]);return e}(n);r&&P(n.extendOptions,r),(e=n.options=Ct(t,n.extendOptions)).name&&(e.components[e.name]=n)}}return e}function Ht(n){this._init(n)}function Zt(n){n.cid=0;var e=1;n.extend=function(n){n=n||{};var t=this,r=t.cid,o=n._Ctor||(n._Ctor={});if(o[r])return o[r];var a=bt(n)||bt(t.options);var s=function(n){this._init(n)};return(s.prototype=Object.create(t.prototype)).constructor=s,s.cid=e++,s.options=Ct(t.options,n),s.super=t,s.options.props&&function(n){var e=n.options.props;for(var t in e)Rt(n.prototype,"_props",t)}(s),s.options.computed&&function(n){var e=n.options.computed;for(var t in e)Ut(n.prototype,t,e[t])}(s),s.extend=t.extend,s.mixin=t.mixin,s.use=t.use,U.forEach((function(n){s[n]=t[n]})),a&&(s.options.components[a]=s),s.superOptions=t.options,s.extendOptions=n,s.sealedOptions=P({},s.options),o[r]=s,s}}function Kt(n){return n&&(bt(n.Ctor.options)||n.tag)}function Xt(n,e){return o(n)?n.indexOf(e)>-1:"string"==typeof n?n.split(",").indexOf(e)>-1:!!m(n)&&n.test(e)}function Jt(n,e){var t=n.cache,r=n.keys,o=n._vnode,a=n.$vnode;for(var s in t){var i=t[s];if(i){var l=i.name;l&&!e(l)&&Yt(t,s,r,o)}}a.componentOptions.children=void 0}function Yt(n,e,t,r){var o=n[e];!o||r&&o.tag===r.tag||o.componentInstance.$destroy(),n[e]=null,k(t,e)}!function(n){n.prototype._init=function(n){var e=this;e._uid=$t++,e._isVue=!0,e.__v_skip=!0,e._scope=new Gn(!0),e._scope.parent=void 0,e._scope._vm=!0,n&&n._isComponent?function(n,e){var t=n.$options=Object.create(n.constructor.options),r=e._parentVnode;t.parent=e.parent,t._parentVnode=r;var o=r.componentOptions;t.propsData=o.propsData,t._parentListeners=o.listeners,t._renderChildren=o.children,t._componentTag=o.tag,e.render&&(t.render=e.render,t.staticRenderFns=e.staticRenderFns)}(e,n):e.$options=Ct(Wt(e.constructor),n||{},e),e._renderProxy=e,e._self=e,function(n){var e=n.$options,t=e.parent;if(t&&!e.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(n)}n.$parent=t,n.$root=t?t.$root:n,n.$children=[],n.$refs={},n._provided=t?t._provided:Object.create(null),n._watcher=null,n._inactive=null,n._directInactive=!1,n._isMounted=!1,n._isDestroyed=!1,n._isBeingDestroyed=!1}(e),function(n){n._events=Object.create(null),n._hasHookEvent=!1;var e=n.$options._parentListeners;e&&Xe(n,e)}(e),function(n){n._vnode=null,n._staticTrees=null;var e=n.$options,t=n.$vnode=e._parentVnode,o=t&&t.context;n.$slots=me(e._renderChildren,o),n.$scopedSlots=t?he(n.$parent,t.data.scopedSlots,n.$slots):r,n._c=function(e,t,r,o){return Be(n,e,t,r,o,!1)},n.$createElement=function(e,t,r,o){return Be(n,e,t,r,o,!0)};var a=t&&t.data;In(n,"$attrs",a&&a.attrs||r,null,!0),In(n,"$listeners",e._parentListeners||r,null,!0)}(e),et(e,"beforeCreate",void 0,!1),function(n){var e=gt(n.$options.inject,n);e&&(Tn(!1),Object.keys(e).forEach((function(t){In(n,t,e[t])})),Tn(!0))}(e),Ft(e),function(n){var e=n.$options.provide;if(e){var t=c(e)?e.call(n):e;if(!p(t))return;for(var r=Vn(n),o=dn?Reflect.ownKeys(t):Object.keys(t),a=0;a<o.length;a++){var s=o[a];Object.defineProperty(r,s,Object.getOwnPropertyDescriptor(t,s))}}}(e),et(e,"created"),e.$options.el&&e.$mount(e.$options.el)}}(Ht),function(n){var e={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(n.prototype,"$data",e),Object.defineProperty(n.prototype,"$props",t),n.prototype.$set=qn,n.prototype.$delete=Dn,n.prototype.$watch=function(n,e,t){if(u(e))return Vt(this,n,e,t);(t=t||{}).user=!0;var r=new We(this,n,e,t);if(t.immediate){var o='callback for immediate watcher "'.concat(r.expression,'"');wn(),je(e,this,[r.value],this,o),En()}return function(){r.teardown()}}}(Ht),function(n){var e=/^hook:/;n.prototype.$on=function(n,t){var r=this;if(o(n))for(var a=0,s=n.length;a<s;a++)r.$on(n[a],t);else(r._events[n]||(r._events[n]=[])).push(t),e.test(n)&&(r._hasHookEvent=!0);return r},n.prototype.$once=function(n,e){var t=this;function r(){t.$off(n,r),e.apply(t,arguments)}return r.fn=e,t.$on(n,r),t},n.prototype.$off=function(n,e){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(o(n)){for(var r=0,a=n.length;r<a;r++)t.$off(n[r],e);return t}var s,i=t._events[n];if(!i)return t;if(!e)return t._events[n]=null,t;for(var l=i.length;l--;)if((s=i[l])===e||s.fn===e){i.splice(l,1);break}return t},n.prototype.$emit=function(n){var e=this,t=e._events[n];if(t){t=t.length>1?S(t):t;for(var r=S(arguments,1),o='event handler for "'.concat(n,'"'),a=0,s=t.length;a<s;a++)je(t[a],e,r,e,o)}return e}}(Ht),function(n){n.prototype._update=function(n,e){var t=this,r=t.$el,o=t._vnode,a=Ye(t);t._vnode=n,t.$el=o?t.__patch__(o,n):t.__patch__(t.$el,n,e,!1),a(),r&&(r.__vue__=null),t.$el&&(t.$el.__vue__=t);for(var s=t;s&&s.$vnode&&s.$parent&&s.$vnode===s.$parent._vnode;)s.$parent.$el=s.$el,s=s.$parent},n.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},n.prototype.$destroy=function(){var n=this;if(!n._isBeingDestroyed){et(n,"beforeDestroy"),n._isBeingDestroyed=!0;var e=n.$parent;!e||e._isBeingDestroyed||n.$options.abstract||k(e.$children,n),n._scope.stop(),n._data.__ob__&&n._data.__ob__.vmCount--,n._isDestroyed=!0,n.__patch__(n._vnode,null),et(n,"destroyed"),n.$off(),n.$el&&(n.$el.__vue__=null),n.$vnode&&(n.$vnode.parent=null)}}}(Ht),function(n){ue(n.prototype),n.prototype.$nextTick=function(n){return Le(n,this)},n.prototype._render=function(){var n=this,e=n.$options,t=e.render,r=e._parentVnode;r&&n._isMounted&&(n.$scopedSlots=he(n.$parent,r.data.scopedSlots,n.$slots,n.$scopedSlots),n._slotsProxy&&we(n._slotsProxy,n.$scopedSlots)),n.$vnode=r;var a,s=un,i=Ee;try{mn(n),Ee=n,a=t.call(n._renderProxy,n.$createElement)}catch(e){ze(e,n,"render"),a=n._vnode}finally{Ee=i,mn(s)}return o(a)&&1===a.length&&(a=a[0]),a instanceof gn||(a=fn()),a.parent=r,a}}(Ht);var Qt=[String,RegExp,Array],nr={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:Qt,exclude:Qt,max:[String,Number]},methods:{cacheVNode:function(){var n=this.cache,e=this.keys,t=this.vnodeToCache,r=this.keyToCache;if(t){var o=t.tag,a=t.componentInstance,s=t.componentOptions;n[r]={name:Kt(s),tag:o,componentInstance:a},e.push(r),this.max&&e.length>parseInt(this.max)&&Yt(n,e[0],e,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var n in this.cache)Yt(this.cache,n,this.keys)},mounted:function(){var n=this;this.cacheVNode(),this.$watch("include",(function(e){Jt(n,(function(n){return Xt(e,n)}))})),this.$watch("exclude",(function(e){Jt(n,(function(n){return!Xt(e,n)}))}))},updated:function(){this.cacheVNode()},render:function(){var n=this.$slots.default,e=Ae(n),t=e&&e.componentOptions;if(t){var r=Kt(t),o=this.include,a=this.exclude;if(o&&(!r||!Xt(o,r))||a&&r&&Xt(a,r))return e;var s=this.cache,i=this.keys,l=null==e.key?t.Ctor.cid+(t.tag?"::".concat(t.tag):""):e.key;s[l]?(e.componentInstance=s[l].componentInstance,k(i,l),i.push(l)):(this.vnodeToCache=e,this.keyToCache=l),e.data.keepAlive=!0}return e||n&&n[0]}}};!function(n){var e={get:function(){return G}};Object.defineProperty(n,"config",e),n.util={warn:Et,extend:P,mergeOptions:Ct,defineReactive:In},n.set=qn,n.delete=Dn,n.nextTick=Le,n.observable=function(n){return Pn(n),n},n.options=Object.create(null),U.forEach((function(e){n.options[e+"s"]=Object.create(null)})),n.options._base=n,P(n.options.components,nr),function(n){n.use=function(n){var e=this._installedPlugins||(this._installedPlugins=[]);if(e.indexOf(n)>-1)return this;var t=S(arguments,1);return t.unshift(this),c(n.install)?n.install.apply(n,t):c(n)&&n.apply(null,t),e.push(n),this}}(n),function(n){n.mixin=function(n){return this.options=Ct(this.options,n),this}}(n),Zt(n),function(n){U.forEach((function(e){n[e]=function(n,t){return t?("component"===e&&u(t)&&(t.name=t.name||n,t=this.options._base.extend(t)),"directive"===e&&c(t)&&(t={bind:t,update:t}),this.options[e+"s"][n]=t,t):this.options[e+"s"][n]}}))}(n)}(Ht),Object.defineProperty(Ht.prototype,"$isServer",{get:sn}),Object.defineProperty(Ht.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Ht,"FunctionalRenderContext",{value:ft}),Ht.version="2.7.16";var er=_("style,class"),tr=_("input,textarea,option,select,progress"),rr=_("contenteditable,draggable,spellcheck"),or=_("events,caret,typing,plaintext-only"),ar=_("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),sr="http://www.w3.org/1999/xlink",ir=function(n){return":"===n.charAt(5)&&"xlink"===n.slice(0,5)},lr=function(n){return ir(n)?n.slice(6,n.length):""},cr=function(n){return null==n||!1===n};function pr(n){for(var e=n.data,t=n,r=n;s(r.componentInstance);)(r=r.componentInstance._vnode)&&r.data&&(e=dr(r.data,e));for(;s(t=t.parent);)t&&t.data&&(e=dr(e,t.data));return function(n,e){if(s(n)||s(e))return ur(n,mr(e));return""}(e.staticClass,e.class)}function dr(n,e){return{staticClass:ur(n.staticClass,e.staticClass),class:s(n.class)?[n.class,e.class]:e.class}}function ur(n,e){return n?e?n+" "+e:n:e||""}function mr(n){return Array.isArray(n)?function(n){for(var e,t="",r=0,o=n.length;r<o;r++)s(e=mr(n[r]))&&""!==e&&(t&&(t+=" "),t+=e);return t}(n):p(n)?function(n){var e="";for(var t in n)n[t]&&(e&&(e+=" "),e+=t);return e}(n):"string"==typeof n?n:""}var gr={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},fr=_("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),hr=_("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),vr=function(n){return fr(n)||hr(n)};var br=Object.create(null);var _r=_("text,number,password,search,email,tel,url");var yr=Object.freeze({__proto__:null,createElement:function(n,e){var t=document.createElement(n);return"select"!==n||e.data&&e.data.attrs&&void 0!==e.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(n,e){return document.createElementNS(gr[n],e)},createTextNode:function(n){return document.createTextNode(n)},createComment:function(n){return document.createComment(n)},insertBefore:function(n,e,t){n.insertBefore(e,t)},removeChild:function(n,e){n.removeChild(e)},appendChild:function(n,e){n.appendChild(e)},parentNode:function(n){return n.parentNode},nextSibling:function(n){return n.nextSibling},tagName:function(n){return n.tagName},setTextContent:function(n,e){n.textContent=e},setStyleScope:function(n,e){n.setAttribute(e,"")}}),kr={create:function(n,e){wr(e)},update:function(n,e){n.data.ref!==e.data.ref&&(wr(n,!0),wr(e))},destroy:function(n){wr(n,!0)}};function wr(n,e){var t=n.data.ref;if(s(t)){var r=n.context,a=n.componentInstance||n.elm,i=e?null:a,l=e?void 0:a;if(c(t))je(t,r,[i],r,"template ref function");else{var p=n.data.refInFor,d="string"==typeof t||"number"==typeof t,u=Ln(t),m=r.$refs;if(d||u)if(p){var g=d?m[t]:t.value;e?o(g)&&k(g,a):o(g)?g.includes(a)||g.push(a):d?(m[t]=[a],Er(r,t,m[t])):t.value=[a]}else if(d){if(e&&m[t]!==a)return;m[t]=l,Er(r,t,i)}else if(u){if(e&&t.value!==a)return;t.value=i}else 0}}}function Er(n,e,t){var r=n._setupState;r&&E(r,e)&&(Ln(r[e])?r[e].value=t:r[e]=t)}var xr=new gn("",{},[]),Ar=["create","activate","update","remove","destroy"];function Br(n,e){return n.key===e.key&&n.asyncFactory===e.asyncFactory&&(n.tag===e.tag&&n.isComment===e.isComment&&s(n.data)===s(e.data)&&function(n,e){if("input"!==n.tag)return!0;var t,r=s(t=n.data)&&s(t=t.attrs)&&t.type,o=s(t=e.data)&&s(t=t.attrs)&&t.type;return r===o||_r(r)&&_r(o)}(n,e)||i(n.isAsyncPlaceholder)&&a(e.asyncFactory.error))}function zr(n,e,t){var r,o,a={};for(r=e;r<=t;++r)s(o=n[r].key)&&(a[o]=r);return a}var jr={create:Tr,update:Tr,destroy:function(n){Tr(n,xr)}};function Tr(n,e){(n.data.directives||e.data.directives)&&function(n,e){var t,r,o,a=n===xr,s=e===xr,i=Sr(n.data.directives,n.context),l=Sr(e.data.directives,e.context),c=[],p=[];for(t in l)r=i[t],o=l[t],r?(o.oldValue=r.value,o.oldArg=r.arg,Ir(o,"update",e,n),o.def&&o.def.componentUpdated&&p.push(o)):(Ir(o,"bind",e,n),o.def&&o.def.inserted&&c.push(o));if(c.length){var d=function(){for(var t=0;t<c.length;t++)Ir(c[t],"inserted",e,n)};a?Zn(e,"insert",d):d()}p.length&&Zn(e,"postpatch",(function(){for(var t=0;t<p.length;t++)Ir(p[t],"componentUpdated",e,n)}));if(!a)for(t in i)l[t]||Ir(i[t],"unbind",n,n,s)}(n,e)}var Cr=Object.create(null);function Sr(n,e){var t,r,o=Object.create(null);if(!n)return o;for(t=0;t<n.length;t++){if((r=n[t]).modifiers||(r.modifiers=Cr),o[Pr(r)]=r,e._setupState&&e._setupState.__sfc){var a=r.def||St(e,"_setupState","v-"+r.name);r.def="function"==typeof a?{bind:a,update:a}:a}r.def=r.def||St(e.$options,"directives",r.name)}return o}function Pr(n){return n.rawName||"".concat(n.name,".").concat(Object.keys(n.modifiers||{}).join("."))}function Ir(n,e,t,r,o){var a=n.def&&n.def[e];if(a)try{a(t.elm,n,t,r,o)}catch(r){ze(r,t.context,"directive ".concat(n.name," ").concat(e," hook"))}}var qr=[kr,jr];function Dr(n,e){var t=e.componentOptions;if(!(s(t)&&!1===t.Ctor.options.inheritAttrs||a(n.data.attrs)&&a(e.data.attrs))){var r,o,l=e.elm,c=n.data.attrs||{},p=e.data.attrs||{};for(r in(s(p.__ob__)||i(p._v_attr_proxy))&&(p=e.data.attrs=P({},p)),p)o=p[r],c[r]!==o&&Nr(l,r,o,e.data.pre);for(r in(J||Q)&&p.value!==c.value&&Nr(l,"value",p.value),c)a(p[r])&&(ir(r)?l.removeAttributeNS(sr,lr(r)):rr(r)||l.removeAttribute(r))}}function Nr(n,e,t,r){r||n.tagName.indexOf("-")>-1?Or(n,e,t):ar(e)?cr(t)?n.removeAttribute(e):(t="allowfullscreen"===e&&"EMBED"===n.tagName?"true":e,n.setAttribute(e,t)):rr(e)?n.setAttribute(e,function(n,e){return cr(e)||"false"===e?"false":"contenteditable"===n&&or(e)?e:"true"}(e,t)):ir(e)?cr(t)?n.removeAttributeNS(sr,lr(e)):n.setAttributeNS(sr,e,t):Or(n,e,t)}function Or(n,e,t){if(cr(t))n.removeAttribute(e);else{if(J&&!Y&&"TEXTAREA"===n.tagName&&"placeholder"===e&&""!==t&&!n.__ieph){var r=function(e){e.stopImmediatePropagation(),n.removeEventListener("input",r)};n.addEventListener("input",r),n.__ieph=!0}n.setAttribute(e,t)}}var Rr={create:Dr,update:Dr};function Fr(n,e){var t=e.elm,r=e.data,o=n.data;if(!(a(r.staticClass)&&a(r.class)&&(a(o)||a(o.staticClass)&&a(o.class)))){var i=pr(e),l=t._transitionClasses;s(l)&&(i=ur(i,mr(l))),i!==t._prevClass&&(t.setAttribute("class",i),t._prevClass=i)}}var Lr,Ur={create:Fr,update:Fr};function Mr(n,e,t){var r=Lr;return function o(){var a=e.apply(null,arguments);null!==a&&$r(n,o,t,r)}}var Gr=Pe&&!(tn&&Number(tn[1])<=53);function Vr(n,e,t,r){if(Gr){var o=lt,a=e;e=a._wrapper=function(n){if(n.target===n.currentTarget||n.timeStamp>=o||n.timeStamp<=0||n.target.ownerDocument!==document)return a.apply(this,arguments)}}Lr.addEventListener(n,e,on?{capture:t,passive:r}:t)}function $r(n,e,t,r){(r||Lr).removeEventListener(n,e._wrapper||e,t)}function Wr(n,e){if(!a(n.data.on)||!a(e.data.on)){var t=e.data.on||{},r=n.data.on||{};Lr=e.elm||n.elm,function(n){if(s(n.__r)){var e=J?"change":"input";n[e]=[].concat(n.__r,n[e]||[]),delete n.__r}s(n.__c)&&(n.change=[].concat(n.__c,n.change||[]),delete n.__c)}(t),Hn(t,r,Vr,$r,Mr,e.context),Lr=void 0}}var Hr,Zr={create:Wr,update:Wr,destroy:function(n){return Wr(n,xr)}};function Kr(n,e){if(!a(n.data.domProps)||!a(e.data.domProps)){var t,r,o=e.elm,l=n.data.domProps||{},c=e.data.domProps||{};for(t in(s(c.__ob__)||i(c._v_attr_proxy))&&(c=e.data.domProps=P({},c)),l)t in c||(o[t]="");for(t in c){if(r=c[t],"textContent"===t||"innerHTML"===t){if(e.children&&(e.children.length=0),r===l[t])continue;1===o.childNodes.length&&o.removeChild(o.childNodes[0])}if("value"===t&&"PROGRESS"!==o.tagName){o._value=r;var p=a(r)?"":String(r);Xr(o,p)&&(o.value=p)}else if("innerHTML"===t&&hr(o.tagName)&&a(o.innerHTML)){(Hr=Hr||document.createElement("div")).innerHTML="<svg>".concat(r,"</svg>");for(var d=Hr.firstChild;o.firstChild;)o.removeChild(o.firstChild);for(;d.firstChild;)o.appendChild(d.firstChild)}else if(r!==l[t])try{o[t]=r}catch(n){}}}}function Xr(n,e){return!n.composing&&("OPTION"===n.tagName||function(n,e){var t=!0;try{t=document.activeElement!==n}catch(n){}return t&&n.value!==e}(n,e)||function(n,e){var t=n.value,r=n._vModifiers;if(s(r)){if(r.number)return b(t)!==b(e);if(r.trim)return t.trim()!==e.trim()}return t!==e}(n,e))}var Jr={create:Kr,update:Kr},Yr=x((function(n){var e={},t=/:(.+)/;return n.split(/;(?![^(]*\))/g).forEach((function(n){if(n){var r=n.split(t);r.length>1&&(e[r[0].trim()]=r[1].trim())}})),e}));function Qr(n){var e=no(n.style);return n.staticStyle?P(n.staticStyle,e):e}function no(n){return Array.isArray(n)?I(n):"string"==typeof n?Yr(n):n}var eo,to=/^--/,ro=/\s*!important$/,oo=function(n,e,t){if(to.test(e))n.style.setProperty(e,t);else if(ro.test(t))n.style.setProperty(T(e),t.replace(ro,""),"important");else{var r=so(e);if(Array.isArray(t))for(var o=0,a=t.length;o<a;o++)n.style[r]=t[o];else n.style[r]=t}},ao=["Webkit","Moz","ms"],so=x((function(n){if(eo=eo||document.createElement("div").style,"filter"!==(n=B(n))&&n in eo)return n;for(var e=n.charAt(0).toUpperCase()+n.slice(1),t=0;t<ao.length;t++){var r=ao[t]+e;if(r in eo)return r}}));function io(n,e){var t=e.data,r=n.data;if(!(a(t.staticStyle)&&a(t.style)&&a(r.staticStyle)&&a(r.style))){var o,i,l=e.elm,c=r.staticStyle,p=r.normalizedStyle||r.style||{},d=c||p,u=no(e.data.style)||{};e.data.normalizedStyle=s(u.__ob__)?P({},u):u;var m=function(n,e){var t,r={};if(e)for(var o=n;o.componentInstance;)(o=o.componentInstance._vnode)&&o.data&&(t=Qr(o.data))&&P(r,t);(t=Qr(n.data))&&P(r,t);for(var a=n;a=a.parent;)a.data&&(t=Qr(a.data))&&P(r,t);return r}(e,!0);for(i in d)a(m[i])&&oo(l,i,"");for(i in m)o=m[i],oo(l,i,null==o?"":o)}}var lo={create:io,update:io},co=/\s+/;function po(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(co).forEach((function(e){return n.classList.add(e)})):n.classList.add(e);else{var t=" ".concat(n.getAttribute("class")||""," ");t.indexOf(" "+e+" ")<0&&n.setAttribute("class",(t+e).trim())}}function uo(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(co).forEach((function(e){return n.classList.remove(e)})):n.classList.remove(e),n.classList.length||n.removeAttribute("class");else{for(var t=" ".concat(n.getAttribute("class")||""," "),r=" "+e+" ";t.indexOf(r)>=0;)t=t.replace(r," ");(t=t.trim())?n.setAttribute("class",t):n.removeAttribute("class")}}function mo(n){if(n){if("object"==typeof n){var e={};return!1!==n.css&&P(e,go(n.name||"v")),P(e,n),e}return"string"==typeof n?go(n):void 0}}var go=x((function(n){return{enterClass:"".concat(n,"-enter"),enterToClass:"".concat(n,"-enter-to"),enterActiveClass:"".concat(n,"-enter-active"),leaveClass:"".concat(n,"-leave"),leaveToClass:"".concat(n,"-leave-to"),leaveActiveClass:"".concat(n,"-leave-active")}})),fo=K&&!Y,ho="transition",vo="transitionend",bo="animation",_o="animationend";fo&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(ho="WebkitTransition",vo="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(bo="WebkitAnimation",_o="webkitAnimationEnd"));var yo=K?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(n){return n()};function ko(n){yo((function(){yo(n)}))}function wo(n,e){var t=n._transitionClasses||(n._transitionClasses=[]);t.indexOf(e)<0&&(t.push(e),po(n,e))}function Eo(n,e){n._transitionClasses&&k(n._transitionClasses,e),uo(n,e)}function xo(n,e,t){var r=Bo(n,e),o=r.type,a=r.timeout,s=r.propCount;if(!o)return t();var i="transition"===o?vo:_o,l=0,c=function(){n.removeEventListener(i,p),t()},p=function(e){e.target===n&&++l>=s&&c()};setTimeout((function(){l<s&&c()}),a+1),n.addEventListener(i,p)}var Ao=/\b(transform|all)(,|$)/;function Bo(n,e){var t,r=window.getComputedStyle(n),o=(r[ho+"Delay"]||"").split(", "),a=(r[ho+"Duration"]||"").split(", "),s=zo(o,a),i=(r[bo+"Delay"]||"").split(", "),l=(r[bo+"Duration"]||"").split(", "),c=zo(i,l),p=0,d=0;return"transition"===e?s>0&&(t="transition",p=s,d=a.length):"animation"===e?c>0&&(t="animation",p=c,d=l.length):d=(t=(p=Math.max(s,c))>0?s>c?"transition":"animation":null)?"transition"===t?a.length:l.length:0,{type:t,timeout:p,propCount:d,hasTransform:"transition"===t&&Ao.test(r[ho+"Property"])}}function zo(n,e){for(;n.length<e.length;)n=n.concat(n);return Math.max.apply(null,e.map((function(e,t){return jo(e)+jo(n[t])})))}function jo(n){return 1e3*Number(n.slice(0,-1).replace(",","."))}function To(n,e){var t=n.elm;s(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var r=mo(n.data.transition);if(!a(r)&&!s(t._enterCb)&&1===t.nodeType){for(var o=r.css,i=r.type,l=r.enterClass,d=r.enterToClass,u=r.enterActiveClass,m=r.appearClass,g=r.appearToClass,f=r.appearActiveClass,h=r.beforeEnter,v=r.enter,_=r.afterEnter,y=r.enterCancelled,k=r.beforeAppear,w=r.appear,E=r.afterAppear,x=r.appearCancelled,A=r.duration,B=Je,z=Je.$vnode;z&&z.parent;)B=z.context,z=z.parent;var j=!B._isMounted||!n.isRootInsert;if(!j||w||""===w){var T=j&&m?m:l,C=j&&f?f:u,S=j&&g?g:d,P=j&&k||h,I=j&&c(w)?w:v,q=j&&E||_,D=j&&x||y,N=b(p(A)?A.enter:A);0;var O=!1!==o&&!Y,R=Po(I),L=t._enterCb=F((function(){O&&(Eo(t,S),Eo(t,C)),L.cancelled?(O&&Eo(t,T),D&&D(t)):q&&q(t),t._enterCb=null}));n.data.show||Zn(n,"insert",(function(){var e=t.parentNode,r=e&&e._pending&&e._pending[n.key];r&&r.tag===n.tag&&r.elm._leaveCb&&r.elm._leaveCb(),I&&I(t,L)})),P&&P(t),O&&(wo(t,T),wo(t,C),ko((function(){Eo(t,T),L.cancelled||(wo(t,S),R||(So(N)?setTimeout(L,N):xo(t,i,L)))}))),n.data.show&&(e&&e(),I&&I(t,L)),O||R||L()}}}function Co(n,e){var t=n.elm;s(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var r=mo(n.data.transition);if(a(r)||1!==t.nodeType)return e();if(!s(t._leaveCb)){var o=r.css,i=r.type,l=r.leaveClass,c=r.leaveToClass,d=r.leaveActiveClass,u=r.beforeLeave,m=r.leave,g=r.afterLeave,f=r.leaveCancelled,h=r.delayLeave,v=r.duration,_=!1!==o&&!Y,y=Po(m),k=b(p(v)?v.leave:v);0;var w=t._leaveCb=F((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[n.key]=null),_&&(Eo(t,c),Eo(t,d)),w.cancelled?(_&&Eo(t,l),f&&f(t)):(e(),g&&g(t)),t._leaveCb=null}));h?h(E):E()}function E(){w.cancelled||(!n.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[n.key]=n),u&&u(t),_&&(wo(t,l),wo(t,d),ko((function(){Eo(t,l),w.cancelled||(wo(t,c),y||(So(k)?setTimeout(w,k):xo(t,i,w)))}))),m&&m(t,w),_||y||w())}}function So(n){return"number"==typeof n&&!isNaN(n)}function Po(n){if(a(n))return!1;var e=n.fns;return s(e)?Po(Array.isArray(e)?e[0]:e):(n._length||n.length)>1}function Io(n,e){!0!==e.data.show&&To(e)}var qo=function(n){var e,t,r={},c=n.modules,p=n.nodeOps;for(e=0;e<Ar.length;++e)for(r[Ar[e]]=[],t=0;t<c.length;++t)s(c[t][Ar[e]])&&r[Ar[e]].push(c[t][Ar[e]]);function d(n){var e=p.parentNode(n);s(e)&&p.removeChild(e,n)}function u(n,e,t,o,a,l,c){if(s(n.elm)&&s(l)&&(n=l[c]=vn(n)),n.isRootInsert=!a,!function(n,e,t,o){var a=n.data;if(s(a)){var l=s(n.componentInstance)&&a.keepAlive;if(s(a=a.hook)&&s(a=a.init)&&a(n,!1),s(n.componentInstance))return m(n,e),g(t,n.elm,o),i(l)&&function(n,e,t,o){var a,i=n;for(;i.componentInstance;)if(i=i.componentInstance._vnode,s(a=i.data)&&s(a=a.transition)){for(a=0;a<r.activate.length;++a)r.activate[a](xr,i);e.push(i);break}g(t,n.elm,o)}(n,e,t,o),!0}}(n,e,t,o)){var d=n.data,u=n.children,h=n.tag;s(h)?(n.elm=n.ns?p.createElementNS(n.ns,h):p.createElement(h,n),b(n),f(n,u,e),s(d)&&v(n,e),g(t,n.elm,o)):i(n.isComment)?(n.elm=p.createComment(n.text),g(t,n.elm,o)):(n.elm=p.createTextNode(n.text),g(t,n.elm,o))}}function m(n,e){s(n.data.pendingInsert)&&(e.push.apply(e,n.data.pendingInsert),n.data.pendingInsert=null),n.elm=n.componentInstance.$el,h(n)?(v(n,e),b(n)):(wr(n),e.push(n))}function g(n,e,t){s(n)&&(s(t)?p.parentNode(t)===n&&p.insertBefore(n,e,t):p.appendChild(n,e))}function f(n,e,t){if(o(e)){0;for(var r=0;r<e.length;++r)u(e[r],t,n.elm,null,!0,e,r)}else l(n.text)&&p.appendChild(n.elm,p.createTextNode(String(n.text)))}function h(n){for(;n.componentInstance;)n=n.componentInstance._vnode;return s(n.tag)}function v(n,t){for(var o=0;o<r.create.length;++o)r.create[o](xr,n);s(e=n.data.hook)&&(s(e.create)&&e.create(xr,n),s(e.insert)&&t.push(n))}function b(n){var e;if(s(e=n.fnScopeId))p.setStyleScope(n.elm,e);else for(var t=n;t;)s(e=t.context)&&s(e=e.$options._scopeId)&&p.setStyleScope(n.elm,e),t=t.parent;s(e=Je)&&e!==n.context&&e!==n.fnContext&&s(e=e.$options._scopeId)&&p.setStyleScope(n.elm,e)}function y(n,e,t,r,o,a){for(;r<=o;++r)u(t[r],a,n,e,!1,t,r)}function k(n){var e,t,o=n.data;if(s(o))for(s(e=o.hook)&&s(e=e.destroy)&&e(n),e=0;e<r.destroy.length;++e)r.destroy[e](n);if(s(e=n.children))for(t=0;t<n.children.length;++t)k(n.children[t])}function w(n,e,t){for(;e<=t;++e){var r=n[e];s(r)&&(s(r.tag)?(E(r),k(r)):d(r.elm))}}function E(n,e){if(s(e)||s(n.data)){var t,o=r.remove.length+1;for(s(e)?e.listeners+=o:e=function(n,e){function t(){0==--t.listeners&&d(n)}return t.listeners=e,t}(n.elm,o),s(t=n.componentInstance)&&s(t=t._vnode)&&s(t.data)&&E(t,e),t=0;t<r.remove.length;++t)r.remove[t](n,e);s(t=n.data.hook)&&s(t=t.remove)?t(n,e):e()}else d(n.elm)}function x(n,e,t,r){for(var o=t;o<r;o++){var a=e[o];if(s(a)&&Br(n,a))return o}}function A(n,e,t,o,l,c){if(n!==e){s(e.elm)&&s(o)&&(e=o[l]=vn(e));var d=e.elm=n.elm;if(i(n.isAsyncPlaceholder))s(e.asyncFactory.resolved)?j(n.elm,e,t):e.isAsyncPlaceholder=!0;else if(i(e.isStatic)&&i(n.isStatic)&&e.key===n.key&&(i(e.isCloned)||i(e.isOnce)))e.componentInstance=n.componentInstance;else{var m,g=e.data;s(g)&&s(m=g.hook)&&s(m=m.prepatch)&&m(n,e);var f=n.children,v=e.children;if(s(g)&&h(e)){for(m=0;m<r.update.length;++m)r.update[m](n,e);s(m=g.hook)&&s(m=m.update)&&m(n,e)}a(e.text)?s(f)&&s(v)?f!==v&&function(n,e,t,r,o){var i,l,c,d=0,m=0,g=e.length-1,f=e[0],h=e[g],v=t.length-1,b=t[0],_=t[v],k=!o;for(0;d<=g&&m<=v;)a(f)?f=e[++d]:a(h)?h=e[--g]:Br(f,b)?(A(f,b,r,t,m),f=e[++d],b=t[++m]):Br(h,_)?(A(h,_,r,t,v),h=e[--g],_=t[--v]):Br(f,_)?(A(f,_,r,t,v),k&&p.insertBefore(n,f.elm,p.nextSibling(h.elm)),f=e[++d],_=t[--v]):Br(h,b)?(A(h,b,r,t,m),k&&p.insertBefore(n,h.elm,f.elm),h=e[--g],b=t[++m]):(a(i)&&(i=zr(e,d,g)),a(l=s(b.key)?i[b.key]:x(b,e,d,g))?u(b,r,n,f.elm,!1,t,m):Br(c=e[l],b)?(A(c,b,r,t,m),e[l]=void 0,k&&p.insertBefore(n,c.elm,f.elm)):u(b,r,n,f.elm,!1,t,m),b=t[++m]);d>g?y(n,a(t[v+1])?null:t[v+1].elm,t,m,v,r):m>v&&w(e,d,g)}(d,f,v,t,c):s(v)?(s(n.text)&&p.setTextContent(d,""),y(d,null,v,0,v.length-1,t)):s(f)?w(f,0,f.length-1):s(n.text)&&p.setTextContent(d,""):n.text!==e.text&&p.setTextContent(d,e.text),s(g)&&s(m=g.hook)&&s(m=m.postpatch)&&m(n,e)}}}function B(n,e,t){if(i(t)&&s(n.parent))n.parent.data.pendingInsert=e;else for(var r=0;r<e.length;++r)e[r].data.hook.insert(e[r])}var z=_("attrs,class,staticClass,staticStyle,key");function j(n,e,t,r){var o,a=e.tag,l=e.data,c=e.children;if(r=r||l&&l.pre,e.elm=n,i(e.isComment)&&s(e.asyncFactory))return e.isAsyncPlaceholder=!0,!0;if(s(l)&&(s(o=l.hook)&&s(o=o.init)&&o(e,!0),s(o=e.componentInstance)))return m(e,t),!0;if(s(a)){if(s(c))if(n.hasChildNodes())if(s(o=l)&&s(o=o.domProps)&&s(o=o.innerHTML)){if(o!==n.innerHTML)return!1}else{for(var p=!0,d=n.firstChild,u=0;u<c.length;u++){if(!d||!j(d,c[u],t,r)){p=!1;break}d=d.nextSibling}if(!p||d)return!1}else f(e,c,t);if(s(l)){var g=!1;for(var h in l)if(!z(h)){g=!0,v(e,t);break}!g&&l.class&&Ge(l.class)}}else n.data!==e.text&&(n.data=e.text);return!0}return function(n,e,t,o){if(!a(e)){var l,c=!1,d=[];if(a(n))c=!0,u(e,d);else{var m=s(n.nodeType);if(!m&&Br(n,e))A(n,e,d,null,null,o);else{if(m){if(1===n.nodeType&&n.hasAttribute("data-server-rendered")&&(n.removeAttribute("data-server-rendered"),t=!0),i(t)&&j(n,e,d))return B(e,d,!0),n;l=n,n=new gn(p.tagName(l).toLowerCase(),{},[],void 0,l)}var g=n.elm,f=p.parentNode(g);if(u(e,d,g._leaveCb?null:f,p.nextSibling(g)),s(e.parent))for(var v=e.parent,b=h(e);v;){for(var _=0;_<r.destroy.length;++_)r.destroy[_](v);if(v.elm=e.elm,b){for(var y=0;y<r.create.length;++y)r.create[y](xr,v);var E=v.data.hook.insert;if(E.merged)for(var x=E.fns.slice(1),z=0;z<x.length;z++)x[z]()}else wr(v);v=v.parent}s(f)?w([n],0,0):s(n.tag)&&k(n)}}return B(e,d,c),e.elm}s(n)&&k(n)}}({nodeOps:yr,modules:[Rr,Ur,Zr,Jr,lo,K?{create:Io,activate:Io,remove:function(n,e){!0!==n.data.show?Co(n,e):e()}}:{}].concat(qr)});Y&&document.addEventListener("selectionchange",(function(){var n=document.activeElement;n&&n.vmodel&&Mo(n,"input")}));var Do={inserted:function(n,e,t,r){"select"===t.tag?(r.elm&&!r.elm._vOptions?Zn(t,"postpatch",(function(){Do.componentUpdated(n,e,t)})):No(n,e,t.context),n._vOptions=[].map.call(n.options,Fo)):("textarea"===t.tag||_r(n.type))&&(n._vModifiers=e.modifiers,e.modifiers.lazy||(n.addEventListener("compositionstart",Lo),n.addEventListener("compositionend",Uo),n.addEventListener("change",Uo),Y&&(n.vmodel=!0)))},componentUpdated:function(n,e,t){if("select"===t.tag){No(n,e,t.context);var r=n._vOptions,o=n._vOptions=[].map.call(n.options,Fo);if(o.some((function(n,e){return!O(n,r[e])})))(n.multiple?e.value.some((function(n){return Ro(n,o)})):e.value!==e.oldValue&&Ro(e.value,o))&&Mo(n,"change")}}};function No(n,e,t){Oo(n,e,t),(J||Q)&&setTimeout((function(){Oo(n,e,t)}),0)}function Oo(n,e,t){var r=e.value,o=n.multiple;if(!o||Array.isArray(r)){for(var a,s,i=0,l=n.options.length;i<l;i++)if(s=n.options[i],o)a=R(r,Fo(s))>-1,s.selected!==a&&(s.selected=a);else if(O(Fo(s),r))return void(n.selectedIndex!==i&&(n.selectedIndex=i));o||(n.selectedIndex=-1)}}function Ro(n,e){return e.every((function(e){return!O(e,n)}))}function Fo(n){return"_value"in n?n._value:n.value}function Lo(n){n.target.composing=!0}function Uo(n){n.target.composing&&(n.target.composing=!1,Mo(n.target,"input"))}function Mo(n,e){var t=document.createEvent("HTMLEvents");t.initEvent(e,!0,!0),n.dispatchEvent(t)}function Go(n){return!n.componentInstance||n.data&&n.data.transition?n:Go(n.componentInstance._vnode)}var Vo={model:Do,show:{bind:function(n,e,t){var r=e.value,o=(t=Go(t)).data&&t.data.transition,a=n.__vOriginalDisplay="none"===n.style.display?"":n.style.display;r&&o?(t.data.show=!0,To(t,(function(){n.style.display=a}))):n.style.display=r?a:"none"},update:function(n,e,t){var r=e.value;!r!=!e.oldValue&&((t=Go(t)).data&&t.data.transition?(t.data.show=!0,r?To(t,(function(){n.style.display=n.__vOriginalDisplay})):Co(t,(function(){n.style.display="none"}))):n.style.display=r?n.__vOriginalDisplay:"none")},unbind:function(n,e,t,r,o){o||(n.style.display=n.__vOriginalDisplay)}}},$o={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function Wo(n){var e=n&&n.componentOptions;return e&&e.Ctor.options.abstract?Wo(Ae(e.children)):n}function Ho(n){var e={},t=n.$options;for(var r in t.propsData)e[r]=n[r];var o=t._parentListeners;for(var r in o)e[B(r)]=o[r];return e}function Zo(n,e){if(/\d-keep-alive$/.test(e.tag))return n("keep-alive",{props:e.componentOptions.propsData})}var Ko=function(n){return n.tag||fe(n)},Xo=function(n){return"show"===n.name},Jo={name:"transition",props:$o,abstract:!0,render:function(n){var e=this,t=this.$slots.default;if(t&&(t=t.filter(Ko)).length){0;var r=this.mode;0;var o=t[0];if(function(n){for(;n=n.parent;)if(n.data.transition)return!0}(this.$vnode))return o;var a=Wo(o);if(!a)return o;if(this._leaving)return Zo(n,o);var s="__transition-".concat(this._uid,"-");a.key=null==a.key?a.isComment?s+"comment":s+a.tag:l(a.key)?0===String(a.key).indexOf(s)?a.key:s+a.key:a.key;var i=(a.data||(a.data={})).transition=Ho(this),c=this._vnode,p=Wo(c);if(a.data.directives&&a.data.directives.some(Xo)&&(a.data.show=!0),p&&p.data&&!function(n,e){return e.key===n.key&&e.tag===n.tag}(a,p)&&!fe(p)&&(!p.componentInstance||!p.componentInstance._vnode.isComment)){var d=p.data.transition=P({},i);if("out-in"===r)return this._leaving=!0,Zn(d,"afterLeave",(function(){e._leaving=!1,e.$forceUpdate()})),Zo(n,o);if("in-out"===r){if(fe(a))return c;var u,m=function(){u()};Zn(i,"afterEnter",m),Zn(i,"enterCancelled",m),Zn(d,"delayLeave",(function(n){u=n}))}}return o}}},Yo=P({tag:String,moveClass:String},$o);function Qo(n){n.elm._moveCb&&n.elm._moveCb(),n.elm._enterCb&&n.elm._enterCb()}function na(n){n.data.newPos=n.elm.getBoundingClientRect()}function ea(n){var e=n.data.pos,t=n.data.newPos,r=e.left-t.left,o=e.top-t.top;if(r||o){n.data.moved=!0;var a=n.elm.style;a.transform=a.WebkitTransform="translate(".concat(r,"px,").concat(o,"px)"),a.transitionDuration="0s"}}delete Yo.mode;var ta={Transition:Jo,TransitionGroup:{props:Yo,beforeMount:function(){var n=this,e=this._update;this._update=function(t,r){var o=Ye(n);n.__patch__(n._vnode,n.kept,!1,!0),n._vnode=n.kept,o(),e.call(n,t,r)}},render:function(n){for(var e=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),r=this.prevChildren=this.children,o=this.$slots.default||[],a=this.children=[],s=Ho(this),i=0;i<o.length;i++){if((p=o[i]).tag)if(null!=p.key&&0!==String(p.key).indexOf("__vlist"))a.push(p),t[p.key]=p,(p.data||(p.data={})).transition=s;else;}if(r){var l=[],c=[];for(i=0;i<r.length;i++){var p;(p=r[i]).data.transition=s,p.data.pos=p.elm.getBoundingClientRect(),t[p.key]?l.push(p):c.push(p)}this.kept=n(e,null,l),this.removed=c}return n(e,null,a)},updated:function(){var n=this.prevChildren,e=this.moveClass||(this.name||"v")+"-move";n.length&&this.hasMove(n[0].elm,e)&&(n.forEach(Qo),n.forEach(na),n.forEach(ea),this._reflow=document.body.offsetHeight,n.forEach((function(n){if(n.data.moved){var t=n.elm,r=t.style;wo(t,e),r.transform=r.WebkitTransform=r.transitionDuration="",t.addEventListener(vo,t._moveCb=function n(r){r&&r.target!==t||r&&!/transform$/.test(r.propertyName)||(t.removeEventListener(vo,n),t._moveCb=null,Eo(t,e))})}})))},methods:{hasMove:function(n,e){if(!fo)return!1;if(this._hasMove)return this._hasMove;var t=n.cloneNode();n._transitionClasses&&n._transitionClasses.forEach((function(n){uo(t,n)})),po(t,e),t.style.display="none",this.$el.appendChild(t);var r=Bo(t);return this.$el.removeChild(t),this._hasMove=r.hasTransform}}}};function ra(n,e){for(var t in e)n[t]=e[t];return n}Ht.config.mustUseProp=function(n,e,t){return"value"===t&&tr(n)&&"button"!==e||"selected"===t&&"option"===n||"checked"===t&&"input"===n||"muted"===t&&"video"===n},Ht.config.isReservedTag=vr,Ht.config.isReservedAttr=er,Ht.config.getTagNamespace=function(n){return hr(n)?"svg":"math"===n?"math":void 0},Ht.config.isUnknownElement=function(n){if(!K)return!0;if(vr(n))return!1;if(n=n.toLowerCase(),null!=br[n])return br[n];var e=document.createElement(n);return n.indexOf("-")>-1?br[n]=e.constructor===window.HTMLUnknownElement||e.constructor===window.HTMLElement:br[n]=/HTMLUnknownElement/.test(e.toString())},P(Ht.options.directives,Vo),P(Ht.options.components,ta),Ht.prototype.__patch__=K?qo:q,Ht.prototype.$mount=function(n,e){return function(n,e,t){var r;n.$el=e,n.$options.render||(n.$options.render=fn),et(n,"beforeMount"),r=function(){n._update(n._render(),t)},new We(n,r,q,{before:function(){n._isMounted&&!n._isDestroyed&&et(n,"beforeUpdate")}},!0),t=!1;var o=n._preWatchers;if(o)for(var a=0;a<o.length;a++)o[a].run();return null==n.$vnode&&(n._isMounted=!0,et(n,"mounted")),n}(this,n=n&&K?function(n){if("string"==typeof n){var e=document.querySelector(n);return e||document.createElement("div")}return n}(n):void 0,e)},K&&setTimeout((function(){G.devtools&&ln&&ln.emit("init",Ht)}),0);var oa=/[!'()*]/g,aa=function(n){return"%"+n.charCodeAt(0).toString(16)},sa=/%2C/g,ia=function(n){return encodeURIComponent(n).replace(oa,aa).replace(sa,",")};function la(n){try{return decodeURIComponent(n)}catch(n){0}return n}var ca=function(n){return null==n||"object"==typeof n?n:String(n)};function pa(n){var e={};return(n=n.trim().replace(/^(\?|#|&)/,""))?(n.split("&").forEach((function(n){var t=n.replace(/\+/g," ").split("="),r=la(t.shift()),o=t.length>0?la(t.join("=")):null;void 0===e[r]?e[r]=o:Array.isArray(e[r])?e[r].push(o):e[r]=[e[r],o]})),e):e}function da(n){var e=n?Object.keys(n).map((function(e){var t=n[e];if(void 0===t)return"";if(null===t)return ia(e);if(Array.isArray(t)){var r=[];return t.forEach((function(n){void 0!==n&&(null===n?r.push(ia(e)):r.push(ia(e)+"="+ia(n)))})),r.join("&")}return ia(e)+"="+ia(t)})).filter((function(n){return n.length>0})).join("&"):null;return e?"?"+e:""}var ua=/\/?$/;function ma(n,e,t,r){var o=r&&r.options.stringifyQuery,a=e.query||{};try{a=ga(a)}catch(n){}var s={name:e.name||n&&n.name,meta:n&&n.meta||{},path:e.path||"/",hash:e.hash||"",query:a,params:e.params||{},fullPath:va(e,o),matched:n?ha(n):[]};return t&&(s.redirectedFrom=va(t,o)),Object.freeze(s)}function ga(n){if(Array.isArray(n))return n.map(ga);if(n&&"object"==typeof n){var e={};for(var t in n)e[t]=ga(n[t]);return e}return n}var fa=ma(null,{path:"/"});function ha(n){for(var e=[];n;)e.unshift(n),n=n.parent;return e}function va(n,e){var t=n.path,r=n.query;void 0===r&&(r={});var o=n.hash;return void 0===o&&(o=""),(t||"/")+(e||da)(r)+o}function ba(n,e,t){return e===fa?n===e:!!e&&(n.path&&e.path?n.path.replace(ua,"")===e.path.replace(ua,"")&&(t||n.hash===e.hash&&_a(n.query,e.query)):!(!n.name||!e.name)&&(n.name===e.name&&(t||n.hash===e.hash&&_a(n.query,e.query)&&_a(n.params,e.params))))}function _a(n,e){if(void 0===n&&(n={}),void 0===e&&(e={}),!n||!e)return n===e;var t=Object.keys(n).sort(),r=Object.keys(e).sort();return t.length===r.length&&t.every((function(t,o){var a=n[t];if(r[o]!==t)return!1;var s=e[t];return null==a||null==s?a===s:"object"==typeof a&&"object"==typeof s?_a(a,s):String(a)===String(s)}))}function ya(n){for(var e=0;e<n.matched.length;e++){var t=n.matched[e];for(var r in t.instances){var o=t.instances[r],a=t.enteredCbs[r];if(o&&a){delete t.enteredCbs[r];for(var s=0;s<a.length;s++)o._isBeingDestroyed||a[s](o)}}}}var ka={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(n,e){var t=e.props,r=e.children,o=e.parent,a=e.data;a.routerView=!0;for(var s=o.$createElement,i=t.name,l=o.$route,c=o._routerViewCache||(o._routerViewCache={}),p=0,d=!1;o&&o._routerRoot!==o;){var u=o.$vnode?o.$vnode.data:{};u.routerView&&p++,u.keepAlive&&o._directInactive&&o._inactive&&(d=!0),o=o.$parent}if(a.routerViewDepth=p,d){var m=c[i],g=m&&m.component;return g?(m.configProps&&wa(g,a,m.route,m.configProps),s(g,a,r)):s()}var f=l.matched[p],h=f&&f.components[i];if(!f||!h)return c[i]=null,s();c[i]={component:h},a.registerRouteInstance=function(n,e){var t=f.instances[i];(e&&t!==n||!e&&t===n)&&(f.instances[i]=e)},(a.hook||(a.hook={})).prepatch=function(n,e){f.instances[i]=e.componentInstance},a.hook.init=function(n){n.data.keepAlive&&n.componentInstance&&n.componentInstance!==f.instances[i]&&(f.instances[i]=n.componentInstance),ya(l)};var v=f.props&&f.props[i];return v&&(ra(c[i],{route:l,configProps:v}),wa(h,a,l,v)),s(h,a,r)}};function wa(n,e,t,r){var o=e.props=function(n,e){switch(typeof e){case"undefined":return;case"object":return e;case"function":return e(n);case"boolean":return e?n.params:void 0;default:0}}(t,r);if(o){o=e.props=ra({},o);var a=e.attrs=e.attrs||{};for(var s in o)n.props&&s in n.props||(a[s]=o[s],delete o[s])}}function Ea(n,e,t){var r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;var o=e.split("/");t&&o[o.length-1]||o.pop();for(var a=n.replace(/^\//,"").split("/"),s=0;s<a.length;s++){var i=a[s];".."===i?o.pop():"."!==i&&o.push(i)}return""!==o[0]&&o.unshift(""),o.join("/")}function xa(n){return n.replace(/\/(?:\s*\/)+/g,"/")}var Aa=Array.isArray||function(n){return"[object Array]"==Object.prototype.toString.call(n)},Ba=La,za=Pa,ja=function(n,e){return qa(Pa(n,e),e)},Ta=qa,Ca=Fa,Sa=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function Pa(n,e){for(var t,r=[],o=0,a=0,s="",i=e&&e.delimiter||"/";null!=(t=Sa.exec(n));){var l=t[0],c=t[1],p=t.index;if(s+=n.slice(a,p),a=p+l.length,c)s+=c[1];else{var d=n[a],u=t[2],m=t[3],g=t[4],f=t[5],h=t[6],v=t[7];s&&(r.push(s),s="");var b=null!=u&&null!=d&&d!==u,_="+"===h||"*"===h,y="?"===h||"*"===h,k=t[2]||i,w=g||f;r.push({name:m||o++,prefix:u||"",delimiter:k,optional:y,repeat:_,partial:b,asterisk:!!v,pattern:w?Na(w):v?".*":"[^"+Da(k)+"]+?"})}}return a<n.length&&(s+=n.substr(a)),s&&r.push(s),r}function Ia(n){return encodeURI(n).replace(/[\/?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()}))}function qa(n,e){for(var t=new Array(n.length),r=0;r<n.length;r++)"object"==typeof n[r]&&(t[r]=new RegExp("^(?:"+n[r].pattern+")$",Ra(e)));return function(e,r){for(var o="",a=e||{},s=(r||{}).pretty?Ia:encodeURIComponent,i=0;i<n.length;i++){var l=n[i];if("string"!=typeof l){var c,p=a[l.name];if(null==p){if(l.optional){l.partial&&(o+=l.prefix);continue}throw new TypeError('Expected "'+l.name+'" to be defined')}if(Aa(p)){if(!l.repeat)throw new TypeError('Expected "'+l.name+'" to not repeat, but received `'+JSON.stringify(p)+"`");if(0===p.length){if(l.optional)continue;throw new TypeError('Expected "'+l.name+'" to not be empty')}for(var d=0;d<p.length;d++){if(c=s(p[d]),!t[i].test(c))throw new TypeError('Expected all "'+l.name+'" to match "'+l.pattern+'", but received `'+JSON.stringify(c)+"`");o+=(0===d?l.prefix:l.delimiter)+c}}else{if(c=l.asterisk?encodeURI(p).replace(/[?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()})):s(p),!t[i].test(c))throw new TypeError('Expected "'+l.name+'" to match "'+l.pattern+'", but received "'+c+'"');o+=l.prefix+c}}else o+=l}return o}}function Da(n){return n.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function Na(n){return n.replace(/([=!:$\/()])/g,"\\$1")}function Oa(n,e){return n.keys=e,n}function Ra(n){return n&&n.sensitive?"":"i"}function Fa(n,e,t){Aa(e)||(t=e||t,e=[]);for(var r=(t=t||{}).strict,o=!1!==t.end,a="",s=0;s<n.length;s++){var i=n[s];if("string"==typeof i)a+=Da(i);else{var l=Da(i.prefix),c="(?:"+i.pattern+")";e.push(i),i.repeat&&(c+="(?:"+l+c+")*"),a+=c=i.optional?i.partial?l+"("+c+")?":"(?:"+l+"("+c+"))?":l+"("+c+")"}}var p=Da(t.delimiter||"/"),d=a.slice(-p.length)===p;return r||(a=(d?a.slice(0,-p.length):a)+"(?:"+p+"(?=$))?"),a+=o?"$":r&&d?"":"(?="+p+"|$)",Oa(new RegExp("^"+a,Ra(t)),e)}function La(n,e,t){return Aa(e)||(t=e||t,e=[]),t=t||{},n instanceof RegExp?function(n,e){var t=n.source.match(/\((?!\?)/g);if(t)for(var r=0;r<t.length;r++)e.push({name:r,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return Oa(n,e)}(n,e):Aa(n)?function(n,e,t){for(var r=[],o=0;o<n.length;o++)r.push(La(n[o],e,t).source);return Oa(new RegExp("(?:"+r.join("|")+")",Ra(t)),e)}(n,e,t):function(n,e,t){return Fa(Pa(n,t),e,t)}(n,e,t)}Ba.parse=za,Ba.compile=ja,Ba.tokensToFunction=Ta,Ba.tokensToRegExp=Ca;var Ua=Object.create(null);function Ma(n,e,t){e=e||{};try{var r=Ua[n]||(Ua[n]=Ba.compile(n));return"string"==typeof e.pathMatch&&(e[0]=e.pathMatch),r(e,{pretty:!0})}catch(n){return""}finally{delete e[0]}}function Ga(n,e,t,r){var o="string"==typeof n?{path:n}:n;if(o._normalized)return o;if(o.name){var a=(o=ra({},n)).params;return a&&"object"==typeof a&&(o.params=ra({},a)),o}if(!o.path&&o.params&&e){(o=ra({},o))._normalized=!0;var s=ra(ra({},e.params),o.params);if(e.name)o.name=e.name,o.params=s;else if(e.matched.length){var i=e.matched[e.matched.length-1].path;o.path=Ma(i,s,e.path)}else 0;return o}var l=function(n){var e="",t="",r=n.indexOf("#");r>=0&&(e=n.slice(r),n=n.slice(0,r));var o=n.indexOf("?");return o>=0&&(t=n.slice(o+1),n=n.slice(0,o)),{path:n,query:t,hash:e}}(o.path||""),c=e&&e.path||"/",p=l.path?Ea(l.path,c,t||o.append):c,d=function(n,e,t){void 0===e&&(e={});var r,o=t||pa;try{r=o(n||"")}catch(n){r={}}for(var a in e){var s=e[a];r[a]=Array.isArray(s)?s.map(ca):ca(s)}return r}(l.query,o.query,r&&r.options.parseQuery),u=o.hash||l.hash;return u&&"#"!==u.charAt(0)&&(u="#"+u),{_normalized:!0,path:p,query:d,hash:u}}var Va,$a=function(){},Wa={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(n){var e=this,t=this.$router,r=this.$route,o=t.resolve(this.to,r,this.append),a=o.location,s=o.route,i=o.href,l={},c=t.options.linkActiveClass,p=t.options.linkExactActiveClass,d=null==c?"router-link-active":c,u=null==p?"router-link-exact-active":p,m=null==this.activeClass?d:this.activeClass,g=null==this.exactActiveClass?u:this.exactActiveClass,f=s.redirectedFrom?ma(null,Ga(s.redirectedFrom),null,t):s;l[g]=ba(r,f,this.exactPath),l[m]=this.exact||this.exactPath?l[g]:function(n,e){return 0===n.path.replace(ua,"/").indexOf(e.path.replace(ua,"/"))&&(!e.hash||n.hash===e.hash)&&function(n,e){for(var t in e)if(!(t in n))return!1;return!0}(n.query,e.query)}(r,f);var h=l[g]?this.ariaCurrentValue:null,v=function(n){Ha(n)&&(e.replace?t.replace(a,$a):t.push(a,$a))},b={click:Ha};Array.isArray(this.event)?this.event.forEach((function(n){b[n]=v})):b[this.event]=v;var _={class:l},y=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:i,route:s,navigate:v,isActive:l[m],isExactActive:l[g]});if(y){if(1===y.length)return y[0];if(y.length>1||!y.length)return 0===y.length?n():n("span",{},y)}if("a"===this.tag)_.on=b,_.attrs={href:i,"aria-current":h};else{var k=function n(e){var t;if(e)for(var r=0;r<e.length;r++){if("a"===(t=e[r]).tag)return t;if(t.children&&(t=n(t.children)))return t}}(this.$slots.default);if(k){k.isStatic=!1;var w=k.data=ra({},k.data);for(var E in w.on=w.on||{},w.on){var x=w.on[E];E in b&&(w.on[E]=Array.isArray(x)?x:[x])}for(var A in b)A in w.on?w.on[A].push(b[A]):w.on[A]=v;var B=k.data.attrs=ra({},k.data.attrs);B.href=i,B["aria-current"]=h}else _.on=b}return n(this.tag,_,this.$slots.default)}};function Ha(n){if(!(n.metaKey||n.altKey||n.ctrlKey||n.shiftKey||n.defaultPrevented||void 0!==n.button&&0!==n.button)){if(n.currentTarget&&n.currentTarget.getAttribute){var e=n.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(e))return}return n.preventDefault&&n.preventDefault(),!0}}var Za="undefined"!=typeof window;function Ka(n,e,t,r,o){var a=e||[],s=t||Object.create(null),i=r||Object.create(null);n.forEach((function(n){!function n(e,t,r,o,a,s){var i=o.path,l=o.name;0;var c=o.pathToRegexpOptions||{},p=function(n,e,t){t||(n=n.replace(/\/$/,""));if("/"===n[0])return n;if(null==e)return n;return xa(e.path+"/"+n)}(i,a,c.strict);"boolean"==typeof o.caseSensitive&&(c.sensitive=o.caseSensitive);var d={path:p,regex:Xa(p,c),components:o.components||{default:o.component},alias:o.alias?"string"==typeof o.alias?[o.alias]:o.alias:[],instances:{},enteredCbs:{},name:l,parent:a,matchAs:s,redirect:o.redirect,beforeEnter:o.beforeEnter,meta:o.meta||{},props:null==o.props?{}:o.components?o.props:{default:o.props}};o.children&&o.children.forEach((function(o){var a=s?xa(s+"/"+o.path):void 0;n(e,t,r,o,d,a)}));t[d.path]||(e.push(d.path),t[d.path]=d);if(void 0!==o.alias)for(var u=Array.isArray(o.alias)?o.alias:[o.alias],m=0;m<u.length;++m){0;var g={path:u[m],children:o.children};n(e,t,r,g,a,d.path||"/")}l&&(r[l]||(r[l]=d))}(a,s,i,n,o)}));for(var l=0,c=a.length;l<c;l++)"*"===a[l]&&(a.push(a.splice(l,1)[0]),c--,l--);return{pathList:a,pathMap:s,nameMap:i}}function Xa(n,e){return Ba(n,[],e)}function Ja(n,e){var t=Ka(n),r=t.pathList,o=t.pathMap,a=t.nameMap;function s(n,t,s){var i=Ga(n,t,!1,e),c=i.name;if(c){var p=a[c];if(!p)return l(null,i);var d=p.regex.keys.filter((function(n){return!n.optional})).map((function(n){return n.name}));if("object"!=typeof i.params&&(i.params={}),t&&"object"==typeof t.params)for(var u in t.params)!(u in i.params)&&d.indexOf(u)>-1&&(i.params[u]=t.params[u]);return i.path=Ma(p.path,i.params),l(p,i,s)}if(i.path){i.params={};for(var m=0;m<r.length;m++){var g=r[m],f=o[g];if(Ya(f.regex,i.path,i.params))return l(f,i,s)}}return l(null,i)}function i(n,t){var r=n.redirect,o="function"==typeof r?r(ma(n,t,null,e)):r;if("string"==typeof o&&(o={path:o}),!o||"object"!=typeof o)return l(null,t);var i=o,c=i.name,p=i.path,d=t.query,u=t.hash,m=t.params;if(d=i.hasOwnProperty("query")?i.query:d,u=i.hasOwnProperty("hash")?i.hash:u,m=i.hasOwnProperty("params")?i.params:m,c){a[c];return s({_normalized:!0,name:c,query:d,hash:u,params:m},void 0,t)}if(p){var g=function(n,e){return Ea(n,e.parent?e.parent.path:"/",!0)}(p,n);return s({_normalized:!0,path:Ma(g,m),query:d,hash:u},void 0,t)}return l(null,t)}function l(n,t,r){return n&&n.redirect?i(n,r||t):n&&n.matchAs?function(n,e,t){var r=s({_normalized:!0,path:Ma(t,e.params)});if(r){var o=r.matched,a=o[o.length-1];return e.params=r.params,l(a,e)}return l(null,e)}(0,t,n.matchAs):ma(n,t,r,e)}return{match:s,addRoute:function(n,e){var t="object"!=typeof n?a[n]:void 0;Ka([e||n],r,o,a,t),t&&t.alias.length&&Ka(t.alias.map((function(n){return{path:n,children:[e]}})),r,o,a,t)},getRoutes:function(){return r.map((function(n){return o[n]}))},addRoutes:function(n){Ka(n,r,o,a)}}}function Ya(n,e,t){var r=e.match(n);if(!r)return!1;if(!t)return!0;for(var o=1,a=r.length;o<a;++o){var s=n.keys[o-1];s&&(t[s.name||"pathMatch"]="string"==typeof r[o]?la(r[o]):r[o])}return!0}var Qa=Za&&window.performance&&window.performance.now?window.performance:Date;function ns(){return Qa.now().toFixed(3)}var es=ns();function ts(){return es}function rs(n){return es=n}var os=Object.create(null);function as(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var n=window.location.protocol+"//"+window.location.host,e=window.location.href.replace(n,""),t=ra({},window.history.state);return t.key=ts(),window.history.replaceState(t,"",e),window.addEventListener("popstate",ls),function(){window.removeEventListener("popstate",ls)}}function ss(n,e,t,r){if(n.app){var o=n.options.scrollBehavior;o&&n.app.$nextTick((function(){var a=function(){var n=ts();if(n)return os[n]}(),s=o.call(n,e,t,r?a:null);s&&("function"==typeof s.then?s.then((function(n){ms(n,a)})).catch((function(n){0})):ms(s,a))}))}}function is(){var n=ts();n&&(os[n]={x:window.pageXOffset,y:window.pageYOffset})}function ls(n){is(),n.state&&n.state.key&&rs(n.state.key)}function cs(n){return ds(n.x)||ds(n.y)}function ps(n){return{x:ds(n.x)?n.x:window.pageXOffset,y:ds(n.y)?n.y:window.pageYOffset}}function ds(n){return"number"==typeof n}var us=/^#\d/;function ms(n,e){var t,r="object"==typeof n;if(r&&"string"==typeof n.selector){var o=us.test(n.selector)?document.getElementById(n.selector.slice(1)):document.querySelector(n.selector);if(o){var a=n.offset&&"object"==typeof n.offset?n.offset:{};e=function(n,e){var t=document.documentElement.getBoundingClientRect(),r=n.getBoundingClientRect();return{x:r.left-t.left-e.x,y:r.top-t.top-e.y}}(o,a={x:ds((t=a).x)?t.x:0,y:ds(t.y)?t.y:0})}else cs(n)&&(e=ps(n))}else r&&cs(n)&&(e=ps(n));e&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:e.x,top:e.y,behavior:n.behavior}):window.scrollTo(e.x,e.y))}var gs,fs=Za&&((-1===(gs=window.navigator.userAgent).indexOf("Android 2.")&&-1===gs.indexOf("Android 4.0")||-1===gs.indexOf("Mobile Safari")||-1!==gs.indexOf("Chrome")||-1!==gs.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function hs(n,e){is();var t=window.history;try{if(e){var r=ra({},t.state);r.key=ts(),t.replaceState(r,"",n)}else t.pushState({key:rs(ns())},"",n)}catch(t){window.location[e?"replace":"assign"](n)}}function vs(n){hs(n,!0)}var bs={redirected:2,aborted:4,cancelled:8,duplicated:16};function _s(n,e){return ks(n,e,bs.redirected,'Redirected when going from "'+n.fullPath+'" to "'+function(n){if("string"==typeof n)return n;if("path"in n)return n.path;var e={};return ws.forEach((function(t){t in n&&(e[t]=n[t])})),JSON.stringify(e,null,2)}(e)+'" via a navigation guard.')}function ys(n,e){return ks(n,e,bs.cancelled,'Navigation cancelled from "'+n.fullPath+'" to "'+e.fullPath+'" with a new navigation.')}function ks(n,e,t,r){var o=new Error(r);return o._isRouter=!0,o.from=n,o.to=e,o.type=t,o}var ws=["params","query","hash"];function Es(n){return Object.prototype.toString.call(n).indexOf("Error")>-1}function xs(n,e){return Es(n)&&n._isRouter&&(null==e||n.type===e)}function As(n,e,t){var r=function(o){o>=n.length?t():n[o]?e(n[o],(function(){r(o+1)})):r(o+1)};r(0)}function Bs(n){return function(e,t,r){var o=!1,a=0,s=null;zs(n,(function(n,e,t,i){if("function"==typeof n&&void 0===n.cid){o=!0,a++;var l,c=Cs((function(e){var o;((o=e).__esModule||Ts&&"Module"===o[Symbol.toStringTag])&&(e=e.default),n.resolved="function"==typeof e?e:Va.extend(e),t.components[i]=e,--a<=0&&r()})),p=Cs((function(n){var e="Failed to resolve async component "+i+": "+n;s||(s=Es(n)?n:new Error(e),r(s))}));try{l=n(c,p)}catch(n){p(n)}if(l)if("function"==typeof l.then)l.then(c,p);else{var d=l.component;d&&"function"==typeof d.then&&d.then(c,p)}}})),o||r()}}function zs(n,e){return js(n.map((function(n){return Object.keys(n.components).map((function(t){return e(n.components[t],n.instances[t],n,t)}))})))}function js(n){return Array.prototype.concat.apply([],n)}var Ts="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Cs(n){var e=!1;return function(){for(var t=[],r=arguments.length;r--;)t[r]=arguments[r];if(!e)return e=!0,n.apply(this,t)}}var Ss=function(n,e){this.router=n,this.base=function(n){if(!n)if(Za){var e=document.querySelector("base");n=(n=e&&e.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else n="/";"/"!==n.charAt(0)&&(n="/"+n);return n.replace(/\/$/,"")}(e),this.current=fa,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Ps(n,e,t,r){var o=zs(n,(function(n,r,o,a){var s=function(n,e){"function"!=typeof n&&(n=Va.extend(n));return n.options[e]}(n,e);if(s)return Array.isArray(s)?s.map((function(n){return t(n,r,o,a)})):t(s,r,o,a)}));return js(r?o.reverse():o)}function Is(n,e){if(e)return function(){return n.apply(e,arguments)}}Ss.prototype.listen=function(n){this.cb=n},Ss.prototype.onReady=function(n,e){this.ready?n():(this.readyCbs.push(n),e&&this.readyErrorCbs.push(e))},Ss.prototype.onError=function(n){this.errorCbs.push(n)},Ss.prototype.transitionTo=function(n,e,t){var r,o=this;try{r=this.router.match(n,this.current)}catch(n){throw this.errorCbs.forEach((function(e){e(n)})),n}var a=this.current;this.confirmTransition(r,(function(){o.updateRoute(r),e&&e(r),o.ensureURL(),o.router.afterHooks.forEach((function(n){n&&n(r,a)})),o.ready||(o.ready=!0,o.readyCbs.forEach((function(n){n(r)})))}),(function(n){t&&t(n),n&&!o.ready&&(xs(n,bs.redirected)&&a===fa||(o.ready=!0,o.readyErrorCbs.forEach((function(e){e(n)}))))}))},Ss.prototype.confirmTransition=function(n,e,t){var r=this,o=this.current;this.pending=n;var a,s,i=function(n){!xs(n)&&Es(n)&&(r.errorCbs.length?r.errorCbs.forEach((function(e){e(n)})):console.error(n)),t&&t(n)},l=n.matched.length-1,c=o.matched.length-1;if(ba(n,o)&&l===c&&n.matched[l]===o.matched[c])return this.ensureURL(),n.hash&&ss(this.router,o,n,!1),i(((s=ks(a=o,n,bs.duplicated,'Avoided redundant navigation to current location: "'+a.fullPath+'".')).name="NavigationDuplicated",s));var p=function(n,e){var t,r=Math.max(n.length,e.length);for(t=0;t<r&&n[t]===e[t];t++);return{updated:e.slice(0,t),activated:e.slice(t),deactivated:n.slice(t)}}(this.current.matched,n.matched),d=p.updated,u=p.deactivated,m=p.activated,g=[].concat(function(n){return Ps(n,"beforeRouteLeave",Is,!0)}(u),this.router.beforeHooks,function(n){return Ps(n,"beforeRouteUpdate",Is)}(d),m.map((function(n){return n.beforeEnter})),Bs(m)),f=function(e,t){if(r.pending!==n)return i(ys(o,n));try{e(n,o,(function(e){!1===e?(r.ensureURL(!0),i(function(n,e){return ks(n,e,bs.aborted,'Navigation aborted from "'+n.fullPath+'" to "'+e.fullPath+'" via a navigation guard.')}(o,n))):Es(e)?(r.ensureURL(!0),i(e)):"string"==typeof e||"object"==typeof e&&("string"==typeof e.path||"string"==typeof e.name)?(i(_s(o,n)),"object"==typeof e&&e.replace?r.replace(e):r.push(e)):t(e)}))}catch(n){i(n)}};As(g,f,(function(){As(function(n){return Ps(n,"beforeRouteEnter",(function(n,e,t,r){return function(n,e,t){return function(r,o,a){return n(r,o,(function(n){"function"==typeof n&&(e.enteredCbs[t]||(e.enteredCbs[t]=[]),e.enteredCbs[t].push(n)),a(n)}))}}(n,t,r)}))}(m).concat(r.router.resolveHooks),f,(function(){if(r.pending!==n)return i(ys(o,n));r.pending=null,e(n),r.router.app&&r.router.app.$nextTick((function(){ya(n)}))}))}))},Ss.prototype.updateRoute=function(n){this.current=n,this.cb&&this.cb(n)},Ss.prototype.setupListeners=function(){},Ss.prototype.teardown=function(){this.listeners.forEach((function(n){n()})),this.listeners=[],this.current=fa,this.pending=null};var qs=function(n){function e(e,t){n.call(this,e,t),this._startLocation=Ds(this.base)}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router,t=e.options.scrollBehavior,r=fs&&t;r&&this.listeners.push(as());var o=function(){var t=n.current,o=Ds(n.base);n.current===fa&&o===n._startLocation||n.transitionTo(o,(function(n){r&&ss(e,n,t,!0)}))};window.addEventListener("popstate",o),this.listeners.push((function(){window.removeEventListener("popstate",o)}))}},e.prototype.go=function(n){window.history.go(n)},e.prototype.push=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){hs(xa(r.base+n.fullPath)),ss(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){vs(xa(r.base+n.fullPath)),ss(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.ensureURL=function(n){if(Ds(this.base)!==this.current.fullPath){var e=xa(this.base+this.current.fullPath);n?hs(e):vs(e)}},e.prototype.getCurrentLocation=function(){return Ds(this.base)},e}(Ss);function Ds(n){var e=window.location.pathname,t=e.toLowerCase(),r=n.toLowerCase();return!n||t!==r&&0!==t.indexOf(xa(r+"/"))||(e=e.slice(n.length)),(e||"/")+window.location.search+window.location.hash}var Ns=function(n){function e(e,t,r){n.call(this,e,t),r&&function(n){var e=Ds(n);if(!/^\/#/.test(e))return window.location.replace(xa(n+"/#"+e)),!0}(this.base)||Os()}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router.options.scrollBehavior,t=fs&&e;t&&this.listeners.push(as());var r=function(){var e=n.current;Os()&&n.transitionTo(Rs(),(function(r){t&&ss(n.router,r,e,!0),fs||Us(r.fullPath)}))},o=fs?"popstate":"hashchange";window.addEventListener(o,r),this.listeners.push((function(){window.removeEventListener(o,r)}))}},e.prototype.push=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){Ls(n.fullPath),ss(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){Us(n.fullPath),ss(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.go=function(n){window.history.go(n)},e.prototype.ensureURL=function(n){var e=this.current.fullPath;Rs()!==e&&(n?Ls(e):Us(e))},e.prototype.getCurrentLocation=function(){return Rs()},e}(Ss);function Os(){var n=Rs();return"/"===n.charAt(0)||(Us("/"+n),!1)}function Rs(){var n=window.location.href,e=n.indexOf("#");return e<0?"":n=n.slice(e+1)}function Fs(n){var e=window.location.href,t=e.indexOf("#");return(t>=0?e.slice(0,t):e)+"#"+n}function Ls(n){fs?hs(Fs(n)):window.location.hash=n}function Us(n){fs?vs(Fs(n)):window.location.replace(Fs(n))}var Ms=function(n){function e(e,t){n.call(this,e,t),this.stack=[],this.index=-1}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.push=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index+1).concat(n),r.index++,e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index).concat(n),e&&e(n)}),t)},e.prototype.go=function(n){var e=this,t=this.index+n;if(!(t<0||t>=this.stack.length)){var r=this.stack[t];this.confirmTransition(r,(function(){var n=e.current;e.index=t,e.updateRoute(r),e.router.afterHooks.forEach((function(e){e&&e(r,n)}))}),(function(n){xs(n,bs.duplicated)&&(e.index=t)}))}},e.prototype.getCurrentLocation=function(){var n=this.stack[this.stack.length-1];return n?n.fullPath:"/"},e.prototype.ensureURL=function(){},e}(Ss),Gs=function(n){void 0===n&&(n={}),this.app=null,this.apps=[],this.options=n,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Ja(n.routes||[],this);var e=n.mode||"hash";switch(this.fallback="history"===e&&!fs&&!1!==n.fallback,this.fallback&&(e="hash"),Za||(e="abstract"),this.mode=e,e){case"history":this.history=new qs(this,n.base);break;case"hash":this.history=new Ns(this,n.base,this.fallback);break;case"abstract":this.history=new Ms(this,n.base);break;default:0}},Vs={currentRoute:{configurable:!0}};Gs.prototype.match=function(n,e,t){return this.matcher.match(n,e,t)},Vs.currentRoute.get=function(){return this.history&&this.history.current},Gs.prototype.init=function(n){var e=this;if(this.apps.push(n),n.$once("hook:destroyed",(function(){var t=e.apps.indexOf(n);t>-1&&e.apps.splice(t,1),e.app===n&&(e.app=e.apps[0]||null),e.app||e.history.teardown()})),!this.app){this.app=n;var t=this.history;if(t instanceof qs||t instanceof Ns){var r=function(n){t.setupListeners(),function(n){var r=t.current,o=e.options.scrollBehavior;fs&&o&&"fullPath"in n&&ss(e,n,r,!1)}(n)};t.transitionTo(t.getCurrentLocation(),r,r)}t.listen((function(n){e.apps.forEach((function(e){e._route=n}))}))}},Gs.prototype.beforeEach=function(n){return Ws(this.beforeHooks,n)},Gs.prototype.beforeResolve=function(n){return Ws(this.resolveHooks,n)},Gs.prototype.afterEach=function(n){return Ws(this.afterHooks,n)},Gs.prototype.onReady=function(n,e){this.history.onReady(n,e)},Gs.prototype.onError=function(n){this.history.onError(n)},Gs.prototype.push=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.push(n,e,t)}));this.history.push(n,e,t)},Gs.prototype.replace=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.replace(n,e,t)}));this.history.replace(n,e,t)},Gs.prototype.go=function(n){this.history.go(n)},Gs.prototype.back=function(){this.go(-1)},Gs.prototype.forward=function(){this.go(1)},Gs.prototype.getMatchedComponents=function(n){var e=n?n.matched?n:this.resolve(n).route:this.currentRoute;return e?[].concat.apply([],e.matched.map((function(n){return Object.keys(n.components).map((function(e){return n.components[e]}))}))):[]},Gs.prototype.resolve=function(n,e,t){var r=Ga(n,e=e||this.history.current,t,this),o=this.match(r,e),a=o.redirectedFrom||o.fullPath;return{location:r,route:o,href:function(n,e,t){var r="hash"===t?"#"+e:e;return n?xa(n+"/"+r):r}(this.history.base,a,this.mode),normalizedTo:r,resolved:o}},Gs.prototype.getRoutes=function(){return this.matcher.getRoutes()},Gs.prototype.addRoute=function(n,e){this.matcher.addRoute(n,e),this.history.current!==fa&&this.history.transitionTo(this.history.getCurrentLocation())},Gs.prototype.addRoutes=function(n){this.matcher.addRoutes(n),this.history.current!==fa&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(Gs.prototype,Vs);var $s=Gs;function Ws(n,e){return n.push(e),function(){var t=n.indexOf(e);t>-1&&n.splice(t,1)}}Gs.install=function n(e){if(!n.installed||Va!==e){n.installed=!0,Va=e;var t=function(n){return void 0!==n},r=function(n,e){var r=n.$options._parentVnode;t(r)&&t(r=r.data)&&t(r=r.registerRouteInstance)&&r(n,e)};e.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),e.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,r(this,this)},destroyed:function(){r(this)}}),Object.defineProperty(e.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(e.prototype,"$route",{get:function(){return this._routerRoot._route}}),e.component("RouterView",ka),e.component("RouterLink",Wa);var o=e.config.optionMergeStrategies;o.beforeRouteEnter=o.beforeRouteLeave=o.beforeRouteUpdate=o.created}},Gs.version="3.6.5",Gs.isNavigationFailure=xs,Gs.NavigationFailureType=bs,Gs.START_LOCATION=fa,Za&&window.Vue&&window.Vue.use(Gs);t(154),t(17),t(164);t(165),t(31);var Hs={NotFound:()=>Promise.all([t.e(0),t.e(4)]).then(t.bind(null,363)),Layout:()=>Promise.all([t.e(0),t.e(2)]).then(t.bind(null,362))},Zs={"v-f7879d60":()=>t.e(8).then(t.bind(null,365)),"v-6f7bb862":()=>t.e(10).then(t.bind(null,366)),"v-08a8939a":()=>t.e(9).then(t.bind(null,367)),"v-29274a29":()=>t.e(12).then(t.bind(null,368)),"v-44df3b79":()=>t.e(13).then(t.bind(null,369)),"v-6430d054":()=>t.e(11).then(t.bind(null,370)),"v-341f9276":()=>t.e(14).then(t.bind(null,371)),"v-ba5a65c4":()=>t.e(15).then(t.bind(null,372)),"v-64f910e0":()=>t.e(6).then(t.bind(null,373)),"v-3ff5ce46":()=>t.e(16).then(t.bind(null,374)),"v-470b5455":()=>t.e(7).then(t.bind(null,375)),"v-411a2b26":()=>t.e(17).then(t.bind(null,376)),"v-14bd5c2a":()=>t.e(18).then(t.bind(null,377)),"v-0ee080d4":()=>t.e(20).then(t.bind(null,378)),"v-9fc226e2":()=>t.e(19).then(t.bind(null,379)),"v-c31c1604":()=>t.e(22).then(t.bind(null,380)),"v-476540fe":()=>t.e(21).then(t.bind(null,381)),"v-38f161f6":()=>t.e(24).then(t.bind(null,382)),"v-44e743b8":()=>t.e(23).then(t.bind(null,383)),"v-2f20c458":()=>t.e(25).then(t.bind(null,384)),"v-e543b750":()=>t.e(27).then(t.bind(null,385)),"v-3c54c66f":()=>t.e(26).then(t.bind(null,386)),"v-7c3ad306":()=>t.e(28).then(t.bind(null,387)),"v-5793b4fb":()=>t.e(29).then(t.bind(null,388)),"v-967c62b6":()=>t.e(30).then(t.bind(null,389)),"v-097050d4":()=>t.e(31).then(t.bind(null,390)),"v-2ecc148c":()=>t.e(32).then(t.bind(null,391)),"v-278df89e":()=>t.e(33).then(t.bind(null,392)),"v-61296d7f":()=>t.e(34).then(t.bind(null,393)),"v-be37f416":()=>t.e(35).then(t.bind(null,394)),"v-ae93950e":()=>t.e(36).then(t.bind(null,395)),"v-834e066a":()=>t.e(37).then(t.bind(null,396)),"v-b9336fc4":()=>t.e(39).then(t.bind(null,397)),"v-300c8022":()=>t.e(40).then(t.bind(null,398)),"v-450eddde":()=>t.e(38).then(t.bind(null,399)),"v-ed00c198":()=>t.e(42).then(t.bind(null,400)),"v-06e111a1":()=>t.e(41).then(t.bind(null,401)),"v-e35e3500":()=>t.e(44).then(t.bind(null,402)),"v-a7079bc2":()=>t.e(45).then(t.bind(null,403)),"v-da2a3b40":()=>t.e(43).then(t.bind(null,404)),"v-3644af7a":()=>t.e(46).then(t.bind(null,405)),"v-6fc4dda8":()=>t.e(48).then(t.bind(null,406)),"v-dea92c98":()=>t.e(47).then(t.bind(null,407)),"v-a6f8fe8c":()=>t.e(50).then(t.bind(null,408)),"v-cf78fd3a":()=>t.e(51).then(t.bind(null,409)),"v-3599af91":()=>t.e(52).then(t.bind(null,410)),"v-3e233877":()=>t.e(49).then(t.bind(null,411)),"v-628321a6":()=>t.e(54).then(t.bind(null,412)),"v-77d8c9f4":()=>t.e(55).then(t.bind(null,413)),"v-226be104":()=>t.e(53).then(t.bind(null,414)),"v-22b0df18":()=>t.e(56).then(t.bind(null,415)),"v-fab79492":()=>t.e(57).then(t.bind(null,416)),"v-fab7554a":()=>t.e(58).then(t.bind(null,417)),"v-15cbdfc3":()=>t.e(59).then(t.bind(null,418)),"v-74cd7d9e":()=>t.e(60).then(t.bind(null,419)),"v-37cf929d":()=>t.e(61).then(t.bind(null,420)),"v-40dce165":()=>t.e(62).then(t.bind(null,421)),"v-722217eb":()=>t.e(63).then(t.bind(null,422)),"v-224b6ec4":()=>t.e(64).then(t.bind(null,423)),"v-73bfa208":()=>t.e(67).then(t.bind(null,424)),"v-9c48962a":()=>t.e(66).then(t.bind(null,425)),"v-ff2c286e":()=>t.e(65).then(t.bind(null,426)),"v-364f49b5":()=>t.e(68).then(t.bind(null,427)),"v-2f2878f8":()=>t.e(69).then(t.bind(null,428)),"v-33efde74":()=>t.e(70).then(t.bind(null,429)),"v-5000cd97":()=>t.e(71).then(t.bind(null,430)),"v-fad5dda8":()=>t.e(72).then(t.bind(null,431)),"v-7f082a66":()=>t.e(73).then(t.bind(null,432)),"v-4371bf05":()=>t.e(75).then(t.bind(null,433)),"v-13f4cf5a":()=>t.e(74).then(t.bind(null,434)),"v-ba59602c":()=>t.e(76).then(t.bind(null,435)),"v-4edff9fd":()=>t.e(77).then(t.bind(null,436)),"v-69c6394c":()=>t.e(79).then(t.bind(null,437)),"v-3d85724c":()=>t.e(78).then(t.bind(null,438)),"v-465edabc":()=>t.e(80).then(t.bind(null,439)),"v-2afdd346":()=>t.e(81).then(t.bind(null,440)),"v-2f3e170c":()=>t.e(82).then(t.bind(null,441)),"v-66d9b7c0":()=>t.e(84).then(t.bind(null,442)),"v-569242f6":()=>t.e(83).then(t.bind(null,443)),"v-deed5aca":()=>t.e(86).then(t.bind(null,444)),"v-2835a650":()=>t.e(85).then(t.bind(null,445)),"v-1c8f04f0":()=>t.e(87).then(t.bind(null,446)),"v-e7a69188":()=>t.e(88).then(t.bind(null,447)),"v-2bccd8fe":()=>t.e(89).then(t.bind(null,448)),"v-6dda71f1":()=>t.e(90).then(t.bind(null,449)),"v-ccb4316a":()=>t.e(91).then(t.bind(null,450)),"v-3b2ad750":()=>t.e(92).then(t.bind(null,451)),"v-d6123402":()=>t.e(94).then(t.bind(null,452)),"v-1ba8c576":()=>t.e(95).then(t.bind(null,453)),"v-3ff27440":()=>t.e(93).then(t.bind(null,454)),"v-99455fdc":()=>t.e(96).then(t.bind(null,455)),"v-7f2a6202":()=>t.e(97).then(t.bind(null,456)),"v-26efa3da":()=>t.e(98).then(t.bind(null,457)),"v-32e66a02":()=>t.e(100).then(t.bind(null,458)),"v-5973e693":()=>t.e(99).then(t.bind(null,459)),"v-7e9794a8":()=>t.e(102).then(t.bind(null,460)),"v-7accfee0":()=>t.e(103).then(t.bind(null,461)),"v-23857ed1":()=>t.e(101).then(t.bind(null,462)),"v-48a6492a":()=>t.e(104).then(t.bind(null,463)),"v-38488cef":()=>t.e(105).then(t.bind(null,464)),"v-602416af":()=>t.e(106).then(t.bind(null,465)),"v-c5fbc8ae":()=>t.e(107).then(t.bind(null,364)),"v-fe55c380":()=>t.e(108).then(t.bind(null,466)),"v-67feae3c":()=>t.e(109).then(t.bind(null,467)),"v-31af7045":()=>t.e(110).then(t.bind(null,468)),"v-36a595c5":()=>t.e(112).then(t.bind(null,469)),"v-1e8d1344":()=>t.e(113).then(t.bind(null,470)),"v-5cc30ba5":()=>t.e(111).then(t.bind(null,471))};function Ks(n){const e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}const Xs=/-(\w)/g,Js=Ks(n=>n.replace(Xs,(n,e)=>e?e.toUpperCase():"")),Ys=/\B([A-Z])/g,Qs=Ks(n=>n.replace(Ys,"-$1").toLowerCase()),ni=Ks(n=>n.charAt(0).toUpperCase()+n.slice(1));function ei(n,e){if(!e)return;if(n(e))return n(e);return e.includes("-")?n(ni(Js(e))):n(ni(e))||n(Qs(e))}const ti=Object.assign({},Hs,Zs),ri=n=>ti[n],oi=n=>Zs[n],ai=n=>Hs[n],si=n=>Ht.component(n);function ii(n){return ei(oi,n)}function li(n){return ei(ai,n)}function ci(n){return ei(ri,n)}function pi(n){return ei(si,n)}function di(...n){return Promise.all(n.filter(n=>n).map(async n=>{if(!pi(n)&&ci(n)){const e=await ci(n)();Ht.component(n,e.default)}}))}function ui(n,e){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[n]=e)}var mi=t(123),gi=t.n(mi),fi=t(124),hi=t.n(fi),vi={created(){if(this.siteMeta=this.$site.headTags.filter(([n])=>"meta"===n).map(([n,e])=>e),this.$ssrContext){const e=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(n=e)?n.map(n=>{let e="<meta";return Object.keys(n).forEach(t=>{e+=` ${t}="${hi()(n[t])}"`}),e+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=_i(this.$canonicalUrl)}var n},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const n=this.getMergedMetaTags();this.currentMetaTags=yi(n,this.currentMetaTags)},getMergedMetaTags(){const n=this.$page.frontmatter.meta||[];return gi()([{name:"description",content:this.$description}],n,this.siteMeta,ki)},updateCanonicalLink(){bi(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",_i(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){yi(null,this.currentMetaTags),bi()}};function bi(){const n=document.querySelector("link[rel='canonical']");n&&n.remove()}function _i(n=""){return n?`<link href="${n}" rel="canonical" />`:""}function yi(n,e){if(e&&[...e].filter(n=>n.parentNode===document.head).forEach(n=>document.head.removeChild(n)),n)return n.map(n=>{const e=document.createElement("meta");return Object.keys(n).forEach(t=>{e.setAttribute(t,n[t])}),document.head.appendChild(e),e})}function ki(n){for(const e of["name","property","itemprop"])if(n.hasOwnProperty(e))return n[e]+e;return JSON.stringify(n)}t(66);var wi=t(68),Ei={mounted(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(wi)()((function(){this.setActiveHash()}),300),setActiveHash(){const n=[].slice.call(document.querySelectorAll(".sidebar-link")),e=[].slice.call(document.querySelectorAll(".header-anchor")).filter(e=>n.some(n=>n.hash===e.hash)),t=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),r=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),o=window.innerHeight+t;for(let n=0;n<e.length;n++){const a=e[n],s=e[n+1],i=0===n&&0===t||t>=a.parentElement.offsetTop+10&&(!s||t<s.parentElement.offsetTop-10),l=decodeURIComponent(this.$route.hash);if(i&&l!==decodeURIComponent(a.hash)){const t=a;if(o===r)for(let t=n+1;t<e.length;t++)if(l===decodeURIComponent(e[t].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(t.hash),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})}}}},beforeDestroy(){window.removeEventListener("scroll",this.onScroll)}},xi=t(45),Ai=t.n(xi),Bi={mounted(){Ai.a.configure({showSpinner:!1}),this.$router.beforeEach((n,e,t)=>{n.path===e.path||Ht.component(n.name)||Ai.a.start(),t()}),this.$router.afterEach(()=>{Ai.a.done(),this.isSidebarOpen=!1})}};t(275),t(276);class zi{constructor(){this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}show({text:n="",duration:e=3e3}){let t=document.createElement("div");t.className="message move-in",t.innerHTML=`\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">${n}</div>\n    `,this.containerEl.appendChild(t),e>0&&setTimeout(()=>{this.close(t)},e)}close(n){n.className=n.className.replace("move-in",""),n.className+="move-out",n.addEventListener("animationend",()=>{n.remove()})}}var ji={mounted(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy(){setTimeout(()=>{(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach(n=>{document.querySelectorAll(n).forEach(this.generateCopyButton)})},1e3)},generateCopyButton(n){if(n.classList.contains("codecopy-enabled"))return;const e=document.createElement("i");e.className="code-copy",e.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',e.title="Copy to clipboard",e.addEventListener("click",()=>{this.copyToClipboard(n.innerText)}),n.appendChild(e),n.classList.add("codecopy-enabled")},copyToClipboard(n){const e=document.createElement("textarea");e.value=n,e.setAttribute("readonly",""),e.style.position="absolute",e.style.left="-9999px",document.body.appendChild(e);const t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);e.select(),document.execCommand("copy");(new zi).show({text:"复制成功",duration:1e3}),document.body.removeChild(e),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}};!function(n,e){void 0===e&&(e={});var t=e.insertAt;if(n&&"undefined"!=typeof document){var r=document.head||document.getElementsByTagName("head")[0],o=document.createElement("style");o.type="text/css","top"===t&&r.firstChild?r.insertBefore(o,r.firstChild):r.appendChild(o),o.styleSheet?o.styleSheet.cssText=n:o.appendChild(document.createTextNode(n))}}("@media (max-width: 1000px) {\n  .vuepress-plugin-demo-block__h_code {\n    display: none;\n  }\n  .vuepress-plugin-demo-block__app {\n    margin-left: auto !important;\n    margin-right: auto !important;\n  }\n}\n.vuepress-plugin-demo-block__wrapper {\n  margin-top: 10px;\n  border: 1px solid #ebebeb;\n  border-radius: 4px;\n  transition: all 0.2s;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display {\n  height: 400px;\n  display: flex;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__app {\n  width: 300px;\n  border: 1px solid #ebebeb;\n  box-shadow: 1px 1px 3px #ebebeb;\n  margin-right: 5px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code {\n  flex: 1;\n  overflow: auto;\n  height: 100%;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code > pre {\n  overflow: visible;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  max-height: 400px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper div {\n  box-sizing: border-box;\n}\n.vuepress-plugin-demo-block__wrapper:hover {\n  box-shadow: 0 0 11px rgba(33, 33, 33, 0.2);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code {\n  overflow: hidden;\n  height: 0;\n  padding: 0 !important;\n  background-color: #282c34;\n  border-radius: 0 !important;\n  transition: height 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code pre {\n  margin: 0 !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  padding: 20px;\n  border-bottom: 1px solid #ebebeb;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer {\n  position: relative;\n  text-align: center;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__codepen {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__expand::before {\n  border-top: none;\n  border-right: 6px solid transparent;\n  border-bottom: 6px solid #ccc;\n  border-left: 6px solid transparent;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__codepen,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand span,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand::before {\n  border-top-color: #3eaf7c !important;\n  border-bottom-color: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover svg {\n  fill: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand-text {\n  transition: all 0.5s;\n  opacity: 0;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:nth-last-child(2) {\n  right: 50px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:last-child {\n  right: 10px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button {\n  border-color: transparent;\n  background-color: transparent;\n  font-size: 14px;\n  color: #3eaf7c;\n  cursor: pointer;\n  outline: none;\n  margin: 0;\n  width: 46px;\n  position: relative;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::before {\n  content: attr(data-tip);\n  white-space: nowrap;\n  position: absolute;\n  top: -30px;\n  left: 50%;\n  color: #eee;\n  line-height: 1;\n  z-index: 1000;\n  border-radius: 4px;\n  padding: 6px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  background-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::after {\n  content: '' !important;\n  display: block;\n  position: absolute;\n  left: 50%;\n  top: -5px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  border: 5px solid transparent;\n  border-top-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button svg {\n  width: 34px;\n  height: 20px;\n  fill: #ccc;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__codepen {\n  position: absolute;\n  top: 10px;\n  transition: all 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand {\n  position: relative;\n  width: 100px;\n  height: 40px;\n  margin: 0;\n  color: #3eaf7c;\n  font-size: 14px;\n  background-color: transparent;\n  border-color: transparent;\n  outline: none;\n  transition: all 0.5s;\n  cursor: pointer;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand::before {\n  content: \"\";\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  width: 0;\n  height: 0;\n  border-top: 6px solid #ccc;\n  border-right: 6px solid transparent;\n  border-left: 6px solid transparent;\n  -webkit-transform: translate(-50%, -50%);\n          transform: translate(-50%, -50%);\n}\n");var Ti={jsLib:[],cssLib:[],jsfiddle:!0,codepen:!0,codepenLayout:"left",codepenJsProcessor:"babel",codepenEditors:"101",horizontal:!1,vue:"https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js",react:"https://cdn.jsdelivr.net/npm/react/umd/react.production.min.js",reactDOM:"https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.production.min.js"},Ci={},Si=function(n){return'<div id="app">\n'.concat(n,"\n</div>")},Pi=function(n){return window.$VUEPRESS_DEMO_BLOCK&&void 0!==window.$VUEPRESS_DEMO_BLOCK[n]?window.$VUEPRESS_DEMO_BLOCK[n]:Ti[n]},Ii=function n(e,t,r){var o=document.createElement(e);return t&&Object.keys(t).forEach((function(n){if(n.indexOf("data"))o[n]=t[n];else{var e=n.replace("data","");o.dataset[e]=t[n]}})),r&&r.forEach((function(e){var t=e.tag,r=e.attrs,a=e.children;o.appendChild(n(t,r,a))})),o},qi=function(n,e,t){var r,o=(r=n.querySelectorAll(".".concat(e)),Array.prototype.slice.call(r));return 1!==o.length||t?o:o[0]},Di=function(n,e){var t,r,o=n.match(/<style>([\s\S]+)<\/style>/),a=n.match(/<template>([\s\S]+)<\/template>/),s=n.match(/<script>([\s\S]+)<\/script>/),i={css:o&&o[1].replace(/^\n|\n$/g,""),html:a&&a[1].replace(/^\n|\n$/g,""),js:s&&s[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};i.htmlTpl=Si(i.html),i.jsTpl=(t=i.js,r=t.replace(/export\s+default\s*?\{\n*/,"").replace(/\n*\}\s*$/,"").trim(),"new Vue({\n  el: '#app',\n  ".concat(r,"\n})")),i.script=function(n,e){var t=n.split(/export\s+default/),r="(function() {".concat(t[0]," ; return ").concat(t[1],"})()"),o=window.Babel?window.Babel.transform(r,{presets:["es2015"]}).code:r,a=[eval][0](o);return a.template=e,a}(i.js,i.html);var l=Pi("vue");return i.jsLib.unshift(l),i},Ni=function(n,e){var t,r=n.match(/<style>([\s\S]+)<\/style>/),o=n.match(/<html>([\s\S]+)<\/html>/),a=n.match(/<script>([\s\S]+)<\/script>/),s={css:r&&r[1].replace(/^\n|\n$/g,""),html:o&&o[1].replace(/^\n|\n$/g,""),js:a&&a[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};return s.htmlTpl=s.html,s.jsTpl=s.js,s.script=(t=s.js,window.Babel?window.Babel.transform(t,{presets:["es2015"]}).code:t),s},Oi=function(n){return n=n.replace("export default ","").replace(/App\.__style__(\s*)=(\s*)`([\s\S]*)?`/,""),n+='ReactDOM.render(React.createElement(App), document.getElementById("app"))'};function Ri(){var n=qi(document,"vuepress-plugin-demo-block__wrapper",!0);n.length?n.forEach((function(n){if("true"!==n.dataset.created){n.style.display="block";var e=qi(n,"vuepress-plugin-demo-block__code"),t=qi(n,"vuepress-plugin-demo-block__display"),r=qi(n,"vuepress-plugin-demo-block__footer"),o=qi(t,"vuepress-plugin-demo-block__app"),a=decodeURIComponent(n.dataset.code),s=decodeURIComponent(n.dataset.config),i=decodeURIComponent(n.dataset.type);s=s?JSON.parse(s):{};var l=e.querySelector("div").clientHeight,c="react"===i?function(n,e){var t=(0,window.Babel.transform)(n,{presets:["es2015","react"]}).code,r="(function(exports){var module={};module.exports=exports;".concat(t,";return module.exports.__esModule?module.exports.default:module.exports;})({})"),o=new Function("return ".concat(r))(),a={js:o,css:o.__style__||"",jsLib:e.jsLib||[],cssLib:e.cssLib||[],jsTpl:Oi(n),htmlTpl:Si("")},s=Pi("react"),i=Pi("reactDOM");return a.jsLib.unshift(s,i),a}(a,s):"vanilla"===i?Ni(a,s):Di(a,s),p=Ii("button",{className:"".concat("vuepress-plugin-demo-block__expand")});if(r.appendChild(p),p.addEventListener("click",Fi.bind(null,p,l,e,r)),Pi("jsfiddle")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,o=n.jsLib,a=n.cssLib,s=o.concat(a).concat(Pi("cssLib")).concat(Pi("jsLib")).join(",");return Ii("form",{className:"vuepress-plugin-demo-block__jsfiddle",target:"_blank",action:"https://jsfiddle.net/api/post/library/pure/",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"css",value:e}},{tag:"input",attrs:{type:"hidden",name:"html",value:t}},{tag:"input",attrs:{type:"hidden",name:"js",value:r}},{tag:"input",attrs:{type:"hidden",name:"panel_js",value:3}},{tag:"input",attrs:{type:"hidden",name:"wrap",value:1}},{tag:"input",attrs:{type:"hidden",name:"resources",value:s}},{tag:"button",attrs:{type:"submit",className:"vuepress-plugin-demo-block__button",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088289967" class="icon" style="" viewBox="0 0 1170 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1952" xmlns:xlink="http://www.w3.org/1999/xlink" width="228.515625" height="200"><defs><style type="text/css"></style></defs><path d="M1028.571429 441.142857q63.428571 26.285714 102.571428 83.142857T1170.285714 650.857143q0 93.714286-67.428571 160.285714T940 877.714286q-2.285714 0-6.571429-0.285715t-6-0.285714H232q-97.142857-5.714286-164.571429-71.714286T0 645.142857q0-62.857143 31.428571-116t84-84q-6.857143-22.285714-6.857142-46.857143 0-65.714286 46.857142-112t113.714286-46.285714q54.285714 0 98.285714 33.142857 42.857143-88 127.142858-141.714286t186.571428-53.714285q94.857143 0 174.857143 46T982.571429 248.571429t46.571428 172q0 3.428571-0.285714 10.285714t-0.285714 10.285714zM267.428571 593.142857q0 69.714286 48 110.285714t118.857143 40.571429q78.285714 0 137.142857-56.571429-9.142857-11.428571-27.142857-32.285714T519.428571 626.285714q-38.285714 37.142857-82.285714 37.142857-31.428571 0-53.428571-19.142857T361.714286 594.285714q0-30.285714 22-49.714285t52.285714-19.428572q25.142857 0 48.285714 12t41.714286 31.428572 37.142857 42.857142 39.428572 46.857143 44 42.857143 55.428571 31.428572 69.428571 12q69.142857 0 116.857143-40.857143T936 594.857143q0-69.142857-48-109.714286t-118.285714-40.571428q-81.714286 0-137.714286 55.428571l53.142857 61.714286q37.714286-36.571429 81.142857-36.571429 29.714286 0 52.571429 18.857143t22.857143 48q0 32.571429-21.142857 52.285714t-53.714286 19.714286q-24.571429 0-47.142857-12t-41.142857-31.428571-37.428572-42.857143-39.714286-46.857143-44.285714-42.857143-55.142857-31.428571T434.285714 444.571429q-69.714286 0-118.285714 40.285714T267.428571 593.142857z" p-id="1953"></path></svg>',datatip:"JSFiddle"}}])}(c)),Pi("codepen")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,o=n.jsLib,a=n.cssLib,s=JSON.stringify({css:e,html:t,js:r,js_external:o.concat(Pi("jsLib")).join(";"),css_external:a.concat(Pi("cssLib")).join(";"),layout:Pi("codepenLayout"),js_pre_processor:Pi("codepenJsProcessor"),editors:Pi("codepenEditors")});return Ii("form",{className:"vuepress-plugin-demo-block__codepen",target:"_blank",action:"https://codepen.io/pen/define",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"data",value:s}},{tag:"button",attrs:{type:"submit",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088271207" class="icon" style="" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1737" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><defs><style type="text/css"></style></defs><path d="M123.428571 668l344.571429 229.714286v-205.142857L277.142857 565.142857z m-35.428571-82.285714l110.285714-73.714286-110.285714-73.714286v147.428572z m468 312l344.571429-229.714286-153.714286-102.857143-190.857143 127.428572v205.142857z m-44-281.714286l155.428571-104-155.428571-104-155.428571 104zM277.142857 458.857143l190.857143-127.428572V126.285714L123.428571 356z m548.571429 53.142857l110.285714 73.714286V438.285714z m-78.857143-53.142857l153.714286-102.857143-344.571429-229.714286v205.142857z m277.142857-102.857143v312q0 23.428571-19.428571 36.571429l-468 312q-12 7.428571-24.571429 7.428571t-24.571429-7.428571L19.428571 704.571429q-19.428571-13.142857-19.428571-36.571429V356q0-23.428571 19.428571-36.571429L487.428571 7.428571q12-7.428571 24.571429-7.428571t24.571429 7.428571l468 312q19.428571 13.142857 19.428571 36.571429z" p-id="1738"></path></svg>',className:"vuepress-plugin-demo-block__button",datatip:"Codepen"}}])}(c)),void 0!==s.horizontal?s.horizontal:Pi("horizontal")){n.classList.add("vuepress-plugin-demo-block__horizontal");var d=e.firstChild.cloneNode(!0);d.classList.add("vuepress-plugin-demo-block__h_code"),t.appendChild(d)}if(c.css&&function(n){if(!Ci[n]){var e=Ii("style",{innerHTML:n});document.body.appendChild(e),Ci[n]=!0}}(c.css),"react"===i)ReactDOM.render(React.createElement(c.js),o);else if("vue"===i){var u=(new(Vue.extend(c.script))).$mount();o.appendChild(u.$el)}else"vanilla"===i&&(o.innerHTML=c.html,new Function("return (function(){".concat(c.script,"})()"))());n.dataset.created="true"}})):setTimeout((function(n){Ri()}),300)}function Fi(n,e,t,r){var o="1"!==n.dataset.isExpand;t.style.height=o?"".concat(e,"px"):0,o?r.classList.add("vuepress-plugin-demo-block__show-link"):r.classList.remove("vuepress-plugin-demo-block__show-link"),n.dataset.isExpand=o?"1":"0"}var Li={mounted:function(){window.$VUEPRESS_DEMO_BLOCK={jsfiddle:!1,codepen:!0,horizontal:!1},Ri()},updated:function(){Ri()}},Ui="auto",Mi="zoom-in",Gi="zoom-out",Vi="grab",$i="move";function Wi(n,e,t){var r=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],o={passive:!1};r?n.addEventListener(e,t,o):n.removeEventListener(e,t,o)}function Hi(n,e){if(n){var t=new Image;t.onload=function(){e&&e(t)},t.src=n}}function Zi(n){return n.dataset.original?n.dataset.original:"A"===n.parentNode.tagName?n.parentNode.getAttribute("href"):null}function Ki(n,e,t){!function(n){var e=Xi,t=Ji;if(n.transition){var r=n.transition;delete n.transition,n[e]=r}if(n.transform){var o=n.transform;delete n.transform,n[t]=o}}(e);var r=n.style,o={};for(var a in e)t&&(o[a]=r[a]||""),r[a]=e[a];return o}var Xi="transition",Ji="transform",Yi="transform",Qi="transitionend";var nl=function(){},el={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:nl,onClose:nl,onGrab:nl,onMove:nl,onRelease:nl,onBeforeOpen:nl,onBeforeClose:nl,onBeforeGrab:nl,onBeforeRelease:nl,onImageLoading:nl,onImageLoaded:nl},tl={init:function(n){var e,t;e=this,t=n,Object.getOwnPropertyNames(Object.getPrototypeOf(e)).forEach((function(n){e[n]=e[n].bind(t)}))},click:function(n){if(n.preventDefault(),ol(n))return window.open(this.target.srcOriginal||n.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(n.currentTarget)},scroll:function(){var n=document.documentElement||document.body.parentNode||document.body,e=window.pageXOffset||n.scrollLeft,t=window.pageYOffset||n.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:e,y:t});var r=this.lastScrollPosition.x-e,o=this.lastScrollPosition.y-t,a=this.options.scrollThreshold;(Math.abs(o)>=a||Math.abs(r)>=a)&&(this.lastScrollPosition=null,this.close())},keydown:function(n){(function(n){return"Escape"===(n.key||n.code)||27===n.keyCode})(n)&&(this.released?this.close():this.release(this.close))},mousedown:function(n){if(rl(n)&&!ol(n)){n.preventDefault();var e=n.clientX,t=n.clientY;this.pressTimer=setTimeout(function(){this.grab(e,t)}.bind(this),200)}},mousemove:function(n){this.released||this.move(n.clientX,n.clientY)},mouseup:function(n){rl(n)&&!ol(n)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(n){n.preventDefault();var e=n.touches[0],t=e.clientX,r=e.clientY;this.pressTimer=setTimeout(function(){this.grab(t,r)}.bind(this),200)},touchmove:function(n){if(!this.released){var e=n.touches[0],t=e.clientX,r=e.clientY;this.move(t,r)}},touchend:function(n){(function(n){n.targetTouches.length})(n)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function rl(n){return 0===n.button}function ol(n){return n.metaKey||n.ctrlKey}var al={init:function(n){this.el=document.createElement("div"),this.instance=n,this.parent=document.body,Ki(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(n.options),Wi(this.el,"click",n.handler.clickOverlay.bind(n))},updateStyle:function(n){Ki(this.el,{zIndex:n.zIndex,backgroundColor:n.bgColor,transition:"opacity\n        "+n.transitionDuration+"s\n        "+n.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},sl="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n},il=function(){function n(n,e){for(var t=0;t<e.length;t++){var r=e[t];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(n,r.key,r)}}return function(e,t,r){return t&&n(e.prototype,t),r&&n(e,r),e}}(),ll=Object.assign||function(n){for(var e=1;e<arguments.length;e++){var t=arguments[e];for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(n[r]=t[r])}return n},cl={init:function(n,e){this.el=n,this.instance=e,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=Zi(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var n=this.instance.options,e=n.zIndex,t=n.enableGrab,r=n.transitionDuration,o=n.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:e+1,cursor:t?Vi:Gi,transition:Yi+"\n        "+r+"s\n        "+o,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=Ki(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,Ki(this.el,{transform:"none"})},grab:function(n,e,t){var r=pl(),o=r.x-n,a=r.y-e;Ki(this.el,{cursor:$i,transform:"translate3d(\n        "+(this.translate.x+o)+"px, "+(this.translate.y+a)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(n,e,t){var r=pl(),o=r.x-n,a=r.y-e;Ki(this.el,{transition:Yi,transform:"translate3d(\n        "+(this.translate.x+o)+"px, "+(this.translate.y+a)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){Ki(this.el,this.styleClose)},restoreOpenStyle:function(){Ki(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var n=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var e=this.el.cloneNode(!1);e.setAttribute("src",this.srcOriginal),e.style.position="fixed",e.style.visibility="hidden",n.appendChild(e),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),n.removeChild(e)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var n=pl(),e=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:n.x-e,y:n.y-t}},calculateScale:function(){var n=this.el.dataset,e=n.zoomingHeight,t=n.zoomingWidth,r=this.instance.options,o=r.customSize,a=r.scaleBase;if(!o&&e&&t)return{x:t/this.rect.width,y:e/this.rect.height};if(o&&"object"===(void 0===o?"undefined":sl(o)))return{x:o.width/this.rect.width,y:o.height/this.rect.height};var s=this.rect.width/2,i=this.rect.height/2,l=pl(),c={x:l.x-s,y:l.y-i},p=c.x/s,d=c.y/i,u=a+Math.min(p,d);if(o&&"string"==typeof o){var m=t||this.el.naturalWidth,g=e||this.el.naturalHeight,f=parseFloat(o)*m/(100*this.rect.width),h=parseFloat(o)*g/(100*this.rect.height);if(u>f||u>h)return{x:f,y:h}}return{x:u,y:u}}};function pl(){var n=document.documentElement;return{x:Math.min(n.clientWidth,window.innerWidth)/2,y:Math.min(n.clientHeight,window.innerHeight)/2}}function dl(n,e,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(r){Wi(n,r,e[r],t)}))}var ul=function(){function n(e){!function(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}(this,n),this.target=Object.create(cl),this.overlay=Object.create(al),this.handler=Object.create(tl),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=ll({},el,e),this.overlay.init(this),this.handler.init(this)}return il(n,[{key:"listen",value:function(n){if("string"==typeof n)for(var e=document.querySelectorAll(n),t=e.length;t--;)this.listen(e[t]);else"IMG"===n.tagName&&(n.style.cursor=Mi,Wi(n,"click",this.handler.click),this.options.preloadImage&&Hi(Zi(n)));return this}},{key:"config",value:function(n){return n?(ll(this.options,n),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(n){var e=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var r="string"==typeof n?document.querySelector(n):n;if("IMG"===r.tagName){if(this.options.onBeforeOpen(r),this.target.init(r,this),!this.options.preloadImage){var o=this.target.srcOriginal;null!=o&&(this.options.onImageLoading(r),Hi(o,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),Wi(document,"scroll",this.handler.scroll),Wi(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&Wi(window,"resize",this.handler.resizeWindow);var a=function n(){Wi(r,Qi,n,!1),e.lock=!1,e.target.upgradeSource(),e.options.enableGrab&&dl(document,e.handler,!0),t(r)};return Wi(r,Qi,a),this}}}},{key:"close",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=Ui,this.overlay.fadeOut(),this.target.zoomOut(),Wi(document,"scroll",this.handler.scroll,!1),Wi(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&Wi(window,"resize",this.handler.resizeWindow,!1);var r=function r(){Wi(t,Qi,r,!1),n.shown=!1,n.lock=!1,n.target.downgradeSource(),n.options.enableGrab&&dl(document,n.handler,!1),n.target.restoreCloseStyle(),n.overlay.remove(),e(t)};return Wi(t,Qi,r),this}}},{key:"grab",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var o=this.target.el;this.options.onBeforeGrab(o),this.released=!1,this.target.grab(n,e,t);var a=function n(){Wi(o,Qi,n,!1),r(o)};return Wi(o,Qi,a),this}}},{key:"move",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=$i,this.target.move(n,e,t);var o=this.target.el,a=function n(){Wi(o,Qi,n,!1),r(o)};return Wi(o,Qi,a),this}}},{key:"release",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=Ui,this.target.restoreOpenStyle();var r=function r(){Wi(t,Qi,r,!1),n.lock=!1,n.released=!0,e(t)};return Wi(t,Qi,r),this}}}]),n}();const ml=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),gl=Number("500");class fl{constructor(){this.instance=new ul(ml)}update(n=".theme-vdoing-content img:not(.no-zoom)"){"undefined"!=typeof window&&this.instance.listen(n)}updateDelay(n=".theme-vdoing-content img:not(.no-zoom)",e=gl){setTimeout(()=>this.update(n),e)}}var hl=[vi,Ei,Bi,ji,Li,{watch:{"$page.path"(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted(){this.$vuepress.zooming=new fl,this.$vuepress.zooming.updateDelay()}}],vl={name:"GlobalLayout",computed:{layout(){const n=this.getLayout();return ui("layout",n),Ht.component(n)}},methods:{getLayout(){if(this.$page.path){const n=this.$page.frontmatter.layout;return n&&(this.$vuepress.getLayoutAsyncComponent(n)||this.$vuepress.getVueComponent(n))?n:"Layout"}return"NotFound"}}},bl=t(5),_l=Object(bl.a)(vl,(function(){return(0,this._self._c)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(n,e,t){switch(e){case"components":n[e]||(n[e]={}),Object.assign(n[e],t);break;case"mixins":n[e]||(n[e]=[]),n[e].push(...t);break;default:throw new Error("Unknown option name.")}}(_l,"mixins",hl);const yl=[{name:"v-f7879d60",path:"/pages/f3cf17/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-f7879d60").then(t)}},{path:"/pages/f3cf17/index.html",redirect:"/pages/f3cf17/"},{path:"/01.云原生/06.docker/01.容器的本质.html",redirect:"/pages/f3cf17/"},{name:"v-6f7bb862",path:"/pages/d3768c/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-6f7bb862").then(t)}},{path:"/pages/d3768c/index.html",redirect:"/pages/d3768c/"},{path:"/01.云原生/06.docker/03.手动实现docker容器bridge网络模型.html",redirect:"/pages/d3768c/"},{name:"v-08a8939a",path:"/pages/39f36e/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-08a8939a").then(t)}},{path:"/pages/39f36e/index.html",redirect:"/pages/39f36e/"},{path:"/01.云原生/06.docker/02.docker容器.html",redirect:"/pages/39f36e/"},{name:"v-29274a29",path:"/pages/2b547f/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-29274a29").then(t)}},{path:"/pages/2b547f/index.html",redirect:"/pages/2b547f/"},{path:"/01.云原生/07.k8s/03.k8s之pod.html",redirect:"/pages/2b547f/"},{name:"v-44df3b79",path:"/pages/d73c88/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-44df3b79").then(t)}},{path:"/pages/d73c88/index.html",redirect:"/pages/d73c88/"},{path:"/01.云原生/07.k8s/04.k8s之deployment.html",redirect:"/pages/d73c88/"},{name:"v-6430d054",path:"/pages/0ddeb7/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-6430d054").then(t)}},{path:"/pages/0ddeb7/index.html",redirect:"/pages/0ddeb7/"},{path:"/01.云原生/06.docker/04.docker容器单机网络.html",redirect:"/pages/0ddeb7/"},{name:"v-341f9276",path:"/pages/1f860b/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-341f9276").then(t)}},{path:"/pages/1f860b/index.html",redirect:"/pages/1f860b/"},{path:"/01.云原生/07.k8s/05.k8s之service.html",redirect:"/pages/1f860b/"},{name:"v-ba5a65c4",path:"/pages/ff8188/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-ba5a65c4").then(t)}},{path:"/pages/ff8188/index.html",redirect:"/pages/ff8188/"},{path:"/01.云原生/07.k8s/06.k8s之ConfigMap和Secret.html",redirect:"/pages/ff8188/"},{name:"v-64f910e0",path:"/go_performance/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-64f910e0").then(t)}},{path:"/go_performance/index.html",redirect:"/go_performance/"},{path:"/00.目录页/01.Go语言高性能编程.html",redirect:"/go_performance/"},{name:"v-3ff5ce46",path:"/pages/c96905/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-3ff5ce46").then(t)}},{path:"/pages/c96905/index.html",redirect:"/pages/c96905/"},{path:"/01.云原生/07.k8s/07.k8s之Job和CronJob.html",redirect:"/pages/c96905/"},{name:"v-470b5455",path:"/bug_hunt/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-470b5455").then(t)}},{path:"/bug_hunt/index.html",redirect:"/bug_hunt/"},{path:"/00.目录页/02.Bug 通缉令.html",redirect:"/bug_hunt/"},{name:"v-411a2b26",path:"/pages/92bee4/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-411a2b26").then(t)}},{path:"/pages/92bee4/index.html",redirect:"/pages/92bee4/"},{path:"/01.云原生/07.k8s/08.k8s之DaemonSet.html",redirect:"/pages/92bee4/"},{name:"v-14bd5c2a",path:"/pages/095c75/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-14bd5c2a").then(t)}},{path:"/pages/095c75/index.html",redirect:"/pages/095c75/"},{path:"/01.云原生/07.k8s/09.k8s之PV、PVC和StorageClass.html",redirect:"/pages/095c75/"},{name:"v-0ee080d4",path:"/pages/9e17c8/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-0ee080d4").then(t)}},{path:"/pages/9e17c8/index.html",redirect:"/pages/9e17c8/"},{path:"/01.云原生/07.k8s/11.使用kubeadm安装k8s.html",redirect:"/pages/9e17c8/"},{name:"v-9fc226e2",path:"/pages/d178a2/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-9fc226e2").then(t)}},{path:"/pages/d178a2/index.html",redirect:"/pages/d178a2/"},{path:"/01.云原生/07.k8s/10.k8s之StatefulSet.html",redirect:"/pages/d178a2/"},{name:"v-c31c1604",path:"/pages/b1b4a3/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-c31c1604").then(t)}},{path:"/pages/b1b4a3/index.html",redirect:"/pages/b1b4a3/"},{path:"/01.云原生/07.k8s/13.django后端服务、logstash和flink接入VictoriaMetrics指标监控.html",redirect:"/pages/b1b4a3/"},{name:"v-476540fe",path:"/pages/27987d/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-476540fe").then(t)}},{path:"/pages/27987d/index.html",redirect:"/pages/27987d/"},{path:"/01.云原生/07.k8s/12.pod中将代码与运行环境分离.html",redirect:"/pages/27987d/"},{name:"v-38f161f6",path:"/pages/f0f725/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-38f161f6").then(t)}},{path:"/pages/f0f725/index.html",redirect:"/pages/f0f725/"},{path:"/01.云原生/07.k8s/15.理解calico容器网络通信方案原理.html",redirect:"/pages/f0f725/"},{name:"v-44e743b8",path:"/pages/d9d0ce/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-44e743b8").then(t)}},{path:"/pages/d9d0ce/index.html",redirect:"/pages/d9d0ce/"},{path:"/01.云原生/07.k8s/14.理解flannel的三种容器网络方案原理.html",redirect:"/pages/d9d0ce/"},{name:"v-2f20c458",path:"/pages/b3955c/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-2f20c458").then(t)}},{path:"/pages/b3955c/index.html",redirect:"/pages/b3955c/"},{path:"/01.云原生/07.k8s/16.kubernetes service如何通过iptables转发.html",redirect:"/pages/b3955c/"},{name:"v-e543b750",path:"/pages/cf65ba/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-e543b750").then(t)}},{path:"/pages/cf65ba/index.html",redirect:"/pages/cf65ba/"},{path:"/02.Bug 通缉令/01.一次服务升级时pg表DDL执行超时失败.html",redirect:"/pages/cf65ba/"},{name:"v-3c54c66f",path:"/pages/6e0045/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-3c54c66f").then(t)}},{path:"/pages/6e0045/index.html",redirect:"/pages/6e0045/"},{path:"/01.云原生/07.k8s/17.kube-proxy源码分析.html",redirect:"/pages/6e0045/"},{name:"v-7c3ad306",path:"/pages/de98b1/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-7c3ad306").then(t)}},{path:"/pages/de98b1/index.html",redirect:"/pages/de98b1/"},{path:"/02.Bug 通缉令/02.服务启动时出现 OOM.html",redirect:"/pages/de98b1/"},{name:"v-5793b4fb",path:"/pages/fa114f/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-5793b4fb").then(t)}},{path:"/pages/fa114f/index.html",redirect:"/pages/fa114f/"},{path:"/03.中间件/01.kafka/01.listener和advertised.listeners的作用.html",redirect:"/pages/fa114f/"},{name:"v-967c62b6",path:"/pages/2d69c7/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-967c62b6").then(t)}},{path:"/pages/2d69c7/index.html",redirect:"/pages/2d69c7/"},{path:"/03.中间件/03.mysql/01.mysql之日志.html",redirect:"/pages/2d69c7/"},{name:"v-097050d4",path:"/pages/0d8f4a/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-097050d4").then(t)}},{path:"/pages/0d8f4a/index.html",redirect:"/pages/0d8f4a/"},{path:"/03.中间件/03.mysql/02.mysql之MVCC原理.html",redirect:"/pages/0d8f4a/"},{name:"v-2ecc148c",path:"/pages/2bbeb3/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-2ecc148c").then(t)}},{path:"/pages/2bbeb3/index.html",redirect:"/pages/2bbeb3/"},{path:"/03.中间件/05.redis/01.redis之五种基本数据类型.html",redirect:"/pages/2bbeb3/"},{name:"v-278df89e",path:"/pages/4c6b13/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-278df89e").then(t)}},{path:"/pages/4c6b13/index.html",redirect:"/pages/4c6b13/"},{path:"/03.中间件/05.redis/02.redis之持久化.html",redirect:"/pages/4c6b13/"},{name:"v-61296d7f",path:"/pages/8072eb/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-61296d7f").then(t)}},{path:"/pages/8072eb/index.html",redirect:"/pages/8072eb/"},{path:"/03.中间件/05.redis/03. redis之主从库同步.html",redirect:"/pages/8072eb/"},{name:"v-be37f416",path:"/pages/ffee9e/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-be37f416").then(t)}},{path:"/pages/ffee9e/index.html",redirect:"/pages/ffee9e/"},{path:"/03.中间件/05.redis/04. redis之哨兵机制.html",redirect:"/pages/ffee9e/"},{name:"v-ae93950e",path:"/pages/1c2914/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-ae93950e").then(t)}},{path:"/pages/1c2914/index.html",redirect:"/pages/1c2914/"},{path:"/03.中间件/05.redis/05. redis之分片集群.html",redirect:"/pages/1c2914/"},{name:"v-834e066a",path:"/pages/0d7b25/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-834e066a").then(t)}},{path:"/pages/0d7b25/index.html",redirect:"/pages/0d7b25/"},{path:"/03.中间件/05.redis/06. redis之缓存.html",redirect:"/pages/0d7b25/"},{name:"v-b9336fc4",path:"/pages/e31b06/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-b9336fc4").then(t)}},{path:"/pages/e31b06/index.html",redirect:"/pages/e31b06/"},{path:"/04.编程/01.python/01.基础/01.python迭代器与生成器.html",redirect:"/pages/e31b06/"},{name:"v-300c8022",path:"/pages/5fa368/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-300c8022").then(t)}},{path:"/pages/5fa368/index.html",redirect:"/pages/5fa368/"},{path:"/04.编程/01.python/01.基础/02.python元编程.html",redirect:"/pages/5fa368/"},{name:"v-450eddde",path:"/pages/adedbd/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-450eddde").then(t)}},{path:"/pages/adedbd/index.html",redirect:"/pages/adedbd/"},{path:"/03.中间件/06.logstash/01.pulsar阻塞导致logstash无法接入日志.html",redirect:"/pages/adedbd/"},{name:"v-ed00c198",path:"/pages/a6b804/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-ed00c198").then(t)}},{path:"/pages/a6b804/index.html",redirect:"/pages/a6b804/"},{path:"/04.编程/01.python/01.基础/04.python上下文管理器.html",redirect:"/pages/a6b804/"},{name:"v-06e111a1",path:"/pages/78c648/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-06e111a1").then(t)}},{path:"/pages/78c648/index.html",redirect:"/pages/78c648/"},{path:"/04.编程/01.python/01.基础/03.python垃圾回收机制.html",redirect:"/pages/78c648/"},{name:"v-e35e3500",path:"/pages/33b8d0/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-e35e3500").then(t)}},{path:"/pages/33b8d0/index.html",redirect:"/pages/33b8d0/"},{path:"/04.编程/01.python/01.基础/06.使用python实现单例模式的三种方式.html",redirect:"/pages/33b8d0/"},{name:"v-a7079bc2",path:"/pages/d8fd49/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-a7079bc2").then(t)}},{path:"/pages/d8fd49/index.html",redirect:"/pages/d8fd49/"},{path:"/04.编程/01.python/01.基础/07.python中import原理.html",redirect:"/pages/d8fd49/"},{name:"v-da2a3b40",path:"/pages/7434f1/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-da2a3b40").then(t)}},{path:"/pages/7434f1/index.html",redirect:"/pages/7434f1/"},{path:"/04.编程/01.python/01.基础/05.python装饰器的使用方法.html",redirect:"/pages/7434f1/"},{name:"v-3644af7a",path:"/pages/8d9ab9/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-3644af7a").then(t)}},{path:"/pages/8d9ab9/index.html",redirect:"/pages/8d9ab9/"},{path:"/04.编程/01.python/02.第三方库/01.使用ddt实现unittest的参数化测试.html",redirect:"/pages/8d9ab9/"},{name:"v-6fc4dda8",path:"/pages/ec5110/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-6fc4dda8").then(t)}},{path:"/pages/ec5110/index.html",redirect:"/pages/ec5110/"},{path:"/04.编程/01.python/02.第三方库/03.django-apschedule定时任务异常停止.html",redirect:"/pages/ec5110/"},{name:"v-dea92c98",path:"/pages/069c65/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-dea92c98").then(t)}},{path:"/pages/069c65/index.html",redirect:"/pages/069c65/"},{path:"/04.编程/01.python/02.第三方库/02.ddt源码分析.html",redirect:"/pages/069c65/"},{name:"v-a6f8fe8c",path:"/pages/25eafd/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-a6f8fe8c").then(t)}},{path:"/pages/25eafd/index.html",redirect:"/pages/25eafd/"},{path:"/04.编程/01.python/06.django/02.django rest_framework使用jwt.html",redirect:"/pages/25eafd/"},{name:"v-cf78fd3a",path:"/pages/626675/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-cf78fd3a").then(t)}},{path:"/pages/626675/index.html",redirect:"/pages/626675/"},{path:"/04.编程/01.python/06.django/03.django rest_framework Authentication.html",redirect:"/pages/626675/"},{name:"v-3599af91",path:"/pages/070fec/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-3599af91").then(t)}},{path:"/pages/070fec/index.html",redirect:"/pages/070fec/"},{path:"/04.编程/01.python/06.django/04.django rest_framework异常处理.html",redirect:"/pages/070fec/"},{name:"v-3e233877",path:"/pages/853501/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-3e233877").then(t)}},{path:"/pages/853501/index.html",redirect:"/pages/853501/"},{path:"/04.编程/01.python/06.django/01.django celery 结合使用.html",redirect:"/pages/853501/"},{name:"v-628321a6",path:"/pages/f2738b/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-628321a6").then(t)}},{path:"/pages/f2738b/index.html",redirect:"/pages/f2738b/"},{path:"/04.编程/01.python/06.django/06.django压缩文件下载.html",redirect:"/pages/f2738b/"},{name:"v-77d8c9f4",path:"/pages/c28126/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-77d8c9f4").then(t)}},{path:"/pages/c28126/index.html",redirect:"/pages/c28126/"},{path:"/04.编程/01.python/06.django/07.django rest_framework使用pytest单元测试.html",redirect:"/pages/c28126/"},{name:"v-226be104",path:"/pages/c3af6a/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-226be104").then(t)}},{path:"/pages/c3af6a/index.html",redirect:"/pages/c3af6a/"},{path:"/04.编程/01.python/06.django/05.django rest_framework 自定义文档.html",redirect:"/pages/c3af6a/"},{name:"v-22b0df18",path:"/pages/b90015/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-22b0df18").then(t)}},{path:"/pages/b90015/index.html",redirect:"/pages/b90015/"},{path:"/04.编程/01.python/06.django/08.django restframework choice 自定义输出数据.html",redirect:"/pages/b90015/"},{name:"v-fab79492",path:"/pages/cfdb5f/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-fab79492").then(t)}},{path:"/pages/cfdb5f/index.html",redirect:"/pages/cfdb5f/"},{path:"/04.编程/01.python/06.django/09.django Filtering 使用.html",redirect:"/pages/cfdb5f/"},{name:"v-fab7554a",path:"/pages/e75ceb/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-fab7554a").then(t)}},{path:"/pages/e75ceb/index.html",redirect:"/pages/e75ceb/"},{path:"/04.编程/01.python/06.django/10.django viewset 和 Router 配合使用时报的错.html",redirect:"/pages/e75ceb/"},{name:"v-15cbdfc3",path:"/pages/acdd50/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-15cbdfc3").then(t)}},{path:"/pages/acdd50/index.html",redirect:"/pages/acdd50/"},{path:"/04.编程/01.python/06.django/11.django model的序列化.html",redirect:"/pages/acdd50/"},{name:"v-74cd7d9e",path:"/pages/382755/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-74cd7d9e").then(t)}},{path:"/pages/382755/index.html",redirect:"/pages/382755/"},{path:"/04.编程/01.python/06.django/12.django中使用AbStractUser.html",redirect:"/pages/382755/"},{name:"v-37cf929d",path:"/pages/060c51/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-37cf929d").then(t)}},{path:"/pages/060c51/index.html",redirect:"/pages/060c51/"},{path:"/04.编程/01.python/06.django/13.django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users.html",redirect:"/pages/060c51/"},{name:"v-40dce165",path:"/pages/de01e2/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-40dce165").then(t)}},{path:"/pages/de01e2/index.html",redirect:"/pages/de01e2/"},{path:"/04.编程/01.python/06.django/14.django 中 media配置.html",redirect:"/pages/de01e2/"},{name:"v-722217eb",path:"/pages/b422bd/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-722217eb").then(t)}},{path:"/pages/b422bd/index.html",redirect:"/pages/b422bd/"},{path:"/04.编程/01.python/06.django/15.django 外键引用自身和on_delete参数.html",redirect:"/pages/b422bd/"},{name:"v-224b6ec4",path:"/pages/f0d816/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-224b6ec4").then(t)}},{path:"/pages/f0d816/index.html",redirect:"/pages/f0d816/"},{path:"/04.编程/01.python/06.django/16.django 警告 while time zone support is active.html",redirect:"/pages/f0d816/"},{name:"v-73bfa208",path:"/pages/b71dc2/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-73bfa208").then(t)}},{path:"/pages/b71dc2/index.html",redirect:"/pages/b71dc2/"},{path:"/04.编程/01.python/07.flask/01.Flask使用flask_socketio实现websocket.html",redirect:"/pages/b71dc2/"},{name:"v-9c48962a",path:"/pages/4b0adb/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-9c48962a").then(t)}},{path:"/pages/4b0adb/index.html",redirect:"/pages/4b0adb/"},{path:"/04.编程/01.python/06.django/18.django-prometheus使用及源码分析.html",redirect:"/pages/4b0adb/"},{name:"v-ff2c286e",path:"/pages/cb262f/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-ff2c286e").then(t)}},{path:"/pages/cb262f/index.html",redirect:"/pages/cb262f/"},{path:"/04.编程/01.python/06.django/17.django rest_framework 分页.html",redirect:"/pages/cb262f/"},{name:"v-364f49b5",path:"/pages/c59edf/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-364f49b5").then(t)}},{path:"/pages/c59edf/index.html",redirect:"/pages/c59edf/"},{path:"/04.编程/01.python/07.flask/02.flask结合mongo.html",redirect:"/pages/c59edf/"},{name:"v-2f2878f8",path:"/pages/4c38f5/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-2f2878f8").then(t)}},{path:"/pages/4c38f5/index.html",redirect:"/pages/4c38f5/"},{path:"/04.编程/01.python/08.tornado/01.tornado 文件上传.html",redirect:"/pages/4c38f5/"},{name:"v-33efde74",path:"/pages/c24905/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-33efde74").then(t)}},{path:"/pages/c24905/index.html",redirect:"/pages/c24905/"},{path:"/04.编程/01.python/08.tornado/02.tornado 使用jwt完成用户异步认证.html",redirect:"/pages/c24905/"},{name:"v-5000cd97",path:"/pages/22f35b/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-5000cd97").then(t)}},{path:"/pages/22f35b/index.html",redirect:"/pages/22f35b/"},{path:"/04.编程/01.python/08.tornado/03.tornado 用户密码 bcrypt加密.html",redirect:"/pages/22f35b/"},{name:"v-fad5dda8",path:"/pages/7ac01f/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-fad5dda8").then(t)}},{path:"/pages/7ac01f/index.html",redirect:"/pages/7ac01f/"},{path:"/04.编程/01.python/08.tornado/04.tornado 结合wtforms使用表单操作.html",redirect:"/pages/7ac01f/"},{name:"v-7f082a66",path:"/pages/d18657/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-7f082a66").then(t)}},{path:"/pages/d18657/index.html",redirect:"/pages/d18657/"},{path:"/04.编程/01.python/08.tornado/05.tornado finish和write区别.html",redirect:"/pages/d18657/"},{name:"v-4371bf05",path:"/pages/f9d78c/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-4371bf05").then(t)}},{path:"/pages/f9d78c/index.html",redirect:"/pages/f9d78c/"},{path:"/04.编程/01.python/09.其他/01.python简单使用grpc.html",redirect:"/pages/f9d78c/"},{name:"v-13f4cf5a",path:"/pages/113ab1/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-13f4cf5a").then(t)}},{path:"/pages/113ab1/index.html",redirect:"/pages/113ab1/"},{path:"/04.编程/01.python/08.tornado/06.tornado 使用peewee-async 完成异步orm数据库操作.html",redirect:"/pages/113ab1/"},{name:"v-ba59602c",path:"/pages/72664a/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-ba59602c").then(t)}},{path:"/pages/72664a/index.html",redirect:"/pages/72664a/"},{path:"/04.编程/01.python/09.其他/02.pyspark streaming简介 和 消费 kafka示例.html",redirect:"/pages/72664a/"},{name:"v-4edff9fd",path:"/pages/7f6078/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-4edff9fd").then(t)}},{path:"/pages/7f6078/index.html",redirect:"/pages/7f6078/"},{path:"/04.编程/01.python/09.其他/03.基于pre-commit的Python代码规范落地实践.html",redirect:"/pages/7f6078/"},{name:"v-69c6394c",path:"/pages/c41003/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-69c6394c").then(t)}},{path:"/pages/c41003/index.html",redirect:"/pages/c41003/"},{path:"/04.编程/02.go语言/02. gin中validator模块的源码分析.html",redirect:"/pages/c41003/"},{name:"v-3d85724c",path:"/pages/87014e/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-3d85724c").then(t)}},{path:"/pages/87014e/index.html",redirect:"/pages/87014e/"},{path:"/04.编程/02.go语言/01.go简单使用grpc.html",redirect:"/pages/87014e/"},{name:"v-465edabc",path:"/pages/cf9a4d/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-465edabc").then(t)}},{path:"/pages/cf9a4d/index.html",redirect:"/pages/cf9a4d/"},{path:"/04.编程/02.go语言/03.优化gin表单的错误提示信息.html",redirect:"/pages/cf9a4d/"},{name:"v-2afdd346",path:"/pages/d93df5/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-2afdd346").then(t)}},{path:"/pages/d93df5/index.html",redirect:"/pages/d93df5/"},{path:"/04.编程/02.go语言/04.go中如何处理error.html",redirect:"/pages/d93df5/"},{name:"v-2f3e170c",path:"/pages/36b0b2/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-2f3e170c").then(t)}},{path:"/pages/36b0b2/index.html",redirect:"/pages/36b0b2/"},{path:"/04.编程/02.go语言/05.tcp缓存引起的日志丢失.html",redirect:"/pages/36b0b2/"},{name:"v-66d9b7c0",path:"/pages/d2c214/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-66d9b7c0").then(t)}},{path:"/pages/d2c214/index.html",redirect:"/pages/d2c214/"},{path:"/04.编程/02.go语言/07.go语言高性能编程/01.Go协程池深度解析：原理、实现与最佳实践.html",redirect:"/pages/d2c214/"},{name:"v-569242f6",path:"/pages/91d2d9/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-569242f6").then(t)}},{path:"/pages/91d2d9/index.html",redirect:"/pages/91d2d9/"},{path:"/04.编程/02.go语言/06.使用etcd分布式锁导致的协程泄露与死锁问题.html",redirect:"/pages/91d2d9/"},{name:"v-deed5aca",path:"/pages/88360d/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-deed5aca").then(t)}},{path:"/pages/88360d/index.html",redirect:"/pages/88360d/"},{path:"/04.编程/02.go语言/07.go语言高性能编程/03.Go语言遍历性能深度解析：从原理到优化实践.html",redirect:"/pages/88360d/"},{name:"v-2835a650",path:"/pages/49057b/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-2835a650").then(t)}},{path:"/pages/49057b/index.html",redirect:"/pages/49057b/"},{path:"/04.编程/02.go语言/07.go语言高性能编程/02.Go语言Interface Boxing原理与性能优化指南.html",redirect:"/pages/49057b/"},{name:"v-1c8f04f0",path:"/pages/4f7497/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-1c8f04f0").then(t)}},{path:"/pages/4f7497/index.html",redirect:"/pages/4f7497/"},{path:"/04.编程/02.go语言/07.go语言高性能编程/04.Go语言零拷贝技术完全指南.html",redirect:"/pages/4f7497/"},{name:"v-e7a69188",path:"/pages/b03207/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-e7a69188").then(t)}},{path:"/pages/b03207/index.html",redirect:"/pages/b03207/"},{path:"/04.编程/02.go语言/07.go语言高性能编程/05.Go语言不可变数据共享：无锁并发编程实践.html",redirect:"/pages/b03207/"},{name:"v-2bccd8fe",path:"/pages/d7dbc7/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-2bccd8fe").then(t)}},{path:"/pages/d7dbc7/index.html",redirect:"/pages/d7dbc7/"},{path:"/04.编程/02.go语言/07.go语言高性能编程/06.Go语言内存预分配完全指南.html",redirect:"/pages/d7dbc7/"},{name:"v-6dda71f1",path:"/pages/821b25/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-6dda71f1").then(t)}},{path:"/pages/821b25/index.html",redirect:"/pages/821b25/"},{path:"/04.编程/02.go语言/07.go语言高性能编程/07.Go语言原子操作完全指南.html",redirect:"/pages/821b25/"},{name:"v-ccb4316a",path:"/pages/c19d45/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-ccb4316a").then(t)}},{path:"/pages/c19d45/index.html",redirect:"/pages/c19d45/"},{path:"/04.编程/02.go语言/07.go语言高性能编程/08.Go语言堆栈分配与逃逸分析深度解析.html",redirect:"/pages/c19d45/"},{name:"v-3b2ad750",path:"/pages/df4833/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-3b2ad750").then(t)}},{path:"/pages/df4833/index.html",redirect:"/pages/df4833/"},{path:"/04.编程/02.go语言/07.go语言高性能编程/09.Go语言空结构体：零内存消耗的高效编程.html",redirect:"/pages/df4833/"},{name:"v-d6123402",path:"/pages/d4c8eb/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-d6123402").then(t)}},{path:"/pages/d4c8eb/index.html",redirect:"/pages/d4c8eb/"},{path:"/04.编程/02.go语言/07.go语言高性能编程/11.Go语言字符串拼接性能对比与优化指南.html",redirect:"/pages/d4c8eb/"},{name:"v-1ba8c576",path:"/pages/f9a2a3/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-1ba8c576").then(t)}},{path:"/pages/f9a2a3/index.html",redirect:"/pages/f9a2a3/"},{path:"/04.编程/02.go语言/07.go语言高性能编程/12.Go语言延迟初始化(Lazy Initialization)最佳实践.html",redirect:"/pages/f9a2a3/"},{name:"v-3ff27440",path:"/pages/13969e/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-3ff27440").then(t)}},{path:"/pages/13969e/index.html",redirect:"/pages/13969e/"},{path:"/04.编程/02.go语言/07.go语言高性能编程/10.Go语言高性能编程之结构体内存对齐.html",redirect:"/pages/13969e/"},{name:"v-99455fdc",path:"/pages/d8ed61/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-99455fdc").then(t)}},{path:"/pages/d8ed61/index.html",redirect:"/pages/d8ed61/"},{path:"/04.编程/02.go语言/07.go语言高性能编程/13.Go语言高效IO缓冲技术详解.html",redirect:"/pages/d8ed61/"},{name:"v-7f2a6202",path:"/pages/72ba9a/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-7f2a6202").then(t)}},{path:"/pages/72ba9a/index.html",redirect:"/pages/72ba9a/"},{path:"/04.编程/03.linux/01.快速了解iptables.html",redirect:"/pages/72ba9a/"},{name:"v-26efa3da",path:"/pages/143447/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-26efa3da").then(t)}},{path:"/pages/143447/index.html",redirect:"/pages/143447/"},{path:"/04.编程/03.linux/02.理解Linux TunTap设备.html",redirect:"/pages/143447/"},{name:"v-32e66a02",path:"/pages/c128e7/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-32e66a02").then(t)}},{path:"/pages/c128e7/index.html",redirect:"/pages/c128e7/"},{path:"/04.编程/03.linux/04.理解Linux IPIP隧道.html",redirect:"/pages/c128e7/"},{name:"v-5973e693",path:"/pages/8a4b28/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-5973e693").then(t)}},{path:"/pages/8a4b28/index.html",redirect:"/pages/8a4b28/"},{path:"/04.编程/03.linux/03.理解VXLAN网络.html",redirect:"/pages/8a4b28/"},{name:"v-7e9794a8",path:"/pages/aba491/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-7e9794a8").then(t)}},{path:"/pages/aba491/index.html",redirect:"/pages/aba491/"},{path:"/04.编程/09.其他/02.使用hue创建ozzie的pyspark action workflow.html",redirect:"/pages/aba491/"},{name:"v-7accfee0",path:"/pages/7f16f6/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-7accfee0").then(t)}},{path:"/pages/7f16f6/index.html",redirect:"/pages/7f16f6/"},{path:"/04.编程/09.其他/03.使用java开发logstash的filter插件.html",redirect:"/pages/7f16f6/"},{name:"v-23857ed1",path:"/pages/d91dfb/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-23857ed1").then(t)}},{path:"/pages/d91dfb/index.html",redirect:"/pages/d91dfb/"},{path:"/04.编程/09.其他/01.分布式锁.html",redirect:"/pages/d91dfb/"},{name:"v-48a6492a",path:"/pages/19cfb6/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-48a6492a").then(t)}},{path:"/pages/19cfb6/index.html",redirect:"/pages/19cfb6/"},{path:"/04.编程/09.其他/20.count的性能优化.html",redirect:"/pages/19cfb6/"},{name:"v-38488cef",path:"/pages/8bdb8d/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-38488cef").then(t)}},{path:"/pages/8bdb8d/index.html",redirect:"/pages/8bdb8d/"},{path:"/05.读书破万卷/01.如何阅读一本书.html",redirect:"/pages/8bdb8d/"},{name:"v-602416af",path:"/pages/92e280/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-602416af").then(t)}},{path:"/pages/92e280/index.html",redirect:"/pages/92e280/"},{path:"/06.AI/01.初识 MCP Server.html",redirect:"/pages/92e280/"},{name:"v-c5fbc8ae",path:"/about/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-c5fbc8ae").then(t)}},{path:"/about/index.html",redirect:"/about/"},{path:"/08.关于/01.关于.html",redirect:"/about/"},{name:"v-fe55c380",path:"/pages/beb6c0bd8a66cea6/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-fe55c380").then(t)}},{path:"/pages/beb6c0bd8a66cea6/index.html",redirect:"/pages/beb6c0bd8a66cea6/"},{path:"/09.更多/01.收藏.html",redirect:"/pages/beb6c0bd8a66cea6/"},{name:"v-67feae3c",path:"/friends/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-67feae3c").then(t)}},{path:"/friends/index.html",redirect:"/friends/"},{path:"/09.更多/02.友链.html",redirect:"/friends/"},{name:"v-31af7045",path:"/archives/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-31af7045").then(t)}},{path:"/archives/index.html",redirect:"/archives/"},{path:"/@pages/archivesPage.html",redirect:"/archives/"},{name:"v-36a595c5",path:"/tags/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-36a595c5").then(t)}},{path:"/tags/index.html",redirect:"/tags/"},{path:"/@pages/tagsPage.html",redirect:"/tags/"},{name:"v-1e8d1344",path:"/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-1e8d1344").then(t)}},{path:"/index.html",redirect:"/"},{name:"v-5cc30ba5",path:"/categories/",component:_l,beforeEnter:(n,e,t)=>{di("Layout","v-5cc30ba5").then(t)}},{path:"/categories/index.html",redirect:"/categories/"},{path:"/@pages/categoriesPage.html",redirect:"/categories/"},{path:"*",component:_l}],kl={title:"郑文峰的博客",description:"技术博客，专注于后端学习与总结，python,go,redis,k8s,mysql,kafka,flask,django,tornado,git,github,markdown等技术类文章",base:"/",headTags:[["link",{rel:"icon",href:"/img/favicon.ico"}],["meta",{name:"keywords",content:"后端博客,个人技术博客,后端,后端开发,后端框架,后端面试题,技术文档,学习,面试,python,go,redis,k8s,mysql,kafka,flask,django,tornado,git,github,markdown"}],["meta",{name:"baidu-site-verification",content:"7F55weZDDc"}],["meta",{name:"theme-color",content:"#11a8cd"}],["meta",{name:"viewport",content:"width=device-width, initial-scale=1"}],["script",{},'var _hmt = _hmt || [];\n      (function() {\n        var hm = document.createElement("script");\n        hm.src = "https://hm.baidu.com/hm.js?7c28cc47ffa100de44e976f816b0b294";\n        var s = document.getElementsByTagName("script")[0]; \n        s.parentNode.insertBefore(hm, s);\n      })();'],["link",{rel:"alternate",type:"application/rss+xml",href:"https://www.zhengwenfeng.com/rss.xml",title:"郑文峰的博客 RSS Feed"}],["link",{rel:"alternate",type:"application/atom+xml",href:"https://www.zhengwenfeng.com/feed.atom",title:"郑文峰的博客 Atom Feed"}],["link",{rel:"alternate",type:"application/json",href:"https://www.zhengwenfeng.com/feed.json",title:"郑文峰的博客 JSON Feed"}]],pages:[{title:"容器的本质",frontmatter:{title:"容器的本质",date:"2022-08-10T00:11:48.000Z",permalink:"/pages/f3cf17/",tags:["docker","云原生"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"容器实现的主要技术：namespace、cgroup、chroot, 通过代码实现一个容器来深入理解其本质。",feed:{enable:!0},categories:["云原生","docker"],comment:!0,meta:[{name:"twitter:title",content:"容器的本质"},{name:"twitter:description",content:"容器实现的主要技术：namespace、cgroup、chroot, 通过代码实现一个容器来深入理解其本质。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/01.%E5%AE%B9%E5%99%A8%E7%9A%84%E6%9C%AC%E8%B4%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"容器的本质"},{property:"og:description",content:"容器实现的主要技术：namespace、cgroup、chroot, 通过代码实现一个容器来深入理解其本质。"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/01.%E5%AE%B9%E5%99%A8%E7%9A%84%E6%9C%AC%E8%B4%A8.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:11:48.000Z"},{property:"article:tag",content:"docker"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"容器的本质"},{itemprop:"description",content:"容器实现的主要技术：namespace、cgroup、chroot, 通过代码实现一个容器来深入理解其本质。"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/01.%E5%AE%B9%E5%99%A8%E7%9A%84%E6%9C%AC%E8%B4%A8.html",relativePath:"01.云原生/06.docker/01.容器的本质.md",key:"v-f7879d60",path:"/pages/f3cf17/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"NameSpace",slug:"namespace",normalizedTitle:"namespace",charIndex:8},{level:2,title:"chroot",slug:"chroot",normalizedTitle:"chroot",charIndex:95},{level:2,title:"手动构造一个容器",slug:"手动构造一个容器",normalizedTitle:"手动构造一个容器",charIndex:819},{level:2,title:"cgroup",slug:"cgroup",normalizedTitle:"cgroup",charIndex:3796}],headersStr:"前言 NameSpace chroot 手动构造一个容器 cgroup",content:'# 前言\n\n使用NameSpace技术来修改进程视图，创建出独立的文件系统、主机名、进程号、网络等资源空间，再使用Cgroups来实现对进程的 CPU、内存等资源的优先级和配额限制，最后使用chroot更改进程的根目录，也就是限制访问文件系统\n\n\n# NameSpace\n\n可以创建出独立的文件系统、主机名、进程号、网络等资源空间，实现系统全局资源和进程局部资源的隔离。\n\nNameSpace有多种隔离类型，像常见的有PID NameSpace可以隔离进程ID、NET Namespace隔离网络设备端口号等。\n\n举个例子\n\nNameSpace可以让当前进程只能看到当前Namespace里的进程，看不到宿主机创建的进程。并且运行容器的命令为1号进程。\n\n# docker run -it busybox /bin/sh\n\n/ # ps aux\nPID   USER     COMMAND\n    1 root     /bin/sh\n    8 root     ps aux\n\n/ # echo $$\n1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在宿主机中可以看到该容器进程ID并不为1。再次证明容器也只是宿主机中的一个进程而已。\n\n[root@k8s-master ~]# ps aux | grep /bin/sh | grep -v grep\nroot     1398061  0.1  0.3 1368728 54104 pts/1   Sl+  10:36   0:00 docker run -it mirrors.sangfor.com/busybox /bin/sh\nroot     1398102  0.8  0.0   3176   188 pts/0    Ss+  10:36   0:00 /bin/sh\n\n\n1\n2\n3\n\n\n\n# chroot\n\n可以更改进程的根目录，限制访问文件系统。\n\n\n# 手动构造一个容器\n\n我们使用clone创建一个子进程，传入的参数是CLONE_NEWPID代表着启用了PID NameSpace，当前进程看到的是一个全新的进程空间，在该命名空间中，自己是1号进程。\n\n#define _GNU_SOURCE\n#include <sys/mount.h> \n#include <sys/types.h>\n#include <sys/wait.h>\n#include <stdio.h>\n#include <sched.h>\n#include <signal.h>\n#include <unistd.h>\n#define STACK_SIZE (1024 * 1024)\nstatic char container_stack[STACK_SIZE];\nchar* const container_args[] = {\n  "/bin/bash",\n  NULL\n};\n\nint container_main(void* arg)\n{  \n  printf("Container - inside the container!\\n");\n  execv(container_args[0], container_args);\n  printf("Something\'s wrong!\\n");\n  return 1;\n}\n\nint main()\n{\n  printf("Parent - start a container!\\n");\n  int container_pid = clone(container_main, container_stack+STACK_SIZE, CLONE_NEWPID | SIGCHLD , NULL);\n  waitpid(container_pid, NULL, 0);\n  printf("Parent - container stopped!\\n");\n  return 0;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n[root@k8s-master k8s]# gcc a.c -o a\n\n[root@k8s-master k8s]# ./a \nParent - start a container!\nContainer - inside the container!\n\n[root@k8s-master k8s]# echo $$\n1\n\n[root@k8s-master k8s]# exit\nParent - container stopped!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n但是我们在使用ps aux时，还是看到整个宿主机的进程，并且进程ID为1的还是Systemd，为什么呢？\n\n这是因为ps命令是读/proc文件系统的，所以我们还需要进行文件系统的隔离。\n\n我们再使用Mount NameSpace进行文件系统的隔离，在clone中使用CLONE_NEWNS参数。\n\nint main()\n{\n  printf("Parent - start a container!\\n");\n  int container_pid = clone(container_main, container_stack+STACK_SIZE, CLONE_NEWPID | CLONE_NEWNS  | SIGCHLD , NULL);\n  waitpid(container_pid, NULL, 0);\n  printf("Parent - container stopped!\\n");\n  return 0;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n编译运行后，发现当前文件系统并未发生变化，这个是因为，创建子进程时，会继承父进程的挂载点。\n\n所以我们需要在子进程中修改当前的挂载点，并且子进程在新的namespace的挂载动作只影响自身的挂载文件系统。\n\n先拷贝一个文件系统出来作为我们容器的根文件系统\n\ndocker export 48ab2ddd04dc | tar -C ./testfs -xvf -\n\n\n1\n\n\n再挂载proc，并且将testfs作为该进程的根目录\n\nint container_main(void* arg)\n{  \n  printf("Container - inside the container!\\n");\n\n  if (mount("proc", "testfs/proc", "proc", 0, NULL)) {\n     perror("proc");\n  }\n\n  if ( chdir("./testfs")!=0 ||  chroot("./") != 0) {\n     perror("chroot");\n  }\n\n  execv(container_args[0], container_args);\n  printf("Something\'s wrong!\\n");\n  return 1;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n再次运行进入容器中，当前的根目录是上面我们构造的testfs，并且ps aux命令只能看到当前namespace的进程，而看不到宿主机namespace的进程了。\n\n[root@k8s-worker1 k8s]# ./a\nParent - start a container!\nContainer - inside the container!\nroot@k8s-worker1:/# ls\nbin  boot  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\nroot@k8s-worker1:/# ps aux\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot           1  0.0  0.0  26680  5452 ?        S    07:42   0:00 /bin/bash\nroot          94  0.0  0.0   5352   692 ?        S    07:49   0:00 ./a\nroot          95  0.0  0.0   4620  3872 ?        S    07:49   0:00 /bin/bash\nroot          99  0.0  0.0   7056  1556 ?        R+   07:49   0:00 ps aux\nroot@k8s-worker1:/# echo $$\n1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# cgroup\n\n可以实现对进程的CPU、内存等资源的配额限制\n\ncgroup在操作系统中暴露出来的接口是文件系统，会以文件和目录在/sys/fs/cgroup/目录中展示，下面的目录都是子系统，可以限制各种资源：\n\n[root@iZwz93q4afq8ck02cesqh4Z ~]# ls /sys/fs/cgroup/\nblkio  cpuacct      cpuset   freezer  memory   net_cls,net_prio  perf_event  systemd\ncpu    cpu,cpuacct  devices  hugetlb  net_cls  net_prio          pids\n\n\n1\n2\n3\n\n\n如何限制进程CPU\n\n执行以下命令将CPU吃到100%\n\n$ while : ; do : ; done &\n\n\n1\n\n\n使用top命令查看是否cpu是否满负载\n\n# top\n\nPID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                                                                              \n2503037 root      20   0   26672   5412   3520 R  99.0   0.0   0:46.09 -bash                                                                                  99.49%\n\n\n1\n2\n3\n4\n\n\n在目录/sys/fs/cgroup/cpu,cpuacct/下创建目录container，操作系统会自动创建资源限制文件\n\n[root@k8s-worker1 container]# mkdir container\n[root@k8s-worker1 container]# ls\ncgroup.clone_children  cpuacct.usage         cpuacct.usage_percpu_sys   cpuacct.usage_user  cpu.rt_period_us   cpu.stat\ncgroup.procs           cpuacct.usage_all     cpuacct.usage_percpu_user  cpu.cfs_period_us   cpu.rt_runtime_us  notify_on_release\ncpuacct.stat           cpuacct.usage_percpu  cpuacct.usage_sys          cpu.cfs_quota_us    cpu.shares         tasks\n\n\n1\n2\n3\n4\n5\n\n\n在文件夹下面可以查看到cpu.cfs_quota_us的默认值是-1，代表没有限制，cpu.cfs_period_us默认值为100ms(100000us)\n\n# cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us\n100000\n# cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us\n-1\n\n\n1\n2\n3\n4\n\n\n\n向cpu.cfs_quota_us写入20ms(20000us)，也就是每100ms时间里，限制的进程只能适用20ms，也就是这个进程只能使用到20%的CPU带宽\n\necho 20000 > /sys/fs/cgroup/cpu//cpu.cfs_quota_us\n\n\n1\n\n\n再将限制的进程ID写入到tasks文件中，可以看到该文件中已经包含了该容器进程ID\n\n# echo 2503037 > tasks\n# cat tasks\n2503037\n\n\n1\n2\n3\n\n\n再使用top可以发现该进程的cpu被限制在20%\n\n# top\n\nPID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                                                                              \n2503037 root      20   0   26672   5412   3520 R  20.4   0.0   6:43.71 -bash\n\n\n1\n2\n3\n4\n\n\n容器被cgroup的情况\n\n当然docker已经封装好了，直接调用以下命令即可实现上面CPU的限制\n\ndocker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash\n\n\n1\n\n\n可以看到在/sys/fs/cgroup/cpu,cpuacct/docker目录下创建了该容器的目录，目录下面包含了资源限制文件\n\n[root@k8s-worker1 docker]# pwd\n/sys/fs/cgroup/cpu,cpuacct/docker\n[root@k8s-worker1 docker]# ls\n87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c  cpuacct.usage             cpuacct.usage_percpu_user  cpu.cfs_quota_us   cpu.stat\ncgroup.clone_children                                             cpuacct.usage_all         cpuacct.usage_sys          cpu.rt_period_us   notify_on_release\ncgroup.procs                                                      cpuacct.usage_percpu      cpuacct.usage_user         cpu.rt_runtime_us  tasks\ncpuacct.stat\n[root@k8s-worker1 docker]# cd 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c/\n[root@k8s-worker1 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c]# ls\ncgroup.clone_children  cpuacct.usage         cpuacct.usage_percpu_sys   cpuacct.usage_user  cpu.rt_period_us   cpu.stat\ncgroup.procs           cpuacct.usage_all     cpuacct.usage_percpu_user  cpu.cfs_period_us   cpu.rt_runtime_us  notify_on_release\ncpuacct.stat           cpuacct.usage_percpu  cpuacct.usage_sys          cpu.cfs_quota_us    cpu.shares         tasks\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n在该目录下可以看到cpu.cfs_quota_us设置成了20000，并且tasks中包含了该容器进程的ID\n\n[root@k8s-worker1 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c]# cat cpu.cfs_quota_us \n20000\n[root@k8s-worker1 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c]# cat tasks\n2560954\n\n\n1\n2\n3\n4\n',normalizedContent:'# 前言\n\n使用namespace技术来修改进程视图，创建出独立的文件系统、主机名、进程号、网络等资源空间，再使用cgroups来实现对进程的 cpu、内存等资源的优先级和配额限制，最后使用chroot更改进程的根目录，也就是限制访问文件系统\n\n\n# namespace\n\n可以创建出独立的文件系统、主机名、进程号、网络等资源空间，实现系统全局资源和进程局部资源的隔离。\n\nnamespace有多种隔离类型，像常见的有pid namespace可以隔离进程id、net namespace隔离网络设备端口号等。\n\n举个例子\n\nnamespace可以让当前进程只能看到当前namespace里的进程，看不到宿主机创建的进程。并且运行容器的命令为1号进程。\n\n# docker run -it busybox /bin/sh\n\n/ # ps aux\npid   user     command\n    1 root     /bin/sh\n    8 root     ps aux\n\n/ # echo $$\n1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在宿主机中可以看到该容器进程id并不为1。再次证明容器也只是宿主机中的一个进程而已。\n\n[root@k8s-master ~]# ps aux | grep /bin/sh | grep -v grep\nroot     1398061  0.1  0.3 1368728 54104 pts/1   sl+  10:36   0:00 docker run -it mirrors.sangfor.com/busybox /bin/sh\nroot     1398102  0.8  0.0   3176   188 pts/0    ss+  10:36   0:00 /bin/sh\n\n\n1\n2\n3\n\n\n\n# chroot\n\n可以更改进程的根目录，限制访问文件系统。\n\n\n# 手动构造一个容器\n\n我们使用clone创建一个子进程，传入的参数是clone_newpid代表着启用了pid namespace，当前进程看到的是一个全新的进程空间，在该命名空间中，自己是1号进程。\n\n#define _gnu_source\n#include <sys/mount.h> \n#include <sys/types.h>\n#include <sys/wait.h>\n#include <stdio.h>\n#include <sched.h>\n#include <signal.h>\n#include <unistd.h>\n#define stack_size (1024 * 1024)\nstatic char container_stack[stack_size];\nchar* const container_args[] = {\n  "/bin/bash",\n  null\n};\n\nint container_main(void* arg)\n{  \n  printf("container - inside the container!\\n");\n  execv(container_args[0], container_args);\n  printf("something\'s wrong!\\n");\n  return 1;\n}\n\nint main()\n{\n  printf("parent - start a container!\\n");\n  int container_pid = clone(container_main, container_stack+stack_size, clone_newpid | sigchld , null);\n  waitpid(container_pid, null, 0);\n  printf("parent - container stopped!\\n");\n  return 0;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n[root@k8s-master k8s]# gcc a.c -o a\n\n[root@k8s-master k8s]# ./a \nparent - start a container!\ncontainer - inside the container!\n\n[root@k8s-master k8s]# echo $$\n1\n\n[root@k8s-master k8s]# exit\nparent - container stopped!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n但是我们在使用ps aux时，还是看到整个宿主机的进程，并且进程id为1的还是systemd，为什么呢？\n\n这是因为ps命令是读/proc文件系统的，所以我们还需要进行文件系统的隔离。\n\n我们再使用mount namespace进行文件系统的隔离，在clone中使用clone_newns参数。\n\nint main()\n{\n  printf("parent - start a container!\\n");\n  int container_pid = clone(container_main, container_stack+stack_size, clone_newpid | clone_newns  | sigchld , null);\n  waitpid(container_pid, null, 0);\n  printf("parent - container stopped!\\n");\n  return 0;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n编译运行后，发现当前文件系统并未发生变化，这个是因为，创建子进程时，会继承父进程的挂载点。\n\n所以我们需要在子进程中修改当前的挂载点，并且子进程在新的namespace的挂载动作只影响自身的挂载文件系统。\n\n先拷贝一个文件系统出来作为我们容器的根文件系统\n\ndocker export 48ab2ddd04dc | tar -c ./testfs -xvf -\n\n\n1\n\n\n再挂载proc，并且将testfs作为该进程的根目录\n\nint container_main(void* arg)\n{  \n  printf("container - inside the container!\\n");\n\n  if (mount("proc", "testfs/proc", "proc", 0, null)) {\n     perror("proc");\n  }\n\n  if ( chdir("./testfs")!=0 ||  chroot("./") != 0) {\n     perror("chroot");\n  }\n\n  execv(container_args[0], container_args);\n  printf("something\'s wrong!\\n");\n  return 1;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n再次运行进入容器中，当前的根目录是上面我们构造的testfs，并且ps aux命令只能看到当前namespace的进程，而看不到宿主机namespace的进程了。\n\n[root@k8s-worker1 k8s]# ./a\nparent - start a container!\ncontainer - inside the container!\nroot@k8s-worker1:/# ls\nbin  boot  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\nroot@k8s-worker1:/# ps aux\nuser         pid %cpu %mem    vsz   rss tty      stat start   time command\nroot           1  0.0  0.0  26680  5452 ?        s    07:42   0:00 /bin/bash\nroot          94  0.0  0.0   5352   692 ?        s    07:49   0:00 ./a\nroot          95  0.0  0.0   4620  3872 ?        s    07:49   0:00 /bin/bash\nroot          99  0.0  0.0   7056  1556 ?        r+   07:49   0:00 ps aux\nroot@k8s-worker1:/# echo $$\n1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# cgroup\n\n可以实现对进程的cpu、内存等资源的配额限制\n\ncgroup在操作系统中暴露出来的接口是文件系统，会以文件和目录在/sys/fs/cgroup/目录中展示，下面的目录都是子系统，可以限制各种资源：\n\n[root@izwz93q4afq8ck02cesqh4z ~]# ls /sys/fs/cgroup/\nblkio  cpuacct      cpuset   freezer  memory   net_cls,net_prio  perf_event  systemd\ncpu    cpu,cpuacct  devices  hugetlb  net_cls  net_prio          pids\n\n\n1\n2\n3\n\n\n如何限制进程cpu\n\n执行以下命令将cpu吃到100%\n\n$ while : ; do : ; done &\n\n\n1\n\n\n使用top命令查看是否cpu是否满负载\n\n# top\n\npid user      pr  ni    virt    res    shr s  %cpu  %mem     time+ command                                                                              \n2503037 root      20   0   26672   5412   3520 r  99.0   0.0   0:46.09 -bash                                                                                  99.49%\n\n\n1\n2\n3\n4\n\n\n在目录/sys/fs/cgroup/cpu,cpuacct/下创建目录container，操作系统会自动创建资源限制文件\n\n[root@k8s-worker1 container]# mkdir container\n[root@k8s-worker1 container]# ls\ncgroup.clone_children  cpuacct.usage         cpuacct.usage_percpu_sys   cpuacct.usage_user  cpu.rt_period_us   cpu.stat\ncgroup.procs           cpuacct.usage_all     cpuacct.usage_percpu_user  cpu.cfs_period_us   cpu.rt_runtime_us  notify_on_release\ncpuacct.stat           cpuacct.usage_percpu  cpuacct.usage_sys          cpu.cfs_quota_us    cpu.shares         tasks\n\n\n1\n2\n3\n4\n5\n\n\n在文件夹下面可以查看到cpu.cfs_quota_us的默认值是-1，代表没有限制，cpu.cfs_period_us默认值为100ms(100000us)\n\n# cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us\n100000\n# cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us\n-1\n\n\n1\n2\n3\n4\n\n\n\n向cpu.cfs_quota_us写入20ms(20000us)，也就是每100ms时间里，限制的进程只能适用20ms，也就是这个进程只能使用到20%的cpu带宽\n\necho 20000 > /sys/fs/cgroup/cpu//cpu.cfs_quota_us\n\n\n1\n\n\n再将限制的进程id写入到tasks文件中，可以看到该文件中已经包含了该容器进程id\n\n# echo 2503037 > tasks\n# cat tasks\n2503037\n\n\n1\n2\n3\n\n\n再使用top可以发现该进程的cpu被限制在20%\n\n# top\n\npid user      pr  ni    virt    res    shr s  %cpu  %mem     time+ command                                                                              \n2503037 root      20   0   26672   5412   3520 r  20.4   0.0   6:43.71 -bash\n\n\n1\n2\n3\n4\n\n\n容器被cgroup的情况\n\n当然docker已经封装好了，直接调用以下命令即可实现上面cpu的限制\n\ndocker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash\n\n\n1\n\n\n可以看到在/sys/fs/cgroup/cpu,cpuacct/docker目录下创建了该容器的目录，目录下面包含了资源限制文件\n\n[root@k8s-worker1 docker]# pwd\n/sys/fs/cgroup/cpu,cpuacct/docker\n[root@k8s-worker1 docker]# ls\n87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c  cpuacct.usage             cpuacct.usage_percpu_user  cpu.cfs_quota_us   cpu.stat\ncgroup.clone_children                                             cpuacct.usage_all         cpuacct.usage_sys          cpu.rt_period_us   notify_on_release\ncgroup.procs                                                      cpuacct.usage_percpu      cpuacct.usage_user         cpu.rt_runtime_us  tasks\ncpuacct.stat\n[root@k8s-worker1 docker]# cd 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c/\n[root@k8s-worker1 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c]# ls\ncgroup.clone_children  cpuacct.usage         cpuacct.usage_percpu_sys   cpuacct.usage_user  cpu.rt_period_us   cpu.stat\ncgroup.procs           cpuacct.usage_all     cpuacct.usage_percpu_user  cpu.cfs_period_us   cpu.rt_runtime_us  notify_on_release\ncpuacct.stat           cpuacct.usage_percpu  cpuacct.usage_sys          cpu.cfs_quota_us    cpu.shares         tasks\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n在该目录下可以看到cpu.cfs_quota_us设置成了20000，并且tasks中包含了该容器进程的id\n\n[root@k8s-worker1 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c]# cat cpu.cfs_quota_us \n20000\n[root@k8s-worker1 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c]# cat tasks\n2560954\n\n\n1\n2\n3\n4\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"手动实现docker容器bridge网络模型",frontmatter:{title:"手动实现docker容器bridge网络模型",date:"2023-01-08T10:52:18.000Z",permalink:"/pages/d3768c/",tags:["docker","云原生","容器"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文主要是通过使用Network Namespace来模式docker的bridge模式来深入的理解其原理。",feed:{enable:!0},categories:["云原生","docker"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16731830378711673183036984.png"},{name:"twitter:title",content:"手动实现docker容器bridge网络模型"},{name:"twitter:description",content:"本文主要是通过使用Network Namespace来模式docker的bridge模式来深入的理解其原理。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16731830378711673183036984.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/03.%E6%89%8B%E5%8A%A8%E5%AE%9E%E7%8E%B0docker%E5%AE%B9%E5%99%A8bridge%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B.html"},{property:"og:type",content:"article"},{property:"og:title",content:"手动实现docker容器bridge网络模型"},{property:"og:description",content:"本文主要是通过使用Network Namespace来模式docker的bridge模式来深入的理解其原理。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16731830378711673183036984.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/03.%E6%89%8B%E5%8A%A8%E5%AE%9E%E7%8E%B0docker%E5%AE%B9%E5%99%A8bridge%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-01-08T10:52:18.000Z"},{property:"article:tag",content:"docker"},{property:"article:tag",content:"云原生"},{property:"article:tag",content:"容器"},{itemprop:"name",content:"手动实现docker容器bridge网络模型"},{itemprop:"description",content:"本文主要是通过使用Network Namespace来模式docker的bridge模式来深入的理解其原理。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16731830378711673183036984.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/03.%E6%89%8B%E5%8A%A8%E5%AE%9E%E7%8E%B0docker%E5%AE%B9%E5%99%A8bridge%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B.html",relativePath:"01.云原生/06.docker/03.手动实现docker容器bridge网络模型.md",key:"v-6f7bb862",path:"/pages/d3768c/",headers:[{level:2,title:"Network Namespace",slug:"network-namespace",normalizedTitle:"network namespace",charIndex:2},{level:2,title:"容器间网络互通",slug:"容器间网络互通",normalizedTitle:"容器间网络互通",charIndex:202},{level:3,title:"veth pair",slug:"veth-pair",normalizedTitle:"veth pair",charIndex:491},{level:3,title:"实践",slug:"实践",normalizedTitle:"实践",charIndex:635},{level:3,title:"测试",slug:"测试",normalizedTitle:"测试",charIndex:3971},{level:2,title:"宿主机访问容器",slug:"宿主机访问容器",normalizedTitle:"宿主机访问容器",charIndex:6151},{level:2,title:"容器内访问外部",slug:"容器内访问外部",normalizedTitle:"容器内访问外部",charIndex:7551},{level:2,title:"外部访问容器暴露的服务",slug:"外部访问容器暴露的服务",normalizedTitle:"外部访问容器暴露的服务",charIndex:10201}],headersStr:"Network Namespace 容器间网络互通 veth pair 实践 测试 宿主机访问容器 容器内访问外部 外部访问容器暴露的服务",content:"# Network Namespace\n\nNamespace 技术是容器虚拟化的重要技术，可以将进程隔离在自己的 Namespace 中。而 Network Namespace 技术是将进程隔离在自己的网络空间中，拥有独立的网络栈，仿佛自己处于独立的网络中。\n\n> 网络栈是指网卡、回环设备、路由表和 iptables 规则等等。网络栈是指网卡、回环设备、路由表和 iptables 规则等等。\n\n\n# 容器间网络互通\n\n容器的 bridge 网络模式会创建属于自己的 Network Namespace 来隔离自己与宿主机，拥有属于自己的网络栈。可以理解为不同的 Network Namespace 是不同的主机，那么它们想要网络通信，该如何实现？\n\n首先想到的当然是交换机和路由器了，因为它们是处于同一个网络中，所以使用交换机即可，而 Linux 提供了 bridge 来充当虚拟交换机的角色，将多个 Network Namespace 接入到 bridge 中，它们就能网络互通了。\n\n那么如何将容器的 Network Namespace 接入到 bridge 呢？\n\n\n# veth pair\n\nveth pair 是成对出现的虚拟网卡，可以把它看做成一个管道，或者一根网线，从一段输入的数据包会从另一端输出，可以通过它来连接容器的 Network Namespace 和 bridge。\n\n使用 veth pair + bridge 的网络模型如下：\n\n\n# 实践\n\n我们不用安装 docker，直接用 Network Namespace 来模拟容器的网络环境。\n\n 1. 创建 bridge 设备\n\n这里使用 ip 命令来对 bridge 进行操作，也可以使用 brctl 命令，该命令是在 bridge-utils 包中。\n\n[root@localhost ~]# ip link add br0 type bridge\n[root@localhost ~]# ip link set dev br0 up\n[root@localhost ~]# ip addr add 10.0.0.3/24 dev br0\n\n[root@localhost ~]# ip link\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n2: ens18: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000\n    link/ether fe:fc:fe:af:4b:ea brd ff:ff:ff:ff:ff:ff\n60: br0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000\n    link/ether 7e:b5:12:2d:fd:d4 brd ff:ff:ff:ff:ff:ff\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n 2. 创建 3 个 Network Namespace\n\n使用 ip netns 命令可以对 Network Namesapce 进行操作，所以使用该命令创建 net0、net1 两个 Network Namespace\n\n[root@localhost ~]# ip netns add net0\n[root@localhost ~]# ip netns add net1\n\n\n1\n2\n\n 3. 创建两对 veth pair\n\n首先创建两对 veth pair 虚拟网卡，它们是一一对应的，veth0 和 veth1，veth2 和 veth3\n\n[root@localhost ~]# ip link add veth0 type veth peer name veth1\n[root@localhost ~]# ip link add veth2 type veth peer name veth3\n\n\n1\n2\n\n\n查看创建出来的 4 个虚拟网卡，@前面的是该网卡的名称，后面的是该网卡的另一端。\n\n[root@localhost ~]# ip a\n...\n67: veth1@veth0: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether 7e:b5:12:2d:fd:d4 brd ff:ff:ff:ff:ff:ff\n68: veth0@veth1: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether 26:22:ef:1a:b3:33 brd ff:ff:ff:ff:ff:ff\n69: veth3@veth2: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether c6:f2:d1:2d:c7:95 brd ff:ff:ff:ff:ff:ff\n70: veth2@veth3: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether ee:4b:0d:17:60:b1 brd ff:ff:ff:ff:ff:ff\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n 4. 将 veth pair 的一端接入到 Network Namespace 中，并设置好其 IP 地址\n\n[root@localhost ~]# ip link set dev veth0 netns net0\n[root@localhost ~]# ip netns exec net0 ip addr add 10.0.0.1/24 dev veth0\n[root@localhost ~]# ip netns exec net0 ip link set dev veth0 up\n\n\n[root@localhost ~]# ip link set dev veth2 netns net1\n[root@localhost ~]# ip netns exec net1 ip addr add 10.0.0.2/24 dev veth2\n[root@localhost ~]# ip netns exec net1 ip link set dev veth2 up\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n> ip netns exec 命令可以进入到指定的 Network Namespace 中执行命令\n\n 5. 将 veth pair 的另一端设置到 bridge 中\n\n[root@localhost ~]# ip link set dev veth1 master br0\n[root@localhost ~]# ip link set dev veth3 master br0\n\n[root@localhost ~]# ip link set dev veth1 up\n[root@localhost ~]# ip link set dev veth3 up\n\n\n1\n2\n3\n4\n5\n\n\n可以通过命令 bridge link 查看到 veth1、veth3都插入到 br0 中了。\n\n[root@localhost ~]# bridge link\n67: veth1 state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master br0 state forwarding priority 32 cost 2 \n69: veth3 state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master br0 state forwarding priority 32 cost 2\n\n\n1\n2\n3\n\n\n也可以通过 brctl 命令查看\n\n[root@localhost ~]# brctl show\n[root@localhost ~]# brctl show\nbridge name     bridge id               STP enabled     interfaces\nbr0             8000.7eb5122dfdd4       no              veth1\n                                                        veth3\n\n\n1\n2\n3\n4\n5\n\n\n\n# 测试\n\n 1. 首先监听 br0 网卡\n\n[root@localhost ~]# tcpdump -i br0\n\n\n1\n\n 2. 在 net0 中 ping net1 的 ip\n\nip netns exec net0 ping -c 3 10.0.0.2\n\n\n1\n\n 3. 会发现监听 br0 网卡是有流量的：\n\n[root@localhost ~]# tcpdump -i br0\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type EN10MB (Ethernet), capture size 262144 bytes\n02:39:41.251428 ARP, Request who-has 10.0.0.2 tell 10.0.0.1, length 28\n02:39:41.251495 ARP, Reply 10.0.0.2 is-at ee:4b:0d:17:60:b1 (oui Unknown), length 28\n02:39:41.251502 IP 10.0.0.1 > 10.0.0.2: ICMP echo request, id 15665, seq 1, length 64\n02:39:41.251702 IP 10.0.0.2 > 10.0.0.1: ICMP echo reply, id 15665, seq 1, length 64\n02:39:42.251435 IP 10.0.0.1 > 10.0.0.2: ICMP echo request, id 15665, seq 2, length 64\n02:39:42.251554 IP 10.0.0.2 > 10.0.0.1: ICMP echo reply, id 15665, seq 2, length 64\n02:39:43.251414 IP 10.0.0.1 > 10.0.0.2: ICMP echo request, id 15665, seq 3, length 64\n02:39:43.251512 IP 10.0.0.2 > 10.0.0.1: ICMP echo reply, id 15665, seq 3, length 64\n02:39:46.261377 ARP, Request who-has 10.0.0.1 tell 10.0.0.2, length 28\n02:39:46.261400 ARP, Reply 10.0.0.1 is-at 26:22:ef:1a:b3:33 (oui Unknown), length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n可以看到先是 10.0.0.1 发送的 ARP 获取 10.0.0.2 的 MAC 地址，然后再发送 ICMP 的请求和响应，最后 10.0.0.2 也发送 ARP 获取 10.0.0.1 的 MAC 地址。\n\n因为 bridge 是二层网络设备，所以它是需要通过识别 MAC 地址来进行通信的局域网。\n\n后面我又通过 net0 ping net1 的 ip，发现它没有发送 ARP 了，这个是因为第一次 bridge 已经将 MAC 地址和端口的映射关系已经记录了下来，后面可以直接通过查表，而不用再发送 ARP 了。\n\n[root@localhost ~]# tcpdump -i br0 -n \ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type EN10MB (Ethernet), capture size 262144 bytes\n02:40:01.267689 IP 10.0.0.1 > 10.0.0.2: ICMP echo request, id 15991, seq 1, length 64\n02:40:01.267948 IP 10.0.0.2 > 10.0.0.1: ICMP echo reply, id 15991, seq 1, length 64\n02:40:02.267509 IP 10.0.0.1 > 10.0.0.2: ICMP echo request, id 15991, seq 2, length 64\n02:40:02.267641 IP 10.0.0.2 > 10.0.0.1: ICMP echo reply, id 15991, seq 2, length 64\n02:40:03.267458 IP 10.0.0.1 > 10.0.0.2: ICMP echo request, id 15991, seq 3, length 64\n02:40:03.267582 IP 10.0.0.2 > 10.0.0.1: ICMP echo reply, id 15991, seq 3, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 宿主机访问容器\n\n 1. 再次监听 br0 网卡\n\ntcpdump -i br0\n\n\n1\n\n 2. 在宿主机上 ping 容器内部 ip，是可以 ping 通的\n\nping 10.0.0.1 -n 3\n\n\n1\n\n 3. 查看监听的 br0 网卡流量：\n\n[root@localhost ~]# tcpdump -i br0 -n \ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type EN10MB (Ethernet), capture size 262144 bytes\n02:56:03.232293 ARP, Request who-has 10.0.0.1 tell 10.0.0.3, length 28\n02:56:03.232342 ARP, Reply 10.0.0.1 is-at 26:22:ef:1a:b3:33, length 28\n02:56:03.232379 IP 10.0.0.3 > 10.0.0.1: ICMP echo request, id 3964, seq 1, length 64\n02:56:03.232402 IP 10.0.0.1 > 10.0.0.3: ICMP echo reply, id 3964, seq 1, length 64\n02:56:04.232494 IP 10.0.0.3 > 10.0.0.1: ICMP echo request, id 3964, seq 2, length 64\n02:56:04.232554 IP 10.0.0.1 > 10.0.0.3: ICMP echo reply, id 3964, seq 2, length 64\n02:56:05.232517 IP 10.0.0.3 > 10.0.0.1: ICMP echo request, id 3964, seq 3, length 64\n02:56:05.232607 IP 10.0.0.1 > 10.0.0.3: ICMP echo reply, id 3964, seq 3, length 64\n02:56:08.245354 ARP, Request who-has 10.0.0.3 tell 10.0.0.1, length 28\n02:56:08.245412 ARP, Reply 10.0.0.3 is-at 7e:b5:12:2d:fd:d4, length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n可以看到是 10.0.0.3 访问通了 10.0.0.1 ，我们是通过宿主机访问的容器内部，为什么源 ip 变成 10.0.0.3？\n\n 4. 通过查看宿主机的路由表，可以看到当我们 ping 10.0.0.1 时，是匹配上了该条路由，然后走 br0 网卡，使用的源 ip 是 br0 的 ip 10.0.0.3\n\n[root@localhost ~]# ip r\n...\n10.0.0.0/24 dev br0 proto kernel scope link src 10.0.0.3 \n...\n\n\n1\n2\n3\n4\n\n\n\n# 容器内访问外部\n\n 1. 配置 Network Namespace 中将 bridge 作为默认网关\n\n当我们在 net0 内部访问外部 ip 时，会发现网络不可达。\n\n[root@localhost ~]# ip netns exec net0 ping 10.65.132.187\nconnect: Network is unreachable\n\n\n1\n2\n\n\n这个是因为没有匹配上路由表上的原因\n\n[root@localhost ~]# ip netns exec net0 ip r\n10.0.0.0/24 dev veth0 proto kernel scope link src 10.0.0.1\n\n\n1\n2\n\n\n我们加上默认网关，也就是在没有匹配上其他路由时，走该网关\n\n[root@localhost ~]# ip netns exec net0 ip r add default via 10.0.0.3 dev veth0\n\n[root@localhost ~]# ip netns exec net0 ip r \ndefault via 10.0.0.3 dev veth0 \n10.0.0.0/24 dev veth0 proto kernel scope link src 10.0.0.1 \n\n\n1\n2\n3\n4\n5\n\n 2. 配置宿主机 iptables 的 SNAT 规则\n\n我们再次在容器中访问外部 ip 时，发现网络还不可达，但是我们监听 br0 网卡发现是有数据包的，也就是路由配的没问题\n\n[root@localhost ~]# tcpdump -i br0\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type EN10MB (Ethernet), capture size 262144 bytes\n03:23:23.738010 IP 10.0.0.1 > 10.65.132.187: ICMP echo request, id 11228, seq 1, length 64\n03:23:24.737415 IP 10.0.0.1 > 10.65.132.187: ICMP echo request, id 11228, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n\n\n我们再看宿主机上的路由，是有配置默认路由的。\n\n[root@localhost ~]# ip r\ndefault via 10.61.74.1 dev ens18 proto static metric 100\n\n\n1\n2\n\n\n所以我再监听一下宿主机的网卡 ens18 看看：\n\n[root@localhost ~]# tcpdump -i ens18 dst host 10.65.132.187\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type EN10MB (Ethernet), capture size 262144 bytes\n03:24:47.162152 IP 10.0.0.1 > 10.65.132.187: ICMP echo request, id 13281, seq 1, length 64\n03:24:48.161585 IP 10.0.0.1 > 10.65.132.187: ICMP echo request, id 13281, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n\n\n发现也是有数据包的，但是原地址是 net0 的 ip 地址 10.0.0.1，外部是不认识的，所以需要配置 iptables，将源 IP 改为宿主机的 IP。\n\n# 创建规则\n[root@localhost ~]# iptables -t nat -A POSTROUTING -s 10.0.0.0/24 ! -o br0 -j MASQUERADE\n\n# 查看规则\n[root@localhost ~]# iptables -L POSTROUTING -t nat\n...\nMASQUERADE  all  --  10.0.0.0/24          anywhere\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n上面设置 ipatbels 的命令的含义是，在 POSTROUTING 链的 nat 表中添加一条规则，当数据包的源 IP 网段为 10.0.0.0/24 时，并且不是网卡 br0 发送的，就执行 MASQUERADE 动作，该动作就是源地址改为宿主机地址的转换动作。\n\n现在就可以 ping 通外部 IP 了，查看 ens18 网卡的数据包，源地址已经修改成宿主机网卡 ens18 的地址了。\n\n[root@localhost ~]# tcpdump -i ens18 dst host 10.65.132.187 -n \ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type EN10MB (Ethernet), capture size 262144 bytes\n03:41:51.157483 IP 10.61.74.37 > 10.65.132.187: ICMP echo request, id 3972, seq 1, length 64\n03:41:52.158483 IP 10.61.74.37 > 10.65.132.187: ICMP echo request, id 3972, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n\n\n那外部 IP 回包时，只有宿主机的 IP，并没有容器的 IP，那宿主机怎么知道发送容器中呢？\n\n这个是因为内核 netfilter 会追踪记录连接，我们在增加了 SNAT 规则时，系统会自动增加一个隐式的反向规则，这样返回的包会自动将宿主机的 IP 替换为容器 IP。\n\n\n# 外部访问容器暴露的服务\n\ndocker 容器可以通过-p 的方式将容器内部的端口暴露到宿主机中，给外部访问，这个是怎么实现的呢？\n\n 1. 这个是通过 iptables 的 DNAT 规则实现的\n\n# 创建规则\n[root@localhost ~]# iptables -t nat -A PREROUTING  ! -i br0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 10.0.0.1:80\n\n# 查看规则\n[root@localhost ~]# iptables -L PREROUTING -t nat\nDNAT       tcp  --  anywhere             anywhere             tcp dpt:http to:10.0.0.1:80\n\n\n1\n2\n3\n4\n5\n6\n\n\n创建规则的命令的意思是，在 PREROUTING 链的 nat 表中添加一条规则，数据包的来源网卡不是 br0，数据包协议是 tcp，目的端口是 80，则进行 DNAT，将目的 IP 从宿主机 IP 改为容器 IP。\n\n 2. 在 net0 中开启 80 端口\n\n[root@localhost ~]# nc -lp 80\n\n\n1\n\n 3. 在外部主机上访问宿主机的 80 端口，是可以访问成功的\n\n[root@k8s-master-07rf9 ~]# telnet 10.61.74.37 80\n\n\n1\n",normalizedContent:"# network namespace\n\nnamespace 技术是容器虚拟化的重要技术，可以将进程隔离在自己的 namespace 中。而 network namespace 技术是将进程隔离在自己的网络空间中，拥有独立的网络栈，仿佛自己处于独立的网络中。\n\n> 网络栈是指网卡、回环设备、路由表和 iptables 规则等等。网络栈是指网卡、回环设备、路由表和 iptables 规则等等。\n\n\n# 容器间网络互通\n\n容器的 bridge 网络模式会创建属于自己的 network namespace 来隔离自己与宿主机，拥有属于自己的网络栈。可以理解为不同的 network namespace 是不同的主机，那么它们想要网络通信，该如何实现？\n\n首先想到的当然是交换机和路由器了，因为它们是处于同一个网络中，所以使用交换机即可，而 linux 提供了 bridge 来充当虚拟交换机的角色，将多个 network namespace 接入到 bridge 中，它们就能网络互通了。\n\n那么如何将容器的 network namespace 接入到 bridge 呢？\n\n\n# veth pair\n\nveth pair 是成对出现的虚拟网卡，可以把它看做成一个管道，或者一根网线，从一段输入的数据包会从另一端输出，可以通过它来连接容器的 network namespace 和 bridge。\n\n使用 veth pair + bridge 的网络模型如下：\n\n\n# 实践\n\n我们不用安装 docker，直接用 network namespace 来模拟容器的网络环境。\n\n 1. 创建 bridge 设备\n\n这里使用 ip 命令来对 bridge 进行操作，也可以使用 brctl 命令，该命令是在 bridge-utils 包中。\n\n[root@localhost ~]# ip link add br0 type bridge\n[root@localhost ~]# ip link set dev br0 up\n[root@localhost ~]# ip addr add 10.0.0.3/24 dev br0\n\n[root@localhost ~]# ip link\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown mode default group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n2: ens18: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state up mode default group default qlen 1000\n    link/ether fe:fc:fe:af:4b:ea brd ff:ff:ff:ff:ff:ff\n60: br0: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up mode default group default qlen 1000\n    link/ether 7e:b5:12:2d:fd:d4 brd ff:ff:ff:ff:ff:ff\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n 2. 创建 3 个 network namespace\n\n使用 ip netns 命令可以对 network namesapce 进行操作，所以使用该命令创建 net0、net1 两个 network namespace\n\n[root@localhost ~]# ip netns add net0\n[root@localhost ~]# ip netns add net1\n\n\n1\n2\n\n 3. 创建两对 veth pair\n\n首先创建两对 veth pair 虚拟网卡，它们是一一对应的，veth0 和 veth1，veth2 和 veth3\n\n[root@localhost ~]# ip link add veth0 type veth peer name veth1\n[root@localhost ~]# ip link add veth2 type veth peer name veth3\n\n\n1\n2\n\n\n查看创建出来的 4 个虚拟网卡，@前面的是该网卡的名称，后面的是该网卡的另一端。\n\n[root@localhost ~]# ip a\n...\n67: veth1@veth0: <broadcast,multicast,m-down> mtu 1500 qdisc noop state down group default qlen 1000\n    link/ether 7e:b5:12:2d:fd:d4 brd ff:ff:ff:ff:ff:ff\n68: veth0@veth1: <broadcast,multicast,m-down> mtu 1500 qdisc noop state down group default qlen 1000\n    link/ether 26:22:ef:1a:b3:33 brd ff:ff:ff:ff:ff:ff\n69: veth3@veth2: <broadcast,multicast,m-down> mtu 1500 qdisc noop state down group default qlen 1000\n    link/ether c6:f2:d1:2d:c7:95 brd ff:ff:ff:ff:ff:ff\n70: veth2@veth3: <broadcast,multicast,m-down> mtu 1500 qdisc noop state down group default qlen 1000\n    link/ether ee:4b:0d:17:60:b1 brd ff:ff:ff:ff:ff:ff\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n 4. 将 veth pair 的一端接入到 network namespace 中，并设置好其 ip 地址\n\n[root@localhost ~]# ip link set dev veth0 netns net0\n[root@localhost ~]# ip netns exec net0 ip addr add 10.0.0.1/24 dev veth0\n[root@localhost ~]# ip netns exec net0 ip link set dev veth0 up\n\n\n[root@localhost ~]# ip link set dev veth2 netns net1\n[root@localhost ~]# ip netns exec net1 ip addr add 10.0.0.2/24 dev veth2\n[root@localhost ~]# ip netns exec net1 ip link set dev veth2 up\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n> ip netns exec 命令可以进入到指定的 network namespace 中执行命令\n\n 5. 将 veth pair 的另一端设置到 bridge 中\n\n[root@localhost ~]# ip link set dev veth1 master br0\n[root@localhost ~]# ip link set dev veth3 master br0\n\n[root@localhost ~]# ip link set dev veth1 up\n[root@localhost ~]# ip link set dev veth3 up\n\n\n1\n2\n3\n4\n5\n\n\n可以通过命令 bridge link 查看到 veth1、veth3都插入到 br0 中了。\n\n[root@localhost ~]# bridge link\n67: veth1 state up @(null): <broadcast,multicast,up,lower_up> mtu 1500 master br0 state forwarding priority 32 cost 2 \n69: veth3 state up @(null): <broadcast,multicast,up,lower_up> mtu 1500 master br0 state forwarding priority 32 cost 2\n\n\n1\n2\n3\n\n\n也可以通过 brctl 命令查看\n\n[root@localhost ~]# brctl show\n[root@localhost ~]# brctl show\nbridge name     bridge id               stp enabled     interfaces\nbr0             8000.7eb5122dfdd4       no              veth1\n                                                        veth3\n\n\n1\n2\n3\n4\n5\n\n\n\n# 测试\n\n 1. 首先监听 br0 网卡\n\n[root@localhost ~]# tcpdump -i br0\n\n\n1\n\n 2. 在 net0 中 ping net1 的 ip\n\nip netns exec net0 ping -c 3 10.0.0.2\n\n\n1\n\n 3. 会发现监听 br0 网卡是有流量的：\n\n[root@localhost ~]# tcpdump -i br0\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type en10mb (ethernet), capture size 262144 bytes\n02:39:41.251428 arp, request who-has 10.0.0.2 tell 10.0.0.1, length 28\n02:39:41.251495 arp, reply 10.0.0.2 is-at ee:4b:0d:17:60:b1 (oui unknown), length 28\n02:39:41.251502 ip 10.0.0.1 > 10.0.0.2: icmp echo request, id 15665, seq 1, length 64\n02:39:41.251702 ip 10.0.0.2 > 10.0.0.1: icmp echo reply, id 15665, seq 1, length 64\n02:39:42.251435 ip 10.0.0.1 > 10.0.0.2: icmp echo request, id 15665, seq 2, length 64\n02:39:42.251554 ip 10.0.0.2 > 10.0.0.1: icmp echo reply, id 15665, seq 2, length 64\n02:39:43.251414 ip 10.0.0.1 > 10.0.0.2: icmp echo request, id 15665, seq 3, length 64\n02:39:43.251512 ip 10.0.0.2 > 10.0.0.1: icmp echo reply, id 15665, seq 3, length 64\n02:39:46.261377 arp, request who-has 10.0.0.1 tell 10.0.0.2, length 28\n02:39:46.261400 arp, reply 10.0.0.1 is-at 26:22:ef:1a:b3:33 (oui unknown), length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n可以看到先是 10.0.0.1 发送的 arp 获取 10.0.0.2 的 mac 地址，然后再发送 icmp 的请求和响应，最后 10.0.0.2 也发送 arp 获取 10.0.0.1 的 mac 地址。\n\n因为 bridge 是二层网络设备，所以它是需要通过识别 mac 地址来进行通信的局域网。\n\n后面我又通过 net0 ping net1 的 ip，发现它没有发送 arp 了，这个是因为第一次 bridge 已经将 mac 地址和端口的映射关系已经记录了下来，后面可以直接通过查表，而不用再发送 arp 了。\n\n[root@localhost ~]# tcpdump -i br0 -n \ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type en10mb (ethernet), capture size 262144 bytes\n02:40:01.267689 ip 10.0.0.1 > 10.0.0.2: icmp echo request, id 15991, seq 1, length 64\n02:40:01.267948 ip 10.0.0.2 > 10.0.0.1: icmp echo reply, id 15991, seq 1, length 64\n02:40:02.267509 ip 10.0.0.1 > 10.0.0.2: icmp echo request, id 15991, seq 2, length 64\n02:40:02.267641 ip 10.0.0.2 > 10.0.0.1: icmp echo reply, id 15991, seq 2, length 64\n02:40:03.267458 ip 10.0.0.1 > 10.0.0.2: icmp echo request, id 15991, seq 3, length 64\n02:40:03.267582 ip 10.0.0.2 > 10.0.0.1: icmp echo reply, id 15991, seq 3, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 宿主机访问容器\n\n 1. 再次监听 br0 网卡\n\ntcpdump -i br0\n\n\n1\n\n 2. 在宿主机上 ping 容器内部 ip，是可以 ping 通的\n\nping 10.0.0.1 -n 3\n\n\n1\n\n 3. 查看监听的 br0 网卡流量：\n\n[root@localhost ~]# tcpdump -i br0 -n \ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type en10mb (ethernet), capture size 262144 bytes\n02:56:03.232293 arp, request who-has 10.0.0.1 tell 10.0.0.3, length 28\n02:56:03.232342 arp, reply 10.0.0.1 is-at 26:22:ef:1a:b3:33, length 28\n02:56:03.232379 ip 10.0.0.3 > 10.0.0.1: icmp echo request, id 3964, seq 1, length 64\n02:56:03.232402 ip 10.0.0.1 > 10.0.0.3: icmp echo reply, id 3964, seq 1, length 64\n02:56:04.232494 ip 10.0.0.3 > 10.0.0.1: icmp echo request, id 3964, seq 2, length 64\n02:56:04.232554 ip 10.0.0.1 > 10.0.0.3: icmp echo reply, id 3964, seq 2, length 64\n02:56:05.232517 ip 10.0.0.3 > 10.0.0.1: icmp echo request, id 3964, seq 3, length 64\n02:56:05.232607 ip 10.0.0.1 > 10.0.0.3: icmp echo reply, id 3964, seq 3, length 64\n02:56:08.245354 arp, request who-has 10.0.0.3 tell 10.0.0.1, length 28\n02:56:08.245412 arp, reply 10.0.0.3 is-at 7e:b5:12:2d:fd:d4, length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n可以看到是 10.0.0.3 访问通了 10.0.0.1 ，我们是通过宿主机访问的容器内部，为什么源 ip 变成 10.0.0.3？\n\n 4. 通过查看宿主机的路由表，可以看到当我们 ping 10.0.0.1 时，是匹配上了该条路由，然后走 br0 网卡，使用的源 ip 是 br0 的 ip 10.0.0.3\n\n[root@localhost ~]# ip r\n...\n10.0.0.0/24 dev br0 proto kernel scope link src 10.0.0.3 \n...\n\n\n1\n2\n3\n4\n\n\n\n# 容器内访问外部\n\n 1. 配置 network namespace 中将 bridge 作为默认网关\n\n当我们在 net0 内部访问外部 ip 时，会发现网络不可达。\n\n[root@localhost ~]# ip netns exec net0 ping 10.65.132.187\nconnect: network is unreachable\n\n\n1\n2\n\n\n这个是因为没有匹配上路由表上的原因\n\n[root@localhost ~]# ip netns exec net0 ip r\n10.0.0.0/24 dev veth0 proto kernel scope link src 10.0.0.1\n\n\n1\n2\n\n\n我们加上默认网关，也就是在没有匹配上其他路由时，走该网关\n\n[root@localhost ~]# ip netns exec net0 ip r add default via 10.0.0.3 dev veth0\n\n[root@localhost ~]# ip netns exec net0 ip r \ndefault via 10.0.0.3 dev veth0 \n10.0.0.0/24 dev veth0 proto kernel scope link src 10.0.0.1 \n\n\n1\n2\n3\n4\n5\n\n 2. 配置宿主机 iptables 的 snat 规则\n\n我们再次在容器中访问外部 ip 时，发现网络还不可达，但是我们监听 br0 网卡发现是有数据包的，也就是路由配的没问题\n\n[root@localhost ~]# tcpdump -i br0\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type en10mb (ethernet), capture size 262144 bytes\n03:23:23.738010 ip 10.0.0.1 > 10.65.132.187: icmp echo request, id 11228, seq 1, length 64\n03:23:24.737415 ip 10.0.0.1 > 10.65.132.187: icmp echo request, id 11228, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n\n\n我们再看宿主机上的路由，是有配置默认路由的。\n\n[root@localhost ~]# ip r\ndefault via 10.61.74.1 dev ens18 proto static metric 100\n\n\n1\n2\n\n\n所以我再监听一下宿主机的网卡 ens18 看看：\n\n[root@localhost ~]# tcpdump -i ens18 dst host 10.65.132.187\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type en10mb (ethernet), capture size 262144 bytes\n03:24:47.162152 ip 10.0.0.1 > 10.65.132.187: icmp echo request, id 13281, seq 1, length 64\n03:24:48.161585 ip 10.0.0.1 > 10.65.132.187: icmp echo request, id 13281, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n\n\n发现也是有数据包的，但是原地址是 net0 的 ip 地址 10.0.0.1，外部是不认识的，所以需要配置 iptables，将源 ip 改为宿主机的 ip。\n\n# 创建规则\n[root@localhost ~]# iptables -t nat -a postrouting -s 10.0.0.0/24 ! -o br0 -j masquerade\n\n# 查看规则\n[root@localhost ~]# iptables -l postrouting -t nat\n...\nmasquerade  all  --  10.0.0.0/24          anywhere\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n上面设置 ipatbels 的命令的含义是，在 postrouting 链的 nat 表中添加一条规则，当数据包的源 ip 网段为 10.0.0.0/24 时，并且不是网卡 br0 发送的，就执行 masquerade 动作，该动作就是源地址改为宿主机地址的转换动作。\n\n现在就可以 ping 通外部 ip 了，查看 ens18 网卡的数据包，源地址已经修改成宿主机网卡 ens18 的地址了。\n\n[root@localhost ~]# tcpdump -i ens18 dst host 10.65.132.187 -n \ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type en10mb (ethernet), capture size 262144 bytes\n03:41:51.157483 ip 10.61.74.37 > 10.65.132.187: icmp echo request, id 3972, seq 1, length 64\n03:41:52.158483 ip 10.61.74.37 > 10.65.132.187: icmp echo request, id 3972, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n\n\n那外部 ip 回包时，只有宿主机的 ip，并没有容器的 ip，那宿主机怎么知道发送容器中呢？\n\n这个是因为内核 netfilter 会追踪记录连接，我们在增加了 snat 规则时，系统会自动增加一个隐式的反向规则，这样返回的包会自动将宿主机的 ip 替换为容器 ip。\n\n\n# 外部访问容器暴露的服务\n\ndocker 容器可以通过-p 的方式将容器内部的端口暴露到宿主机中，给外部访问，这个是怎么实现的呢？\n\n 1. 这个是通过 iptables 的 dnat 规则实现的\n\n# 创建规则\n[root@localhost ~]# iptables -t nat -a prerouting  ! -i br0 -p tcp -m tcp --dport 80 -j dnat --to-destination 10.0.0.1:80\n\n# 查看规则\n[root@localhost ~]# iptables -l prerouting -t nat\ndnat       tcp  --  anywhere             anywhere             tcp dpt:http to:10.0.0.1:80\n\n\n1\n2\n3\n4\n5\n6\n\n\n创建规则的命令的意思是，在 prerouting 链的 nat 表中添加一条规则，数据包的来源网卡不是 br0，数据包协议是 tcp，目的端口是 80，则进行 dnat，将目的 ip 从宿主机 ip 改为容器 ip。\n\n 2. 在 net0 中开启 80 端口\n\n[root@localhost ~]# nc -lp 80\n\n\n1\n\n 3. 在外部主机上访问宿主机的 80 端口，是可以访问成功的\n\n[root@k8s-master-07rf9 ~]# telnet 10.61.74.37 80\n\n\n1\n",charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"docker容器",frontmatter:{title:"docker容器",date:"2022-08-10T00:11:29.000Z",permalink:"/pages/39f36e/",tags:["docker","云原生","容器"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"简介docker及其使用方法",feed:{enable:!0},categories:["云原生","docker"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220705193057.png"},{name:"twitter:title",content:"docker容器"},{name:"twitter:description",content:"简介docker及其使用方法"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220705193057.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/02.docker%E5%AE%B9%E5%99%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"docker容器"},{property:"og:description",content:"简介docker及其使用方法"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220705193057.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/02.docker%E5%AE%B9%E5%99%A8.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:11:29.000Z"},{property:"article:tag",content:"docker"},{property:"article:tag",content:"云原生"},{property:"article:tag",content:"容器"},{itemprop:"name",content:"docker容器"},{itemprop:"description",content:"简介docker及其使用方法"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220705193057.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/02.docker%E5%AE%B9%E5%99%A8.html",relativePath:"01.云原生/06.docker/02.docker容器.md",key:"v-08a8939a",path:"/pages/39f36e/",headers:[{level:2,title:"容器是什么？",slug:"容器是什么",normalizedTitle:"容器是什么？",charIndex:15},{level:2,title:"为什么要隔离?",slug:"为什么要隔离",normalizedTitle:"为什么要隔离?",charIndex:42},{level:2,title:"和虚拟机的区别是什么?",slug:"和虚拟机的区别是什么",normalizedTitle:"和虚拟机的区别是什么?",charIndex:100},{level:2,title:"什么是容器化应用？",slug:"什么是容器化应用",normalizedTitle:"什么是容器化应用？",charIndex:606},{level:2,title:"docker架构",slug:"docker架构",normalizedTitle:"docker架构",charIndex:840},{level:2,title:"常用镜像操作",slug:"常用镜像操作",normalizedTitle:"常用镜像操作",charIndex:1054},{level:2,title:"常用容器操作",slug:"常用容器操作",normalizedTitle:"常用容器操作",charIndex:1164},{level:2,title:"容器镜像",slug:"容器镜像",normalizedTitle:"容器镜像",charIndex:2093},{level:3,title:"镜像内部机制",slug:"镜像内部机制",normalizedTitle:"镜像内部机制",charIndex:2102},{level:2,title:"Dockerfile",slug:"dockerfile",normalizedTitle:"dockerfile",charIndex:5229},{level:2,title:"容器与外部的交互",slug:"容器与外部的交互",normalizedTitle:"容器与外部的交互",charIndex:5781},{level:2,title:"关于k8s与docker的关系",slug:"关于k8s与docker的关系",normalizedTitle:"关于k8s与docker的关系",charIndex:6584}],headersStr:"容器是什么？ 为什么要隔离? 和虚拟机的区别是什么? 什么是容器化应用？ docker架构 常用镜像操作 常用容器操作 容器镜像 镜像内部机制 Dockerfile 容器与外部的交互 关于k8s与docker的关系",content:'# docker容器\n\n\n# 容器是什么？\n\n容器，就是一个被隔离的进程。\n\n\n# 为什么要隔离?\n\n 1. 将应用程序与外界系统隔离，保证容器外系统安全\n 2. 资源隔离，只能使用指定配额\n\n\n# 和虚拟机的区别是什么?\n\n虚拟机：虚拟的是硬件，需要在上面安装操作系统才能运行应用程序。\n\n容器：共享下层的硬件和操作系统。\n\n下图是官方的图\n\n\n\n其实上图关于容器的部分并不准确，APP也就是容器并不是运行在Docker上的，Docker只是在帮助用户创建进程时添加了各种Namespace参数，容器是特殊的进程，还是运行在操作系统上的。\n\n      实现方式             优势             劣势\n虚拟机   虚拟化硬件            隔离程度非常高        资源消耗大，启动慢\n容器    直接利用下层的硬件和操作系统   资源利用率高，运行速度快   隔离程度低, 安全性低\n\n 1. 虚拟机是硬件级别的隔离，而容器化是进程间的隔离。\n\n 2. 虚拟化需要模拟硬件占用部分内存，并且对宿主机操作的系统调用需要经过虚拟化软件的拦截与转换，造成资源的开销。而容器就是一个普通的进程，基本无额外的计算资源的开销。\n\n 3. 在Linux内核中有部分的资源和对象无法namespace化，如时间。\n\n 4. 因为容器是共享宿主机内核，所以对外暴露的供给面非常的大。\n\n\n# 什么是容器化应用？\n\n镜像，就是将容器的初始化环境固化下来，将运行进程所需要的文件系统、依赖库、环境变量、启动参数等打包整合到一起，保存成一个静态的文件。\n\n容器化环境可以通过镜像快速重建容器，应用程序看到的就是一致的运行环境。\n\n容器化应用，也就是应用程序不直接与操作系统去打交道，而是将应用程序打包成镜像，再交给容器环境去运行\n\n镜像与容器的关系还可以用"序列化"和"反序列化"来理解，镜像就是序列化到磁盘的数据，而容器是反序列化后内存中的对象。\n\n\n\n\n\n\n# docker架构\n\n创建容器时，我们通过docker命令请求Docker Daemon服务，然后该服务再通过RPC请求Containerd进程，该进程会创建Containerd-shim进程，该进程会再创建RunC进程，该进程是真正创建容器的是进程，等容器创建好后，RunC会退出，容器的父进程会变成Containerd-shim，当容器结束时，Conatinerd-shim会回收容器进程的资源，以防止僵尸进程。\n\n\n\n\n# 常用镜像操作\n\n命令              作用\ndocker pull     从远端仓库拉取镜像\ndocker images   列出当前本地已有镜像\ndocker rmi      删除不再使用的镜像\n\n\n# 常用容器操作\n\n命令              作用            例子\ndocker run      使用镜像启动容器      \ndocker ps       列出正在运行的容器     \ndocker exec     在容器内执行另一个程序   \ndocker stop     停止容器          \ndocker start    将停止的容器再次启动    \ndocker rm       删除容器          \ndocker export   将容器内的文件系统导出   docker export -o rootfs.tar 容器ID\n\n容器被停止后，docker ps命令就看不到该容器了，需要使用docker ps -a来查看所有容器，包括已经停止的容器。\n\n可能会导致非常多已经停止的容器占用系统资源，所以建议docker run时添加--rm参数，在容器运行完毕时自动清除\n\ndocker exec是如何进入到容器中的?\n\n该命令会创建一个新的进程加入到容器的namepsace中。\n\n/proc/{进程ID}/ns/下的虚拟文件会链接到真实的Namespace文件上。通过查看exec创建的进程ns文件可以看出和容器的Namespace文件一致\n\n[root@k8s-master proc]# ll /proc/288948/ns/pid\nlrwxrwxrwx 1 root root 0 Jul  8 11:27 /proc/288948/ns/pid -> \'pid:[4026532247]\'\n\n[root@k8s-master proc]# ll /proc/289220/ns/pid\nlrwxrwxrwx 1 root root 0 Jul  8 11:27 /proc/289220/ns/pid -> \'pid:[4026532247]\'\n\n\n1\n2\n3\n4\n5\n\n\ndocker run和docker exec的区别是什么?\n\nrun是将镜像运行成容器并执行命令，该命令为1号进程。\n\nexec是在容器中执行一个命令，该命令是另一个进程，加入到了容器的namespace中。\n\n\n# 容器镜像\n\n\n# 镜像内部机制\n\n容器镜像内部是由许多的镜像层(Layer)组成的，每层都是只读不可修改的一组文件，相同的层可以在镜像中共享，然后多个层像搭积木叠加起来，使用**联合文件系统（UnionFS)**将它们合并起来，最终形成容器看到的文件系统。\n\n镜像中的层级是只读层，而容器所在的层级是可读写层。\n\n\n\n镜像的分层信息可以通过命令docker inspect 镜像名称获取，其中RootFs是对应的信息\n\n>>> docker inspect b3log/siyuan\n\n.....\n"RootFS": {\n            "Type": "layers",\n            "Layers": [\n                "sha256:24302eb7d9085da80f016e7e4ae55417e412fb7e0a8021e95e3b60c67cde557d",\n                "sha256:e7356c89d8c31fc628769b331f73d6e036e1d5900d2d2a3990c89ef91bce707a",\n                "sha256:90358380b9ea63cfb8832ae627455faf85596e822ff8abe9e1d7c8bbd93804ad",\n                "sha256:c6d8ffacc07d179562cd70114402e549d9fce92b12a019d3f4003eb94944d089"\n            ]\n        }\n....\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n好处是，如果多个镜像使用了相同的层，可以直接共享，减少磁盘空间的占用。比如nginx镜像和Tomcat镜像都是用了基础镜像centos，那么该基础镜像可以共享。\n\n\n\nOverlayFS\n\n镜像层和容器是如何合并的呢？\n\n\n\nlowerdir是镜像层，upperdir是容器层，如果双方有相同文件则展示容器层的文件。\n\n在容器写文件时，会先从镜像层拷贝一份文件到容器层，然后再写入，使用的是**写时复制(copy on write)**策略\n\n例子\n\noverlay2\n├── lowerdirA\n│   ├── a     内容：AA\n│   └── b     内容：AA\n├── lowerdirB\n│   └── a     内容: BB\n├── merge\n├── upper\n└── work\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n执行以下命令使用overlay进行合并层\n\nmount -t overlay overlay -o lowerdir=lowerdirA:lowerdirB,upperdir=upper,workdir=work merge\n\n\n1\n\n\nlowerdir为镜像层，upperdir为容器层，merge目录为最终展示层。\n\n可以看到merge目录中的a文件内容lowerdirA镜像层的内容\n\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# cat merge/a \nAA\n\n\n1\n2\n\n\n当我们修改megre目录中的a文件时，可以看到upperdir目录的会生成a文件并且内容修改后的内容\n\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# ls upper/\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# echo upper > merge/a\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# ls upper/\na\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# cat upper/a\nupper\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# cat merge/a\nupper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n当删除文件merge/a时，会出现什么情况呢?\n\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# rm merge/a\nrm: remove regular file ‘merge/a’? y\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# ll lowerdirA/\ntotal 8\n-rw-r--r-- 1 root root 3 Jul 12 19:11 a\n-rw-r--r-- 1 root root 3 Jul 12 19:10 b\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# ll upper/\ntotal 0\nc--------- 1 root root 0, 0 Jul 12 19:31 a\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n可以看出镜像层lowerdirA的文件a是不变的，而在容器层upper中的a文件类型变成了c，该文件类型，最终在展示层看不到该文件了。\n\n可以使用命令docker inspect来查看layer的路径\n\n>>> docker inspect xxx\n\n....\n"GraphDriver": {\n            "Data": {\n                "LowerDir": "/var/lib/docker/overlay2/641e486c54d15d2a8d807fd8964f4a4b8687cbcf95c176cd9a46553b1e80341d/diff:/var/lib/docker/overlay2/ed9ad4fb9d0f9bf3aea553c634e54fef89448cf43c5b662468d79f01cf41d0c3/diff:/var/lib/docker/overlay2/9db169e1ad2165f688e652ef06dfe9a3e465c31299f3c357a37a6919747efbc8/diff",\n                "MergedDir": "/var/lib/docker/overlay2/fa3166e545a2d1811dbeecb6f1fdda96b9f97b3cd629f32a8ea378aa79b1c780/merged",\n                "UpperDir": "/var/lib/docker/overlay2/fa3166e545a2d1811dbeecb6f1fdda96b9f97b3cd629f32a8ea378aa79b1c780/diff",\n                "WorkDir": "/var/lib/docker/overlay2/fa3166e545a2d1811dbeecb6f1fdda96b9f97b3cd629f32a8ea378aa79b1c780/work"\n            },\n            "Name": "overlay2"\n        },\n....\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Dockerfile\n\nDockerfile是一个用来创建镜像的文本文件，该文件中的每一条命令都会成生成一个layer。\n\n例子：\n\n最简单的Dockerfile的例子\n\nFROM busybox                  # 选择基础镜像\nCMD echo "hello world"        # 启动容器时默认运行的命令\n\n\n1\n2\n\n\nFROM指令是构建使用的基础镜像\n\nCMD指令是用于启动容器时默认运行的命令\n\n使用docker build 即可执行创建镜像\n\ndocker build -f Dockerfile .\n\nSending build context to Docker daemon   7.68kB\nStep 1/2 : FROM busybox\n ---\x3e d38589532d97\nStep 2/2 : CMD echo "hello world"\n ---\x3e Running in c5a762edd1c8\nRemoving intermediate container c5a762edd1c8\n ---\x3e b61882f42db7\nSuccessfully built b61882f42db7\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 容器与外部的交互\n\n如何拷贝宿主机的文件到容器内\n\n可以使用docker cp命令将宿主机的文件拷贝到容器中。\n\ndocker cp a.txt 062:/tmp\n\n\n1\n\n\n其中的062为容器ID，如果想将容器中的文件拷贝到宿主机中，反过来即可。\n\ndocker cp 062:/tmp/a.txt /tmp\n\n\n1\n\n\n注意，这里的拷贝是临时的，拷贝进容器中的文件只存在于容器中，不存在与镜像中，如果想要将文件拷贝到镜像中，在写Dockerfile时使用copy命令拷贝即可。\n\n宿主机与容器共享文件夹\n\n在使用镜像运行容器时，使用参数-v可以将宿主机中的文件夹映射到容器中，双方修改该文件夹中的内容，都可以及时看到。\n\ndocker run -d --rm -v /tmp:/tmp redis\n\n\n1\n\n\n如何实现网络互通？\n\ndocker提供三种网络模式：\n\n * null，无网络\n * host，直接使用宿主机网络，在创建容器时，使用--net=host参数。\n\n其实就是创建新的namespace，而是直接加入到宿主机的namesapce\n\ndocker run -d --rm --net=host nginx:alpine\n\n\n1\n\n * bridge，桥接模式，由软件虚拟网卡与网桥，容器和宿主机都接入该网桥，即可正常发送数据包。可以使用参数--net=bridge创建容器，但这个是默认参数。\n\ndocker run -d --rm nginx:alpine\n\n\n1\n\n\n\n\n网络模式     优点                        缺点\nhost     因为是直接使用宿主机的网络，效率更高        运行太多的容器，会导致端口发生冲突\nbridge   因为有了网桥可以设置更多的策略，比如流量控制等   需要软件模拟虚拟网卡与网桥，效率更低\n\n\n\n\n\n\n# 关于k8s与docker的关系\n\n在2014年的时候,Docker如日中天，那么k8s自然选择基于docker上运行。\n\n在2016年k8s加入了CNCF，一个开源的云原生计算基金会。\n\n并且引入了一个接口标准：CRI，Container Runtime Interface。也就是规定kubelet该如何调用Container Runtime去管理容器和镜像，但这是一套全新的接口，和之前的Docker完全不兼容。目的很明显，不想绑定Docker，可以随时将Docker踢掉。\n\n因为docker已经非常成熟，各大厂商不可能将Docker全部替换。所以k8s在kubelet和Docker中间加一个"适配器"，把Docker的接口转换成符合CRI标准的接口。\n\n\n\n什么是containerd？\n\n不过 Docker 也没有“坐以待毙”，而是采取了“断臂求生”的策略，推动自身的重构，把原本单体架构的 Docker Engine 拆分成了多个模块，其中的 Docker daemon 部分就捐献给了 CNCF，形成了 containerd。\n\ncontainerd 作为 CNCF 的托管项目，自然是要符合 CRI 标准的。但 Docker 出于自己诸多原因的考虑，它只是在 Docker Engine 里调用了 containerd，外部的接口仍然保持不变，也就是说还不与 CRI 兼容。\n\n由于 Docker 的“固执己见”，这时 Kubernetes 里就出现了两种调用链：第一种是用 CRI 接口调用 dockershim，然后 dockershim 调用 Docker，Docker 再走 containerd 去操作容器。第二种是用 CRI 接口直接调用 containerd 去操作容器。\n\n\n\n显而易见，使用第二种省去了dockershim和Docker Engine两个环节，损耗更少，性能也提升了。\n\n正式"弃用Docker"\n\n在2020年K8s弃用Docker支持，但该弃用支持弃用了"dockershim"的这个组件，也就是把dockershim移出kubelete，只是绕过Docker，直接调用了Docker内部的containerd而已。\n\n并且对docker也无影响，因为docker内部也是使用开源的containerd。\n\n\n\n唯一影响的是，k8s是直接操作containerd操作容器，那么它和docker是独立的工作环境，彼此都不能访问对方的容器和镜像，也就是docker ps看不到k8s运行的容器。改用crictl命令。\n\nDocker 重构自身，分离出 containerd，这是否算是一种“自掘坟墓”的行为呢？如果没有 containerd，那现在的情形会是怎么样的呢？\n\nDocker 是一个完整的软件产品线，不止是 containerd，它还包括了镜像构建、分发、测试等许多服务，甚至在 Docker Desktop 里还内置了 Kubernetes。\n\n> docker分离containerd是一个很聪明的举动！与其将来被人分离或者抛弃不用，不如我主动革新，把Kubernates绑在我的战车上，这样cri的第一选择仍然是docker的自己人。\n> 一时的退让是为了更好的将来。',normalizedContent:'# docker容器\n\n\n# 容器是什么？\n\n容器，就是一个被隔离的进程。\n\n\n# 为什么要隔离?\n\n 1. 将应用程序与外界系统隔离，保证容器外系统安全\n 2. 资源隔离，只能使用指定配额\n\n\n# 和虚拟机的区别是什么?\n\n虚拟机：虚拟的是硬件，需要在上面安装操作系统才能运行应用程序。\n\n容器：共享下层的硬件和操作系统。\n\n下图是官方的图\n\n\n\n其实上图关于容器的部分并不准确，app也就是容器并不是运行在docker上的，docker只是在帮助用户创建进程时添加了各种namespace参数，容器是特殊的进程，还是运行在操作系统上的。\n\n      实现方式             优势             劣势\n虚拟机   虚拟化硬件            隔离程度非常高        资源消耗大，启动慢\n容器    直接利用下层的硬件和操作系统   资源利用率高，运行速度快   隔离程度低, 安全性低\n\n 1. 虚拟机是硬件级别的隔离，而容器化是进程间的隔离。\n\n 2. 虚拟化需要模拟硬件占用部分内存，并且对宿主机操作的系统调用需要经过虚拟化软件的拦截与转换，造成资源的开销。而容器就是一个普通的进程，基本无额外的计算资源的开销。\n\n 3. 在linux内核中有部分的资源和对象无法namespace化，如时间。\n\n 4. 因为容器是共享宿主机内核，所以对外暴露的供给面非常的大。\n\n\n# 什么是容器化应用？\n\n镜像，就是将容器的初始化环境固化下来，将运行进程所需要的文件系统、依赖库、环境变量、启动参数等打包整合到一起，保存成一个静态的文件。\n\n容器化环境可以通过镜像快速重建容器，应用程序看到的就是一致的运行环境。\n\n容器化应用，也就是应用程序不直接与操作系统去打交道，而是将应用程序打包成镜像，再交给容器环境去运行\n\n镜像与容器的关系还可以用"序列化"和"反序列化"来理解，镜像就是序列化到磁盘的数据，而容器是反序列化后内存中的对象。\n\n\n\n\n\n\n# docker架构\n\n创建容器时，我们通过docker命令请求docker daemon服务，然后该服务再通过rpc请求containerd进程，该进程会创建containerd-shim进程，该进程会再创建runc进程，该进程是真正创建容器的是进程，等容器创建好后，runc会退出，容器的父进程会变成containerd-shim，当容器结束时，conatinerd-shim会回收容器进程的资源，以防止僵尸进程。\n\n\n\n\n# 常用镜像操作\n\n命令              作用\ndocker pull     从远端仓库拉取镜像\ndocker images   列出当前本地已有镜像\ndocker rmi      删除不再使用的镜像\n\n\n# 常用容器操作\n\n命令              作用            例子\ndocker run      使用镜像启动容器      \ndocker ps       列出正在运行的容器     \ndocker exec     在容器内执行另一个程序   \ndocker stop     停止容器          \ndocker start    将停止的容器再次启动    \ndocker rm       删除容器          \ndocker export   将容器内的文件系统导出   docker export -o rootfs.tar 容器id\n\n容器被停止后，docker ps命令就看不到该容器了，需要使用docker ps -a来查看所有容器，包括已经停止的容器。\n\n可能会导致非常多已经停止的容器占用系统资源，所以建议docker run时添加--rm参数，在容器运行完毕时自动清除\n\ndocker exec是如何进入到容器中的?\n\n该命令会创建一个新的进程加入到容器的namepsace中。\n\n/proc/{进程id}/ns/下的虚拟文件会链接到真实的namespace文件上。通过查看exec创建的进程ns文件可以看出和容器的namespace文件一致\n\n[root@k8s-master proc]# ll /proc/288948/ns/pid\nlrwxrwxrwx 1 root root 0 jul  8 11:27 /proc/288948/ns/pid -> \'pid:[4026532247]\'\n\n[root@k8s-master proc]# ll /proc/289220/ns/pid\nlrwxrwxrwx 1 root root 0 jul  8 11:27 /proc/289220/ns/pid -> \'pid:[4026532247]\'\n\n\n1\n2\n3\n4\n5\n\n\ndocker run和docker exec的区别是什么?\n\nrun是将镜像运行成容器并执行命令，该命令为1号进程。\n\nexec是在容器中执行一个命令，该命令是另一个进程，加入到了容器的namespace中。\n\n\n# 容器镜像\n\n\n# 镜像内部机制\n\n容器镜像内部是由许多的镜像层(layer)组成的，每层都是只读不可修改的一组文件，相同的层可以在镜像中共享，然后多个层像搭积木叠加起来，使用**联合文件系统（unionfs)**将它们合并起来，最终形成容器看到的文件系统。\n\n镜像中的层级是只读层，而容器所在的层级是可读写层。\n\n\n\n镜像的分层信息可以通过命令docker inspect 镜像名称获取，其中rootfs是对应的信息\n\n>>> docker inspect b3log/siyuan\n\n.....\n"rootfs": {\n            "type": "layers",\n            "layers": [\n                "sha256:24302eb7d9085da80f016e7e4ae55417e412fb7e0a8021e95e3b60c67cde557d",\n                "sha256:e7356c89d8c31fc628769b331f73d6e036e1d5900d2d2a3990c89ef91bce707a",\n                "sha256:90358380b9ea63cfb8832ae627455faf85596e822ff8abe9e1d7c8bbd93804ad",\n                "sha256:c6d8ffacc07d179562cd70114402e549d9fce92b12a019d3f4003eb94944d089"\n            ]\n        }\n....\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n好处是，如果多个镜像使用了相同的层，可以直接共享，减少磁盘空间的占用。比如nginx镜像和tomcat镜像都是用了基础镜像centos，那么该基础镜像可以共享。\n\n\n\noverlayfs\n\n镜像层和容器是如何合并的呢？\n\n\n\nlowerdir是镜像层，upperdir是容器层，如果双方有相同文件则展示容器层的文件。\n\n在容器写文件时，会先从镜像层拷贝一份文件到容器层，然后再写入，使用的是**写时复制(copy on write)**策略\n\n例子\n\noverlay2\n├── lowerdira\n│   ├── a     内容：aa\n│   └── b     内容：aa\n├── lowerdirb\n│   └── a     内容: bb\n├── merge\n├── upper\n└── work\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n执行以下命令使用overlay进行合并层\n\nmount -t overlay overlay -o lowerdir=lowerdira:lowerdirb,upperdir=upper,workdir=work merge\n\n\n1\n\n\nlowerdir为镜像层，upperdir为容器层，merge目录为最终展示层。\n\n可以看到merge目录中的a文件内容lowerdira镜像层的内容\n\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# cat merge/a \naa\n\n\n1\n2\n\n\n当我们修改megre目录中的a文件时，可以看到upperdir目录的会生成a文件并且内容修改后的内容\n\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# ls upper/\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# echo upper > merge/a\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# ls upper/\na\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# cat upper/a\nupper\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# cat merge/a\nupper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n当删除文件merge/a时，会出现什么情况呢?\n\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# rm merge/a\nrm: remove regular file ‘merge/a’? y\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# ll lowerdira/\ntotal 8\n-rw-r--r-- 1 root root 3 jul 12 19:11 a\n-rw-r--r-- 1 root root 3 jul 12 19:10 b\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# ll upper/\ntotal 0\nc--------- 1 root root 0, 0 jul 12 19:31 a\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n可以看出镜像层lowerdira的文件a是不变的，而在容器层upper中的a文件类型变成了c，该文件类型，最终在展示层看不到该文件了。\n\n可以使用命令docker inspect来查看layer的路径\n\n>>> docker inspect xxx\n\n....\n"graphdriver": {\n            "data": {\n                "lowerdir": "/var/lib/docker/overlay2/641e486c54d15d2a8d807fd8964f4a4b8687cbcf95c176cd9a46553b1e80341d/diff:/var/lib/docker/overlay2/ed9ad4fb9d0f9bf3aea553c634e54fef89448cf43c5b662468d79f01cf41d0c3/diff:/var/lib/docker/overlay2/9db169e1ad2165f688e652ef06dfe9a3e465c31299f3c357a37a6919747efbc8/diff",\n                "mergeddir": "/var/lib/docker/overlay2/fa3166e545a2d1811dbeecb6f1fdda96b9f97b3cd629f32a8ea378aa79b1c780/merged",\n                "upperdir": "/var/lib/docker/overlay2/fa3166e545a2d1811dbeecb6f1fdda96b9f97b3cd629f32a8ea378aa79b1c780/diff",\n                "workdir": "/var/lib/docker/overlay2/fa3166e545a2d1811dbeecb6f1fdda96b9f97b3cd629f32a8ea378aa79b1c780/work"\n            },\n            "name": "overlay2"\n        },\n....\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# dockerfile\n\ndockerfile是一个用来创建镜像的文本文件，该文件中的每一条命令都会成生成一个layer。\n\n例子：\n\n最简单的dockerfile的例子\n\nfrom busybox                  # 选择基础镜像\ncmd echo "hello world"        # 启动容器时默认运行的命令\n\n\n1\n2\n\n\nfrom指令是构建使用的基础镜像\n\ncmd指令是用于启动容器时默认运行的命令\n\n使用docker build 即可执行创建镜像\n\ndocker build -f dockerfile .\n\nsending build context to docker daemon   7.68kb\nstep 1/2 : from busybox\n ---\x3e d38589532d97\nstep 2/2 : cmd echo "hello world"\n ---\x3e running in c5a762edd1c8\nremoving intermediate container c5a762edd1c8\n ---\x3e b61882f42db7\nsuccessfully built b61882f42db7\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 容器与外部的交互\n\n如何拷贝宿主机的文件到容器内\n\n可以使用docker cp命令将宿主机的文件拷贝到容器中。\n\ndocker cp a.txt 062:/tmp\n\n\n1\n\n\n其中的062为容器id，如果想将容器中的文件拷贝到宿主机中，反过来即可。\n\ndocker cp 062:/tmp/a.txt /tmp\n\n\n1\n\n\n注意，这里的拷贝是临时的，拷贝进容器中的文件只存在于容器中，不存在与镜像中，如果想要将文件拷贝到镜像中，在写dockerfile时使用copy命令拷贝即可。\n\n宿主机与容器共享文件夹\n\n在使用镜像运行容器时，使用参数-v可以将宿主机中的文件夹映射到容器中，双方修改该文件夹中的内容，都可以及时看到。\n\ndocker run -d --rm -v /tmp:/tmp redis\n\n\n1\n\n\n如何实现网络互通？\n\ndocker提供三种网络模式：\n\n * null，无网络\n * host，直接使用宿主机网络，在创建容器时，使用--net=host参数。\n\n其实就是创建新的namespace，而是直接加入到宿主机的namesapce\n\ndocker run -d --rm --net=host nginx:alpine\n\n\n1\n\n * bridge，桥接模式，由软件虚拟网卡与网桥，容器和宿主机都接入该网桥，即可正常发送数据包。可以使用参数--net=bridge创建容器，但这个是默认参数。\n\ndocker run -d --rm nginx:alpine\n\n\n1\n\n\n\n\n网络模式     优点                        缺点\nhost     因为是直接使用宿主机的网络，效率更高        运行太多的容器，会导致端口发生冲突\nbridge   因为有了网桥可以设置更多的策略，比如流量控制等   需要软件模拟虚拟网卡与网桥，效率更低\n\n\n\n\n\n\n# 关于k8s与docker的关系\n\n在2014年的时候,docker如日中天，那么k8s自然选择基于docker上运行。\n\n在2016年k8s加入了cncf，一个开源的云原生计算基金会。\n\n并且引入了一个接口标准：cri，container runtime interface。也就是规定kubelet该如何调用container runtime去管理容器和镜像，但这是一套全新的接口，和之前的docker完全不兼容。目的很明显，不想绑定docker，可以随时将docker踢掉。\n\n因为docker已经非常成熟，各大厂商不可能将docker全部替换。所以k8s在kubelet和docker中间加一个"适配器"，把docker的接口转换成符合cri标准的接口。\n\n\n\n什么是containerd？\n\n不过 docker 也没有“坐以待毙”，而是采取了“断臂求生”的策略，推动自身的重构，把原本单体架构的 docker engine 拆分成了多个模块，其中的 docker daemon 部分就捐献给了 cncf，形成了 containerd。\n\ncontainerd 作为 cncf 的托管项目，自然是要符合 cri 标准的。但 docker 出于自己诸多原因的考虑，它只是在 docker engine 里调用了 containerd，外部的接口仍然保持不变，也就是说还不与 cri 兼容。\n\n由于 docker 的“固执己见”，这时 kubernetes 里就出现了两种调用链：第一种是用 cri 接口调用 dockershim，然后 dockershim 调用 docker，docker 再走 containerd 去操作容器。第二种是用 cri 接口直接调用 containerd 去操作容器。\n\n\n\n显而易见，使用第二种省去了dockershim和docker engine两个环节，损耗更少，性能也提升了。\n\n正式"弃用docker"\n\n在2020年k8s弃用docker支持，但该弃用支持弃用了"dockershim"的这个组件，也就是把dockershim移出kubelete，只是绕过docker，直接调用了docker内部的containerd而已。\n\n并且对docker也无影响，因为docker内部也是使用开源的containerd。\n\n\n\n唯一影响的是，k8s是直接操作containerd操作容器，那么它和docker是独立的工作环境，彼此都不能访问对方的容器和镜像，也就是docker ps看不到k8s运行的容器。改用crictl命令。\n\ndocker 重构自身，分离出 containerd，这是否算是一种“自掘坟墓”的行为呢？如果没有 containerd，那现在的情形会是怎么样的呢？\n\ndocker 是一个完整的软件产品线，不止是 containerd，它还包括了镜像构建、分发、测试等许多服务，甚至在 docker desktop 里还内置了 kubernetes。\n\n> docker分离containerd是一个很聪明的举动！与其将来被人分离或者抛弃不用，不如我主动革新，把kubernates绑在我的战车上，这样cri的第一选择仍然是docker的自己人。\n> 一时的退让是为了更好的将来。',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"k8s之Pod",frontmatter:{tags:["k8s","容器","云原生"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},title:"k8s之Pod",date:"2022-08-30T12:48:34.000Z",permalink:"/pages/2b547f/",description:"介绍k8s中的pod资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220331113937.png#crop=0&crop=0&crop=1&crop=1&id=mo242&originHeight=381&originWidth=481&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{name:"twitter:title",content:"k8s之Pod"},{name:"twitter:description",content:"介绍k8s中的pod资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220331113937.png#crop=0&crop=0&crop=1&crop=1&id=mo242&originHeight=381&originWidth=481&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/03.k8s%E4%B9%8Bpod.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之Pod"},{property:"og:description",content:"介绍k8s中的pod资源对象，及其使用方法和案例"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220331113937.png#crop=0&crop=0&crop=1&crop=1&id=mo242&originHeight=381&originWidth=481&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/03.k8s%E4%B9%8Bpod.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-30T12:48:34.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之Pod"},{itemprop:"description",content:"介绍k8s中的pod资源对象，及其使用方法和案例"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220331113937.png#crop=0&crop=0&crop=1&crop=1&id=mo242&originHeight=381&originWidth=481&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/03.k8s%E4%B9%8Bpod.html",relativePath:"01.云原生/07.k8s/03.k8s之pod.md",key:"v-29274a29",path:"/pages/2b547f/",headers:[{level:2,title:"什么是pod?",slug:"什么是pod",normalizedTitle:"什么是pod?",charIndex:2},{level:2,title:"为什么需要Pod?",slug:"为什么需要pod",normalizedTitle:"为什么需要pod?",charIndex:110},{level:2,title:"使用Pod",slug:"使用pod",normalizedTitle:"使用pod",charIndex:615},{level:2,title:"容器状态探针",slug:"容器状态探针",normalizedTitle:"容器状态探针",charIndex:1959},{level:2,title:"资源配置",slug:"资源配置",normalizedTitle:"资源配置",charIndex:2292}],headersStr:"什么是pod? 为什么需要Pod? 使用Pod 容器状态探针 资源配置",content:'# 什么是pod?\n\nPod是一组共享了某些资源的容器。\n\n容器的隔离是通过各种namespace来实现的，Pod 里的所有容器，可以通过Namespace来共享系统资源，像Network Namepsace。\n\n\n# 为什么需要Pod?\n\n众所周知所周知，容器是一个特殊的进程，但有些场景是，一个应用的运行，是需要多个进程结合使用，并有一定的依赖关系的。虽然我们也可以使用单独的容器来配置运行应用，但是都是独立的。而pod是k8s的原子调度，pod中的容器可以指定分配到同一个节点，统一按照资源调度。\n\n使用docker也可以实现A、B容器共享网络和Volume，但是容器B必须比容器A先启动，是一个拓扑结构，而不是平等关系\n\n$ docker run --net=B --volumes-from=B --name=A image-A ...\n\n\n1\n\n\n在Pod中，先创建启动的是Infra容器，该容器会处于一个禁止状态，而其他定义的容器，则通过Join Network Namespace与Infra容器连接在一起。\n\n\n\n在Pod中的容器处于同一个Network Namespace中，所以可以通过localhost直接进行通信，看到的网络设备是一致的。而Pod的生命周期和Infra容器一致，和容器A、B无关。\n\nPod，实际上是在扮演传统基础设施里“虚拟机”的角色；而容器，则是这个虚拟机里运行的用户程序。\n\n\n# 使用Pod\n\n使用yaml来描述一个Pod。\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\n\nspec:\n  containers:\n  - name: nginx\n    image: nginx:laster\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n再使用kubectl apply来创建pod\n\n[root@k8s-worker1 zwf]# kubectl apply -f pod.yaml -n zwf\npod/nginx-pod created\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf -o wide\nNAME        READY   STATUS    RESTARTS   AGE     IP              NODE          NOMINATED NODE   READINESS GATES\nnginx-pod   1/1     Running   0          2m51s   10.222.126.60   k8s-worker2   <none>           <none>\n\n\n1\n2\n3\n4\n5\n6\n\n\n我们可以使用curl访问到pod中的nginx的服务了\n\n[root@k8s-worker1 zwf]# curl 10.222.126.60:80\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n<style>\nhtml { color-scheme: light dark; }\nbody { width: 35em; margin: 0 auto;\nfont-family: Tahoma, Verdana, Arial, sans-serif; }\n</style>\n</head>\n<body>\n<h1>Welcome to nginx!</h1>\n<p>If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.</p>\n\n<p>For online documentation and support please refer to\n<a href="http://nginx.org/">nginx.org</a>.<br/>\nCommercial support is available at\n<a href="http://nginx.com/">nginx.com</a>.</p>\n\n<p><em>Thank you for using nginx.</em></p>\n</body>\n</html>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n一般我们不直接创建Pod，而是通过各种控制器来管理创建\n\n\n# 容器状态探针\n\n * ReadinessProbe\n\n就绪性探针，判断容器中的程序是否健康，不健康，则会将该pod从service可用端点列表移除。\n\n * livenessProbe\n\n存活性探针，判断容器是否健康，不健康，则会将容器重启。 注意：是将容器重启而不是pod\n\n * startupProbe\n\n在pod启动后按照配置执行一次，如果成功，则不再执行，如果失败，则会重启pod. 其他两个探针是在startupProbe运行成功之前都是暂停的。\n\n探测方式\n\n * exec，执行一个Linux命令，看返回值\n\n * tcpSocket，使用tcp尝试连接某个端口，看是否连接成功\n\n * httpGet，尝试使用http请求，看是否请求成功\n\n\n# 资源配置\n\n在配置中使用resources字段来设置限制容器的资源。\n\n * requests，系统必须预留的可用资源\n\n * limits，容器可申请使用的最大可用资源，超过则会被kill的可能性\n\n这里的cpu使用的是m(milli)的单位，1000m代表1个cpu，10m代表1%cpu\n\n而内存使用Mi代表MB。\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: ngx-pod-resources\n\nspec:\n  containers:\n  - image: nginx:alpine\n    name: ngx\n\n    resources:\n      requests:\n        cpu: 10m\n        memory: 100Mi\n      limits:\n        cpu: 20m\n        memory: 200Mi\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n我们再来看看是怎么使用cgroup来限制pod中容器的资源\n\n先找到pod中该容器的ID\n\n>>> kubectl describe pod -n zwf ngx-pod-resources\nName:         ngx-pod-resources\nNamespace:    zwf\nPriority:     0\nNode:         k8s-worker1/10.64.2.141\nStart Time:   Tue, 30 Aug 2022 16:11:45 +0800\nLabels:       <none>\nAnnotations:  cni.projectcalico.org/containerID: 4c8f23863e6589d44b96ded48a2abd857ca9e45637fb9dd6b106c3c217be0904\n              cni.projectcalico.org/podIP: 10.222.194.100/32\n              cni.projectcalico.org/podIPs: 10.222.194.100/32\nStatus:       Running\nIP:           10.222.194.100\nIPs:\n  IP:  10.222.194.100\nContainers:\n  ngx:\n    Container ID:   docker://c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859\n    Image:          nginx:alpine\n    Image ID:       docker-pullable://nginx@sha256:082f8c10bd47b6acc8ef15ae61ae45dd8fde0e9f389a8b5cb23c37408642bf5d\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Tue, 30 Aug 2022 16:11:54 +0800\n    Ready:          True\n    Restart Count:  0\n    Limits:\n      cpu:     20m\n      memory:  200Mi\n    Requests:\n      cpu:        10m\n      memory:     100Mi\n    Environment:  <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-jcccn (ro)\n\n....\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n然后再通过docker inspect找到限制该容器的cgroup的路径\n\n>>> docker inspect c60e37 | grep Cgroup\n            "CgroupnsMode": "host",\n            "Cgroup": "",\n            "CgroupParent": "/kubepods/burstable/poda9ca2eed-ef7b-4564-b448-e35b06c7bdd0",\n            "DeviceCgroupRules": null\n\n\n1\n2\n3\n4\n5\n\n\n我们再进入到/sys/fs/cgroup/cpu/kubepods/burstable/poda9ca2eed-ef7b-4564-b448-e35b06c7bdd0，可以看到有两个容器ID的目录，因为除了我们nginx容器之外，还有一个infra容器。\n\n[root@k8s-worker1]# cd /sys/fs/cgroup/cpu/kubepods/burstable/poda9ca2eed-ef7b-4564-b448-e35b06c7bdd0\n\n[root@k8s-worker1]# ls\n4c8f23863e6589d44b96ded48a2abd857ca9e45637fb9dd6b106c3c217be0904  cpuacct.usage              cpuacct.usage_sys   cpu.rt_runtime_us\nc60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859  cpuacct.usage_all          cpuacct.usage_user  cpu.shares\ncgroup.clone_children                                             cpuacct.usage_percpu       cpu.cfs_period_us   cpu.stat\ncgroup.procs                                                      cpuacct.usage_percpu_sys   cpu.cfs_quota_us    notify_on_release\ncpuacct.stat                                                      cpuacct.usage_percpu_user  cpu.rt_period_us    tasks\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n我们进入到nginx的容器ID目录下，查看tasks文件，发现有很多进程ID，为什么呢？\n\n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# cat tasks\n2733304\n2733402\n2733403\n2733404\n2733405\n2733406\n2733407\n2733408\n2733409\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n容器就是一个隔离的进程，我们看下该容器的进程ID，再通过该ID找到该进程，确实是nginx没错，也在cgroup的tasks文件中，但是其他的进程ID是什么呢？\n\n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# docker inspect c60e | grep Pid\n            "Pid": 2733304,\n            "PidMode": "",\n            "PidsLimit": null,\n            \n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# ps aux | grep 2733304\nroot     2733304  0.0  0.0   6304  4544 ?        Ss   16:11   0:00 nginx: master process nginx -g daemon off;\nroot     2787238  0.0  0.0  12132  1156 pts/3    S+   16:45   0:00 grep --color=auto 2733304\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n我通过ps aux来搜索一下nginx，容器ID为nginx master，而其他的进程ID都是nginx的worker进程。\n\n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# ps aux | grep nginx\nroot     2733304  0.0  0.0   6304  4544 ?        Ss   16:11   0:00 nginx: master process nginx -g daemon off;\n101      2733402  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733403  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733404  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733405  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733406  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733407  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733408  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733409  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\nroot     2781594  0.0  0.0  12132  1164 pts/3    S+   16:41   0:00 grep --color=auto nginx\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n',normalizedContent:'# 什么是pod?\n\npod是一组共享了某些资源的容器。\n\n容器的隔离是通过各种namespace来实现的，pod 里的所有容器，可以通过namespace来共享系统资源，像network namepsace。\n\n\n# 为什么需要pod?\n\n众所周知所周知，容器是一个特殊的进程，但有些场景是，一个应用的运行，是需要多个进程结合使用，并有一定的依赖关系的。虽然我们也可以使用单独的容器来配置运行应用，但是都是独立的。而pod是k8s的原子调度，pod中的容器可以指定分配到同一个节点，统一按照资源调度。\n\n使用docker也可以实现a、b容器共享网络和volume，但是容器b必须比容器a先启动，是一个拓扑结构，而不是平等关系\n\n$ docker run --net=b --volumes-from=b --name=a image-a ...\n\n\n1\n\n\n在pod中，先创建启动的是infra容器，该容器会处于一个禁止状态，而其他定义的容器，则通过join network namespace与infra容器连接在一起。\n\n\n\n在pod中的容器处于同一个network namespace中，所以可以通过localhost直接进行通信，看到的网络设备是一致的。而pod的生命周期和infra容器一致，和容器a、b无关。\n\npod，实际上是在扮演传统基础设施里“虚拟机”的角色；而容器，则是这个虚拟机里运行的用户程序。\n\n\n# 使用pod\n\n使用yaml来描述一个pod。\n\napiversion: v1\nkind: pod\nmetadata:\n  name: nginx-pod\n\nspec:\n  containers:\n  - name: nginx\n    image: nginx:laster\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n再使用kubectl apply来创建pod\n\n[root@k8s-worker1 zwf]# kubectl apply -f pod.yaml -n zwf\npod/nginx-pod created\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf -o wide\nname        ready   status    restarts   age     ip              node          nominated node   readiness gates\nnginx-pod   1/1     running   0          2m51s   10.222.126.60   k8s-worker2   <none>           <none>\n\n\n1\n2\n3\n4\n5\n6\n\n\n我们可以使用curl访问到pod中的nginx的服务了\n\n[root@k8s-worker1 zwf]# curl 10.222.126.60:80\n<!doctype html>\n<html>\n<head>\n<title>welcome to nginx!</title>\n<style>\nhtml { color-scheme: light dark; }\nbody { width: 35em; margin: 0 auto;\nfont-family: tahoma, verdana, arial, sans-serif; }\n</style>\n</head>\n<body>\n<h1>welcome to nginx!</h1>\n<p>if you see this page, the nginx web server is successfully installed and\nworking. further configuration is required.</p>\n\n<p>for online documentation and support please refer to\n<a href="http://nginx.org/">nginx.org</a>.<br/>\ncommercial support is available at\n<a href="http://nginx.com/">nginx.com</a>.</p>\n\n<p><em>thank you for using nginx.</em></p>\n</body>\n</html>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n一般我们不直接创建pod，而是通过各种控制器来管理创建\n\n\n# 容器状态探针\n\n * readinessprobe\n\n就绪性探针，判断容器中的程序是否健康，不健康，则会将该pod从service可用端点列表移除。\n\n * livenessprobe\n\n存活性探针，判断容器是否健康，不健康，则会将容器重启。 注意：是将容器重启而不是pod\n\n * startupprobe\n\n在pod启动后按照配置执行一次，如果成功，则不再执行，如果失败，则会重启pod. 其他两个探针是在startupprobe运行成功之前都是暂停的。\n\n探测方式\n\n * exec，执行一个linux命令，看返回值\n\n * tcpsocket，使用tcp尝试连接某个端口，看是否连接成功\n\n * httpget，尝试使用http请求，看是否请求成功\n\n\n# 资源配置\n\n在配置中使用resources字段来设置限制容器的资源。\n\n * requests，系统必须预留的可用资源\n\n * limits，容器可申请使用的最大可用资源，超过则会被kill的可能性\n\n这里的cpu使用的是m(milli)的单位，1000m代表1个cpu，10m代表1%cpu\n\n而内存使用mi代表mb。\n\napiversion: v1\nkind: pod\nmetadata:\n  name: ngx-pod-resources\n\nspec:\n  containers:\n  - image: nginx:alpine\n    name: ngx\n\n    resources:\n      requests:\n        cpu: 10m\n        memory: 100mi\n      limits:\n        cpu: 20m\n        memory: 200mi\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n我们再来看看是怎么使用cgroup来限制pod中容器的资源\n\n先找到pod中该容器的id\n\n>>> kubectl describe pod -n zwf ngx-pod-resources\nname:         ngx-pod-resources\nnamespace:    zwf\npriority:     0\nnode:         k8s-worker1/10.64.2.141\nstart time:   tue, 30 aug 2022 16:11:45 +0800\nlabels:       <none>\nannotations:  cni.projectcalico.org/containerid: 4c8f23863e6589d44b96ded48a2abd857ca9e45637fb9dd6b106c3c217be0904\n              cni.projectcalico.org/podip: 10.222.194.100/32\n              cni.projectcalico.org/podips: 10.222.194.100/32\nstatus:       running\nip:           10.222.194.100\nips:\n  ip:  10.222.194.100\ncontainers:\n  ngx:\n    container id:   docker://c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859\n    image:          nginx:alpine\n    image id:       docker-pullable://nginx@sha256:082f8c10bd47b6acc8ef15ae61ae45dd8fde0e9f389a8b5cb23c37408642bf5d\n    port:           <none>\n    host port:      <none>\n    state:          running\n      started:      tue, 30 aug 2022 16:11:54 +0800\n    ready:          true\n    restart count:  0\n    limits:\n      cpu:     20m\n      memory:  200mi\n    requests:\n      cpu:        10m\n      memory:     100mi\n    environment:  <none>\n    mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-jcccn (ro)\n\n....\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n然后再通过docker inspect找到限制该容器的cgroup的路径\n\n>>> docker inspect c60e37 | grep cgroup\n            "cgroupnsmode": "host",\n            "cgroup": "",\n            "cgroupparent": "/kubepods/burstable/poda9ca2eed-ef7b-4564-b448-e35b06c7bdd0",\n            "devicecgrouprules": null\n\n\n1\n2\n3\n4\n5\n\n\n我们再进入到/sys/fs/cgroup/cpu/kubepods/burstable/poda9ca2eed-ef7b-4564-b448-e35b06c7bdd0，可以看到有两个容器id的目录，因为除了我们nginx容器之外，还有一个infra容器。\n\n[root@k8s-worker1]# cd /sys/fs/cgroup/cpu/kubepods/burstable/poda9ca2eed-ef7b-4564-b448-e35b06c7bdd0\n\n[root@k8s-worker1]# ls\n4c8f23863e6589d44b96ded48a2abd857ca9e45637fb9dd6b106c3c217be0904  cpuacct.usage              cpuacct.usage_sys   cpu.rt_runtime_us\nc60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859  cpuacct.usage_all          cpuacct.usage_user  cpu.shares\ncgroup.clone_children                                             cpuacct.usage_percpu       cpu.cfs_period_us   cpu.stat\ncgroup.procs                                                      cpuacct.usage_percpu_sys   cpu.cfs_quota_us    notify_on_release\ncpuacct.stat                                                      cpuacct.usage_percpu_user  cpu.rt_period_us    tasks\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n我们进入到nginx的容器id目录下，查看tasks文件，发现有很多进程id，为什么呢？\n\n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# cat tasks\n2733304\n2733402\n2733403\n2733404\n2733405\n2733406\n2733407\n2733408\n2733409\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n容器就是一个隔离的进程，我们看下该容器的进程id，再通过该id找到该进程，确实是nginx没错，也在cgroup的tasks文件中，但是其他的进程id是什么呢？\n\n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# docker inspect c60e | grep pid\n            "pid": 2733304,\n            "pidmode": "",\n            "pidslimit": null,\n            \n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# ps aux | grep 2733304\nroot     2733304  0.0  0.0   6304  4544 ?        ss   16:11   0:00 nginx: master process nginx -g daemon off;\nroot     2787238  0.0  0.0  12132  1156 pts/3    s+   16:45   0:00 grep --color=auto 2733304\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n我通过ps aux来搜索一下nginx，容器id为nginx master，而其他的进程id都是nginx的worker进程。\n\n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# ps aux | grep nginx\nroot     2733304  0.0  0.0   6304  4544 ?        ss   16:11   0:00 nginx: master process nginx -g daemon off;\n101      2733402  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733403  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733404  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733405  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733406  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733407  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733408  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733409  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\nroot     2781594  0.0  0.0  12132  1164 pts/3    s+   16:41   0:00 grep --color=auto nginx\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"k8s之Deployment",frontmatter:{tags:["k8s","容器","云原生"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},title:"k8s之Deployment",date:"2022-08-29T16:27:11.000Z",permalink:"/pages/d73c88/",description:"介绍k8s中的deployment资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220820143105.png"},{name:"twitter:title",content:"k8s之Deployment"},{name:"twitter:description",content:"介绍k8s中的deployment资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220820143105.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/04.k8s%E4%B9%8Bdeployment.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之Deployment"},{property:"og:description",content:"介绍k8s中的deployment资源对象，及其使用方法和案例"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220820143105.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/04.k8s%E4%B9%8Bdeployment.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-29T16:27:11.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之Deployment"},{itemprop:"description",content:"介绍k8s中的deployment资源对象，及其使用方法和案例"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220820143105.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/04.k8s%E4%B9%8Bdeployment.html",relativePath:"01.云原生/07.k8s/04.k8s之deployment.md",key:"v-44df3b79",path:"/pages/d73c88/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"使用yaml描述Deployment",slug:"使用yaml描述deployment",normalizedTitle:"使用yaml描述deployment",charIndex:86},{level:2,title:"查看Deployment",slug:"查看deployment",normalizedTitle:"查看deployment",charIndex:730},{level:2,title:"ReplicaSet",slug:"replicaset",normalizedTitle:"replicaset",charIndex:1679},{level:2,title:"水平扩缩容",slug:"水平扩缩容",normalizedTitle:"水平扩缩容",charIndex:3501},{level:2,title:"滚动更新",slug:"滚动更新",normalizedTitle:"滚动更新",charIndex:4473}],headersStr:"简介 使用yaml描述Deployment 查看Deployment ReplicaSet 水平扩缩容 滚动更新",content:'# 简介\n\nDeployment是k8s用来管理部署无状态Pod的控制器。\n\n适用场景\n\n无状态应用，所有的pod无依赖关系，无指定节点运行、无特殊处理的方式部署\n\n\n# 使用yaml描述Deployment\n\n使用下面的yaml文件用来创建nginx的Deployment对象\n\nreplicas是用来定义创建pod的数量。template中的是所管理的Pod模板，Deployment就是根据该字段来创建pod资源对象。selector是用来筛选需要管理的pod对象，template下的labels的值需要与selector的值需要保持一致，这样Deployment才能找到需要控制的Pod。\n\n更多的字段说明可以看官网\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n  \nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ngx-dep\n      \n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: nginx:alpine\n        name: nginx\n        ports:\n        - containerPort: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# 查看Deployment\n\n我们有了yaml来描述deployment之后，就可以使用kubectl apply来创建Deployment对象。\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments.yaml  -n zwf\ndeployment.apps/ngx-dep created\n\n\n1\n2\n\n\n我也也可以使用kubectl get来查看我们创建的deplotment对象的信息\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   2/2     2            2           19m\n\n\n1\n2\n3\n\n\n信息：\n\n * READY，就绪个数/期望个数\n * UP-TO-DATE，当前处于最新版本的pod数\n * AVAILABLE，当前可用的Pod数，也就是已经经过ready之后的Pod\n * age，存活时间\n\n我们将其中一个pod删除了，会发现不就后pod还会自动创建，因为k8s会根据yaml中replicas的值，让deployment的实际状态不断的向期望状态逼近，最终达到一个应用"永不宕机"\n\n[root@k8s-worker1 zwf]# kubectl delete pods ngx-dep-69b9455bcf-cfwgd -n zwf\npod "ngx-dep-69b9455bcf-cfwgd" deleted\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME                       READY   STATUS    RESTARTS   AGE\nngx-dep-69b9455bcf-ddjml   1/1     Running   0          13m\nngx-dep-69b9455bcf-fn6gw   1/1     Running   0          5s\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# ReplicaSet\n\nDeployment并不是直接管理Pod，而是通过ReplicaSet对象间接管理的，也就是说真正管理pod的其实是replicaSet对象.\n\n我们使用kubectl get rs可以查看到ReplicaSet对象，该对象是在创建Deployment时创建的，查看一下ReplicaSet对象的信息，其中的DESIRED和CURRENT对应在和Deployment的READY，READY和Deployment中的是一样的。\n\n[root@k8s-worker1 zwf]# kubectl get rs -n zwf\nNAME                 DESIRED   CURRENT   READY   AGE\nngx-dep-69b9455bcf   2         2         2       43s\n\n\n1\n2\n3\n\n\n通过kubectl describe查看deploment的详情，可以看到NewReplicaSet的值指向的是ReplicaSet对象，并间接管理Pod。\n\n[root@k8s-worker1 zwf]# kubectl describe deploy ngx-dep -n zwf \nName:                   ngx-dep\nNamespace:              zwf\nCreationTimestamp:      Tue, 30 Aug 2022 11:27:14 +0800\nLabels:                 app=ngx-dep\nAnnotations:            deployment.kubernetes.io/revision: 1\nSelector:               app=ngx-dep\nReplicas:               2 desired | 2 updated | 2 total | 2 available | 0 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  app=ngx-dep\n  Containers:\n   nginx:\n    Image:        mirrors.sangfor.com/nginx:alpine\n    Port:         80/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Progressing    True    NewReplicaSetAvailable\n  Available      True    MinimumReplicasAvailable\nOldReplicaSets:  <none>\nNewReplicaSet:   ngx-dep-69b9455bcf (2/2 replicas created)\nEvents:\n  Type    Reason             Age   From                   Message\n  ----    ------             ----  ----                   -------\n  Normal  ScalingReplicaSet  13m   deployment-controller  Scaled up replica set ngx-dep-69b9455bcf to 2\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 水平扩缩容\n\n水平扩缩容是可以动态的改变Pod的数量，在高峰期可以扩大应用的数量提高并发，在低峰期缩减Pod减少资源的使用。\n\n我们使用kubectl scale动态改变Deployment的副本数，查看Deployment对象可以看到READY从2/4到4/4，并且AVALIABLE的值也是逐渐的从2到4\n\n[root@k8s-worker1 zwf]# kubectl scale deploy ngx-dep -n zwf --replicas=4\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   2/4     4            2           18m\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   3/4     4            3           18m\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   4/4     4            4           18m\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n我们再看看ReplicaSet对象，可以看到当前正在运行Pod数量也发生了改变。因为水平扩缩容的实质是deplotment去修改ReplicaSet的Pod副本的数量。\n\n[root@k8s-worker1 zwf]# kubectl get replicaset  -n zwf\nNAME                 DESIRED   CURRENT   READY   AGE\nngx-dep-69b9455bcf   4         4         4       50m\n\n\n1\n2\n3\n\n\n\n\n\n# 滚动更新\n\n在更新的过程，是逐渐将旧的ReplicaSet所管理的Pod删除，新的ReplicaSet管理的Pod新增这么一个过程。\n\n我们修改Deployment的yaml文件，将containers的name修改为nginx2\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n  \nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ngx-dep\n      \n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: nginx:alpine\n        name: nginx2   # 修改\n        ports:\n        - containerPort: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再使用kubectl apply执行，更新Deployment，可以看到，UP-TO-DATE是逐渐的从1到2，旧的pod会逐渐的更新成最新的pod.\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments.yaml -n zwf\ndeployment.apps/ngx-dep configured\n\n[root@k8s-worker1 zwf]# kubectl get deploy -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   2/2     1            2           55m\n\n[root@k8s-worker1 zwf]# kubectl get deploy -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   2/2     2            2           55m\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n我们再看下ReplicaSet对象，可以看到有两个对象。这是因为我们更新了Deployment中的pod template模板，也就是会更新pod，我们知道Deployment是通过ReplicaSet来管理对象的，所以会创建一个新版本的ReplicaSet对象用来创建新版本的Pod并逐渐增加，然后逐渐将旧版本的ReplicaSet对象管理的pod删除直至为0。\n\n[root@k8s-worker1 zwf]# kubectl get rs -n zwf\nNAME                 DESIRED   CURRENT   READY   AGE\nngx-dep-54d65f4d8c   2         2         2       2m54s\nngx-dep-69b9455bcf   0         0         0       58m\n\n\n1\n2\n3\n4\n\n\n我们再看Deployment的详情，Events字段是代表着Deployment中发生的事件，可以看到ngx-dep-69b9455bcf所管理的pod逐渐减少，而ngx-dep-69b9455bcf在逐渐增加pod的数量。这也就解释了上面为什么有两个ReplicaSet对象，因为一个是新对象，一个是旧对象，在更新Deployment时，都会保留下来。\n\n[root@k8s-worker1 zwf]# kubectl describe deploy ngx-dep -n zwf\nName:                   ngx-dep\nNamespace:              zwf\nCreationTimestamp:      Tue, 30 Aug 2022 11:27:14 +0800\nLabels:                 app=ngx-dep\nAnnotations:            deployment.kubernetes.io/revision: 2\nSelector:               app=ngx-dep\nReplicas:               2 desired | 2 updated | 2 total | 2 available | 0 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  app=ngx-dep\n  Containers:\n   nginx2:\n    Image:        mirrors.sangfor.com/nginx:alpine\n    Port:         80/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    NewReplicaSetAvailable\nOldReplicaSets:  <none>\nNewReplicaSet:   ngx-dep-54d65f4d8c (2/2 replicas created)\nEvents:\n  Type    Reason             Age                  From                   Message\n  ----    ------             ----                 ----                   -------\n  Normal  ScalingReplicaSet  5m                   deployment-controller  Scaled up replica set ngx-dep-54d65f4d8c to 1\n  Normal  ScalingReplicaSet  4m58s                deployment-controller  Scaled down replica set ngx-dep-69b9455bcf to 1\n  Normal  ScalingReplicaSet  4m58s                deployment-controller  Scaled up replica set ngx-dep-54d65f4d8c to 2\n  Normal  ScalingReplicaSet  4m54s                deployment-controller  Scaled down replica set ngx-dep-69b9455bcf to 0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n',normalizedContent:'# 简介\n\ndeployment是k8s用来管理部署无状态pod的控制器。\n\n适用场景\n\n无状态应用，所有的pod无依赖关系，无指定节点运行、无特殊处理的方式部署\n\n\n# 使用yaml描述deployment\n\n使用下面的yaml文件用来创建nginx的deployment对象\n\nreplicas是用来定义创建pod的数量。template中的是所管理的pod模板，deployment就是根据该字段来创建pod资源对象。selector是用来筛选需要管理的pod对象，template下的labels的值需要与selector的值需要保持一致，这样deployment才能找到需要控制的pod。\n\n更多的字段说明可以看官网\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n  \nspec:\n  replicas: 2\n  selector:\n    matchlabels:\n      app: ngx-dep\n      \n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: nginx:alpine\n        name: nginx\n        ports:\n        - containerport: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# 查看deployment\n\n我们有了yaml来描述deployment之后，就可以使用kubectl apply来创建deployment对象。\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments.yaml  -n zwf\ndeployment.apps/ngx-dep created\n\n\n1\n2\n\n\n我也也可以使用kubectl get来查看我们创建的deplotment对象的信息\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nname      ready   up-to-date   available   age\nngx-dep   2/2     2            2           19m\n\n\n1\n2\n3\n\n\n信息：\n\n * ready，就绪个数/期望个数\n * up-to-date，当前处于最新版本的pod数\n * available，当前可用的pod数，也就是已经经过ready之后的pod\n * age，存活时间\n\n我们将其中一个pod删除了，会发现不就后pod还会自动创建，因为k8s会根据yaml中replicas的值，让deployment的实际状态不断的向期望状态逼近，最终达到一个应用"永不宕机"\n\n[root@k8s-worker1 zwf]# kubectl delete pods ngx-dep-69b9455bcf-cfwgd -n zwf\npod "ngx-dep-69b9455bcf-cfwgd" deleted\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname                       ready   status    restarts   age\nngx-dep-69b9455bcf-ddjml   1/1     running   0          13m\nngx-dep-69b9455bcf-fn6gw   1/1     running   0          5s\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# replicaset\n\ndeployment并不是直接管理pod，而是通过replicaset对象间接管理的，也就是说真正管理pod的其实是replicaset对象.\n\n我们使用kubectl get rs可以查看到replicaset对象，该对象是在创建deployment时创建的，查看一下replicaset对象的信息，其中的desired和current对应在和deployment的ready，ready和deployment中的是一样的。\n\n[root@k8s-worker1 zwf]# kubectl get rs -n zwf\nname                 desired   current   ready   age\nngx-dep-69b9455bcf   2         2         2       43s\n\n\n1\n2\n3\n\n\n通过kubectl describe查看deploment的详情，可以看到newreplicaset的值指向的是replicaset对象，并间接管理pod。\n\n[root@k8s-worker1 zwf]# kubectl describe deploy ngx-dep -n zwf \nname:                   ngx-dep\nnamespace:              zwf\ncreationtimestamp:      tue, 30 aug 2022 11:27:14 +0800\nlabels:                 app=ngx-dep\nannotations:            deployment.kubernetes.io/revision: 1\nselector:               app=ngx-dep\nreplicas:               2 desired | 2 updated | 2 total | 2 available | 0 unavailable\nstrategytype:           rollingupdate\nminreadyseconds:        0\nrollingupdatestrategy:  25% max unavailable, 25% max surge\npod template:\n  labels:  app=ngx-dep\n  containers:\n   nginx:\n    image:        mirrors.sangfor.com/nginx:alpine\n    port:         80/tcp\n    host port:    0/tcp\n    environment:  <none>\n    mounts:       <none>\n  volumes:        <none>\nconditions:\n  type           status  reason\n  ----           ------  ------\n  progressing    true    newreplicasetavailable\n  available      true    minimumreplicasavailable\noldreplicasets:  <none>\nnewreplicaset:   ngx-dep-69b9455bcf (2/2 replicas created)\nevents:\n  type    reason             age   from                   message\n  ----    ------             ----  ----                   -------\n  normal  scalingreplicaset  13m   deployment-controller  scaled up replica set ngx-dep-69b9455bcf to 2\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 水平扩缩容\n\n水平扩缩容是可以动态的改变pod的数量，在高峰期可以扩大应用的数量提高并发，在低峰期缩减pod减少资源的使用。\n\n我们使用kubectl scale动态改变deployment的副本数，查看deployment对象可以看到ready从2/4到4/4，并且avaliable的值也是逐渐的从2到4\n\n[root@k8s-worker1 zwf]# kubectl scale deploy ngx-dep -n zwf --replicas=4\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nname      ready   up-to-date   available   age\nngx-dep   2/4     4            2           18m\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nname      ready   up-to-date   available   age\nngx-dep   3/4     4            3           18m\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nname      ready   up-to-date   available   age\nngx-dep   4/4     4            4           18m\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n我们再看看replicaset对象，可以看到当前正在运行pod数量也发生了改变。因为水平扩缩容的实质是deplotment去修改replicaset的pod副本的数量。\n\n[root@k8s-worker1 zwf]# kubectl get replicaset  -n zwf\nname                 desired   current   ready   age\nngx-dep-69b9455bcf   4         4         4       50m\n\n\n1\n2\n3\n\n\n\n\n\n# 滚动更新\n\n在更新的过程，是逐渐将旧的replicaset所管理的pod删除，新的replicaset管理的pod新增这么一个过程。\n\n我们修改deployment的yaml文件，将containers的name修改为nginx2\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n  \nspec:\n  replicas: 2\n  selector:\n    matchlabels:\n      app: ngx-dep\n      \n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: nginx:alpine\n        name: nginx2   # 修改\n        ports:\n        - containerport: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再使用kubectl apply执行，更新deployment，可以看到，up-to-date是逐渐的从1到2，旧的pod会逐渐的更新成最新的pod.\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments.yaml -n zwf\ndeployment.apps/ngx-dep configured\n\n[root@k8s-worker1 zwf]# kubectl get deploy -n zwf\nname      ready   up-to-date   available   age\nngx-dep   2/2     1            2           55m\n\n[root@k8s-worker1 zwf]# kubectl get deploy -n zwf\nname      ready   up-to-date   available   age\nngx-dep   2/2     2            2           55m\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n我们再看下replicaset对象，可以看到有两个对象。这是因为我们更新了deployment中的pod template模板，也就是会更新pod，我们知道deployment是通过replicaset来管理对象的，所以会创建一个新版本的replicaset对象用来创建新版本的pod并逐渐增加，然后逐渐将旧版本的replicaset对象管理的pod删除直至为0。\n\n[root@k8s-worker1 zwf]# kubectl get rs -n zwf\nname                 desired   current   ready   age\nngx-dep-54d65f4d8c   2         2         2       2m54s\nngx-dep-69b9455bcf   0         0         0       58m\n\n\n1\n2\n3\n4\n\n\n我们再看deployment的详情，events字段是代表着deployment中发生的事件，可以看到ngx-dep-69b9455bcf所管理的pod逐渐减少，而ngx-dep-69b9455bcf在逐渐增加pod的数量。这也就解释了上面为什么有两个replicaset对象，因为一个是新对象，一个是旧对象，在更新deployment时，都会保留下来。\n\n[root@k8s-worker1 zwf]# kubectl describe deploy ngx-dep -n zwf\nname:                   ngx-dep\nnamespace:              zwf\ncreationtimestamp:      tue, 30 aug 2022 11:27:14 +0800\nlabels:                 app=ngx-dep\nannotations:            deployment.kubernetes.io/revision: 2\nselector:               app=ngx-dep\nreplicas:               2 desired | 2 updated | 2 total | 2 available | 0 unavailable\nstrategytype:           rollingupdate\nminreadyseconds:        0\nrollingupdatestrategy:  25% max unavailable, 25% max surge\npod template:\n  labels:  app=ngx-dep\n  containers:\n   nginx2:\n    image:        mirrors.sangfor.com/nginx:alpine\n    port:         80/tcp\n    host port:    0/tcp\n    environment:  <none>\n    mounts:       <none>\n  volumes:        <none>\nconditions:\n  type           status  reason\n  ----           ------  ------\n  available      true    minimumreplicasavailable\n  progressing    true    newreplicasetavailable\noldreplicasets:  <none>\nnewreplicaset:   ngx-dep-54d65f4d8c (2/2 replicas created)\nevents:\n  type    reason             age                  from                   message\n  ----    ------             ----                 ----                   -------\n  normal  scalingreplicaset  5m                   deployment-controller  scaled up replica set ngx-dep-54d65f4d8c to 1\n  normal  scalingreplicaset  4m58s                deployment-controller  scaled down replica set ngx-dep-69b9455bcf to 1\n  normal  scalingreplicaset  4m58s                deployment-controller  scaled up replica set ngx-dep-54d65f4d8c to 2\n  normal  scalingreplicaset  4m54s                deployment-controller  scaled down replica set ngx-dep-69b9455bcf to 0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"docker容器单机网络",frontmatter:{title:"docker容器单机网络",date:"2023-01-08T10:52:41.000Z",permalink:"/pages/0ddeb7/",tags:["docker","云原生","容器"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文主要讲述docker容器的四种网络模式：host、bridge、container、null，并介绍它们的使用方法及实现原理。",feed:{enable:!0},categories:["云原生","docker"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16731831018681673183100953.png"},{name:"twitter:title",content:"docker容器单机网络"},{name:"twitter:description",content:"本文主要讲述docker容器的四种网络模式：host、bridge、container、null，并介绍它们的使用方法及实现原理。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16731831018681673183100953.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/04.docker%E5%AE%B9%E5%99%A8%E5%8D%95%E6%9C%BA%E7%BD%91%E7%BB%9C.html"},{property:"og:type",content:"article"},{property:"og:title",content:"docker容器单机网络"},{property:"og:description",content:"本文主要讲述docker容器的四种网络模式：host、bridge、container、null，并介绍它们的使用方法及实现原理。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16731831018681673183100953.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/04.docker%E5%AE%B9%E5%99%A8%E5%8D%95%E6%9C%BA%E7%BD%91%E7%BB%9C.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-01-08T10:52:41.000Z"},{property:"article:tag",content:"docker"},{property:"article:tag",content:"云原生"},{property:"article:tag",content:"容器"},{itemprop:"name",content:"docker容器单机网络"},{itemprop:"description",content:"本文主要讲述docker容器的四种网络模式：host、bridge、container、null，并介绍它们的使用方法及实现原理。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16731831018681673183100953.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/04.docker%E5%AE%B9%E5%99%A8%E5%8D%95%E6%9C%BA%E7%BD%91%E7%BB%9C.html",relativePath:"01.云原生/06.docker/04.docker容器单机网络.md",key:"v-6430d054",path:"/pages/0ddeb7/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"host",slug:"host",normalizedTitle:"host",charIndex:146},{level:2,title:"bridge",slug:"bridge",normalizedTitle:"bridge",charIndex:548},{level:3,title:"原理",slug:"原理",normalizedTitle:"原理",charIndex:138},{level:3,title:"验证",slug:"验证",normalizedTitle:"验证",charIndex:856},{level:3,title:"容器网络互通",slug:"容器网络互通",normalizedTitle:"容器网络互通",charIndex:3442},{level:3,title:"容器连接其他主机",slug:"容器连接其他主机",normalizedTitle:"容器连接其他主机",charIndex:5783},{level:2,title:"container",slug:"container",normalizedTitle:"container",charIndex:6181},{level:2,title:"none",slug:"none",normalizedTitle:"none",charIndex:7668}],headersStr:"前言 host bridge 原理 验证 容器网络互通 容器连接其他主机 container none",content:"# 前言\n\n通过文章 容器的本质可知，容器只是一个进程，而容器所能看到的网络栈，是隔离在自己的 Network Namespace 中。docker 容器单机网络支持四种网络模式，也都是基于 Network Namespace 实现的。本文主要是介绍这四种模式的使用方法及实现原理。\n\n\n# host\n\n使用该模式的容器和宿主机是在同一个 Network Namespace 中的，所以和宿主机用的是同一个网络栈，那么容器暴露的端口，也就是宿主机上端口。\n\n> 注意，使用该模式，需要关注端口冲突\n\n通过添加 --net=host 参数即可开启 host 模式\n\ndocker run -d --net=host nginx\n\n\n1\n\n\n因为和宿主机使用的是同一个网络栈，所以容器与宿主机是可以互相连通的，在宿主机上直接可以通过 127.0.0.1 访问到该容器的的端口。\n\ncurl 127.0.0.1\n\n\n1\n\n\n运行另一个容器进入其中执行 curl 127.0.0.1 可以看到一样可以访问到 nginx 暴露的 80 端口，因为都是使用宿主机网络栈。\n\n docker run -it --net=host curlimages/curl curl 127.0.0.1\n\n\n1\n\n\n\n# bridge\n\n\n# 原理\n\n该模式为桥接模式，创建容器时会创建属于自己的 Network Namepsace，该容器和宿主机使用的是不同的 Network Namespace，也就是说它们使用的是不同的网络栈。\n\nbridge 网络模型的实现原理可以参考文章 手动实现docker容器bridge网络模型\n\n宿主机创建了 docker0 作为虚拟网桥，其作用主要是作为交换机在二层网络，再将使用 bridge 模式创建的容器通过 veth pair 连接到 dcoker0 上，这样连接到 docker0 上的容器都可以互相网络通信。\n\n> veth pair 类似一个管道，数据包会从一端到另一端。\n\n\n\n\n# 验证\n\n默认运行容器时使用的就是 bridge 模式，docker 会自动为容器添加 veth pair 并配置好其 ip 地址，这里的 eth0 就是其中的一端，可以看到其 ip 地址为 172.17.0.2\n\n[root@localhost ~]# docker run -d --name nginx1 nginx\n\n[root@localhost ~]# docker exec -it nginx1 ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n20: eth0@if21: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\nveth pair 的另一端会接入到 docker0 上，在容器中执行以下命令可以看到 veth pair 另一端的序号\n\n[root@localhost ~]# docker exec nginx1 cat /sys/class/net/eth0/iflink\n21\n\n\n1\n2\n\n\n在宿主机上可以看到 21 序号上的 veth pair 的名称是 veth702ba20，也就是管道的另一端。\n\n[root@localhost ~]# ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: ens18: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether fe:fc:fe:af:4b:ea brd ff:ff:ff:ff:ff:ff\n    inet 10.61.74.37/23 brd 10.61.75.255 scope global noprefixroute ens18\n       valid_lft forever preferred_lft forever\n    inet6 fe80::1bdd:fe7:4a90:1a67/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:84:c1:3b:ea brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:84ff:fec1:3bea/64 scope link \n       valid_lft forever preferred_lft forever\n21: veth702ba20@if20: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default \n    link/ether 0a:21:51:0c:7e:db brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet6 fe80::821:51ff:fe0c:7edb/64 scope link \n       valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再查看 docker0 插入的设备可以发现 veth702ba20 是插入在 docker0 上的。\n\n[root@localhost ~]# brctl show\nbridge name     bridge id               STP enabled     interfaces\ndocker0         8000.024284c13bea       no              veth702ba20\n\n\n1\n2\n3\n\n\n\n# 容器网络互通\n\n再创建另一个容器 nginx2，查看其 ip 为 172.17.0.3，可以发现 nginx1 是可以 ping 通 nginx2 的该 ip 的。\n\n[root@localhost ~]# docker run -d --name nginx2 nginx\n[root@localhost ~]# docker exec nginx2 ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n54: eth0@if55: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n为什么可以互通呢？\n\n我们来看下 nginx1 的路由，当 ping nginx2 的 ip 时，会匹配到第二条路由，然后走 eth0 网卡，因为其是 veth pair 的一端，数据包会在另一端出现，另一端接入到了 docker0 上，最终数据包到达 docker0\n\n[root@localhost ~]# docker exec nginx1 ip r\ndefault via 172.17.0.1 dev eth0 \n172.17.0.0/16 dev eth0  proto kernel  scope link  src 172.17.0.2 \n\n\n1\n2\n3\n\n\n当通过 nginx1 ping nginx2 的 ip 时，我过监听 docker0 网卡看一下数据包：\n\n[root@localhost ~]# docker exec -it nginx1 ping 172.17.0.3 -c 3\n\n[root@localhost ~]# tcpdump -i docker0\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on docker0, link-type EN10MB (Ethernet), capture size 262144 bytes\n04:32:57.596814 ARP, Request who-has 172.17.0.3 tell 172.17.0.2, length 28\n04:32:57.596848 ARP, Reply 172.17.0.3 is-at 02:42:ac:11:00:03 (oui Unknown), length 28\n04:32:57.596853 IP 172.17.0.2 > 172.17.0.3: ICMP echo request, id 17, seq 1, length 64\n04:32:57.596896 IP 172.17.0.3 > 172.17.0.2: ICMP echo reply, id 17, seq 1, length 64\n04:32:58.596437 IP 172.17.0.2 > 172.17.0.3: ICMP echo request, id 17, seq 2, length 64\n04:32:58.596492 IP 172.17.0.3 > 172.17.0.2: ICMP echo reply, id 17, seq 2, length 64\n04:32:59.596444 IP 172.17.0.2 > 172.17.0.3: ICMP echo request, id 17, seq 3, length 64\n04:32:59.596491 IP 172.17.0.3 > 172.17.0.2: ICMP echo reply, id 17, seq 3, length 64\n04:33:02.598361 ARP, Request who-has 172.17.0.2 tell 172.17.0.3, length 28\n04:33:02.598386 ARP, Reply 172.17.0.2 is-at 02:42:ac:11:00:02 (oui Unknown), length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n由上可知，nginx1(10.17.0.2) 会发送 ARP 获取 nginx2(10.17.0.3) 的 mac 地址，然后使用该 mac 地址通过二层设备 bridge 向 nginx2 转发数据包，进入到了 nginx2 的 Network Namespace 中，由它的网络栈处理该数据包，最后回包。\n\n\n\n\n# 容器连接其他主机\n\n容器内连接其他主机时，比如 ping 10.65.132.187 时，会先通过 docker0 达到宿主机上，然后通过宿主机的网络栈处理。\n\n通过查看宿主机路由表，到达宿主机的数据表会走第一条默认路由，通过 eth0 网卡下一跳到 10.61.74.1，然后最终达到另一台主机的 eth0 中。\n\n[root@localhost ~]# ip r\ndefault via 10.61.74.1 dev eth0 proto static metric 100 \n10.61.74.0/23 dev eth0 proto kernel scope link src 10.61.74.37 metric 100 \n172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1\n\n\n1\n2\n3\n4\n\n\n\n\n\n# container\n\n使用该模式的容器会加入到指定容器的 Network Namespace 中，也就是两个容器共用同一个网络栈。\n\n首先使用 bridge 模式创建容器 nginx1，该容器会拥有自己的 Network Namespace，然后再使用 container 模式创建 nginx2 容器并加入 nginx1 的 Network Namespace 中。\n\n通过查看两个容器的网卡可以发现两个是一样的。\n\n[root@localhost ~]# docker run -d --name nginx1 nginx\n[root@localhost ~]# docker exec -it nginx1 ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n56: eth0@if57: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n[root@localhost ~]# docker run -it --name nginx2 --net=container:nginx1 nginx /bin/bash\n\n[ root@20069e4c2bde:/etc/nginx ]$ ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n56: eth0@if57: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n\n\n\n# none\n\n该模式创建容器也会创建新的属于自己的 Network Namespace，但是容器内不会有任何的网络配置，没有网卡、路由、路由等信息，需要由我们自己去配置。\n\n[root@localhost ~]# docker run -it --name nginx --net=none nginx /bin/bash\n\n[ root@52480b0a4725:/etc/nginx ]$ ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n[ root@52480b0a4725:/etc/nginx ]$ ip r\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n",normalizedContent:"# 前言\n\n通过文章 容器的本质可知，容器只是一个进程，而容器所能看到的网络栈，是隔离在自己的 network namespace 中。docker 容器单机网络支持四种网络模式，也都是基于 network namespace 实现的。本文主要是介绍这四种模式的使用方法及实现原理。\n\n\n# host\n\n使用该模式的容器和宿主机是在同一个 network namespace 中的，所以和宿主机用的是同一个网络栈，那么容器暴露的端口，也就是宿主机上端口。\n\n> 注意，使用该模式，需要关注端口冲突\n\n通过添加 --net=host 参数即可开启 host 模式\n\ndocker run -d --net=host nginx\n\n\n1\n\n\n因为和宿主机使用的是同一个网络栈，所以容器与宿主机是可以互相连通的，在宿主机上直接可以通过 127.0.0.1 访问到该容器的的端口。\n\ncurl 127.0.0.1\n\n\n1\n\n\n运行另一个容器进入其中执行 curl 127.0.0.1 可以看到一样可以访问到 nginx 暴露的 80 端口，因为都是使用宿主机网络栈。\n\n docker run -it --net=host curlimages/curl curl 127.0.0.1\n\n\n1\n\n\n\n# bridge\n\n\n# 原理\n\n该模式为桥接模式，创建容器时会创建属于自己的 network namepsace，该容器和宿主机使用的是不同的 network namespace，也就是说它们使用的是不同的网络栈。\n\nbridge 网络模型的实现原理可以参考文章 手动实现docker容器bridge网络模型\n\n宿主机创建了 docker0 作为虚拟网桥，其作用主要是作为交换机在二层网络，再将使用 bridge 模式创建的容器通过 veth pair 连接到 dcoker0 上，这样连接到 docker0 上的容器都可以互相网络通信。\n\n> veth pair 类似一个管道，数据包会从一端到另一端。\n\n\n\n\n# 验证\n\n默认运行容器时使用的就是 bridge 模式，docker 会自动为容器添加 veth pair 并配置好其 ip 地址，这里的 eth0 就是其中的一端，可以看到其 ip 地址为 172.17.0.2\n\n[root@localhost ~]# docker run -d --name nginx1 nginx\n\n[root@localhost ~]# docker exec -it nginx1 ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n20: eth0@if21: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up group default \n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\nveth pair 的另一端会接入到 docker0 上，在容器中执行以下命令可以看到 veth pair 另一端的序号\n\n[root@localhost ~]# docker exec nginx1 cat /sys/class/net/eth0/iflink\n21\n\n\n1\n2\n\n\n在宿主机上可以看到 21 序号上的 veth pair 的名称是 veth702ba20，也就是管道的另一端。\n\n[root@localhost ~]# ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: ens18: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state up group default qlen 1000\n    link/ether fe:fc:fe:af:4b:ea brd ff:ff:ff:ff:ff:ff\n    inet 10.61.74.37/23 brd 10.61.75.255 scope global noprefixroute ens18\n       valid_lft forever preferred_lft forever\n    inet6 fe80::1bdd:fe7:4a90:1a67/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: docker0: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up group default \n    link/ether 02:42:84:c1:3b:ea brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:84ff:fec1:3bea/64 scope link \n       valid_lft forever preferred_lft forever\n21: veth702ba20@if20: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue master docker0 state up group default \n    link/ether 0a:21:51:0c:7e:db brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet6 fe80::821:51ff:fe0c:7edb/64 scope link \n       valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再查看 docker0 插入的设备可以发现 veth702ba20 是插入在 docker0 上的。\n\n[root@localhost ~]# brctl show\nbridge name     bridge id               stp enabled     interfaces\ndocker0         8000.024284c13bea       no              veth702ba20\n\n\n1\n2\n3\n\n\n\n# 容器网络互通\n\n再创建另一个容器 nginx2，查看其 ip 为 172.17.0.3，可以发现 nginx1 是可以 ping 通 nginx2 的该 ip 的。\n\n[root@localhost ~]# docker run -d --name nginx2 nginx\n[root@localhost ~]# docker exec nginx2 ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n54: eth0@if55: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up group default \n    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n为什么可以互通呢？\n\n我们来看下 nginx1 的路由，当 ping nginx2 的 ip 时，会匹配到第二条路由，然后走 eth0 网卡，因为其是 veth pair 的一端，数据包会在另一端出现，另一端接入到了 docker0 上，最终数据包到达 docker0\n\n[root@localhost ~]# docker exec nginx1 ip r\ndefault via 172.17.0.1 dev eth0 \n172.17.0.0/16 dev eth0  proto kernel  scope link  src 172.17.0.2 \n\n\n1\n2\n3\n\n\n当通过 nginx1 ping nginx2 的 ip 时，我过监听 docker0 网卡看一下数据包：\n\n[root@localhost ~]# docker exec -it nginx1 ping 172.17.0.3 -c 3\n\n[root@localhost ~]# tcpdump -i docker0\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on docker0, link-type en10mb (ethernet), capture size 262144 bytes\n04:32:57.596814 arp, request who-has 172.17.0.3 tell 172.17.0.2, length 28\n04:32:57.596848 arp, reply 172.17.0.3 is-at 02:42:ac:11:00:03 (oui unknown), length 28\n04:32:57.596853 ip 172.17.0.2 > 172.17.0.3: icmp echo request, id 17, seq 1, length 64\n04:32:57.596896 ip 172.17.0.3 > 172.17.0.2: icmp echo reply, id 17, seq 1, length 64\n04:32:58.596437 ip 172.17.0.2 > 172.17.0.3: icmp echo request, id 17, seq 2, length 64\n04:32:58.596492 ip 172.17.0.3 > 172.17.0.2: icmp echo reply, id 17, seq 2, length 64\n04:32:59.596444 ip 172.17.0.2 > 172.17.0.3: icmp echo request, id 17, seq 3, length 64\n04:32:59.596491 ip 172.17.0.3 > 172.17.0.2: icmp echo reply, id 17, seq 3, length 64\n04:33:02.598361 arp, request who-has 172.17.0.2 tell 172.17.0.3, length 28\n04:33:02.598386 arp, reply 172.17.0.2 is-at 02:42:ac:11:00:02 (oui unknown), length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n由上可知，nginx1(10.17.0.2) 会发送 arp 获取 nginx2(10.17.0.3) 的 mac 地址，然后使用该 mac 地址通过二层设备 bridge 向 nginx2 转发数据包，进入到了 nginx2 的 network namespace 中，由它的网络栈处理该数据包，最后回包。\n\n\n\n\n# 容器连接其他主机\n\n容器内连接其他主机时，比如 ping 10.65.132.187 时，会先通过 docker0 达到宿主机上，然后通过宿主机的网络栈处理。\n\n通过查看宿主机路由表，到达宿主机的数据表会走第一条默认路由，通过 eth0 网卡下一跳到 10.61.74.1，然后最终达到另一台主机的 eth0 中。\n\n[root@localhost ~]# ip r\ndefault via 10.61.74.1 dev eth0 proto static metric 100 \n10.61.74.0/23 dev eth0 proto kernel scope link src 10.61.74.37 metric 100 \n172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1\n\n\n1\n2\n3\n4\n\n\n\n\n\n# container\n\n使用该模式的容器会加入到指定容器的 network namespace 中，也就是两个容器共用同一个网络栈。\n\n首先使用 bridge 模式创建容器 nginx1，该容器会拥有自己的 network namespace，然后再使用 container 模式创建 nginx2 容器并加入 nginx1 的 network namespace 中。\n\n通过查看两个容器的网卡可以发现两个是一样的。\n\n[root@localhost ~]# docker run -d --name nginx1 nginx\n[root@localhost ~]# docker exec -it nginx1 ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n56: eth0@if57: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up group default \n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n[root@localhost ~]# docker run -it --name nginx2 --net=container:nginx1 nginx /bin/bash\n\n[ root@20069e4c2bde:/etc/nginx ]$ ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n56: eth0@if57: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up group default \n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n\n\n\n# none\n\n该模式创建容器也会创建新的属于自己的 network namespace，但是容器内不会有任何的网络配置，没有网卡、路由、路由等信息，需要由我们自己去配置。\n\n[root@localhost ~]# docker run -it --name nginx --net=none nginx /bin/bash\n\n[ root@52480b0a4725:/etc/nginx ]$ ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n[ root@52480b0a4725:/etc/nginx ]$ ip r\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n",charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"k8s之Service",frontmatter:{tags:["k8s","容器","云原生"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},title:"k8s之Service",date:"2022-08-30T16:59:37.000Z",permalink:"/pages/1f860b/",description:"介绍k8s中的service资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220808185926.png"},{name:"twitter:title",content:"k8s之Service"},{name:"twitter:description",content:"介绍k8s中的service资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220808185926.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/05.k8s%E4%B9%8Bservice.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之Service"},{property:"og:description",content:"介绍k8s中的service资源对象，及其使用方法和案例"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220808185926.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/05.k8s%E4%B9%8Bservice.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-30T16:59:37.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之Service"},{itemprop:"description",content:"介绍k8s中的service资源对象，及其使用方法和案例"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220808185926.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/05.k8s%E4%B9%8Bservice.html",relativePath:"01.云原生/07.k8s/05.k8s之service.md",key:"v-341f9276",path:"/pages/1f860b/",headers:[{level:2,title:"什么是service？",slug:"什么是service",normalizedTitle:"什么是service？",charIndex:2},{level:2,title:"使用ClusterIP Service",slug:"使用clusterip-service",normalizedTitle:"使用clusterip service",charIndex:372},{level:2,title:"使用NodePort Service",slug:"使用nodeport-service",normalizedTitle:"使用nodeport service",charIndex:5163},{level:2,title:"如何实现的代理？",slug:"如何实现的代理",normalizedTitle:"如何实现的代理？",charIndex:6453}],headersStr:"什么是service？ 使用ClusterIP Service 使用NodePort Service 如何实现的代理？",content:"# 什么是service？\n\n将运行在一组 Pods 上的应用程序公开为网络服务的抽象方法。\n\n为什么需要service?\n\n 1. pod的数量、IP都是动态变化的，service可以给该集合的Pod一个固定的IP，无论pod的集合如何改变，都可以通过service的固定IP来访问到应用。\n\n 2. 可以给pod集合提供负载均衡的功能。\n\nService类型\n\n * LoadBalance，使用云提供商的负载均衡器向外部暴露服务。\n * ExternalName，将服务映射到指定的域名，这个域名可以集群内部也可以是外部的。\n * NodePort，提供的服务既可对外部服务通过NodeIp:NodePort访问，也可以对集群内部通过ClusterIp访问\n * ClusterIP，service提供的访问IP仅在集群内部可达\n\n\n# 使用ClusterIP Service\n\n我们定义service如下，其中selector是用来筛选需要代理的pod，targetPort是目标pod的端口，port是指该service的端口。\n\nkind: Service \napiVersion: v1 \nmetadata: \n  name: demoapp-svc \nspec: \n  selector: \n    app: demoapp \n  ports: \n  - name: http \n    protocol: TCP    \n    port: 80\n    targetPort: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n使用上面定义的yaml创建service对象，并可以看到SELECTOR的值是app=demoapp，我们需要创建带有该标签的pod，才能够进行代理。\n\n[root@k8s-worker1 zwf]# kubectl apply -f service.yaml -n zwf\nservice/demoapp-svc created\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf -o wide\nNAME          TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR\ndemoapp-svc   ClusterIP   10.0.0.74    <none>        80/TCP    18s   app=demoapp\n\n\n1\n2\n3\n4\n5\n6\n\n\n定义deployment，会创建带有app=demoapp的Pod\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: demoapp\n  name: demo-deploy\n\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: demoapp\n\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n      - image: mirrors.sangfor.com/ikubernetes/demoapp:v1.0\n        name: demoapp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n创建Deployment对象，并且可以看到创建了2个Pod\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments_service.yaml -n zwf\ndeployment.apps/demo-deploy created\n\n[root@k8s-worker1 zwf]# kubectl get deploy -o wide -n zwf\nNAME          READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES                                         SELECTOR\ndemo-deploy   2/2     2            2           2m37s   demoapp      mirrors.sangfor.com/ikubernetes/demoapp:v1.0   app=demoapp\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n查看pod的详情，可以看到Labels有一个app=demoapp的标签\n\n[root@k8s-worker1 zwf]# kubectl get pods -o wide -n zwf\nNAME                           READY   STATUS    RESTARTS   AGE   IP               NODE          NOMINATED NODE   READINESS GATES\ndemo-deploy-6c6d588789-h9gmd   1/1     Running   0          32s   10.222.126.1     k8s-worker2   <none>           <none>\ndemo-deploy-6c6d588789-nhzhl   1/1     Running   0          32s   10.222.194.104   k8s-worker1   <none>           <none>\n\n[root@k8s-worker1 zwf]# kubectl describe demo-deploy-6c6d588789-h9gmd -n zwf\nName:         demo-deploy-6c6d588789-h9gmd\nNamespace:    zwf\nPriority:     0\nNode:         k8s-worker2/10.64.2.153\nStart Time:   Tue, 30 Aug 2022 19:23:22 +0800\nLabels:       app=demoapp\n              pod-template-hash=6c6d588789\n\n....\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n通过查看service的详情，我们可以看到Endpoints的值是上面创建的两个Pod的IP。\n\n[root@k8s-worker1 zwf]# kubectl describe svc -n zwf\nName:              demoapp-svc\nNamespace:         zwf\nLabels:            <none>\nAnnotations:       <none>\nSelector:          app=demoapp\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.0.0.74\nIPs:               10.0.0.74\nPort:              http  80/TCP\nTargetPort:        80/TCP\nEndpoints:         10.222.126.1:80,10.222.194.104:80\nSession Affinity:  None\nEvents:            <none>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\nEndpoints也是一个资源对象，Service通过筛选标签到的Pod会添加到Endpints中保存\n\n[root@k8s-worker1 zwf]# kubectl get endpoints -n zwf\nNAME          ENDPOINTS                           AGE\ndemoapp-svc   10.222.126.1:80,10.222.194.104:80   15m\n\n\n1\n2\n3\n\n\n这个时候，我们访问service的80端口，会访问到轮询访问到这两个pod中，我们就可以通过访问service来访问pod集合。\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.141, ServerName: demo-deploy-6c6d588789-nhzhl, ServerIP: 10.222.194.104!\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.141, ServerName: demo-deploy-6c6d588789-h9gmd, ServerIP: 10.222.126.1!\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.141, ServerName: demo-deploy-6c6d588789-nhzhl, ServerIP: 10.222.194.104!\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.141, ServerName: demo-deploy-6c6d588789-h9gmd, ServerIP: 10.222.126.1!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n除了通过ClusterIP访问，在集群中也能通过域名进行访问，访问方式：<serviceName>.<namespace>.svc.cluster.local\n\n[root@k8s-worker1 zwf]# kubectl exec -it demo-deploy-6c6d588789-h9gmd -n zwf  -- nslookup demoapp-svc.zwf.svc.cluster.local\nServer:         10.0.0.2\nAddress:        10.0.0.2#53\n\nName:   demoapp-svc.zwf.svc.cluster.local\nAddress: 10.0.0.74\n\n[root@k8s-worker1 zwf]# kubectl exec -it demo-deploy-6c6d588789-h9gmd -n zwf  -- curl demoapp-svc.zwf.svc.cluster.local\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.153, ServerName: demo-deploy-6c6d588789-h9gmd, ServerIP: 10.222.126.1!\n\n[root@k8s-worker1 zwf]# kubectl exec -it demo-deploy-6c6d588789-h9gmd -n zwf  -- curl demoapp-svc.zwf.svc.cluster.local\niKubernetes demoapp v1.0 !! ClientIP: 10.222.126.1, ServerName: demo-deploy-6c6d588789-nhzhl, ServerIP: 10.222.194.104!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 使用NodePort Service\n\n定义NodePort Service如下，和ClusterIP Service比较，新增type: NodePort代表该Service的类型是NodePort，然后nodePort是节点的端口，在每一台Node上都会创建这么一个端口给集群外调用。\n\nkind: Service\napiVersion: v1\nmetadata:\n  name: demoapp-nodeport-svc\nspec:\n  selector:\n    app: demoapp\n  ports:\n  - name: http\n    protocol: TCP\n    port: 80\n    targetPort: 80\n    nodePort: 31999\n  type: NodePort\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n创建该Service，可以看到TYPE是NodePort，PORT是80:31999代表着将80端口映射到节点的31999端口\n\n[root@k8s-worker1 zwf]# kubectl apply -f service_nodeport.yaml -n zwf\nservice/demoapp-nodeport-svc created\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf -o wide\nNAME                   TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE   SELECTOR\ndemoapp-nodeport-svc   NodePort    10.0.0.144   <none>        80:31999/TCP   10s   app=demoapp\ndemoapp-svc            ClusterIP   10.0.0.74    <none>        80/TCP         47m   app=demoapp\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们可以在集群外通过节点的IP:31999端口一样可以访问Pod服务。\n\nC:\\Users\\User>curl 10.64.2.141:31999\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.141, ServerName: demo-deploy-6c6d588789-nhzhl, ServerIP: 10.222.194.104!\n\nC:\\Users\\User>curl 10.64.2.141:31999\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.141, ServerName: demo-deploy-6c6d588789-h9gmd, ServerIP: 10.222.126.1!\n\n\n1\n2\n3\n4\n5\n\n\n\n# 如何实现的代理？\n\n每个Node都会有一个kube-proxy进程，该进程会监控Service的创建与EndPoints列表的添加与删除，配置iptables规则，当客户端请求Service的ClusterIP和端口时，会根据规则轮询转发到后端的Pod中。\n\n",normalizedContent:"# 什么是service？\n\n将运行在一组 pods 上的应用程序公开为网络服务的抽象方法。\n\n为什么需要service?\n\n 1. pod的数量、ip都是动态变化的，service可以给该集合的pod一个固定的ip，无论pod的集合如何改变，都可以通过service的固定ip来访问到应用。\n\n 2. 可以给pod集合提供负载均衡的功能。\n\nservice类型\n\n * loadbalance，使用云提供商的负载均衡器向外部暴露服务。\n * externalname，将服务映射到指定的域名，这个域名可以集群内部也可以是外部的。\n * nodeport，提供的服务既可对外部服务通过nodeip:nodeport访问，也可以对集群内部通过clusterip访问\n * clusterip，service提供的访问ip仅在集群内部可达\n\n\n# 使用clusterip service\n\n我们定义service如下，其中selector是用来筛选需要代理的pod，targetport是目标pod的端口，port是指该service的端口。\n\nkind: service \napiversion: v1 \nmetadata: \n  name: demoapp-svc \nspec: \n  selector: \n    app: demoapp \n  ports: \n  - name: http \n    protocol: tcp    \n    port: 80\n    targetport: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n使用上面定义的yaml创建service对象，并可以看到selector的值是app=demoapp，我们需要创建带有该标签的pod，才能够进行代理。\n\n[root@k8s-worker1 zwf]# kubectl apply -f service.yaml -n zwf\nservice/demoapp-svc created\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf -o wide\nname          type        cluster-ip   external-ip   port(s)   age   selector\ndemoapp-svc   clusterip   10.0.0.74    <none>        80/tcp    18s   app=demoapp\n\n\n1\n2\n3\n4\n5\n6\n\n\n定义deployment，会创建带有app=demoapp的pod\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  labels:\n    app: demoapp\n  name: demo-deploy\n\nspec:\n  replicas: 2\n  selector:\n    matchlabels:\n      app: demoapp\n\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n      - image: mirrors.sangfor.com/ikubernetes/demoapp:v1.0\n        name: demoapp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n创建deployment对象，并且可以看到创建了2个pod\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments_service.yaml -n zwf\ndeployment.apps/demo-deploy created\n\n[root@k8s-worker1 zwf]# kubectl get deploy -o wide -n zwf\nname          ready   up-to-date   available   age     containers   images                                         selector\ndemo-deploy   2/2     2            2           2m37s   demoapp      mirrors.sangfor.com/ikubernetes/demoapp:v1.0   app=demoapp\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n查看pod的详情，可以看到labels有一个app=demoapp的标签\n\n[root@k8s-worker1 zwf]# kubectl get pods -o wide -n zwf\nname                           ready   status    restarts   age   ip               node          nominated node   readiness gates\ndemo-deploy-6c6d588789-h9gmd   1/1     running   0          32s   10.222.126.1     k8s-worker2   <none>           <none>\ndemo-deploy-6c6d588789-nhzhl   1/1     running   0          32s   10.222.194.104   k8s-worker1   <none>           <none>\n\n[root@k8s-worker1 zwf]# kubectl describe demo-deploy-6c6d588789-h9gmd -n zwf\nname:         demo-deploy-6c6d588789-h9gmd\nnamespace:    zwf\npriority:     0\nnode:         k8s-worker2/10.64.2.153\nstart time:   tue, 30 aug 2022 19:23:22 +0800\nlabels:       app=demoapp\n              pod-template-hash=6c6d588789\n\n....\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n通过查看service的详情，我们可以看到endpoints的值是上面创建的两个pod的ip。\n\n[root@k8s-worker1 zwf]# kubectl describe svc -n zwf\nname:              demoapp-svc\nnamespace:         zwf\nlabels:            <none>\nannotations:       <none>\nselector:          app=demoapp\ntype:              clusterip\nip family policy:  singlestack\nip families:       ipv4\nip:                10.0.0.74\nips:               10.0.0.74\nport:              http  80/tcp\ntargetport:        80/tcp\nendpoints:         10.222.126.1:80,10.222.194.104:80\nsession affinity:  none\nevents:            <none>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\nendpoints也是一个资源对象，service通过筛选标签到的pod会添加到endpints中保存\n\n[root@k8s-worker1 zwf]# kubectl get endpoints -n zwf\nname          endpoints                           age\ndemoapp-svc   10.222.126.1:80,10.222.194.104:80   15m\n\n\n1\n2\n3\n\n\n这个时候，我们访问service的80端口，会访问到轮询访问到这两个pod中，我们就可以通过访问service来访问pod集合。\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\nikubernetes demoapp v1.0 !! clientip: 10.64.2.141, servername: demo-deploy-6c6d588789-nhzhl, serverip: 10.222.194.104!\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\nikubernetes demoapp v1.0 !! clientip: 10.64.2.141, servername: demo-deploy-6c6d588789-h9gmd, serverip: 10.222.126.1!\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\nikubernetes demoapp v1.0 !! clientip: 10.64.2.141, servername: demo-deploy-6c6d588789-nhzhl, serverip: 10.222.194.104!\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\nikubernetes demoapp v1.0 !! clientip: 10.64.2.141, servername: demo-deploy-6c6d588789-h9gmd, serverip: 10.222.126.1!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n除了通过clusterip访问，在集群中也能通过域名进行访问，访问方式：<servicename>.<namespace>.svc.cluster.local\n\n[root@k8s-worker1 zwf]# kubectl exec -it demo-deploy-6c6d588789-h9gmd -n zwf  -- nslookup demoapp-svc.zwf.svc.cluster.local\nserver:         10.0.0.2\naddress:        10.0.0.2#53\n\nname:   demoapp-svc.zwf.svc.cluster.local\naddress: 10.0.0.74\n\n[root@k8s-worker1 zwf]# kubectl exec -it demo-deploy-6c6d588789-h9gmd -n zwf  -- curl demoapp-svc.zwf.svc.cluster.local\nikubernetes demoapp v1.0 !! clientip: 10.64.2.153, servername: demo-deploy-6c6d588789-h9gmd, serverip: 10.222.126.1!\n\n[root@k8s-worker1 zwf]# kubectl exec -it demo-deploy-6c6d588789-h9gmd -n zwf  -- curl demoapp-svc.zwf.svc.cluster.local\nikubernetes demoapp v1.0 !! clientip: 10.222.126.1, servername: demo-deploy-6c6d588789-nhzhl, serverip: 10.222.194.104!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 使用nodeport service\n\n定义nodeport service如下，和clusterip service比较，新增type: nodeport代表该service的类型是nodeport，然后nodeport是节点的端口，在每一台node上都会创建这么一个端口给集群外调用。\n\nkind: service\napiversion: v1\nmetadata:\n  name: demoapp-nodeport-svc\nspec:\n  selector:\n    app: demoapp\n  ports:\n  - name: http\n    protocol: tcp\n    port: 80\n    targetport: 80\n    nodeport: 31999\n  type: nodeport\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n创建该service，可以看到type是nodeport，port是80:31999代表着将80端口映射到节点的31999端口\n\n[root@k8s-worker1 zwf]# kubectl apply -f service_nodeport.yaml -n zwf\nservice/demoapp-nodeport-svc created\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf -o wide\nname                   type        cluster-ip   external-ip   port(s)        age   selector\ndemoapp-nodeport-svc   nodeport    10.0.0.144   <none>        80:31999/tcp   10s   app=demoapp\ndemoapp-svc            clusterip   10.0.0.74    <none>        80/tcp         47m   app=demoapp\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们可以在集群外通过节点的ip:31999端口一样可以访问pod服务。\n\nc:\\users\\user>curl 10.64.2.141:31999\nikubernetes demoapp v1.0 !! clientip: 10.64.2.141, servername: demo-deploy-6c6d588789-nhzhl, serverip: 10.222.194.104!\n\nc:\\users\\user>curl 10.64.2.141:31999\nikubernetes demoapp v1.0 !! clientip: 10.64.2.141, servername: demo-deploy-6c6d588789-h9gmd, serverip: 10.222.126.1!\n\n\n1\n2\n3\n4\n5\n\n\n\n# 如何实现的代理？\n\n每个node都会有一个kube-proxy进程，该进程会监控service的创建与endpoints列表的添加与删除，配置iptables规则，当客户端请求service的clusterip和端口时，会根据规则轮询转发到后端的pod中。\n\n",charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"k8s之ConfigMap和Secret",frontmatter:{tags:["k8s","容器","云原生"],title:"k8s之ConfigMap和Secret",date:"2022-08-30T21:16:09.000Z",permalink:"/pages/ff8188/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍k8s中的configmap和secret资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"twitter:title",content:"k8s之ConfigMap和Secret"},{name:"twitter:description",content:"介绍k8s中的configmap和secret资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/06.k8s%E4%B9%8BConfigMap%E5%92%8CSecret.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之ConfigMap和Secret"},{property:"og:description",content:"介绍k8s中的configmap和secret资源对象，及其使用方法和案例"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/06.k8s%E4%B9%8BConfigMap%E5%92%8CSecret.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-30T21:16:09.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之ConfigMap和Secret"},{itemprop:"description",content:"介绍k8s中的configmap和secret资源对象，及其使用方法和案例"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/06.k8s%E4%B9%8BConfigMap%E5%92%8CSecret.html",relativePath:"01.云原生/07.k8s/06.k8s之ConfigMap和Secret.md",key:"v-ba5a65c4",path:"/pages/ff8188/",headers:[{level:2,title:"ConfigMap",slug:"configmap",normalizedTitle:"configmap",charIndex:2},{level:3,title:"什么是ConfigMap?",slug:"什么是configmap",normalizedTitle:"什么是configmap?",charIndex:16},{level:3,title:"创建ConifgMap",slug:"创建conifgmap",normalizedTitle:"创建conifgmap",charIndex:54},{level:2,title:"Secret",slug:"secret",normalizedTitle:"secret",charIndex:526},{level:3,title:"什么是Secret?",slug:"什么是secret",normalizedTitle:"什么是secret?",charIndex:537},{level:3,title:"创建Secret",slug:"创建secret",normalizedTitle:"创建secret",charIndex:650},{level:2,title:"如何使用ConfigMap/Secret",slug:"如何使用configmap-secret",normalizedTitle:"如何使用configmap/secret",charIndex:2439},{level:3,title:"注入环境变量",slug:"注入环境变量",normalizedTitle:"注入环境变量",charIndex:2544},{level:3,title:"注入配置文件",slug:"注入配置文件",normalizedTitle:"注入配置文件",charIndex:4200}],headersStr:"ConfigMap 什么是ConfigMap? 创建ConifgMap Secret 什么是Secret? 创建Secret 如何使用ConfigMap/Secret 注入环境变量 注入配置文件",content:'# ConfigMap\n\n\n# 什么是ConfigMap?\n\n用来存储应用所需要的明文配置数据的。\n\n\n# 创建ConifgMap\n\n使用yaml定义ConfigMap对象，在data字段中定义配置数据。\n\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: info\n\ndata:\n  count: \'10\'\n  debug: \'on\'\n  path: \'/etc/systemd\'\n  greeting: |\n    say hello to kubernetes.\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n使用定义的yaml文件创建ConfigMap对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f config.yaml  -n zwf\nconfigmap/info created\n\n[root@k8s-worker1 zwf]# kubectl get cm -n zwf\nNAME               DATA   AGE\ninfo               4      9s\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# Secret\n\n\n# 什么是Secret?\n\n和ConfigMap基本相同，差异在于存储的是密文的配置数据。\n\n具体的体现在于，使用kubectl describe时，ConfigMap可以看到配置信息，而Secret是看不到具体内容的。\n\n\n# 创建Secret\n\n使用yaml描述文件创建Secret对象，其中的数据必须得是base64编码的密文，否则会创建失败。\n\napiVersion: v1\nkind: Secret\nmetadata:\n  name: user\n\ndata:\n  name: cm9vdA==  # root\n  pwd: MTIzNDU2   # 123456\n  db: bXlzcWw=    # mysql\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n使用上面的yaml文件创建Secret对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f secret.yaml -n zwf\nsecret/user created\n\n[root@k8s-worker1 zwf]# kubectl get secret -n zwf\nNAME                                 TYPE                                  DATA   AGE\nuser                                 Opaque                                3      9s\n\n\n1\n2\n3\n4\n5\n6\n\n\n通过查看Secret详情，会发现都是密文的，无法查看\n\n[root@k8s-worker1 zwf]# kubectl describe secret user -n zwf\nName:         user\nNamespace:    zwf\nLabels:       <none>\nAnnotations:  <none>\n\nType:  Opaque\n\nData\n====\ndb:    5 bytes\nname:  4 bytes\npwd:   6 bytes\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n但是还是可以通过自己通过base64解码来获取\n\n[root@k8s-worker1 zwf]# kubectl get secret user -n zwf -o json\n{\n    "apiVersion": "v1",\n    "data": {\n        "db": "bXlzcWw=",\n        "name": "cm9vdA==",\n        "pwd": "MTIzNDU2"\n    },\n    "kind": "Secret",\n    "metadata": {\n        "annotations": {\n            "kubectl.kubernetes.io/last-applied-configuration": "{\\"apiVersion\\":\\"v1\\",\\"data\\":{\\"db\\":\\"bXlzcWw=\\",\\"name\\":\\"cm9vdA==\\",\\"pwd\\":\\"MTIzNDU2\\"},\\"kind\\":\\"Secret\\",\\"metadata\\":{\\"annotations\\":{},\\"name\\":\\"user\\",\\"namespace\\":\\"zwf\\"}}\\n"\n        },\n        "creationTimestamp": "2022-08-31T01:43:30Z",\n        "name": "user",\n        "namespace": "zwf",\n        "resourceVersion": "17208325",\n        "uid": "c5082495-1b85-42ef-a202-596d65e2449c"\n    },\n    "type": "Opaque"\n}\n\n[root@k8s-worker1 zwf]#  kubectl get secret user -n zwf -o jsonpath="{.data.name}" | base64 --decode\nroot\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 如何使用ConfigMap/Secret\n\n使用的方式\n\n * 将配置以环境变量的方式注入到容器中，应用程序从环境变量中获取配置\n\n * 将配置以文件的方式放在容器的目录中，应用程序从文件中获取配置。\n\n\n# 注入环境变量\n\n定义Deployment的yaml文件，在containers下的env中使用configMapKeyRef来使用ConfigMap中的值作为环境变量。\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ngx-dep\n\n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: mirrors.sangfor.com/nginx:alpine\n        name: nginx2\n        ports:\n        - containerPort: 80\n        env:\n        - name: count\n          valueFrom:\n            configMapKeyRef:\n              name: info\n              key: count\n        - name: debug\n          valueFrom:\n            configMapKeyRef:\n              name: info\n              key: debug\n        - name: pwd\n          valueFrom:\n            secretKeyRef:\n              name: user\n              key: pwd\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n使用上面定义的yaml创建Deployment对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments_cm.yaml -n zwf\ndeployment.apps/ngx-dep created\n\n[root@k8s-worker1 zwf]# kubectl get deploy -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   2/2     2            2           1h\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME                       READY   STATUS    RESTARTS   AGE\nngx-dep-6c659bcc45-nnkgz   1/1     Running   0          8s\nngx-dep-6c659bcc45-rgfxx   1/1     Running   0          6s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n进入到容器中，可以查看到我们设置debug、count、pwd的值\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-6c659bcc45-nnkgz -n zwf -- /bin/sh\n/ # echo $debug\non\n/ # echo $count\n10\n/ # echo $pwd\n123456\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 注入配置文件\n\n编写描述Deployment文件，在sepc下定义两个volume，然后在containers下进行使用volumeMounts字段进行挂载。\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ngx-dep\n\n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: mirrors.sangfor.com/nginx:alpine\n        name: nginx2\n        ports:\n        - containerPort: 80\n      - volumeMounts：\n        - mountPath: /tmp/cm-items\n          name: cm-vol\n        - mountPath: /tmp/sec-items\n          name: sec-vol\n\n      volumes:\n      - name: cm-vol\n        configMap:\n          name: info\n\t  - name: sec-vol \n\t    secret: \n\t    secretName: user\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n创建该Deployment对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments_cm_file.yaml -n zwf\ndeployment.apps/ngx-dep configured\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME                       READY   STATUS    RESTARTS   AGE\nngx-dep-798f6f6c4f-cg6lv   1/1     Running   0          9s\nngx-dep-798f6f6c4f-s8wws   1/1     Running   0          6s\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们可以看到在容器内部在tmp目录下创建了cm-items和sec-items目录\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- ls /tmp/\ncm-items   sec-items\n\n\n1\n2\n\n\n再看到这两个目录下的文件，都是以ConfigMap和Secret中定义的key为文件名，value为文件中的内容\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- ls /tmp/cm-items\ncount     debug     greeting  path\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- cat /tmp/cm-items/debug\non\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- ls /tmp/sec-items\ndb    name  pwd\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- cat /tmp/sec-items/pwd\n123456\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n',normalizedContent:'# configmap\n\n\n# 什么是configmap?\n\n用来存储应用所需要的明文配置数据的。\n\n\n# 创建conifgmap\n\n使用yaml定义configmap对象，在data字段中定义配置数据。\n\napiversion: v1\nkind: configmap\nmetadata:\n  name: info\n\ndata:\n  count: \'10\'\n  debug: \'on\'\n  path: \'/etc/systemd\'\n  greeting: |\n    say hello to kubernetes.\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n使用定义的yaml文件创建configmap对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f config.yaml  -n zwf\nconfigmap/info created\n\n[root@k8s-worker1 zwf]# kubectl get cm -n zwf\nname               data   age\ninfo               4      9s\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# secret\n\n\n# 什么是secret?\n\n和configmap基本相同，差异在于存储的是密文的配置数据。\n\n具体的体现在于，使用kubectl describe时，configmap可以看到配置信息，而secret是看不到具体内容的。\n\n\n# 创建secret\n\n使用yaml描述文件创建secret对象，其中的数据必须得是base64编码的密文，否则会创建失败。\n\napiversion: v1\nkind: secret\nmetadata:\n  name: user\n\ndata:\n  name: cm9vda==  # root\n  pwd: mtizndu2   # 123456\n  db: bxlzcww=    # mysql\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n使用上面的yaml文件创建secret对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f secret.yaml -n zwf\nsecret/user created\n\n[root@k8s-worker1 zwf]# kubectl get secret -n zwf\nname                                 type                                  data   age\nuser                                 opaque                                3      9s\n\n\n1\n2\n3\n4\n5\n6\n\n\n通过查看secret详情，会发现都是密文的，无法查看\n\n[root@k8s-worker1 zwf]# kubectl describe secret user -n zwf\nname:         user\nnamespace:    zwf\nlabels:       <none>\nannotations:  <none>\n\ntype:  opaque\n\ndata\n====\ndb:    5 bytes\nname:  4 bytes\npwd:   6 bytes\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n但是还是可以通过自己通过base64解码来获取\n\n[root@k8s-worker1 zwf]# kubectl get secret user -n zwf -o json\n{\n    "apiversion": "v1",\n    "data": {\n        "db": "bxlzcww=",\n        "name": "cm9vda==",\n        "pwd": "mtizndu2"\n    },\n    "kind": "secret",\n    "metadata": {\n        "annotations": {\n            "kubectl.kubernetes.io/last-applied-configuration": "{\\"apiversion\\":\\"v1\\",\\"data\\":{\\"db\\":\\"bxlzcww=\\",\\"name\\":\\"cm9vda==\\",\\"pwd\\":\\"mtizndu2\\"},\\"kind\\":\\"secret\\",\\"metadata\\":{\\"annotations\\":{},\\"name\\":\\"user\\",\\"namespace\\":\\"zwf\\"}}\\n"\n        },\n        "creationtimestamp": "2022-08-31t01:43:30z",\n        "name": "user",\n        "namespace": "zwf",\n        "resourceversion": "17208325",\n        "uid": "c5082495-1b85-42ef-a202-596d65e2449c"\n    },\n    "type": "opaque"\n}\n\n[root@k8s-worker1 zwf]#  kubectl get secret user -n zwf -o jsonpath="{.data.name}" | base64 --decode\nroot\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 如何使用configmap/secret\n\n使用的方式\n\n * 将配置以环境变量的方式注入到容器中，应用程序从环境变量中获取配置\n\n * 将配置以文件的方式放在容器的目录中，应用程序从文件中获取配置。\n\n\n# 注入环境变量\n\n定义deployment的yaml文件，在containers下的env中使用configmapkeyref来使用configmap中的值作为环境变量。\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n\nspec:\n  replicas: 2\n  selector:\n    matchlabels:\n      app: ngx-dep\n\n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: mirrors.sangfor.com/nginx:alpine\n        name: nginx2\n        ports:\n        - containerport: 80\n        env:\n        - name: count\n          valuefrom:\n            configmapkeyref:\n              name: info\n              key: count\n        - name: debug\n          valuefrom:\n            configmapkeyref:\n              name: info\n              key: debug\n        - name: pwd\n          valuefrom:\n            secretkeyref:\n              name: user\n              key: pwd\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n使用上面定义的yaml创建deployment对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments_cm.yaml -n zwf\ndeployment.apps/ngx-dep created\n\n[root@k8s-worker1 zwf]# kubectl get deploy -n zwf\nname      ready   up-to-date   available   age\nngx-dep   2/2     2            2           1h\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname                       ready   status    restarts   age\nngx-dep-6c659bcc45-nnkgz   1/1     running   0          8s\nngx-dep-6c659bcc45-rgfxx   1/1     running   0          6s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n进入到容器中，可以查看到我们设置debug、count、pwd的值\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-6c659bcc45-nnkgz -n zwf -- /bin/sh\n/ # echo $debug\non\n/ # echo $count\n10\n/ # echo $pwd\n123456\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 注入配置文件\n\n编写描述deployment文件，在sepc下定义两个volume，然后在containers下进行使用volumemounts字段进行挂载。\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n\nspec:\n  replicas: 2\n  selector:\n    matchlabels:\n      app: ngx-dep\n\n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: mirrors.sangfor.com/nginx:alpine\n        name: nginx2\n        ports:\n        - containerport: 80\n      - volumemounts：\n        - mountpath: /tmp/cm-items\n          name: cm-vol\n        - mountpath: /tmp/sec-items\n          name: sec-vol\n\n      volumes:\n      - name: cm-vol\n        configmap:\n          name: info\n\t  - name: sec-vol \n\t    secret: \n\t    secretname: user\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n创建该deployment对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments_cm_file.yaml -n zwf\ndeployment.apps/ngx-dep configured\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname                       ready   status    restarts   age\nngx-dep-798f6f6c4f-cg6lv   1/1     running   0          9s\nngx-dep-798f6f6c4f-s8wws   1/1     running   0          6s\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们可以看到在容器内部在tmp目录下创建了cm-items和sec-items目录\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- ls /tmp/\ncm-items   sec-items\n\n\n1\n2\n\n\n再看到这两个目录下的文件，都是以configmap和secret中定义的key为文件名，value为文件中的内容\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- ls /tmp/cm-items\ncount     debug     greeting  path\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- cat /tmp/cm-items/debug\non\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- ls /tmp/sec-items\ndb    name  pwd\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- cat /tmp/sec-items/pwd\n123456\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"Go语言高性能编程",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"04.编程/02.go语言/01.go语言高性能编程",description:"go语言高性能编程"}},title:"Go语言高性能编程",date:"2025-06-14T23:31:00.000Z",permalink:"/go_performance/",sidebar:!1,article:!1,comment:!1,editLink:!1,feed:{enable:!0},author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"",meta:[{name:"twitter:title",content:"Go语言高性能编程"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/01.Go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go语言高性能编程"},{property:"og:description",content:""},{property:"og:url",content:"https://www.zhengwenfeng.com/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/01.Go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-14T23:31:00.000Z"},{itemprop:"name",content:"Go语言高性能编程"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/01.Go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B.html",relativePath:"00.目录页/01.Go语言高性能编程.md",key:"v-64f910e0",path:"/go_performance/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"k8s之Job和CronJob",frontmatter:{tags:["k8s","容器","云原生"],title:"k8s之Job和CronJob",date:"2022-08-31T10:34:54.000Z",permalink:"/pages/c96905/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍k8s中的job资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220721102314.png"},{name:"twitter:title",content:"k8s之Job和CronJob"},{name:"twitter:description",content:"介绍k8s中的job资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220721102314.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/07.k8s%E4%B9%8BJob%E5%92%8CCronJob.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之Job和CronJob"},{property:"og:description",content:"介绍k8s中的job资源对象，及其使用方法和案例"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220721102314.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/07.k8s%E4%B9%8BJob%E5%92%8CCronJob.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-31T10:34:54.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之Job和CronJob"},{itemprop:"description",content:"介绍k8s中的job资源对象，及其使用方法和案例"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220721102314.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/07.k8s%E4%B9%8BJob%E5%92%8CCronJob.html",relativePath:"01.云原生/07.k8s/07.k8s之Job和CronJob.md",key:"v-3ff5ce46",path:"/pages/c96905/",headers:[{level:2,title:"Job",slug:"job",normalizedTitle:"job",charIndex:2},{level:3,title:"什么是Job?",slug:"什么是job",normalizedTitle:"什么是job?",charIndex:10},{level:3,title:"使用Job",slug:"使用job",normalizedTitle:"使用job",charIndex:46},{level:2,title:"CronJob",slug:"cronjob",normalizedTitle:"cronjob",charIndex:1082},{level:3,title:"什么是ConJob？",slug:"什么是conjob",normalizedTitle:"什么是conjob？",charIndex:1094},{level:3,title:"使用CronJob",slug:"使用cronjob",normalizedTitle:"使用cronjob",charIndex:1121}],headersStr:"Job 什么是Job? 使用Job CronJob 什么是ConJob？ 使用CronJob",content:'# Job\n\n\n# 什么是Job?\n\n该对象是用来执行运行一段时间后会退出的任务。\n\n\n# 使用Job\n\n使用yaml描述Job对象，其中restartPolicy是重启策略，需要设定为OnFailure，代表着如果失败则重启，如果是正常执行完成退出，则不需要再次启动。默认的值是Always，会保持着该Pod总是运行的。\n\ntemplate下的Pod模板，Job通过该模板来创建Pod。\n\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: echo-job\n\nspec:\n  template:\n    spec:\n      restartPolicy: OnFailure\n      containers:\n      - image: busybox\n        name: echo-job\n        command: ["/bin/echo"]\n        args: ["hello", "world"]\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\n使用yaml文件创建Job，然后查看job的pod对象，会发现它的STATUS状态为Completed，因为该job正常完成结束退出了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f job.yaml -n zwf\njob.batch/echo-job created\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME                       READY   STATUS      RESTARTS   AGE\necho-job-45pmc             0/1     Completed   0          5s\n\n\n1\n2\n3\n4\n5\n6\n\n\n再来看下该Completed的log，会发现已经输出了hello world\n\n[root@k8s-worker1 zwf]# kubectl logs echo-job-45pmc  -n zwf\nhello world\n\n\n1\n2\n\n\nJob的参数\n\n * activeDeadlineSeconds，设置 Pod 运行的超时时间。\n\n * backoffLimit，设置 Pod 的失败重试次数。\n\n为什么不直接在Pod上实现，而要新创建对象Job?\n\n保持单一原则，将业务特性与容器管理分开。\n\n\n# CronJob\n\n\n# 什么是ConJob？\n\n该对象用于定时任务。\n\n\n# 使用CronJob\n\n使用Yaml描述CronJob对象，会发现该对象多了一个schedule字段，这个是用来描述定时任务周期的规则，jobTemplate是Job对象的模板，也就是在定时周期内不断创建Job对象来达到定时任务的目的，也是一种组合的方式。\n\n\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: echo-cj\n\nspec:\n  schedule: \'*/1 * * * *\'\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          restartPolicy: OnFailure\n          containers:\n          - image: busybox\n            name: echo-cj\n            imagePullPolicy: IfNotPresent\n            command: ["/bin/echo"]\n            args: ["hello", "world"]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n\n\n使用定义的Yaml创建CronJob\n\n[root@k8s-worker1 zwf]# kubectl apply -f cronjob.yaml -n zwf\ncronjob.batch/echo-cj created\n\n[root@k8s-worker1 zwf]# kubectl get cronjob -n zwf\nNAME      SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE\necho-cj   */1 * * * *   False     1        1s              2m24s\n\n\n1\n2\n3\n4\n5\n6\n\n\n等待3分钟后，创建了3个CronJob的Pod，并且通过AGE可以发现是每分钟创建一个。\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME                       READY   STATUS      RESTARTS   AGE\necho-cj-27698578-jtfxm     0/1     Completed   0          2m23s\necho-cj-27698579-cdzxg     0/1     Completed   0          83s\necho-cj-27698580-rfp72     0/1     Completed   0          23s\n\n1\n2\n3\n4\n',normalizedContent:'# job\n\n\n# 什么是job?\n\n该对象是用来执行运行一段时间后会退出的任务。\n\n\n# 使用job\n\n使用yaml描述job对象，其中restartpolicy是重启策略，需要设定为onfailure，代表着如果失败则重启，如果是正常执行完成退出，则不需要再次启动。默认的值是always，会保持着该pod总是运行的。\n\ntemplate下的pod模板，job通过该模板来创建pod。\n\napiversion: batch/v1\nkind: job\nmetadata:\n  name: echo-job\n\nspec:\n  template:\n    spec:\n      restartpolicy: onfailure\n      containers:\n      - image: busybox\n        name: echo-job\n        command: ["/bin/echo"]\n        args: ["hello", "world"]\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\n使用yaml文件创建job，然后查看job的pod对象，会发现它的status状态为completed，因为该job正常完成结束退出了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f job.yaml -n zwf\njob.batch/echo-job created\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname                       ready   status      restarts   age\necho-job-45pmc             0/1     completed   0          5s\n\n\n1\n2\n3\n4\n5\n6\n\n\n再来看下该completed的log，会发现已经输出了hello world\n\n[root@k8s-worker1 zwf]# kubectl logs echo-job-45pmc  -n zwf\nhello world\n\n\n1\n2\n\n\njob的参数\n\n * activedeadlineseconds，设置 pod 运行的超时时间。\n\n * backofflimit，设置 pod 的失败重试次数。\n\n为什么不直接在pod上实现，而要新创建对象job?\n\n保持单一原则，将业务特性与容器管理分开。\n\n\n# cronjob\n\n\n# 什么是conjob？\n\n该对象用于定时任务。\n\n\n# 使用cronjob\n\n使用yaml描述cronjob对象，会发现该对象多了一个schedule字段，这个是用来描述定时任务周期的规则，jobtemplate是job对象的模板，也就是在定时周期内不断创建job对象来达到定时任务的目的，也是一种组合的方式。\n\n\napiversion: batch/v1\nkind: cronjob\nmetadata:\n  name: echo-cj\n\nspec:\n  schedule: \'*/1 * * * *\'\n  jobtemplate:\n    spec:\n      template:\n        spec:\n          restartpolicy: onfailure\n          containers:\n          - image: busybox\n            name: echo-cj\n            imagepullpolicy: ifnotpresent\n            command: ["/bin/echo"]\n            args: ["hello", "world"]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n\n\n使用定义的yaml创建cronjob\n\n[root@k8s-worker1 zwf]# kubectl apply -f cronjob.yaml -n zwf\ncronjob.batch/echo-cj created\n\n[root@k8s-worker1 zwf]# kubectl get cronjob -n zwf\nname      schedule      suspend   active   last schedule   age\necho-cj   */1 * * * *   false     1        1s              2m24s\n\n\n1\n2\n3\n4\n5\n6\n\n\n等待3分钟后，创建了3个cronjob的pod，并且通过age可以发现是每分钟创建一个。\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname                       ready   status      restarts   age\necho-cj-27698578-jtfxm     0/1     completed   0          2m23s\necho-cj-27698579-cdzxg     0/1     completed   0          83s\necho-cj-27698580-rfp72     0/1     completed   0          23s\n\n1\n2\n3\n4\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"Bug 通缉令",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"02.Bug 通缉令",description:"排查 Bug 的破案报告。"}},title:"Bug 通缉令",date:"2025-09-14T10:59:00.000Z",permalink:"/bug_hunt/",sidebar:!1,article:!1,comment:!1,editLink:!1,feed:{enable:!0},author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"",meta:[{name:"twitter:title",content:"Bug 通缉令"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/02.Bug%20%E9%80%9A%E7%BC%89%E4%BB%A4.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Bug 通缉令"},{property:"og:description",content:""},{property:"og:url",content:"https://www.zhengwenfeng.com/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/02.Bug%20%E9%80%9A%E7%BC%89%E4%BB%A4.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-09-14T10:59:00.000Z"},{itemprop:"name",content:"Bug 通缉令"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/02.Bug%20%E9%80%9A%E7%BC%89%E4%BB%A4.html",relativePath:"00.目录页/02.Bug 通缉令.md",key:"v-470b5455",path:"/bug_hunt/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2025/09/14, 11:01:01",lastUpdatedTimestamp:1757818861e3},{title:"k8s之DaemonSet",frontmatter:{tags:["k8s","容器","云原生"],title:"k8s之DaemonSet",date:"2022-08-31T11:06:48.000Z",permalink:"/pages/92bee4/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍k8s中的daemonset资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"twitter:title",content:"k8s之DaemonSet"},{name:"twitter:description",content:"介绍k8s中的daemonset资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/08.k8s%E4%B9%8BDaemonSet.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之DaemonSet"},{property:"og:description",content:"介绍k8s中的daemonset资源对象，及其使用方法和案例"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/08.k8s%E4%B9%8BDaemonSet.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-31T11:06:48.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之DaemonSet"},{itemprop:"description",content:"介绍k8s中的daemonset资源对象，及其使用方法和案例"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/08.k8s%E4%B9%8BDaemonSet.html",relativePath:"01.云原生/07.k8s/08.k8s之DaemonSet.md",key:"v-411a2b26",path:"/pages/92bee4/",headers:[{level:2,title:"什么是DaemonSet？",slug:"什么是daemonset",normalizedTitle:"什么是daemonset？",charIndex:2},{level:2,title:"使用DaemonSet",slug:"使用daemonset",normalizedTitle:"使用daemonset",charIndex:153}],headersStr:"什么是DaemonSet？ 使用DaemonSet",content:"# 什么是DaemonSet？\n\n在K8s集群中的每一个Node中都会运行一个Pod的控制器。\n\n使用场景是？\n\n * 日志收集，每个节点运行一个Pod用于收集容器产生的日志\n * 监控管理，每个节点运行一个pod用于监控节点的状态\n * 网络应用，每个节点运行一个Pod用于将节点加入k8s网络\n\n\n# 使用DaemonSet\n\n使用yaml描述DaemonSet对象\n\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nginx-ds\n  labels:\n    k8s-app: nginx-ds\nspec:\n  selector:\n    matchLabels:\n      name: nginx-ds\n  template:\n    metadata:\n      labels:\n        name: nginx-ds\n    spec:\n      containers:\n      - name: nginx-ds\n        image: nginx\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n创建DaemonSet对象，会看到自动的每一个节点中都创建了一个pod。\n\n[root@k8s-worker1 zwf]# kubectl apply -f daemonset.yaml -n zwf\ndaemonset.apps/nginx-ds configured\n\n[root@k8s-worker1 zwf]# kubectl get nodes\nNAME          STATUS   ROLES    AGE    VERSION\nk8s-master    Ready    <none>   32d    v1.23.4\nk8s-worker1   Ready    <none>   152d   v1.23.4\nk8s-worker2   Ready    <none>   152d   v1.23.4\n\n[root@k8s-worker1 zwf]# kubectl get ds -n zwf\nNAME       DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE\nnginx-ds   3         3         3       3            3           <none>          4m2s\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf -o wide\nNAME             READY   STATUS    RESTARTS   AGE   IP               NODE          NOMINATED NODE   READINESS GATES\nnginx-ds-7w2kx   1/1     Running   0          81s   10.222.194.73    k8s-worker1   <none>           <none>\nnginx-ds-l5lmx   1/1     Running   0          46s   10.222.126.38    k8s-worker2   <none>           <none>\nnginx-ds-zdfgl   1/1     Running   0          82s   10.222.235.217   k8s-master    <none>           <none>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n",normalizedContent:"# 什么是daemonset？\n\n在k8s集群中的每一个node中都会运行一个pod的控制器。\n\n使用场景是？\n\n * 日志收集，每个节点运行一个pod用于收集容器产生的日志\n * 监控管理，每个节点运行一个pod用于监控节点的状态\n * 网络应用，每个节点运行一个pod用于将节点加入k8s网络\n\n\n# 使用daemonset\n\n使用yaml描述daemonset对象\n\napiversion: apps/v1\nkind: daemonset\nmetadata:\n  name: nginx-ds\n  labels:\n    k8s-app: nginx-ds\nspec:\n  selector:\n    matchlabels:\n      name: nginx-ds\n  template:\n    metadata:\n      labels:\n        name: nginx-ds\n    spec:\n      containers:\n      - name: nginx-ds\n        image: nginx\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n创建daemonset对象，会看到自动的每一个节点中都创建了一个pod。\n\n[root@k8s-worker1 zwf]# kubectl apply -f daemonset.yaml -n zwf\ndaemonset.apps/nginx-ds configured\n\n[root@k8s-worker1 zwf]# kubectl get nodes\nname          status   roles    age    version\nk8s-master    ready    <none>   32d    v1.23.4\nk8s-worker1   ready    <none>   152d   v1.23.4\nk8s-worker2   ready    <none>   152d   v1.23.4\n\n[root@k8s-worker1 zwf]# kubectl get ds -n zwf\nname       desired   current   ready   up-to-date   available   node selector   age\nnginx-ds   3         3         3       3            3           <none>          4m2s\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf -o wide\nname             ready   status    restarts   age   ip               node          nominated node   readiness gates\nnginx-ds-7w2kx   1/1     running   0          81s   10.222.194.73    k8s-worker1   <none>           <none>\nnginx-ds-l5lmx   1/1     running   0          46s   10.222.126.38    k8s-worker2   <none>           <none>\nnginx-ds-zdfgl   1/1     running   0          82s   10.222.235.217   k8s-master    <none>           <none>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n",charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"k8s之PV、PVC和StorageClass",frontmatter:{tags:["k8s","容器","云原生"],title:"k8s之PV、PVC和StorageClass",date:"2022-08-31T15:03:37.000Z",permalink:"/pages/095c75/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍k8s中的pv、pvc和storageclass资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220831163136.png"},{name:"twitter:title",content:"k8s之PV、PVC和StorageClass"},{name:"twitter:description",content:"介绍k8s中的pv、pvc和storageclass资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220831163136.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/09.k8s%E4%B9%8BPV%E3%80%81PVC%E5%92%8CStorageClass.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之PV、PVC和StorageClass"},{property:"og:description",content:"介绍k8s中的pv、pvc和storageclass资源对象，及其使用方法和案例"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220831163136.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/09.k8s%E4%B9%8BPV%E3%80%81PVC%E5%92%8CStorageClass.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-31T15:03:37.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之PV、PVC和StorageClass"},{itemprop:"description",content:"介绍k8s中的pv、pvc和storageclass资源对象，及其使用方法和案例"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220831163136.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/09.k8s%E4%B9%8BPV%E3%80%81PVC%E5%92%8CStorageClass.html",relativePath:"01.云原生/07.k8s/09.k8s之PV、PVC和StorageClass.md",key:"v-14bd5c2a",path:"/pages/095c75/",headers:[{level:2,title:"PV",slug:"pv",normalizedTitle:"pv",charIndex:2},{level:3,title:"什么是PV？",slug:"什么是pv",normalizedTitle:"什么是pv？",charIndex:9},{level:3,title:"创建PV",slug:"创建pv",normalizedTitle:"创建pv",charIndex:78},{level:2,title:"PVC",slug:"pvc",normalizedTitle:"pvc",charIndex:918},{level:3,title:"什么是PVC？",slug:"什么是pvc",normalizedTitle:"什么是pvc？",charIndex:926},{level:3,title:"创建PVC",slug:"创建pvc",normalizedTitle:"创建pvc",charIndex:1095},{level:2,title:"在Pod中申请PVC",slug:"在pod中申请pvc",normalizedTitle:"在pod中申请pvc",charIndex:1861},{level:2,title:"StorageClass",slug:"storageclass",normalizedTitle:"storageclass",charIndex:2832},{level:3,title:"通过StorageClass配置NFS Provisioner",slug:"通过storageclass配置nfs-provisioner",normalizedTitle:"通过storageclass配置nfs provisioner",charIndex:3020},{level:3,title:"使用NFS动态存储卷",slug:"使用nfs动态存储卷",normalizedTitle:"使用nfs动态存储卷",charIndex:4499}],headersStr:"PV 什么是PV？ 创建PV PVC 什么是PVC？ 创建PVC 在Pod中申请PVC StorageClass 通过StorageClass配置NFS Provisioner 使用NFS动态存储卷",content:'# PV\n\n\n# 什么是PV？\n\nPV 描述的，则是一个具体的 Volume 的属性，比如 Volume 的类型、挂载目录、远程存储服务器地址等。\n\n\n# 创建PV\n\n使用yaml来定义PV\n\n\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: nfs-1g-pv\n\nspec:\n  storageClassName: nfs\n  accessModes:\n    - ReadWriteMany\n  capacity:\n    storage: 1Gi\n\n  nfs:\n    path: /root/zwf/share\n    server: 10.64.2.153\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n参数说明：\n\n * storageClassName的值为nfs，使用了NFS网络文件系统作为存储卷，\n * accessModes的值为ReadWriteMany，支持多个节点同时读写该共享目录\n * storage的值为1Gi，分配了1G的存储空间\n\n使用yaml定义的描述文件来创建PV对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f pv.yaml -n zwf\npersistentvolume/nfs-1g-pv created\n[root@k8s-worker1 zwf]# kubectl get pv -n zwf\nNAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                           STORAGECLASS   REASON   AGE\nnfs-1g-pv   1Gi        RWX            Retain           Available                                   nfs                     12s\n\n\n1\n2\n3\n4\n5\n\n\n\n# PVC\n\n\n# 什么是PVC？\n\n提供给应用开发获取存储资源的对象，开发将pod与PVC进行绑定可以达到持久化的存储状态，而PVC会与相对应的PV相绑定，提供具体的存储空间。\n\nPV和PVC有什么区别？\n\n实际上类似于“接口”和“实现”的思想。开发者只要知道并会使用“接口”，即：PVC；而运维人员则负责给“接口”绑定具体的实现，即：PV。\n\n\n\n\n# 创建PVC\n\n有了pv之后，创建申请存储的PVC对象，yaml定义如下，定义的内容和PV基本相同，但是不包含NFS的存储细节。\n\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: nfs-static-pvc\n\nspec:\n  storageClassName: nfs\n  accessModes:\n    - ReadWriteMany\n\n  resources:\n    requests:\n      storage: 1Gi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n创建pvc对象，并且可以看到VOLUME的值是上面创建的pv对象，这样两者就进行绑定了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f pvc.yaml -n zwf\npersistentvolumeclaim/nfs-static-pvc created\n[root@k8s-worker1 zwf]# \n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nNAME             STATUS   VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE\nnfs-static-pvc   Bound    nfs-1g-pv   1Gi        RWX            nfs            9s\n\n\n1\n2\n3\n4\n5\n6\n\n\n我们再pvc文件中并没有填写pv的任何信息，它是如何知道该绑定那个pv对象的呢？这是因为pvc会根据自身需要的容量去找到对应的pv进行匹配绑定。\n\n\n# 在Pod中申请PVC\n\nPod的yaml定义如下，使用volumes定义了存储卷使用上面创建的pvc对象nfs-static-pvc，在containers中使用vlumeMounts在pod中挂载了/tmp目录在该存储卷中。\n\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nfs-static-pod\n\nspec:\n  volumes:\n  - name: nfs-pvc-vol\n    persistentVolumeClaim:\n      claimName: nfs-static-pvc\n\n  containers:\n    - name: nfs-pvc-test\n      image: nginx:alpine\n      ports:\n      - containerPort: 80\n\n      volumeMounts:\n        - name: nfs-pvc-vol\n          mountPath: /tmp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n创建pod后，我们进入pod中在/tmp写入数据\n\n[root@k8s-worker1 zwf]# kubectl apply -f pod_pvc.yaml -n zwf\npod/nfs-static-pod created\n\n[root@k8s-worker1 zwf]# kubectl exec -it nfs-static-pod -n zwf -- /bin/sh\n/ # cd /tmp\n/tmp # echo 222 > 2.txt\n\n\n1\n2\n3\n4\n5\n6\n\n\n在nfs服务器中的/root/zwf/share中，我们也可以看到上面写的数据\n\n[root@k8s-worker2 share]# pwd\n/root/zwf/share\n[root@k8s-worker2 share]# ls\n2.txt\n[root@k8s-worker2 share]# cat 2.txt\n222\n\n\n1\n2\n3\n4\n5\n6\n\n\nPod、PVC、PV 和 NFS 存储的关系可以用下图来形象地表示：\n\n\n\n\n# StorageClass\n\n上面的PV是需要管理员手动创建的，每一次的开发都需要根据需求逐个创建PV，并且还需要精确创建空间大小，导致工作量巨大。所以我们需要在开发中可以动态的创建PV。\n\nStoreageClass可以用来绑定Provisioner对象，而这个Provisioner就是一个能够自动管理存储、创建 PV 的应用，代替了原来系统管理员的手工劳动。\n\n\n\n\n# 通过StorageClass配置NFS Provisioner\n\nk8s中每一类的存储设备都有相应的Provisioner，这里我们使用的是NFS Provisioner(https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner)\n\n在 GitHub 的 deploy 目录里是部署它所需的 YAML 文件，一共有三个，分别是 rbac.yaml、class.yaml和 deployment.yaml。\n\n 1. 首先将rbac.yaml的namespace改成kube-system\n 2. 在修改deployment.yaml的namespace也改为kube-system，再修改其中的volumes 和 env 里的 IP 地址和共享目录名，与NFS服务器保持一致.\n\n\nspec:\n  template:\n    spec:\n      serviceAccountName: nfs-client-provisioner\n      containers:\n      ...\n          env:\n            - name: PROVISIONER_NAME\n              value: k8s-sigs.io/nfs-subdir-external-provisioner\n            - name: NFS_SERVER\n              value: 192.168.10.208        #改IP地址\n            - name: NFS_PATH\n              value: /tmp/nfs              #改共享目录名\n      volumes:\n        - name: nfs-client-root\n          nfs:\n            server: 192.168.10.208         #改IP地址\n            Path: /tmp/nfs                 #改共享目录名\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n再将k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2改成chronolaw/nfs-subdir-external-provisioner:v4.0.2\n\n 3. 最后创建NFS Provisioner\n\nkubectl apply -f rbac.yaml\nkubectl apply -f class.yaml\nkubectl apply -f deployment.yaml\n\n\n1\n2\n3\n\n\n查看kube-system的pod可以看到nfs的provisioner。\n\n[root@k8s-worker1 zwf]# kubectl get pods -n kube-system\nNAME                                      READY   STATUS    RESTARTS      AGE\nnfs-client-provisioner-57789d96b7-42q67   1/1     Running   0             22h\n\n\n1\n2\n3\n\n\n\n# 使用NFS动态存储卷\n\n创建StrogeClass对象，onDelete: "remain"代表着即使Pod被删除，也会保留分配的存储，之后再手动删除。\n\n\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: nfs-client\n\nprovisioner: k8s-sigs.io/nfs-subdir-external-provisioner \nparameters:\n  onDelete: "remain"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n创建StrageClass对象，并可以看到PROVISIONER已经绑定了我们上面创建的nfs-provisioner了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f pvc_dyn.yaml -n zwf\nstorageclass.storage.k8s.io/nfs-client-retained created\n\n[root@k8s-worker1 zwf]# kubectl get sc -n zwf\nNAME                  PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\nnfs-client   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           false                  21h\n\n\n1\n2\n3\n4\n5\n6\n\n\n定义PVC，配置storageClassName:nfs-client与上面的StrageClass对象相绑定。\n\n\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: nfs-dyn-10m-pvc\n\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteMany\n\n  resources:\n    requests:\n      storage: 10Mi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n创建PVC，然后你会发现STATUS的状态为Bound，已经自动的创建了PV，并且已经相互绑定。\n\n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nNAME              STATUS    VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE\nnfs-dyn-10m-pvc   Pending                                         nfs-client     25s\n\n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nNAME              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\nnfs-dyn-10m-pvc   Bound    pvc-292cfed3-bec8-4425-aeac-697e3740c76c   10Mi       RWX            nfs-client     9s\n\n[root@k8s-worker1 zwf]# kubectl get pv -n zwf\nNAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                           STORAGECLASS   REASON   AGE\npvc-292cfed3-bec8-4425-aeac-697e3740c76c   10Mi       RWX            Delete           Bound    zwf/nfs-dyn-10m-pvc             nfs-client              47s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n去NFS文件服务器的共享目录中查看，可以看到多出来了一个目录，目录名称为命名空间-pvc名称-pvc名称\n\n[root@k8s-worker2 share]# pwd\n/root/zwf/share\n[root@k8s-worker2 share]# ls\nzwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c\n\n\n1\n2\n3\n4\n\n\n定义Pod，挂载上面创建的PVC到容器的/tmp目录中\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nfs-dyn-pod\n\nspec:\n  volumes:\n  - name: nfs-dyn-10m-vol\n    persistentVolumeClaim:\n      claimName: nfs-dyn-10m-pvc\n\n  containers:\n    - name: nfs-dyn-test\n      image: nginx:alpine\n\n      volumeMounts:\n        - name: nfs-dyn-10m-vol\n          mountPath: /tmp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n创建Pod成功\n\n[root@k8s-worker1 zwf]# kubectl apply -f pod_strageclass.yaml -n zwf\npod/nfs-dyn-pod created\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME          READY   STATUS    RESTARTS   AGE\nnfs-dyn-pod   1/1     Running   0          10s\n\n\n1\n2\n3\n4\n5\n\n\n进入到挂载了pvc的pod，然后在/tmp目录下写一个文件\n\nkubectl exec -it nfs-dyn-pod -n zwf -- /bin/sh\n/ # cd /tmp\n/tmp # echo 111 > 3.txt\n\n\n1\n2\n3\n\n\n再到NFS服务器上的共享目录对应的pv目录下，能看到之前写的文件。\n\n[root@k8s-worker2 zwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c]# pwd\n/root/zwf/share/zwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c\n\n[root@k8s-worker2 zwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c]# cat 3.txt \n111\n\n\n1\n2\n3\n4\n5\n\n\n关系图如下：\n\n',normalizedContent:'# pv\n\n\n# 什么是pv？\n\npv 描述的，则是一个具体的 volume 的属性，比如 volume 的类型、挂载目录、远程存储服务器地址等。\n\n\n# 创建pv\n\n使用yaml来定义pv\n\n\napiversion: v1\nkind: persistentvolume\nmetadata:\n  name: nfs-1g-pv\n\nspec:\n  storageclassname: nfs\n  accessmodes:\n    - readwritemany\n  capacity:\n    storage: 1gi\n\n  nfs:\n    path: /root/zwf/share\n    server: 10.64.2.153\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n参数说明：\n\n * storageclassname的值为nfs，使用了nfs网络文件系统作为存储卷，\n * accessmodes的值为readwritemany，支持多个节点同时读写该共享目录\n * storage的值为1gi，分配了1g的存储空间\n\n使用yaml定义的描述文件来创建pv对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f pv.yaml -n zwf\npersistentvolume/nfs-1g-pv created\n[root@k8s-worker1 zwf]# kubectl get pv -n zwf\nname        capacity   access modes   reclaim policy   status      claim                           storageclass   reason   age\nnfs-1g-pv   1gi        rwx            retain           available                                   nfs                     12s\n\n\n1\n2\n3\n4\n5\n\n\n\n# pvc\n\n\n# 什么是pvc？\n\n提供给应用开发获取存储资源的对象，开发将pod与pvc进行绑定可以达到持久化的存储状态，而pvc会与相对应的pv相绑定，提供具体的存储空间。\n\npv和pvc有什么区别？\n\n实际上类似于“接口”和“实现”的思想。开发者只要知道并会使用“接口”，即：pvc；而运维人员则负责给“接口”绑定具体的实现，即：pv。\n\n\n\n\n# 创建pvc\n\n有了pv之后，创建申请存储的pvc对象，yaml定义如下，定义的内容和pv基本相同，但是不包含nfs的存储细节。\n\napiversion: v1\nkind: persistentvolumeclaim\nmetadata:\n  name: nfs-static-pvc\n\nspec:\n  storageclassname: nfs\n  accessmodes:\n    - readwritemany\n\n  resources:\n    requests:\n      storage: 1gi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n创建pvc对象，并且可以看到volume的值是上面创建的pv对象，这样两者就进行绑定了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f pvc.yaml -n zwf\npersistentvolumeclaim/nfs-static-pvc created\n[root@k8s-worker1 zwf]# \n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nname             status   volume      capacity   access modes   storageclass   age\nnfs-static-pvc   bound    nfs-1g-pv   1gi        rwx            nfs            9s\n\n\n1\n2\n3\n4\n5\n6\n\n\n我们再pvc文件中并没有填写pv的任何信息，它是如何知道该绑定那个pv对象的呢？这是因为pvc会根据自身需要的容量去找到对应的pv进行匹配绑定。\n\n\n# 在pod中申请pvc\n\npod的yaml定义如下，使用volumes定义了存储卷使用上面创建的pvc对象nfs-static-pvc，在containers中使用vlumemounts在pod中挂载了/tmp目录在该存储卷中。\n\n\napiversion: v1\nkind: pod\nmetadata:\n  name: nfs-static-pod\n\nspec:\n  volumes:\n  - name: nfs-pvc-vol\n    persistentvolumeclaim:\n      claimname: nfs-static-pvc\n\n  containers:\n    - name: nfs-pvc-test\n      image: nginx:alpine\n      ports:\n      - containerport: 80\n\n      volumemounts:\n        - name: nfs-pvc-vol\n          mountpath: /tmp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n创建pod后，我们进入pod中在/tmp写入数据\n\n[root@k8s-worker1 zwf]# kubectl apply -f pod_pvc.yaml -n zwf\npod/nfs-static-pod created\n\n[root@k8s-worker1 zwf]# kubectl exec -it nfs-static-pod -n zwf -- /bin/sh\n/ # cd /tmp\n/tmp # echo 222 > 2.txt\n\n\n1\n2\n3\n4\n5\n6\n\n\n在nfs服务器中的/root/zwf/share中，我们也可以看到上面写的数据\n\n[root@k8s-worker2 share]# pwd\n/root/zwf/share\n[root@k8s-worker2 share]# ls\n2.txt\n[root@k8s-worker2 share]# cat 2.txt\n222\n\n\n1\n2\n3\n4\n5\n6\n\n\npod、pvc、pv 和 nfs 存储的关系可以用下图来形象地表示：\n\n\n\n\n# storageclass\n\n上面的pv是需要管理员手动创建的，每一次的开发都需要根据需求逐个创建pv，并且还需要精确创建空间大小，导致工作量巨大。所以我们需要在开发中可以动态的创建pv。\n\nstoreageclass可以用来绑定provisioner对象，而这个provisioner就是一个能够自动管理存储、创建 pv 的应用，代替了原来系统管理员的手工劳动。\n\n\n\n\n# 通过storageclass配置nfs provisioner\n\nk8s中每一类的存储设备都有相应的provisioner，这里我们使用的是nfs provisioner(https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner)\n\n在 github 的 deploy 目录里是部署它所需的 yaml 文件，一共有三个，分别是 rbac.yaml、class.yaml和 deployment.yaml。\n\n 1. 首先将rbac.yaml的namespace改成kube-system\n 2. 在修改deployment.yaml的namespace也改为kube-system，再修改其中的volumes 和 env 里的 ip 地址和共享目录名，与nfs服务器保持一致.\n\n\nspec:\n  template:\n    spec:\n      serviceaccountname: nfs-client-provisioner\n      containers:\n      ...\n          env:\n            - name: provisioner_name\n              value: k8s-sigs.io/nfs-subdir-external-provisioner\n            - name: nfs_server\n              value: 192.168.10.208        #改ip地址\n            - name: nfs_path\n              value: /tmp/nfs              #改共享目录名\n      volumes:\n        - name: nfs-client-root\n          nfs:\n            server: 192.168.10.208         #改ip地址\n            path: /tmp/nfs                 #改共享目录名\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n再将k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2改成chronolaw/nfs-subdir-external-provisioner:v4.0.2\n\n 3. 最后创建nfs provisioner\n\nkubectl apply -f rbac.yaml\nkubectl apply -f class.yaml\nkubectl apply -f deployment.yaml\n\n\n1\n2\n3\n\n\n查看kube-system的pod可以看到nfs的provisioner。\n\n[root@k8s-worker1 zwf]# kubectl get pods -n kube-system\nname                                      ready   status    restarts      age\nnfs-client-provisioner-57789d96b7-42q67   1/1     running   0             22h\n\n\n1\n2\n3\n\n\n\n# 使用nfs动态存储卷\n\n创建strogeclass对象，ondelete: "remain"代表着即使pod被删除，也会保留分配的存储，之后再手动删除。\n\n\napiversion: storage.k8s.io/v1\nkind: storageclass\nmetadata:\n  name: nfs-client\n\nprovisioner: k8s-sigs.io/nfs-subdir-external-provisioner \nparameters:\n  ondelete: "remain"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n创建strageclass对象，并可以看到provisioner已经绑定了我们上面创建的nfs-provisioner了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f pvc_dyn.yaml -n zwf\nstorageclass.storage.k8s.io/nfs-client-retained created\n\n[root@k8s-worker1 zwf]# kubectl get sc -n zwf\nname                  provisioner                                   reclaimpolicy   volumebindingmode   allowvolumeexpansion   age\nnfs-client   k8s-sigs.io/nfs-subdir-external-provisioner   delete          immediate           false                  21h\n\n\n1\n2\n3\n4\n5\n6\n\n\n定义pvc，配置storageclassname:nfs-client与上面的strageclass对象相绑定。\n\n\napiversion: v1\nkind: persistentvolumeclaim\nmetadata:\n  name: nfs-dyn-10m-pvc\n\nspec:\n  storageclassname: nfs-client\n  accessmodes:\n    - readwritemany\n\n  resources:\n    requests:\n      storage: 10mi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n创建pvc，然后你会发现status的状态为bound，已经自动的创建了pv，并且已经相互绑定。\n\n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nname              status    volume      capacity   access modes   storageclass   age\nnfs-dyn-10m-pvc   pending                                         nfs-client     25s\n\n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nname              status   volume                                     capacity   access modes   storageclass   age\nnfs-dyn-10m-pvc   bound    pvc-292cfed3-bec8-4425-aeac-697e3740c76c   10mi       rwx            nfs-client     9s\n\n[root@k8s-worker1 zwf]# kubectl get pv -n zwf\nname                                       capacity   access modes   reclaim policy   status   claim                           storageclass   reason   age\npvc-292cfed3-bec8-4425-aeac-697e3740c76c   10mi       rwx            delete           bound    zwf/nfs-dyn-10m-pvc             nfs-client              47s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n去nfs文件服务器的共享目录中查看，可以看到多出来了一个目录，目录名称为命名空间-pvc名称-pvc名称\n\n[root@k8s-worker2 share]# pwd\n/root/zwf/share\n[root@k8s-worker2 share]# ls\nzwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c\n\n\n1\n2\n3\n4\n\n\n定义pod，挂载上面创建的pvc到容器的/tmp目录中\n\napiversion: v1\nkind: pod\nmetadata:\n  name: nfs-dyn-pod\n\nspec:\n  volumes:\n  - name: nfs-dyn-10m-vol\n    persistentvolumeclaim:\n      claimname: nfs-dyn-10m-pvc\n\n  containers:\n    - name: nfs-dyn-test\n      image: nginx:alpine\n\n      volumemounts:\n        - name: nfs-dyn-10m-vol\n          mountpath: /tmp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n创建pod成功\n\n[root@k8s-worker1 zwf]# kubectl apply -f pod_strageclass.yaml -n zwf\npod/nfs-dyn-pod created\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname          ready   status    restarts   age\nnfs-dyn-pod   1/1     running   0          10s\n\n\n1\n2\n3\n4\n5\n\n\n进入到挂载了pvc的pod，然后在/tmp目录下写一个文件\n\nkubectl exec -it nfs-dyn-pod -n zwf -- /bin/sh\n/ # cd /tmp\n/tmp # echo 111 > 3.txt\n\n\n1\n2\n3\n\n\n再到nfs服务器上的共享目录对应的pv目录下，能看到之前写的文件。\n\n[root@k8s-worker2 zwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c]# pwd\n/root/zwf/share/zwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c\n\n[root@k8s-worker2 zwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c]# cat 3.txt \n111\n\n\n1\n2\n3\n4\n5\n\n\n关系图如下：\n\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"使用kubeadm安装k8s",frontmatter:{tags:["k8s","容器","云原生"],title:"使用kubeadm安装k8s",date:"2022-09-13T20:14:37.000Z",permalink:"/pages/9e17c8/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍如何使用kubeadm来搭建一个小型的k8s集群",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"twitter:title",content:"使用kubeadm安装k8s"},{name:"twitter:description",content:"介绍如何使用kubeadm来搭建一个小型的k8s集群"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/11.%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85k8s.html"},{property:"og:type",content:"article"},{property:"og:title",content:"使用kubeadm安装k8s"},{property:"og:description",content:"介绍如何使用kubeadm来搭建一个小型的k8s集群"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/11.%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85k8s.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-09-13T20:14:37.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"使用kubeadm安装k8s"},{itemprop:"description",content:"介绍如何使用kubeadm来搭建一个小型的k8s集群"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/11.%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85k8s.html",relativePath:"01.云原生/07.k8s/11.使用kubeadm安装k8s.md",key:"v-0ee080d4",path:"/pages/9e17c8/",headers:[{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:2},{level:2,title:"安装配置",slug:"安装配置",normalizedTitle:"安装配置",charIndex:44},{level:2,title:"主节点执行",slug:"主节点执行",normalizedTitle:"主节点执行",charIndex:1557},{level:2,title:"子节点加入集群",slug:"子节点加入集群",normalizedTitle:"子节点加入集群",charIndex:2189},{level:2,title:"测试",slug:"测试",normalizedTitle:"测试",charIndex:2648},{level:2,title:"常见错误",slug:"常见错误",normalizedTitle:"常见错误",charIndex:4155}],headersStr:"相关链接 安装配置 主节点执行 子节点加入集群 测试 常见错误",content:'# 相关链接\n\nkubeadm安装官网\n\nkubeadm安装k8s完整教程 ‍\n\n\n# 安装配置\n\n以下操作是每个节点都要执行的步骤\n\n 1. 配置hosts\n\n将主节点与子节点分别配置hostname如下：\n\nhostnamectl set-hostname master  # 主节点\nhostnamectl set-hostname node1   # 子节点\nhostnamectl set-hostname node2   # 子节点\n\n\n1\n2\n3\n\n\n在/etc/hosts中添加本机hostname与ip的映射关系\n\n1.1.1.1 master\n1.1.1.2 node1\n1.1.1.3 node2\n\n\n1\n2\n3\n\n 2. 关闭防火墙\n\n需要将主节点与子节点都关闭防火墙\n\nsystemctl stop firewalld\n\n\n1\n\n 3. 配置yum源\n\n在安装kubeadm之前，都需要配置yum源，创建文件/etc/yum.repos.d/kubernetes.repo\n\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=0\n\n\n1\n2\n3\n4\n5\n\n 4. 将 SELinux 设置为 permissive 模式（相当于将其禁用）\n\nsudo setenforce 0\nsudo sed -i \'s/^SELINUX=enforcing$/SELINUX=permissive/\' /etc/selinux/config\n\n\n1\n2\n\n 5. 安装kubeadm、kubelet、kubectl\n\nsudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n\n1\n\n 6. 安装docker并开启\n\ncurl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun\nsystemctl enable --now docker\n\n\n1\n2\n\n 7. 开启kubelet\n\nsudo systemctl enable --now kubelet\n\n\n1\n\n 8. 手动配置containerd的配置\n\n自动生成的文件会使用k8s.gcr.io/pause:3.6镜像，国内无法下载，导致kubeadm初始化失败。\n\n生成 containerd 的配置文件\n\nmkdir -p /etc/containerd\ncontainerd config default > /etc/containerd/config.toml\n\n\n1\n2\n\n\n修改 SystemdCgroup 为 true\n\n# 编辑文件\nvi /etc/containerd/config.toml\n\n#更改SystemdCgroup值为true\nSystemdCgroup = true\n\n\n1\n2\n3\n4\n5\n\n\n修改 sandbox_image 值\n\n# 更改k8s.gcr.io/pause:3.6为registry.aliyuncs.com/google_containers/pause:3.7\nsandbox_image = "registry.aliyuncs.com/google_containers/pause:3.7"\n\n\n1\n2\n\n\n重启containerd\n\nsystemctl restart containerd\n\n\n1\n\n\n\n# 主节点执行\n\n 1. 使用kubedam init初始化\n\nkubeadm init --image-repository registry.aliyuncs.com/google_containers --v=5 --pod-network-cidr 10.244.0.0/16\n\n\n1\n\n 2. kubectl读取k8s授权认证文件\n\n将安全配置文件放在指定目录中，该文件时kubectl需要读取的授权文件，放在指定目录下，kubectl才能读取到并访问到k8s\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n\n1\n2\n3\n\n\n或者放在环境变量中，kubectl会读取该环境变量中的文件\n\nvim /etc/profile\nexport KUBECONFIG=/etc/kubernetes/admin.conf\nsource /etc/profile\n\n\n1\n2\n3\n\n 3. 创建网络flannel\n\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n\n\n1\n\n\n‍\n\n\n# 子节点加入集群\n\n 1. 使用kubeadm join加入集群\n\n先在主节点使用kubeadm token create --print-join-command来获取到子节点加入主节点的命令\n\n[root@master ~]# kubeadm token create --print-join-command\nkubeadm join 172.16.16.16:6443 --token vnu6yz.4zk8f7hdorb8fpl0 --discovery-token-ca-cert-hash sha256:ca4e1e3e2afe16f592c3623f17a6b0dc9cfebd4ec459755e02f4b8db779e21d4\n\n\n1\n2\n\n\n再在子节点上执行该命令，即可加入集群\n\n 2. 将主节点的config移动到子节点\n\n子节点也需要主节点的config文件，才能通过kubectl访问集群\n\nscp ~/.kube/config node1:~/.kube/config\n\n\n1\n\n\n\n# 测试\n\n在主节点创建deployment.yaml文件如下\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: demoapp\n  name: demo-deploy\n\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: demoapp\n\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n      - image: ikubernetes/demoapp:v1.0\n        name: demoapp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n创建控制器\n\n[root@master ~]# kubectl apply -f deployment.yaml \ndeployment.apps/demo-deploy created\n\n\n1\n2\n\n\n可以看到创建成功，并且所有的pod已经READY\n\n[root@master ~]# kubectl get deploy -n zwf\nNAME          READY   UP-TO-DATE   AVAILABLE   AGE\ndemo-deploy   10/10   10           10          3m15s\n\n\n1\n2\n3\n\n\n可以看到pod都已经创建成功。\n\n[root@master ~]# kubectl get pods -n zwf \nNAME                           READY   STATUS    RESTARTS   AGE\ndemo-deploy-55c5f88dcb-2nzbf   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-5kwc9   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-8jd9k   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-b7zjp   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-bs7tm   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-jrbzw   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-lsfff   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-mgqpq   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-wfzzb   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-wkbv2   1/1     Running   0          4m38s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 常见错误\n\n * kubeadm init 报错 ”unknown service runtime.v1alpha2.RuntimeService”\n\n解决：\n\nrm /etc/containerd/config.toml -f\nsystemctl restart containerd\n\n\n1\n2\n\n\n * 如果在kubeadm init中出现了失败，在解决问题后，需要执行kubeadm reset，否则会报错\n\n * Failed to create pod sandbox: rpc error: code = Unknown desc = failed to get sandbox image "k8s.gcr.io/pause:3.6": failed to pull image "k8s.gcr.io/pause:3.6": failed to pull and unpack image "k8s.gcr.io/pause:3.6": failed to resolve reference "k8s.gcr.io/pause:3.6": failed to do request: Head "https://k8s.gcr.io/v2/pause/manifests/3.6": dial tcp 74.125.23.82:443: connect: connection refused\n\n是因为拉不到k8s官方的k8s.gcr.io/pause:3.6镜像，使用主节点container配置可以解决。\n\n * kube-flannel报错：\n   \n   running-error-CrashLoopBackOff。node“k8s-master-1“podcidr not assigned\n\nhttps://blog.csdn.net/shm19990131/article/details/107115750/\n\nhttps://blog.csdn.net/anqixiang/article/details/107715591\n\n * plugin type="flannel" failed (add): failed to delegate add: failed to set bridge addr: "cni0" already has an IP address different from\n\n解决办法:\n\nsudo ifconfig cni0 down  \nsudo ip link delete cni0\n\n\n1\n2\n\n\n相关资料：\n\nhttps://blog.csdn.net/ibless/article/details/107899009',normalizedContent:'# 相关链接\n\nkubeadm安装官网\n\nkubeadm安装k8s完整教程 ‍\n\n\n# 安装配置\n\n以下操作是每个节点都要执行的步骤\n\n 1. 配置hosts\n\n将主节点与子节点分别配置hostname如下：\n\nhostnamectl set-hostname master  # 主节点\nhostnamectl set-hostname node1   # 子节点\nhostnamectl set-hostname node2   # 子节点\n\n\n1\n2\n3\n\n\n在/etc/hosts中添加本机hostname与ip的映射关系\n\n1.1.1.1 master\n1.1.1.2 node1\n1.1.1.3 node2\n\n\n1\n2\n3\n\n 2. 关闭防火墙\n\n需要将主节点与子节点都关闭防火墙\n\nsystemctl stop firewalld\n\n\n1\n\n 3. 配置yum源\n\n在安装kubeadm之前，都需要配置yum源，创建文件/etc/yum.repos.d/kubernetes.repo\n\n[kubernetes]\nname=kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=0\n\n\n1\n2\n3\n4\n5\n\n 4. 将 selinux 设置为 permissive 模式（相当于将其禁用）\n\nsudo setenforce 0\nsudo sed -i \'s/^selinux=enforcing$/selinux=permissive/\' /etc/selinux/config\n\n\n1\n2\n\n 5. 安装kubeadm、kubelet、kubectl\n\nsudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n\n1\n\n 6. 安装docker并开启\n\ncurl -fssl https://get.docker.com | bash -s docker --mirror aliyun\nsystemctl enable --now docker\n\n\n1\n2\n\n 7. 开启kubelet\n\nsudo systemctl enable --now kubelet\n\n\n1\n\n 8. 手动配置containerd的配置\n\n自动生成的文件会使用k8s.gcr.io/pause:3.6镜像，国内无法下载，导致kubeadm初始化失败。\n\n生成 containerd 的配置文件\n\nmkdir -p /etc/containerd\ncontainerd config default > /etc/containerd/config.toml\n\n\n1\n2\n\n\n修改 systemdcgroup 为 true\n\n# 编辑文件\nvi /etc/containerd/config.toml\n\n#更改systemdcgroup值为true\nsystemdcgroup = true\n\n\n1\n2\n3\n4\n5\n\n\n修改 sandbox_image 值\n\n# 更改k8s.gcr.io/pause:3.6为registry.aliyuncs.com/google_containers/pause:3.7\nsandbox_image = "registry.aliyuncs.com/google_containers/pause:3.7"\n\n\n1\n2\n\n\n重启containerd\n\nsystemctl restart containerd\n\n\n1\n\n\n\n# 主节点执行\n\n 1. 使用kubedam init初始化\n\nkubeadm init --image-repository registry.aliyuncs.com/google_containers --v=5 --pod-network-cidr 10.244.0.0/16\n\n\n1\n\n 2. kubectl读取k8s授权认证文件\n\n将安全配置文件放在指定目录中，该文件时kubectl需要读取的授权文件，放在指定目录下，kubectl才能读取到并访问到k8s\n\n  mkdir -p $home/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $home/.kube/config\n  sudo chown $(id -u):$(id -g) $home/.kube/config\n\n\n1\n2\n3\n\n\n或者放在环境变量中，kubectl会读取该环境变量中的文件\n\nvim /etc/profile\nexport kubeconfig=/etc/kubernetes/admin.conf\nsource /etc/profile\n\n\n1\n2\n3\n\n 3. 创建网络flannel\n\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/documentation/kube-flannel.yml\n\n\n1\n\n\n‍\n\n\n# 子节点加入集群\n\n 1. 使用kubeadm join加入集群\n\n先在主节点使用kubeadm token create --print-join-command来获取到子节点加入主节点的命令\n\n[root@master ~]# kubeadm token create --print-join-command\nkubeadm join 172.16.16.16:6443 --token vnu6yz.4zk8f7hdorb8fpl0 --discovery-token-ca-cert-hash sha256:ca4e1e3e2afe16f592c3623f17a6b0dc9cfebd4ec459755e02f4b8db779e21d4\n\n\n1\n2\n\n\n再在子节点上执行该命令，即可加入集群\n\n 2. 将主节点的config移动到子节点\n\n子节点也需要主节点的config文件，才能通过kubectl访问集群\n\nscp ~/.kube/config node1:~/.kube/config\n\n\n1\n\n\n\n# 测试\n\n在主节点创建deployment.yaml文件如下\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  labels:\n    app: demoapp\n  name: demo-deploy\n\nspec:\n  replicas: 10\n  selector:\n    matchlabels:\n      app: demoapp\n\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n      - image: ikubernetes/demoapp:v1.0\n        name: demoapp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n创建控制器\n\n[root@master ~]# kubectl apply -f deployment.yaml \ndeployment.apps/demo-deploy created\n\n\n1\n2\n\n\n可以看到创建成功，并且所有的pod已经ready\n\n[root@master ~]# kubectl get deploy -n zwf\nname          ready   up-to-date   available   age\ndemo-deploy   10/10   10           10          3m15s\n\n\n1\n2\n3\n\n\n可以看到pod都已经创建成功。\n\n[root@master ~]# kubectl get pods -n zwf \nname                           ready   status    restarts   age\ndemo-deploy-55c5f88dcb-2nzbf   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-5kwc9   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-8jd9k   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-b7zjp   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-bs7tm   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-jrbzw   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-lsfff   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-mgqpq   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-wfzzb   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-wkbv2   1/1     running   0          4m38s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 常见错误\n\n * kubeadm init 报错 ”unknown service runtime.v1alpha2.runtimeservice”\n\n解决：\n\nrm /etc/containerd/config.toml -f\nsystemctl restart containerd\n\n\n1\n2\n\n\n * 如果在kubeadm init中出现了失败，在解决问题后，需要执行kubeadm reset，否则会报错\n\n * failed to create pod sandbox: rpc error: code = unknown desc = failed to get sandbox image "k8s.gcr.io/pause:3.6": failed to pull image "k8s.gcr.io/pause:3.6": failed to pull and unpack image "k8s.gcr.io/pause:3.6": failed to resolve reference "k8s.gcr.io/pause:3.6": failed to do request: head "https://k8s.gcr.io/v2/pause/manifests/3.6": dial tcp 74.125.23.82:443: connect: connection refused\n\n是因为拉不到k8s官方的k8s.gcr.io/pause:3.6镜像，使用主节点container配置可以解决。\n\n * kube-flannel报错：\n   \n   running-error-crashloopbackoff。node“k8s-master-1“podcidr not assigned\n\nhttps://blog.csdn.net/shm19990131/article/details/107115750/\n\nhttps://blog.csdn.net/anqixiang/article/details/107715591\n\n * plugin type="flannel" failed (add): failed to delegate add: failed to set bridge addr: "cni0" already has an ip address different from\n\n解决办法:\n\nsudo ifconfig cni0 down  \nsudo ip link delete cni0\n\n\n1\n2\n\n\n相关资料：\n\nhttps://blog.csdn.net/ibless/article/details/107899009',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"k8s之StatefulSet",frontmatter:{tags:["k8s","容器","云原生"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},title:"k8s之StatefulSet",date:"2022-08-31T14:55:02.000Z",permalink:"/pages/d178a2/",description:"介绍k8s中的statefulset资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220831173844.png"},{name:"twitter:title",content:"k8s之StatefulSet"},{name:"twitter:description",content:"介绍k8s中的statefulset资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220831173844.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/10.k8s%E4%B9%8BStatefulSet.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之StatefulSet"},{property:"og:description",content:"介绍k8s中的statefulset资源对象，及其使用方法和案例"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220831173844.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/10.k8s%E4%B9%8BStatefulSet.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-31T14:55:02.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之StatefulSet"},{itemprop:"description",content:"介绍k8s中的statefulset资源对象，及其使用方法和案例"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220831173844.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/10.k8s%E4%B9%8BStatefulSet.html",relativePath:"01.云原生/07.k8s/10.k8s之StatefulSet.md",key:"v-9fc226e2",path:"/pages/d178a2/",headers:[{level:2,title:"什么是StatefulSet?",slug:"什么是statefulset",normalizedTitle:"什么是statefulset?",charIndex:2},{level:2,title:"使用StatefulSet",slug:"使用statefulset",normalizedTitle:"使用statefulset",charIndex:227},{level:3,title:"创建StatefulSet",slug:"创建statefulset",normalizedTitle:"创建statefulset",charIndex:245},{level:3,title:"Service配置",slug:"service配置",normalizedTitle:"service配置",charIndex:1436},{level:3,title:"持久化配置",slug:"持久化配置",normalizedTitle:"持久化配置",charIndex:4150}],headersStr:"什么是StatefulSet? 使用StatefulSet 创建StatefulSet Service配置 持久化配置",content:'# 什么是StatefulSet?\n\n是用来创建有状态应用，可以通过过某种方式记录这些状态，然后在 Pod 被重新创建时，能够为新 Pod 恢复这些状态。\n\n什么是有状态应用？\n\n首先是需要有数据的持久化，即使Pod被重启后，也能恢复，与重启前保持一致。然后是应用创建的所有pod有依赖关系，顺序的创建、需要运行在指定的宿主机上，并且都有对应的网络标志。\n\n应用场景？\n\n分布式应用，它的多个实例之间，往往有依赖关系，比如：主从关系、主备关系。\n\n\n# 使用StatefulSet\n\n\n# 创建StatefulSet\n\n创建yaml文件定义StatefulSet对象如下，与Deployment比较，多了一个serviceName字段，这个是用来指定StatefulSet所管理的pod是用域名访问是通过该service所设定的。\n\n\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: redis-sts\n\nspec:\n  serviceName: redis-svc\n  replicas: 2\n  selector:\n    matchLabels:\n      app: redis-sts\n\n  template:\n    metadata:\n      labels:\n        app: redis-sts\n    spec:\n      containers:\n      - image: redis\n        name: redis\n        ports:\n        - containerPort: 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n创建StatefulSet对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f statefulset.yaml  -n zwf\nstatefulset.apps/redis-sts created\n\n[root@k8s-worker1 zwf]# kubectl get sts -n zwf\nNAME        READY   AGE\nredis-sts   2/2     54s\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看创建的Pod会发现，命名不再是随机创建的名字，而是有了顺序号，从0开始，而k8s也会按照这个顺序一次创建。\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME          READY   STATUS    RESTARTS   AGE\nredis-sts-0   1/1     Running   0          61s\nredis-sts-1   1/1     Running   0          54s\n\n\n1\n2\n3\n4\n\n\n输出pod中的hostname发现与pod的名称也保持一致，也就是应用可以自行决定依赖关系，比如该例子中可以使用0号pod作为主实例，而1号pod作为从实例。\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-sts-0 -n zwf -- hostname\nredis-sts-0\n\n\n1\n2\n\n\n\n# Service配置\n\n定义匹配上面的创建StatefulSet对象所有管理的Service，也就是标签筛选需要和pod的标签保持一致，并且这里的metadata.name也要与StatefulSet中的serviceName一样。\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis-svc\n\nspec:\n  selector:\n    app: redis-sts\n\n  ports:\n  - port: 6379\n    protocol: TCP\n    targetPort: 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n创建Service对象，我们可以看到已经将StatefulSet所创建的pod加入到端点列表了，也就是可以稳定的通过Service来访问到Pod\n\n[root@k8s-worker1 zwf]# kubectl apply -f service_statefulset.yaml -n zwf\nkservice/redis-svc created\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf\nNAME                   TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE\nredis-svc              ClusterIP   10.0.0.246   <none>        6379/TCP       5s\n\n[root@k8s-worker1 zwf]# kubectl describe svc redis-svc -n zwf\nName:              redis-svc\nNamespace:         zwf\nLabels:            <none>\nAnnotations:       <none>\nSelector:          app=redis-sts\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.0.0.246\nIPs:               10.0.0.246\nPort:              <unset>  6379/TCP\nTargetPort:        6379/TCP\nEndpoints:         10.222.126.51:6379,10.222.194.84:6379\nSession Affinity:  None\nEvents:            <none>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n但是我们的Pod不是一般的的应用，是有状态的应用，需要有稳定的网络标识，所以会为每一个Pod也创建一个域名，格式是：<podName>.<serviceName>.<namesapce>.svc.cluster.local。\n\n我们进入pod中验证一下，通过ping redis-sts-1.redis-svc.zwf.svc.cluster.local发现是可以ping通的，虽然Pod的IP会变化，但是通过固定的域名就能访问到指定Pod了。\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-sts-0 -n zwf -- ping redis-sts-1.redis-svc.zwf.svc.cluster.local\nPING redis-sts-1.redis-svc.zwf.svc.cluster.local (10.222.126.51) 56(84) bytes of data.\n64 bytes from redis-sts-1.redis-svc.zwf.svc.cluster.local (10.222.126.51): icmp_seq=1 ttl=62 time=0.964 ms\n64 bytes from redis-sts-1.redis-svc.zwf.svc.cluster.local (10.222.126.51): icmp_seq=2 ttl=62 time=0.932 ms\n\n\n1\n2\n3\n4\n\n\n既然我们的pod有了稳定的网络标识，Service也就不需要再分配ClusterIP了，这个时候，只需要添加字段clusterIP: None，这样就不会再分配IP了，这样的Service称为Headless Service\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis-svc\n\nspec:\n  clusterIP: None\n  selector:\n    app: redis-sts\n\n  ports:\n  - port: 6379\n    protocol: TCP\n    targetPort: 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n创建Headless Service，可以看到CLUSTER-IP为None\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf\nNAME                   TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE\ndemoapp-nodeport-svc   NodePort    10.0.0.144   <none>        80:31999/TCP   21h\ndemoapp-svc            ClusterIP   10.0.0.74    <none>        80/TCP         22h\nredis-svc              ClusterIP   None         <none>        6379/TCP       4s\n\n\n1\n2\n3\n4\n5\n\n\nService和StatefulSet配置图如下：\n\n\n\n\n# 持久化配置\n\n接下来是给StatefulSet对象添加持久化配置。\n\n定义StatefulSet描述如下：\n\n\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: redis-pv-sts\n\nspec:\n  serviceName: redis-pv-svc\n\n  volumeClaimTemplates:\n  - metadata:\n      name: redis-100m-pvc\n    spec:\n      storageClassName: nfs-client\n      accessModes:\n        - ReadWriteMany\n      resources:\n        requests:\n          storage: 100Mi\n\n  replicas: 2\n  selector:\n    matchLabels:\n      app: redis-pv-sts\n\n  template:\n    metadata:\n      labels:\n        app: redis-pv-sts\n    spec:\n      containers:\n      - image: redis:5-alpine\n        name: redis\n\n        volumeMounts:\n        - name: redis-100m-pvc\n          mountPath: /data\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n\n\n参数：\n\n * volumeClaimTemplates，用来将PVC的定义嵌入到StatefulSet中的字段，是创建PVC的模板，可以让每一个Pod都能自动创建PVC\n * voulumeMounts，是用来选择上面的PVC挂载在容器的/data目录中\n\n创建StatefulSet对象，可以看到pod已经创建起来了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f statefulset_pvc.yaml -n zwf\nstatefulset.apps/redis-pv-sts created\n\n[root@k8s-worker1 zwf]# kubectl get sts -n zwf\nNAME           READY   AGE\nredis-pv-sts   2/2     25\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME             READY   STATUS    RESTARTS   AGE\nredis-pv-sts-0   1/1     Running   0          63s\nredis-pv-sts-1   1/1     Running   0          54s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n我们查看pvc，会发现创建了2个对象 ，以PVC名称-pod名称命名。\n\n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nNAME                            STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\nredis-100m-pvc-redis-pv-sts-0   Bound    pvc-2712daa4-36b4-4a63-ac2f-7d3b31e2a887   100Mi      RWX            nfs-client     109s\nredis-100m-pvc-redis-pv-sts-1   Bound    pvc-a3781354-e182-42f7-b6f6-983999603653   100Mi      RWX            nfs-client     100s\n\n\n1\n2\n3\n4\n\n\n进入到pod中，使用redis-cli运行redis客户端，添加一些数据\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-pv-sts-0 -n zwf /bin/bash\n[ root@redis-pv-sts-0:/data ]$ redis-cli  \n127.0.0.1:6379> set name zhangsan\nOK\n127.0.0.1:6379> set age 18\nOK\n127.0.0.1:6379> keys *\n1) "name"\n2) "age"\n127.0.0.1:6379> quit\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n将pod删除，然后再重新进入Pod中，查询之前创建的redis的key，还是能够查询到。\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-pv-sts-0  -n zwf -- /bin/bash\n[ root@redis-pv-sts-0:/data ]$ redis-cli  \n127.0.0.1:6379> keys *\n1) "name"\n2) "age"\n127.0.0.1:6379> get name\n"zhangsan"\n127.0.0.1:6379> get age\n"18"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n配置的关系图如下：\n\n',normalizedContent:'# 什么是statefulset?\n\n是用来创建有状态应用，可以通过过某种方式记录这些状态，然后在 pod 被重新创建时，能够为新 pod 恢复这些状态。\n\n什么是有状态应用？\n\n首先是需要有数据的持久化，即使pod被重启后，也能恢复，与重启前保持一致。然后是应用创建的所有pod有依赖关系，顺序的创建、需要运行在指定的宿主机上，并且都有对应的网络标志。\n\n应用场景？\n\n分布式应用，它的多个实例之间，往往有依赖关系，比如：主从关系、主备关系。\n\n\n# 使用statefulset\n\n\n# 创建statefulset\n\n创建yaml文件定义statefulset对象如下，与deployment比较，多了一个servicename字段，这个是用来指定statefulset所管理的pod是用域名访问是通过该service所设定的。\n\n\napiversion: apps/v1\nkind: statefulset\nmetadata:\n  name: redis-sts\n\nspec:\n  servicename: redis-svc\n  replicas: 2\n  selector:\n    matchlabels:\n      app: redis-sts\n\n  template:\n    metadata:\n      labels:\n        app: redis-sts\n    spec:\n      containers:\n      - image: redis\n        name: redis\n        ports:\n        - containerport: 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n创建statefulset对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f statefulset.yaml  -n zwf\nstatefulset.apps/redis-sts created\n\n[root@k8s-worker1 zwf]# kubectl get sts -n zwf\nname        ready   age\nredis-sts   2/2     54s\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看创建的pod会发现，命名不再是随机创建的名字，而是有了顺序号，从0开始，而k8s也会按照这个顺序一次创建。\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname          ready   status    restarts   age\nredis-sts-0   1/1     running   0          61s\nredis-sts-1   1/1     running   0          54s\n\n\n1\n2\n3\n4\n\n\n输出pod中的hostname发现与pod的名称也保持一致，也就是应用可以自行决定依赖关系，比如该例子中可以使用0号pod作为主实例，而1号pod作为从实例。\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-sts-0 -n zwf -- hostname\nredis-sts-0\n\n\n1\n2\n\n\n\n# service配置\n\n定义匹配上面的创建statefulset对象所有管理的service，也就是标签筛选需要和pod的标签保持一致，并且这里的metadata.name也要与statefulset中的servicename一样。\n\n\napiversion: v1\nkind: service\nmetadata:\n  name: redis-svc\n\nspec:\n  selector:\n    app: redis-sts\n\n  ports:\n  - port: 6379\n    protocol: tcp\n    targetport: 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n创建service对象，我们可以看到已经将statefulset所创建的pod加入到端点列表了，也就是可以稳定的通过service来访问到pod\n\n[root@k8s-worker1 zwf]# kubectl apply -f service_statefulset.yaml -n zwf\nkservice/redis-svc created\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf\nname                   type        cluster-ip   external-ip   port(s)        age\nredis-svc              clusterip   10.0.0.246   <none>        6379/tcp       5s\n\n[root@k8s-worker1 zwf]# kubectl describe svc redis-svc -n zwf\nname:              redis-svc\nnamespace:         zwf\nlabels:            <none>\nannotations:       <none>\nselector:          app=redis-sts\ntype:              clusterip\nip family policy:  singlestack\nip families:       ipv4\nip:                10.0.0.246\nips:               10.0.0.246\nport:              <unset>  6379/tcp\ntargetport:        6379/tcp\nendpoints:         10.222.126.51:6379,10.222.194.84:6379\nsession affinity:  none\nevents:            <none>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n但是我们的pod不是一般的的应用，是有状态的应用，需要有稳定的网络标识，所以会为每一个pod也创建一个域名，格式是：<podname>.<servicename>.<namesapce>.svc.cluster.local。\n\n我们进入pod中验证一下，通过ping redis-sts-1.redis-svc.zwf.svc.cluster.local发现是可以ping通的，虽然pod的ip会变化，但是通过固定的域名就能访问到指定pod了。\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-sts-0 -n zwf -- ping redis-sts-1.redis-svc.zwf.svc.cluster.local\nping redis-sts-1.redis-svc.zwf.svc.cluster.local (10.222.126.51) 56(84) bytes of data.\n64 bytes from redis-sts-1.redis-svc.zwf.svc.cluster.local (10.222.126.51): icmp_seq=1 ttl=62 time=0.964 ms\n64 bytes from redis-sts-1.redis-svc.zwf.svc.cluster.local (10.222.126.51): icmp_seq=2 ttl=62 time=0.932 ms\n\n\n1\n2\n3\n4\n\n\n既然我们的pod有了稳定的网络标识，service也就不需要再分配clusterip了，这个时候，只需要添加字段clusterip: none，这样就不会再分配ip了，这样的service称为headless service\n\n\napiversion: v1\nkind: service\nmetadata:\n  name: redis-svc\n\nspec:\n  clusterip: none\n  selector:\n    app: redis-sts\n\n  ports:\n  - port: 6379\n    protocol: tcp\n    targetport: 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n创建headless service，可以看到cluster-ip为none\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf\nname                   type        cluster-ip   external-ip   port(s)        age\ndemoapp-nodeport-svc   nodeport    10.0.0.144   <none>        80:31999/tcp   21h\ndemoapp-svc            clusterip   10.0.0.74    <none>        80/tcp         22h\nredis-svc              clusterip   none         <none>        6379/tcp       4s\n\n\n1\n2\n3\n4\n5\n\n\nservice和statefulset配置图如下：\n\n\n\n\n# 持久化配置\n\n接下来是给statefulset对象添加持久化配置。\n\n定义statefulset描述如下：\n\n\napiversion: apps/v1\nkind: statefulset\nmetadata:\n  name: redis-pv-sts\n\nspec:\n  servicename: redis-pv-svc\n\n  volumeclaimtemplates:\n  - metadata:\n      name: redis-100m-pvc\n    spec:\n      storageclassname: nfs-client\n      accessmodes:\n        - readwritemany\n      resources:\n        requests:\n          storage: 100mi\n\n  replicas: 2\n  selector:\n    matchlabels:\n      app: redis-pv-sts\n\n  template:\n    metadata:\n      labels:\n        app: redis-pv-sts\n    spec:\n      containers:\n      - image: redis:5-alpine\n        name: redis\n\n        volumemounts:\n        - name: redis-100m-pvc\n          mountpath: /data\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n\n\n参数：\n\n * volumeclaimtemplates，用来将pvc的定义嵌入到statefulset中的字段，是创建pvc的模板，可以让每一个pod都能自动创建pvc\n * voulumemounts，是用来选择上面的pvc挂载在容器的/data目录中\n\n创建statefulset对象，可以看到pod已经创建起来了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f statefulset_pvc.yaml -n zwf\nstatefulset.apps/redis-pv-sts created\n\n[root@k8s-worker1 zwf]# kubectl get sts -n zwf\nname           ready   age\nredis-pv-sts   2/2     25\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname             ready   status    restarts   age\nredis-pv-sts-0   1/1     running   0          63s\nredis-pv-sts-1   1/1     running   0          54s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n我们查看pvc，会发现创建了2个对象 ，以pvc名称-pod名称命名。\n\n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nname                            status   volume                                     capacity   access modes   storageclass   age\nredis-100m-pvc-redis-pv-sts-0   bound    pvc-2712daa4-36b4-4a63-ac2f-7d3b31e2a887   100mi      rwx            nfs-client     109s\nredis-100m-pvc-redis-pv-sts-1   bound    pvc-a3781354-e182-42f7-b6f6-983999603653   100mi      rwx            nfs-client     100s\n\n\n1\n2\n3\n4\n\n\n进入到pod中，使用redis-cli运行redis客户端，添加一些数据\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-pv-sts-0 -n zwf /bin/bash\n[ root@redis-pv-sts-0:/data ]$ redis-cli  \n127.0.0.1:6379> set name zhangsan\nok\n127.0.0.1:6379> set age 18\nok\n127.0.0.1:6379> keys *\n1) "name"\n2) "age"\n127.0.0.1:6379> quit\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n将pod删除，然后再重新进入pod中，查询之前创建的redis的key，还是能够查询到。\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-pv-sts-0  -n zwf -- /bin/bash\n[ root@redis-pv-sts-0:/data ]$ redis-cli  \n127.0.0.1:6379> keys *\n1) "name"\n2) "age"\n127.0.0.1:6379> get name\n"zhangsan"\n127.0.0.1:6379> get age\n"18"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n配置的关系图如下：\n\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"django后端服务、logstash和flink接入VictoriaMetrics指标监控",frontmatter:{title:"django后端服务、logstash和flink接入VictoriaMetrics指标监控",date:"2023-02-21T11:05:03.000Z",permalink:"/pages/b1b4a3/",categories:["云原生","k8s"],tags:[null],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"通过指标监控可以设置对应的告警，快速发现问题，并通过相应的指标定位问题。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20230221110733.png"},{name:"twitter:title",content:"django后端服务、logstash和flink接入VictoriaMetrics指标监控"},{name:"twitter:description",content:"通过指标监控可以设置对应的告警，快速发现问题，并通过相应的指标定位问题。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20230221110733.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/13.django%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1%E3%80%81logstash%E5%92%8Cflink%E6%8E%A5%E5%85%A5VictoriaMetrics%E6%8C%87%E6%A0%87%E7%9B%91%E6%8E%A7.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django后端服务、logstash和flink接入VictoriaMetrics指标监控"},{property:"og:description",content:"通过指标监控可以设置对应的告警，快速发现问题，并通过相应的指标定位问题。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20230221110733.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/13.django%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1%E3%80%81logstash%E5%92%8Cflink%E6%8E%A5%E5%85%A5VictoriaMetrics%E6%8C%87%E6%A0%87%E7%9B%91%E6%8E%A7.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-02-21T11:05:03.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"django后端服务、logstash和flink接入VictoriaMetrics指标监控"},{itemprop:"description",content:"通过指标监控可以设置对应的告警，快速发现问题，并通过相应的指标定位问题。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20230221110733.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/13.django%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1%E3%80%81logstash%E5%92%8Cflink%E6%8E%A5%E5%85%A5VictoriaMetrics%E6%8C%87%E6%A0%87%E7%9B%91%E6%8E%A7.html",relativePath:"01.云原生/07.k8s/13.django后端服务、logstash和flink接入VictoriaMetrics指标监控.md",key:"v-c31c1604",path:"/pages/b1b4a3/",headers:[{level:2,title:"0.简介",slug:"_0-简介",normalizedTitle:"0.简介",charIndex:2},{level:2,title:"1.VictoriaMetrics",slug:"_1-victoriametrics",normalizedTitle:"1.victoriametrics",charIndex:172},{level:2,title:"2.django 服务接入",slug:"_2-django-服务接入",normalizedTitle:"2.django 服务接入",charIndex:376},{level:2,title:"3.logstash 接入",slug:"_3-logstash-接入",normalizedTitle:"3.logstash 接入",charIndex:799},{level:2,title:"4.flink 接入监控",slug:"_4-flink-接入监控",normalizedTitle:"4.flink 接入监控",charIndex:1515},{level:2,title:"5.VMPodScrape",slug:"_5-vmpodscrape",normalizedTitle:"5.vmpodscrape",charIndex:1844}],headersStr:"0.简介 1.VictoriaMetrics 2.django 服务接入 3.logstash 接入 4.flink 接入监控 5.VMPodScrape",content:'# 0.简介\n\n通过指标监控可以设置对应的告警，快速发现问题，并通过相应的指标定位问题。\n\n背景：使用的 VictoriaMetrics(简称 VM) 作为监控的解决方案，需要将 django 服务、logstash 和 flink 引擎接入进来，VM 可以实时的获取它们的指标存储并进行监控告警，以上的服务都是部署在 k8s 中的。\n\n\n# 1.VictoriaMetrics\n\nVictoriaMetrics，是一个快速高效、经济并且可扩展的监控解决方案和时序数据库。比较出名的监控方案有 Promethues，而 VM 是兼容 Promethues 的各种规范、配置等，可以快速的融入 Promethues 生态甚至是取代它。\n\nVM 获取服务指标的方式也是通过主动拉取的方式，每个服务都会暴露一个端口供 VM 来拉取服务的指标信息\n\n\n\n\n# 2.django 服务接入\n\n可以通过使用第三方库 prometheus-client 来收集服务的指标信息，并暴露端口给 VM 拉取。\n\n * 安装\n\npip install prometheus-client\n\n\n1\n\n * 使用\n\n因为该服务使用的是 wsgi 协议的，所以在 wsgi.py 文件中添加以下代码，会开启一个新的线程监听 9300 端口，请求该端口可以获取当前服务的参数指标。\n\nfrom prometheus_client import start_wsgi_server\nstart_wsgi_server(9300)\n\n\n1\n2\n\n\n如果想要上报业务指标，可以通过该库在业务中进行埋点和收集。\n\n还需要在 pod 中添加 ports 属性提供给 VM 使用，这个在后面讲解。\n\n- containerPort: 9300\n  name: exportport\n  protocol: TCP\n\n\n1\n2\n3\n\n\n\n# 3.logstash 接入\n\nlogstash 是有自己的指标监控服务，需要在配置文件 logstash.yaml 中将其端口暴露。\n\nhttp.port: 9600\n\n\n1\n\n\n但是其指标格式和 prometheus 的指标格式是不同的，所以需要通过另一个程序 exporter 来将 logstash 指标转换成 prometheus 指标格式。\n\n该 logstash 是部署在 k8s 中的，使用到容器设计模式 sidecar，就是在 pod 中新增一个容器来辅助主容器 logstash 来做监控指标的转换并提供给 VM 调用。\n\n\n\nlogstash 的 exporter 可以使用 prometheus-logstash-exporter 来完成，可以去 docker hub 中找到对应的镜像，并将其下载下来使用。\n\n在 logstash 的 pod 中添加以下配置来设置 exporter，将暴露 9300 端口作为 logstash 的指标监控端口给 VM 拉取。这里需要配置 ports，在 VM 中需要使用该参数。\n\n- name: logstash-exporter\nimage: alxrem/prometheus-logstash-exporter:0.7.0\nargs:\n- -logstash.host\n- 127.0.0.1\n- -logstash.port\n- 9600\n- -web.listen-address\n- 9300\nports:\n- name: exportport\n  containerPort: 9300\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 4.flink 接入监控\n\nflink 本身是支持 prometheus 的指标监控，只需要通过添加配置 flink 的参数即可开启。\n\n  metrics.reporters: prom\n  metrics.reporter.prom.class: org.apache.flink.metrics.prometheus.PrometheusReporter\n  metrics.reporter.prom.port: "9300"\n\n\n1\n2\n3\n\n\n除了上面的配置外，还需要在 Pod 中设置 ports 来供 VM 使用。\n\nports:\n  - name: exportport\n\tcontainerPort: 9300\n\n\n1\n2\n3\n\n\n\n# 5.VMPodScrape\n\n虽然上面的服务都暴露了指标端口，VM 如何找到它们呢？需要通过创建 VMPodScrape 的资源对象来帮助 VM 来找到它们。\n\n配置如下：\n\napiVersion: operator.victoriametrics.com/v1beta1\nkind: VMPodScrape\nmetadata:\n  labels:\n    prometheus: k8s\n  name: demo-pod-monitor          \n  namespace: monitor\nspec:\n  namespaceSelector:\n    any: true                   \n  podMetricsEndpoints:\n    - path: /metrics            \n      port: exportport          \n  selector:\n    matchLabels:\n      app: django\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n * spec.podMetricsEndpoints.port，这个就是在每个 pod 中添加的 ports 中对应的 name，VM 会去找到对应 name 的端口获取指标\n * spec.selector.matchLabels，通过标签过滤找到指定的 pod\n\n通过 kubectl apply -f 创建该资源对象，VM 就能找到指标提供的服务。',normalizedContent:'# 0.简介\n\n通过指标监控可以设置对应的告警，快速发现问题，并通过相应的指标定位问题。\n\n背景：使用的 victoriametrics(简称 vm) 作为监控的解决方案，需要将 django 服务、logstash 和 flink 引擎接入进来，vm 可以实时的获取它们的指标存储并进行监控告警，以上的服务都是部署在 k8s 中的。\n\n\n# 1.victoriametrics\n\nvictoriametrics，是一个快速高效、经济并且可扩展的监控解决方案和时序数据库。比较出名的监控方案有 promethues，而 vm 是兼容 promethues 的各种规范、配置等，可以快速的融入 promethues 生态甚至是取代它。\n\nvm 获取服务指标的方式也是通过主动拉取的方式，每个服务都会暴露一个端口供 vm 来拉取服务的指标信息\n\n\n\n\n# 2.django 服务接入\n\n可以通过使用第三方库 prometheus-client 来收集服务的指标信息，并暴露端口给 vm 拉取。\n\n * 安装\n\npip install prometheus-client\n\n\n1\n\n * 使用\n\n因为该服务使用的是 wsgi 协议的，所以在 wsgi.py 文件中添加以下代码，会开启一个新的线程监听 9300 端口，请求该端口可以获取当前服务的参数指标。\n\nfrom prometheus_client import start_wsgi_server\nstart_wsgi_server(9300)\n\n\n1\n2\n\n\n如果想要上报业务指标，可以通过该库在业务中进行埋点和收集。\n\n还需要在 pod 中添加 ports 属性提供给 vm 使用，这个在后面讲解。\n\n- containerport: 9300\n  name: exportport\n  protocol: tcp\n\n\n1\n2\n3\n\n\n\n# 3.logstash 接入\n\nlogstash 是有自己的指标监控服务，需要在配置文件 logstash.yaml 中将其端口暴露。\n\nhttp.port: 9600\n\n\n1\n\n\n但是其指标格式和 prometheus 的指标格式是不同的，所以需要通过另一个程序 exporter 来将 logstash 指标转换成 prometheus 指标格式。\n\n该 logstash 是部署在 k8s 中的，使用到容器设计模式 sidecar，就是在 pod 中新增一个容器来辅助主容器 logstash 来做监控指标的转换并提供给 vm 调用。\n\n\n\nlogstash 的 exporter 可以使用 prometheus-logstash-exporter 来完成，可以去 docker hub 中找到对应的镜像，并将其下载下来使用。\n\n在 logstash 的 pod 中添加以下配置来设置 exporter，将暴露 9300 端口作为 logstash 的指标监控端口给 vm 拉取。这里需要配置 ports，在 vm 中需要使用该参数。\n\n- name: logstash-exporter\nimage: alxrem/prometheus-logstash-exporter:0.7.0\nargs:\n- -logstash.host\n- 127.0.0.1\n- -logstash.port\n- 9600\n- -web.listen-address\n- 9300\nports:\n- name: exportport\n  containerport: 9300\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 4.flink 接入监控\n\nflink 本身是支持 prometheus 的指标监控，只需要通过添加配置 flink 的参数即可开启。\n\n  metrics.reporters: prom\n  metrics.reporter.prom.class: org.apache.flink.metrics.prometheus.prometheusreporter\n  metrics.reporter.prom.port: "9300"\n\n\n1\n2\n3\n\n\n除了上面的配置外，还需要在 pod 中设置 ports 来供 vm 使用。\n\nports:\n  - name: exportport\n\tcontainerport: 9300\n\n\n1\n2\n3\n\n\n\n# 5.vmpodscrape\n\n虽然上面的服务都暴露了指标端口，vm 如何找到它们呢？需要通过创建 vmpodscrape 的资源对象来帮助 vm 来找到它们。\n\n配置如下：\n\napiversion: operator.victoriametrics.com/v1beta1\nkind: vmpodscrape\nmetadata:\n  labels:\n    prometheus: k8s\n  name: demo-pod-monitor          \n  namespace: monitor\nspec:\n  namespaceselector:\n    any: true                   \n  podmetricsendpoints:\n    - path: /metrics            \n      port: exportport          \n  selector:\n    matchlabels:\n      app: django\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n * spec.podmetricsendpoints.port，这个就是在每个 pod 中添加的 ports 中对应的 name，vm 会去找到对应 name 的端口获取指标\n * spec.selector.matchlabels，通过标签过滤找到指定的 pod\n\n通过 kubectl apply -f 创建该资源对象，vm 就能找到指标提供的服务。',charsets:{cjk:!0},lastUpdated:"2023/02/21, 11:15:06",lastUpdatedTimestamp:1676949306e3},{title:"pod中将代码与运行环境分离",frontmatter:{title:"pod中将代码与运行环境分离",date:"2022-11-14T09:56:31.000Z",permalink:"/pages/27987d/",tags:["k8s","容器","云原生"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"我们在创建一个 python 的 web 服务的镜像时，一般的做法是，将 python 环境与代码打包成一个镜像，然后将这个镜像进行发布。",categories:["云原生","k8s"],comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20221114095752.png"},{name:"twitter:title",content:"pod中将代码与运行环境分离"},{name:"twitter:description",content:"我们在创建一个 python 的 web 服务的镜像时，一般的做法是，将 python 环境与代码打包成一个镜像，然后将这个镜像进行发布。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20221114095752.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/12.pod%E4%B8%AD%E5%B0%86%E4%BB%A3%E7%A0%81%E4%B8%8E%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E5%88%86%E7%A6%BB.html"},{property:"og:type",content:"article"},{property:"og:title",content:"pod中将代码与运行环境分离"},{property:"og:description",content:"我们在创建一个 python 的 web 服务的镜像时，一般的做法是，将 python 环境与代码打包成一个镜像，然后将这个镜像进行发布。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20221114095752.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/12.pod%E4%B8%AD%E5%B0%86%E4%BB%A3%E7%A0%81%E4%B8%8E%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E5%88%86%E7%A6%BB.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-11-14T09:56:31.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"pod中将代码与运行环境分离"},{itemprop:"description",content:"我们在创建一个 python 的 web 服务的镜像时，一般的做法是，将 python 环境与代码打包成一个镜像，然后将这个镜像进行发布。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20221114095752.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/12.pod%E4%B8%AD%E5%B0%86%E4%BB%A3%E7%A0%81%E4%B8%8E%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E5%88%86%E7%A6%BB.html",relativePath:"01.云原生/07.k8s/12.pod中将代码与运行环境分离.md",key:"v-476540fe",path:"/pages/27987d/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 思路",slug:"_1-思路",normalizedTitle:"1. 思路",charIndex:171},{level:2,title:"2. 案例",slug:"_2-案例",normalizedTitle:"2. 案例",charIndex:337},{level:3,title:"2.1 创建代码镜像",slug:"_2-1-创建代码镜像",normalizedTitle:"2.1 创建代码镜像",charIndex:347},{level:3,title:"2.2 创建 python 运行环境",slug:"_2-2-创建-python-运行环境",normalizedTitle:"2.2 创建 python 运行环境",charIndex:802},{level:3,title:"2.3 容器编排",slug:"_2-3-容器编排",normalizedTitle:"2.3 容器编排",charIndex:1078},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:2797}],headersStr:"0. 前言 1. 思路 2. 案例 2.1 创建代码镜像 2.2 创建 python 运行环境 2.3 容器编排 3. 总结",content:'# 0. 前言\n\n我们在创建一个 python 的 web 服务的镜像时，一般的做法是，将 python 环境与代码打包成一个镜像，然后将这个镜像进行发布。\n\n现在有个需求就是将 python 环境和代码分别构造成两个镜像，让他们进行解耦，并且将他们编排在一个 pod 中。\n\n本文介绍如何将 pod 中的代码与运行的环境进行拆分。\n\n\n# 1. 思路\n\n首先我们将代码打包成镜像 A，再将 python 运行环境打包成镜像 B，通过编排在 Pod 中的 InitContainer 设置为镜像 A，并将其内的代码拷贝到挂载的 emptyDir 存储卷中，然后在镜像 B 中挂载相同的存储卷，在使用运行环境中的 python 去执行存储卷中拷贝过来的代码即可。\n\n\n\n\n# 2. 案例\n\n\n# 2.1 创建代码镜像\n\n先创建一个简单的 python web 程序 main.py\n\nfrom flask import Flask\n\napp = Flask(__name__)\n\n\n@app.route("/")\ndef hello_world():\n    return "Hello, World!"\n\napp.run(host="0.0.0.0")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n我们再创建包含代码镜像的 Dockerfile，做的事情是将 main.py 文件拷贝到镜像的根目录下，文件命名为Dockerfile_code\n\nFROM busybox:latest\nCOPY main.py /\n\n\n1\n2\n\n\n我们通过 docker build 开始创建镜像，镜像名称为 demo_code，默认 tag为 latest\n\ndocker build . -t "demo_code" -f Dockerfile_code\n\n\n1\n\n\n这个时候我们的代码镜像创建好了。\n\n\n# 2.2 创建 python 运行环境\n\n我们开始创建 python 运行环境镜像的 Dockerfile，以 python3 的镜像为基础，并安装 flask 库，文件名为 Dockerfile_runtime\n\nFROM python:3\nRUN pip install flask\n\n\n1\n2\n\n\n再构建一下这个镜像，镜像名为 demo_runtime，默认 tag 是 latest\n\ndocker build . -t "demo_runtime" -f Dockerfile_runtime\n\n\n1\n\n\n这个时候，两个镜像都已准备好\n\n\n# 2.3 容器编排\n\n创建 deployments.yaml 文件，在 Pod 中的 initContainers 中配置代码镜像, 然后挂载临时存储卷，将代码复制到存储卷中。\n\n然后再配置应用容器 python 运行环境，挂载上面相同的临时存储卷，然后再使用 python 将代码运行。\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demo\n  labels:\n    app: demo\nspec:\n  selector:\n    matchLabels:\n      app: demo\n  template:\n    metadata:\n      labels:\n        app: demo\n    spec:\n      initContainers:\n        - image: demo_code:latest\n          name: code\n          imagePullPolicy: IfNotPresent\n          volumeMounts:\n          - mountPath: /opt/demo\n            name: app-volume\n          command: ["cp", "/main.py", "/opt/demo/"]\n      containers:\n        - name: runtime\n          image: demo_runtime:latest\n          imagePullPolicy: IfNotPresent\n          ports:\n            - containerPort: 5000\n              hostPort: 5000\n              protocol: TCP\n              name: http\n          volumeMounts:\n            - mountPath: /opt/demo\n              name: app-volume\n          command: ["python", "/opt/demo/main.py"]\n      volumes:\n      - name: app-volume\n        emptyDir: { }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n我们通过 kubectl apply 创建 deployments\n\nkubectl apply -f deployments.yaml\n\n\n1\n\n\n我们通过 kubectl get pods 可以看到 pod 已经创建成功，然后找到 pod 所在的节点。通过节点 ip+端口即可访问到容器的中接口。\n\n[root@k8s-master-07rf9 test]# kubectl get pods -o wide\nNAME                    READY   STATUS    RESTARTS   AGE     IP               NODE               NOMINATED NODE   READINESS GATES\ndemo-6f49db5d6c-25vss   1/1     Running   0          4m58s   10.244.132.130   k8s-master-07rf9   <none>           <none>\n\n\n[root@k8s-master-07rf9 test]# curl 10.65.132.187:5000\nHello, World!\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 3. 总结\n\n本文的编排方式只是 pod 的设计模式的一种。有兴趣的可以了解更多。\n\n通过这种方式可以让代码与运行环境解耦，当我们更新代码时，并不会影响到运行环境。',normalizedContent:'# 0. 前言\n\n我们在创建一个 python 的 web 服务的镜像时，一般的做法是，将 python 环境与代码打包成一个镜像，然后将这个镜像进行发布。\n\n现在有个需求就是将 python 环境和代码分别构造成两个镜像，让他们进行解耦，并且将他们编排在一个 pod 中。\n\n本文介绍如何将 pod 中的代码与运行的环境进行拆分。\n\n\n# 1. 思路\n\n首先我们将代码打包成镜像 a，再将 python 运行环境打包成镜像 b，通过编排在 pod 中的 initcontainer 设置为镜像 a，并将其内的代码拷贝到挂载的 emptydir 存储卷中，然后在镜像 b 中挂载相同的存储卷，在使用运行环境中的 python 去执行存储卷中拷贝过来的代码即可。\n\n\n\n\n# 2. 案例\n\n\n# 2.1 创建代码镜像\n\n先创建一个简单的 python web 程序 main.py\n\nfrom flask import flask\n\napp = flask(__name__)\n\n\n@app.route("/")\ndef hello_world():\n    return "hello, world!"\n\napp.run(host="0.0.0.0")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n我们再创建包含代码镜像的 dockerfile，做的事情是将 main.py 文件拷贝到镜像的根目录下，文件命名为dockerfile_code\n\nfrom busybox:latest\ncopy main.py /\n\n\n1\n2\n\n\n我们通过 docker build 开始创建镜像，镜像名称为 demo_code，默认 tag为 latest\n\ndocker build . -t "demo_code" -f dockerfile_code\n\n\n1\n\n\n这个时候我们的代码镜像创建好了。\n\n\n# 2.2 创建 python 运行环境\n\n我们开始创建 python 运行环境镜像的 dockerfile，以 python3 的镜像为基础，并安装 flask 库，文件名为 dockerfile_runtime\n\nfrom python:3\nrun pip install flask\n\n\n1\n2\n\n\n再构建一下这个镜像，镜像名为 demo_runtime，默认 tag 是 latest\n\ndocker build . -t "demo_runtime" -f dockerfile_runtime\n\n\n1\n\n\n这个时候，两个镜像都已准备好\n\n\n# 2.3 容器编排\n\n创建 deployments.yaml 文件，在 pod 中的 initcontainers 中配置代码镜像, 然后挂载临时存储卷，将代码复制到存储卷中。\n\n然后再配置应用容器 python 运行环境，挂载上面相同的临时存储卷，然后再使用 python 将代码运行。\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  name: demo\n  labels:\n    app: demo\nspec:\n  selector:\n    matchlabels:\n      app: demo\n  template:\n    metadata:\n      labels:\n        app: demo\n    spec:\n      initcontainers:\n        - image: demo_code:latest\n          name: code\n          imagepullpolicy: ifnotpresent\n          volumemounts:\n          - mountpath: /opt/demo\n            name: app-volume\n          command: ["cp", "/main.py", "/opt/demo/"]\n      containers:\n        - name: runtime\n          image: demo_runtime:latest\n          imagepullpolicy: ifnotpresent\n          ports:\n            - containerport: 5000\n              hostport: 5000\n              protocol: tcp\n              name: http\n          volumemounts:\n            - mountpath: /opt/demo\n              name: app-volume\n          command: ["python", "/opt/demo/main.py"]\n      volumes:\n      - name: app-volume\n        emptydir: { }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n我们通过 kubectl apply 创建 deployments\n\nkubectl apply -f deployments.yaml\n\n\n1\n\n\n我们通过 kubectl get pods 可以看到 pod 已经创建成功，然后找到 pod 所在的节点。通过节点 ip+端口即可访问到容器的中接口。\n\n[root@k8s-master-07rf9 test]# kubectl get pods -o wide\nname                    ready   status    restarts   age     ip               node               nominated node   readiness gates\ndemo-6f49db5d6c-25vss   1/1     running   0          4m58s   10.244.132.130   k8s-master-07rf9   <none>           <none>\n\n\n[root@k8s-master-07rf9 test]# curl 10.65.132.187:5000\nhello, world!\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 3. 总结\n\n本文的编排方式只是 pod 的设计模式的一种。有兴趣的可以了解更多。\n\n通过这种方式可以让代码与运行环境解耦，当我们更新代码时，并不会影响到运行环境。',charsets:{cjk:!0},lastUpdated:"2023/02/07, 09:44:40",lastUpdatedTimestamp:167573428e4},{title:"理解calico容器网络通信方案原理",frontmatter:{title:"理解calico容器网络通信方案原理",date:"2023-06-03T11:04:25.000Z",permalink:"/pages/f0f725/",categories:["云原生","k8s"],tags:["k8s","容器","云原生","计算机网络","Linux网络虚拟化"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"Calico是k8s中常用的容器解决方案的插件，本文主要介绍BGP模式和IPIP模式是如何解决的，并详细了解其原理，并通过实验加深理解。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_calico.png"},{name:"twitter:title",content:"理解calico容器网络通信方案原理"},{name:"twitter:description",content:"Calico是k8s中常用的容器解决方案的插件，本文主要介绍BGP模式和IPIP模式是如何解决的，并详细了解其原理，并通过实验加深理解。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_calico.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/15.%E7%90%86%E8%A7%A3calico%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E6%96%B9%E6%A1%88%E5%8E%9F%E7%90%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"理解calico容器网络通信方案原理"},{property:"og:description",content:"Calico是k8s中常用的容器解决方案的插件，本文主要介绍BGP模式和IPIP模式是如何解决的，并详细了解其原理，并通过实验加深理解。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_calico.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/15.%E7%90%86%E8%A7%A3calico%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E6%96%B9%E6%A1%88%E5%8E%9F%E7%90%86.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-06-03T11:04:25.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{property:"article:tag",content:"计算机网络"},{property:"article:tag",content:"Linux网络虚拟化"},{itemprop:"name",content:"理解calico容器网络通信方案原理"},{itemprop:"description",content:"Calico是k8s中常用的容器解决方案的插件，本文主要介绍BGP模式和IPIP模式是如何解决的，并详细了解其原理，并通过实验加深理解。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_calico.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/15.%E7%90%86%E8%A7%A3calico%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E6%96%B9%E6%A1%88%E5%8E%9F%E7%90%86.html",relativePath:"01.云原生/07.k8s/15.理解calico容器网络通信方案原理.md",key:"v-38f161f6",path:"/pages/f0f725/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 介绍Calico",slug:"_1-介绍calico",normalizedTitle:"1. 介绍calico",charIndex:82},{level:2,title:"2. Calio架构",slug:"_2-calio架构",normalizedTitle:"2. calio架构",charIndex:585},{level:2,title:"3. BGP模式",slug:"_3-bgp模式",normalizedTitle:"3. bgp模式",charIndex:1154},{level:2,title:"4. 手动模拟BGP模式实验",slug:"_4-手动模拟bgp模式实验",normalizedTitle:"4. 手动模拟bgp模式实验",charIndex:1397},{level:3,title:"4.1 操作",slug:"_4-1-操作",normalizedTitle:"4.1 操作",charIndex:1418},{level:3,title:"4.2 分析",slug:"_4-2-分析",normalizedTitle:"4.2 分析",charIndex:3211},{level:2,title:"5. IPIP隧道模式",slug:"_5-ipip隧道模式",normalizedTitle:"5. ipip隧道模式",charIndex:5636}],headersStr:"0. 前言 1. 介绍Calico 2. Calio架构 3. BGP模式 4. 手动模拟BGP模式实验 4.1 操作 4.2 分析 5. IPIP隧道模式",content:"# 0. 前言\n\nCalico是k8s中常用的容器解决方案的插件，本文主要介绍BGP模式和IPIP模式是如何解决的，并详细了解其原理，并通过实验加深理解。\n\n\n# 1. 介绍Calico\n\nCalico是属于纯3层的网络模型，每个容器都通过IP直接通信，中间通过路由转发找到对方。容器所在的节点类似于传统的路由器，提供了路由查找的功能。每个容器所在的主机节点扮演了虚拟路由器 （vRouter）的功能，vRouter必须有某种方法，能够知道整个集群的路由信息。\n\n之前提到的FlannelHost Gateway模式方案是不能跨二层网络，是因为它只能修改主机路由，Calico把改路由表的做法换成了标准的BGP路由协议。相当于在每个节点上模拟出一个额外的路由器，由于采用的是标准协议，Calico模拟路由器的路由表信息可以被传播到网络的其他路由设备中，这样就实现了在三层网络上的高速跨节点网络。\n\n> BGP（Border Gateway Protocol）是一种用于在互联网中交换路由信息的协议。它是一种自治系统（AS）之间的路由协议，用于在不同的自治系统之间交换路由信息。BGP协议的主要作用是将路由信息从一个自治系统传递到另一个自治系统，以便实现互联网的全球路由。\n\n但现实中的网络并不一定支持BGP路由，在这种情况下可以使用IPIP隧道模式来传输数据。\n\n\n# 2. Calio架构\n\n\n\nFelix\n\nFelix是一个守护程序，作为agent运行在托管容器或虚拟机的Calico节点上。Felix负责刷新主机路由和ACL规则等，以便为该主机上的Endpoint正常运行提供所需的网络连接和管理。进出容器、虚拟机和物理主机的所有流量都会遍历Calico，利用Linux内核原生的路由和iptables生成的规则。\n\nBGP Client\n\nCalico在每个运行Felix服务的节点上都部署一个BGP Client（BGP客户端）。BGP客户端的作用是读取Felix编写到内核中的路由信息，由BGP客户端对这些路由信息进行分发。当Felix将路由插入Linux内核时，BGP客户端将接收它们，并将它们分发到集群中的其他工作节点。\n\nNode-to-Node Mesh\n\n该模式为默认模式，在BGP下，集群中的每一个节点的BGP Client都需要和其他所有节点的BGP Client进行通信来交换路由。\n但随着节点数量增加，连接数会以N^2规模增加，给集群网络带来巨大的压力。\n\nBGP Route Reflector\n\nCalico会指定几个节点负责专门跟其他所有节点进行连接并交换路由信息，从而学习到全局的路由信息。而其他节点也只需要跟这几个节点进行通信来获取到整个集群的规则信息。\n\n\n\n\n# 3. BGP模式\n\n\n\n每个容器都会创建一对veth pair网卡，一端放在容器内部，另一端放在宿主机中，容器中发送的IP包通过veth pair网卡可以达到宿主机的网络协议栈中。\n\nFelix会通过监听etcd来获取其他节点的相关信息，然后添加本地路由：\n\n 1. 通往其他节点容器的IP包下一条到其节点物理网卡中。\n 2. 通过本机节点容器的IP包到calixxx网卡中，然后进入到容器中。\n\nBGP Client会读取Felix写入到本地的路由，再通过进行分发到网络中。\n\n\n# 4. 手动模拟BGP模式实验\n\n\n\n\n# 4.1 操作\n\n首先在Node1中创建Network Namespace命名为net1\n\nip netns add net1\n\n\n1\n\n\n然后创建一对veth pair设备veth0和veth1，将veth0放到net1中，拉起并设置好ip地址172.19.1.2/24，veth1也拉取但不用设置IP地址，但需要设置默认的MAC地址为ee:ee:ee:ee:ee:ee\n\nip link add veth0 type veth peer name veth1\nip link set dev veth0 netns net1\nip netns exec net1 ip link set veth0 up\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\n\nip link set dev veth1 up\nip link set dev veth1 address ee:ee:ee:ee:ee:ee\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\nnet1配置的路由有点意思，和一般配置的路由不同，所有的报文都需要通过veth0设备发送到下一跳的地址为169.254.1.1，而这个地址在整个平台找是不存在的，这是一个默认的网关，那如何达到该地址呢？\n\nip netns exec net1 ip r a 169.254.1.1 dev veth0 \nip netns exec net1 ip r a default via 169.254.1.1 dev veth0 \n\n\n1\n2\n\n\n通过设置veth1设备proxy_arp，可以对于任何ARP请求到达veth1时，都响应自己的Mac地址，也就是ee:ee:ee:ee:ee:ee\n\n当访问网关的时候，首先是需要进行ARP请求，请求通过veth0设备达到了veth1中，因为设置proxy_arp，会将自身的mac地址ee:ee:ee:ee:ee:ee作为arp回复。\n\n而容器的后续报文目的IP地址是目的容器的IP地址，而mac地址变成了网关MAC地址ee:ee:ee:ee:ee:ee，而网关的IP地址并不会出现在任何的数据包中，也没人关心这个具体的地址是什么，只要能找到arp就行。\n\necho 1 > /proc/sys/net/ipv4/conf/veth1/proxy_arp\n\n\n1\n\n\n数据包已经从net1中通过veth1作为网关达到宿主机的网络协议栈中，再通过设置宿主机路由表，将目的地址为Node2容器网段的数据包通过Node2 ens18网卡地址作为下一跳地址。\n\nip r add 172.19.2.0/24 via 10.65.132.188 dev ens18\n\n\n1\n\n\n目的地址为Node1的net1时，需要配置通过路由表到达veth1网卡，然后再进入到net1中。\n\nip r add 172.19.1.2 dev veth1\n\n\n1\n\n\n再在Node2中重复Node1的操作创建Network Namespace net2，并初始化网络配置。\n\nip netns add net2\nip link add veth0 type veth peer name veth1\nip link set dev veth0 netns net2\nip netns exec net2 ip addr add 172.19.2.2/24 dev veth0 \nip netns exec net2 ip link set veth0 up\n\nip link set dev veth1 up\nip link set dev veth1 address ee:ee:ee:ee:ee:ee\n\nip netns exec net2 ip r a 169.254.1.1 dev veth0 \nip netns exec net2 ip r a default via 169.254.1.1 dev veth0 \nip r add 172.19.1.0/24 via 10.65.132.187 dev ens18\nip r add 172.19.2.2/32 dev veth1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 4.2 分析\n\n在Node1 net1中ping Node2 net2，然后使用tcpdump监听Node1的veth1，结果如下：\n\n# tcpdump -i veth1 -ne\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytes\n10:38:29.713322 02:1c:9c:83:87:f2 > Broadcast, ethertype ARP (0x0806), length 42: Request who-has 169.254.1.1 tell 172.19.1.2, length 28\n10:38:30.205862 ee:ee:ee:ee:ee:ee > 02:1c:9c:83:87:f2, ethertype ARP (0x0806), length 42: Reply 169.254.1.1 is-at ee:ee:ee:ee:ee:ee, length 28\n10:38:30.205922 02:1c:9c:83:87:f2 > ee:ee:ee:ee:ee:ee, ethertype IPv4 (0x0800), length 98: 172.19.1.2 > 172.19.2.2: ICMP echo request, id 37475, seq 1, length 64\n10:38:30.206393 ee:ee:ee:ee:ee:ee > 02:1c:9c:83:87:f2, ethertype IPv4 (0x0800), length 98: 172.19.2.2 > 172.19.1.2: ICMP echo reply, id 37475, seq 1, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n可以看到，先是发送arp请求获取172.19.1.2的mac地址，因为设置了proxy_arp，所以会将自身的Mac地址进行回复，在后面的ICMP包中，目的IP地址为目的容器IP地址172.19.2.2，而目的Mac地址为veth1的Mac地址ee:ee:ee:ee:ee:ee\n\n再使用tcpdump监听Node2的ens18网卡，结果如下：\n\n# tcpdump -i ens18 host 172.19.2.2 -en\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type EN10MB (Ethernet), capture size 262144 bytes\n10:52:43.993140 fa:16:3e:d3:f6:3a > fa:16:3e:b1:9a:65, ethertype IPv4 (0x0800), length 98: 172.19.1.2 > 172.19.2.2: ICMP echo request, id 4349, seq 1, length 64\n10:52:43.993291 fa:16:3e:b1:9a:65 > fa:16:3e:d3:f6:3a, ethertype IPv4 (0x0800), length 98: 172.19.2.2 > 172.19.1.2: ICMP echo reply, id 4349, seq 1, length 64\n\n\n1\n2\n3\n4\n5\n6\n\n\n数据包从Node1中到达了Node2 ens18网卡，源IP和目的IP分别为net1和net2的IP地址，而mac地址是Node1和Node2的物理网卡ens18 Mac地址.\n\n使用tcpdump监听veth1网卡，结果如下：\n\n# tcpdump -i veth1 -en\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytes\n10:58:13.780247 ee:ee:ee:ee:ee:ee > fa:63:d4:dc:25:01, ethertype IPv4 (0x0800), length 98: 172.19.1.2 > 172.19.2.2: ICMP echo request, id 41971, seq 1, length 64\n10:58:13.780288 fa:63:d4:dc:25:01 > ee:ee:ee:ee:ee:ee, ethertype IPv4 (0x0800), length 98: 172.19.2.2 > 172.19.1.2: ICMP echo reply, id 41971, seq 1, length 64\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看Node2的路由\n\n# ip r\n...\n172.19.2.2 dev veth1 scope link \n...\n\n\n1\n2\n3\n4\n\n\n数据包达到Node2 ens18网卡后，解开mac头，到达网络协议栈中，通过路由，将目的地址为172.19.2.2的数据包都进入到veth1网卡中，最终进入到net2中\n\n\n# 5. IPIP隧道模式\n\n该模式的解决方式是在物理机A和物理机B之间打一个隧道，这个隧道有两个端点，在端点上进行封装，将容器的IP作为乘客协议放在隧道里面，而物理主机的IP放在外面作为承载协议。这样不管外层的IP通过传统的物理网络，走多少跳到达目标物理机，从隧道两端看起来，物理机A的下一跳就是物理机B。",normalizedContent:"# 0. 前言\n\ncalico是k8s中常用的容器解决方案的插件，本文主要介绍bgp模式和ipip模式是如何解决的，并详细了解其原理，并通过实验加深理解。\n\n\n# 1. 介绍calico\n\ncalico是属于纯3层的网络模型，每个容器都通过ip直接通信，中间通过路由转发找到对方。容器所在的节点类似于传统的路由器，提供了路由查找的功能。每个容器所在的主机节点扮演了虚拟路由器 （vrouter）的功能，vrouter必须有某种方法，能够知道整个集群的路由信息。\n\n之前提到的flannelhost gateway模式方案是不能跨二层网络，是因为它只能修改主机路由，calico把改路由表的做法换成了标准的bgp路由协议。相当于在每个节点上模拟出一个额外的路由器，由于采用的是标准协议，calico模拟路由器的路由表信息可以被传播到网络的其他路由设备中，这样就实现了在三层网络上的高速跨节点网络。\n\n> bgp（border gateway protocol）是一种用于在互联网中交换路由信息的协议。它是一种自治系统（as）之间的路由协议，用于在不同的自治系统之间交换路由信息。bgp协议的主要作用是将路由信息从一个自治系统传递到另一个自治系统，以便实现互联网的全球路由。\n\n但现实中的网络并不一定支持bgp路由，在这种情况下可以使用ipip隧道模式来传输数据。\n\n\n# 2. calio架构\n\n\n\nfelix\n\nfelix是一个守护程序，作为agent运行在托管容器或虚拟机的calico节点上。felix负责刷新主机路由和acl规则等，以便为该主机上的endpoint正常运行提供所需的网络连接和管理。进出容器、虚拟机和物理主机的所有流量都会遍历calico，利用linux内核原生的路由和iptables生成的规则。\n\nbgp client\n\ncalico在每个运行felix服务的节点上都部署一个bgp client（bgp客户端）。bgp客户端的作用是读取felix编写到内核中的路由信息，由bgp客户端对这些路由信息进行分发。当felix将路由插入linux内核时，bgp客户端将接收它们，并将它们分发到集群中的其他工作节点。\n\nnode-to-node mesh\n\n该模式为默认模式，在bgp下，集群中的每一个节点的bgp client都需要和其他所有节点的bgp client进行通信来交换路由。\n但随着节点数量增加，连接数会以n^2规模增加，给集群网络带来巨大的压力。\n\nbgp route reflector\n\ncalico会指定几个节点负责专门跟其他所有节点进行连接并交换路由信息，从而学习到全局的路由信息。而其他节点也只需要跟这几个节点进行通信来获取到整个集群的规则信息。\n\n\n\n\n# 3. bgp模式\n\n\n\n每个容器都会创建一对veth pair网卡，一端放在容器内部，另一端放在宿主机中，容器中发送的ip包通过veth pair网卡可以达到宿主机的网络协议栈中。\n\nfelix会通过监听etcd来获取其他节点的相关信息，然后添加本地路由：\n\n 1. 通往其他节点容器的ip包下一条到其节点物理网卡中。\n 2. 通过本机节点容器的ip包到calixxx网卡中，然后进入到容器中。\n\nbgp client会读取felix写入到本地的路由，再通过进行分发到网络中。\n\n\n# 4. 手动模拟bgp模式实验\n\n\n\n\n# 4.1 操作\n\n首先在node1中创建network namespace命名为net1\n\nip netns add net1\n\n\n1\n\n\n然后创建一对veth pair设备veth0和veth1，将veth0放到net1中，拉起并设置好ip地址172.19.1.2/24，veth1也拉取但不用设置ip地址，但需要设置默认的mac地址为ee:ee:ee:ee:ee:ee\n\nip link add veth0 type veth peer name veth1\nip link set dev veth0 netns net1\nip netns exec net1 ip link set veth0 up\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\n\nip link set dev veth1 up\nip link set dev veth1 address ee:ee:ee:ee:ee:ee\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\nnet1配置的路由有点意思，和一般配置的路由不同，所有的报文都需要通过veth0设备发送到下一跳的地址为169.254.1.1，而这个地址在整个平台找是不存在的，这是一个默认的网关，那如何达到该地址呢？\n\nip netns exec net1 ip r a 169.254.1.1 dev veth0 \nip netns exec net1 ip r a default via 169.254.1.1 dev veth0 \n\n\n1\n2\n\n\n通过设置veth1设备proxy_arp，可以对于任何arp请求到达veth1时，都响应自己的mac地址，也就是ee:ee:ee:ee:ee:ee\n\n当访问网关的时候，首先是需要进行arp请求，请求通过veth0设备达到了veth1中，因为设置proxy_arp，会将自身的mac地址ee:ee:ee:ee:ee:ee作为arp回复。\n\n而容器的后续报文目的ip地址是目的容器的ip地址，而mac地址变成了网关mac地址ee:ee:ee:ee:ee:ee，而网关的ip地址并不会出现在任何的数据包中，也没人关心这个具体的地址是什么，只要能找到arp就行。\n\necho 1 > /proc/sys/net/ipv4/conf/veth1/proxy_arp\n\n\n1\n\n\n数据包已经从net1中通过veth1作为网关达到宿主机的网络协议栈中，再通过设置宿主机路由表，将目的地址为node2容器网段的数据包通过node2 ens18网卡地址作为下一跳地址。\n\nip r add 172.19.2.0/24 via 10.65.132.188 dev ens18\n\n\n1\n\n\n目的地址为node1的net1时，需要配置通过路由表到达veth1网卡，然后再进入到net1中。\n\nip r add 172.19.1.2 dev veth1\n\n\n1\n\n\n再在node2中重复node1的操作创建network namespace net2，并初始化网络配置。\n\nip netns add net2\nip link add veth0 type veth peer name veth1\nip link set dev veth0 netns net2\nip netns exec net2 ip addr add 172.19.2.2/24 dev veth0 \nip netns exec net2 ip link set veth0 up\n\nip link set dev veth1 up\nip link set dev veth1 address ee:ee:ee:ee:ee:ee\n\nip netns exec net2 ip r a 169.254.1.1 dev veth0 \nip netns exec net2 ip r a default via 169.254.1.1 dev veth0 \nip r add 172.19.1.0/24 via 10.65.132.187 dev ens18\nip r add 172.19.2.2/32 dev veth1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 4.2 分析\n\n在node1 net1中ping node2 net2，然后使用tcpdump监听node1的veth1，结果如下：\n\n# tcpdump -i veth1 -ne\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on veth1, link-type en10mb (ethernet), capture size 262144 bytes\n10:38:29.713322 02:1c:9c:83:87:f2 > broadcast, ethertype arp (0x0806), length 42: request who-has 169.254.1.1 tell 172.19.1.2, length 28\n10:38:30.205862 ee:ee:ee:ee:ee:ee > 02:1c:9c:83:87:f2, ethertype arp (0x0806), length 42: reply 169.254.1.1 is-at ee:ee:ee:ee:ee:ee, length 28\n10:38:30.205922 02:1c:9c:83:87:f2 > ee:ee:ee:ee:ee:ee, ethertype ipv4 (0x0800), length 98: 172.19.1.2 > 172.19.2.2: icmp echo request, id 37475, seq 1, length 64\n10:38:30.206393 ee:ee:ee:ee:ee:ee > 02:1c:9c:83:87:f2, ethertype ipv4 (0x0800), length 98: 172.19.2.2 > 172.19.1.2: icmp echo reply, id 37475, seq 1, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n可以看到，先是发送arp请求获取172.19.1.2的mac地址，因为设置了proxy_arp，所以会将自身的mac地址进行回复，在后面的icmp包中，目的ip地址为目的容器ip地址172.19.2.2，而目的mac地址为veth1的mac地址ee:ee:ee:ee:ee:ee\n\n再使用tcpdump监听node2的ens18网卡，结果如下：\n\n# tcpdump -i ens18 host 172.19.2.2 -en\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type en10mb (ethernet), capture size 262144 bytes\n10:52:43.993140 fa:16:3e:d3:f6:3a > fa:16:3e:b1:9a:65, ethertype ipv4 (0x0800), length 98: 172.19.1.2 > 172.19.2.2: icmp echo request, id 4349, seq 1, length 64\n10:52:43.993291 fa:16:3e:b1:9a:65 > fa:16:3e:d3:f6:3a, ethertype ipv4 (0x0800), length 98: 172.19.2.2 > 172.19.1.2: icmp echo reply, id 4349, seq 1, length 64\n\n\n1\n2\n3\n4\n5\n6\n\n\n数据包从node1中到达了node2 ens18网卡，源ip和目的ip分别为net1和net2的ip地址，而mac地址是node1和node2的物理网卡ens18 mac地址.\n\n使用tcpdump监听veth1网卡，结果如下：\n\n# tcpdump -i veth1 -en\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on veth1, link-type en10mb (ethernet), capture size 262144 bytes\n10:58:13.780247 ee:ee:ee:ee:ee:ee > fa:63:d4:dc:25:01, ethertype ipv4 (0x0800), length 98: 172.19.1.2 > 172.19.2.2: icmp echo request, id 41971, seq 1, length 64\n10:58:13.780288 fa:63:d4:dc:25:01 > ee:ee:ee:ee:ee:ee, ethertype ipv4 (0x0800), length 98: 172.19.2.2 > 172.19.1.2: icmp echo reply, id 41971, seq 1, length 64\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看node2的路由\n\n# ip r\n...\n172.19.2.2 dev veth1 scope link \n...\n\n\n1\n2\n3\n4\n\n\n数据包达到node2 ens18网卡后，解开mac头，到达网络协议栈中，通过路由，将目的地址为172.19.2.2的数据包都进入到veth1网卡中，最终进入到net2中\n\n\n# 5. ipip隧道模式\n\n该模式的解决方式是在物理机a和物理机b之间打一个隧道，这个隧道有两个端点，在端点上进行封装，将容器的ip作为乘客协议放在隧道里面，而物理主机的ip放在外面作为承载协议。这样不管外层的ip通过传统的物理网络，走多少跳到达目标物理机，从隧道两端看起来，物理机a的下一跳就是物理机b。",charsets:{cjk:!0},lastUpdated:"2023/07/07, 08:56:29",lastUpdatedTimestamp:1688691389e3},{title:"理解flannel的三种容器网络方案原理",frontmatter:{title:"理解flannel的三种容器网络方案原理",date:"2023-06-01T12:56:36.000Z",permalink:"/pages/d9d0ce/",categories:["云原生","k8s"],tags:["k8s","容器","云原生","计算机网络","Linux网络虚拟化"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文主要介绍flannel在k8s网络中作为网络插件通过UDP、VXLAN、HOST-GATEWAY三种模式来解决容器跨主机网络通信的，并通过手动实现这三种模式深入理解其原理。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20230603100424.png"},{name:"twitter:title",content:"理解flannel的三种容器网络方案原理"},{name:"twitter:description",content:"本文主要介绍flannel在k8s网络中作为网络插件通过UDP、VXLAN、HOST-GATEWAY三种模式来解决容器跨主机网络通信的，并通过手动实现这三种模式深入理解其原理。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20230603100424.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/14.%E7%90%86%E8%A7%A3flannel%E7%9A%84%E4%B8%89%E7%A7%8D%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88%E5%8E%9F%E7%90%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"理解flannel的三种容器网络方案原理"},{property:"og:description",content:"本文主要介绍flannel在k8s网络中作为网络插件通过UDP、VXLAN、HOST-GATEWAY三种模式来解决容器跨主机网络通信的，并通过手动实现这三种模式深入理解其原理。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20230603100424.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/14.%E7%90%86%E8%A7%A3flannel%E7%9A%84%E4%B8%89%E7%A7%8D%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88%E5%8E%9F%E7%90%86.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-06-01T12:56:36.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{property:"article:tag",content:"计算机网络"},{property:"article:tag",content:"Linux网络虚拟化"},{itemprop:"name",content:"理解flannel的三种容器网络方案原理"},{itemprop:"description",content:"本文主要介绍flannel在k8s网络中作为网络插件通过UDP、VXLAN、HOST-GATEWAY三种模式来解决容器跨主机网络通信的，并通过手动实现这三种模式深入理解其原理。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20230603100424.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/14.%E7%90%86%E8%A7%A3flannel%E7%9A%84%E4%B8%89%E7%A7%8D%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88%E5%8E%9F%E7%90%86.html",relativePath:"01.云原生/07.k8s/14.理解flannel的三种容器网络方案原理.md",key:"v-44e743b8",path:"/pages/d9d0ce/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. flannel全局网络地址分配机制",slug:"_1-flannel全局网络地址分配机制",normalizedTitle:"1. flannel全局网络地址分配机制",charIndex:102},{level:2,title:"2. UDP模式",slug:"_2-udp模式",normalizedTitle:"2. udp模式",charIndex:353},{level:3,title:"2.1 简介",slug:"_2-1-简介",normalizedTitle:"2.1 简介",charIndex:366},{level:3,title:"2.2 flannel实现UDP流程",slug:"_2-2-flannel实现udp流程",normalizedTitle:"2.2 flannel实现udp流程",charIndex:542},{level:3,title:"2.3 手动模拟flannel实现udp实验",slug:"_2-3-手动模拟flannel实现udp实验",normalizedTitle:"2.3 手动模拟flannel实现udp实验",charIndex:975},{level:3,title:"2.4 分析",slug:"_2-4-分析",normalizedTitle:"2.4 分析",charIndex:4474},{level:2,title:"3. VXLAN模式",slug:"_3-vxlan模式",normalizedTitle:"3. vxlan模式",charIndex:5076},{level:3,title:"3.1 简介",slug:"_3-1-简介",normalizedTitle:"3.1 简介",charIndex:5091},{level:3,title:"3.3 flannel实现vxlan模式流程",slug:"_3-3-flannel实现vxlan模式流程",normalizedTitle:"3.3 flannel实现vxlan模式流程",charIndex:5396},{level:3,title:"3.4 手动模拟flanneld维护VTEP组实践",slug:"_3-4-手动模拟flanneld维护vtep组实践",normalizedTitle:"3.4 手动模拟flanneld维护vtep组实践",charIndex:5837},{level:2,title:"4. Host Gateway模式",slug:"_4-host-gateway模式",normalizedTitle:"4. host gateway模式",charIndex:8588},{level:3,title:"4.1 简介",slug:"_4-1-简介",normalizedTitle:"4.1 简介",charIndex:8610},{level:3,title:"4.3 flannel实现Host Gateway模式流程",slug:"_4-3-flannel实现host-gateway模式流程",normalizedTitle:"4.3 flannel实现host gateway模式流程",charIndex:8879},{level:3,title:"4.4 手动模拟flannel实现Host Gateway模式实验",slug:"_4-4-手动模拟flannel实现host-gateway模式实验",normalizedTitle:"4.4 手动模拟flannel实现host gateway模式实验",charIndex:9078},{level:2,title:"5. 巨人的肩膀",slug:"_5-巨人的肩膀",normalizedTitle:"5. 巨人的肩膀",charIndex:10926}],headersStr:"0. 前言 1. flannel全局网络地址分配机制 2. UDP模式 2.1 简介 2.2 flannel实现UDP流程 2.3 手动模拟flannel实现udp实验 2.4 分析 3. VXLAN模式 3.1 简介 3.3 flannel实现vxlan模式流程 3.4 手动模拟flanneld维护VTEP组实践 4. Host Gateway模式 4.1 简介 4.3 flannel实现Host Gateway模式流程 4.4 手动模拟flannel实现Host Gateway模式实验 5. 巨人的肩膀",content:'# 0. 前言\n\n本文主要介绍flannel在k8s网络中作为网络插件通过UDP、VXLAN、HOST-GATEWAY三种模式来解决容器跨主机网络通信的，并通过手动实现这三种模式深入理解其原理。\n\n\n# 1. flannel全局网络地址分配机制\n\n每台节点上容器的IP地址是由所属节点自动分配的，那么会存在一个问题是，不同节点上的容器所分配的IP地址则可能会有重复的情况。\n\nflannel设计了一种全局的网络地址分配机制，flannel会为每台节点申请一个独一无二的网段，并存储在etcd中，flannel会将该网段配置到各个节点上的Docker(或者其他容器工具)，当前节点上的容器 只从分配的网段里中获取IP地址。\n\n> 修改docker启动参数--bip来限制节点容器获得的IP范围。\n\n\n\n\n# 2. UDP模式\n\n\n# 2.1 简介\n\n在Flannel的UDP模式中，每个节点都会启动一个UDP服务器，用于监听来自其他节点的数据包。当一个容器向另一个容器发送数据包时，它会将数据包发送到目标容器的IP地址和端口号。Flannel会将该数据包封装在一个UDP数据包中，并将其发送到目标节点的UDP服务器。目标节点的UDP服务器会解析该数据包，并将其传递给目标容器。\n\n\n# 2.2 flannel实现UDP流程\n\n\n\nflanneld启动后会通过打开/dev/net/tun的方式创建tun设备，名称为flannel0，该设备是用户空间与内核空间的数据包交互的通道。然后再将从tun设备获取的IP数据包封装到UDP数据包中通过物理网卡发送到其他节点中，内核通过UDP端口转发给flanneld然后解包，得到其中的IP数据包，然后再通过tun设备进入内核空间中，通过路由到达网桥，然后再到目的容器中。\n\nflanneld在其中主要做了：\n\n 1. 开启了udp服务，并对udp数据包封包和解包\n 2. 节点上路由表的动态更新，也就是从网桥出来的数据包目的IP为其他节点容器IP时，需要路由到flanneld中进行封包，并且在flanneld接收UDP包后解封出来的IP包需要通过路由到网桥docker0中\n\n缺点很明显，仅一次网络传输的数据包经历了2次用户态与内核态的切换，而切换的效率是不高的，每一次的切换都是一次数据的复制。\n\n\n\n\n# 2.3 手动模拟flannel实现udp实验\n\n首先创建Network Namesapce net1用来模拟容器\n\nip netns add net1\n\n\n1\n\n\n然后创建一对veth pair网卡veth0和veth1，并将veth0放到net1中，拉起并设置veth0的ip地址为172.19.1.2/24\n\nip link add veth0 type veth peer name veth1\n\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n\n1\n2\n3\n4\n5\n\n\n创建网桥设备，拉起并设置ip地址为172.19.1.1/24，将veth1拉起并绑定到网桥bridge0中\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.1.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n在net1中添加默认路由，设置下一条地址为网桥bridge0的IP地址，从网桥进入到宿主机的网络协议栈中。\n\nip netns exec net1 ip r add default via 172.19.1.1 dev veth0\n\n\n1\n\n\n再运行以下代码，该代码是用来模拟flanneld程序，主要作用是创建了tun设备flannel0，开启了UDP服务收发UDP包，然后就是对容器IP包的封装与解封。\n\nimport os\nimport socket\nimport struct\nimport threading\nfrom fcntl import ioctl\nimport click\n\nBIND_ADDRESS = (\'0.0.0.0\', 8285)\nBUFFER_SIZE = 4096\n\nTUNSETIFF = 0x400454ca\nIFF_TUN = 0x0001\nIFF_TAP = 0x0002\n\n\ndef create_tunnel(tun_name=\'flannel%d\', tun_mode=IFF_TUN):\n    tun_fd = os.open("/dev/net/tun", os.O_RDWR)\n    ifn = ioctl(tun_fd, TUNSETIFF, struct.pack(b"16sH", tun_name.encode(), tun_mode))\n    tun_name = ifn[:16].decode().strip("\\x00")\n    return tun_fd, tun_name\n\n\ndef start_tunnel(tun_name):\n    os.popen(f"ip link set {tun_name} up")\n\n\ndef udp_server(udp_socket, tun_fd):\n    while True:\n        data, addr = udp_socket.recvfrom(2048)\n        print("get data from udp.")\n        if not data:\n            break\n\n        os.write(tun_fd, data)\n\n\n@click.command()\n@click.option("--peer_node_ip", "-p", required=True, help="对端节点IP")\ndef main(peer_node_ip):\n    peer_node_addr = (peer_node_ip, 7000)\n\n    tun_fd, tun_name = create_tunnel()\n    start_tunnel(tun_name)\n\n    udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    udp_socket.bind(BIND_ADDRESS)\n\n    t = threading.Thread(target=udp_server, args=(udp_socket, tun_fd))\n    t.daemon = True\n    t.start()\n\n    while True:\n        data = os.read(tun_fd, BUFFER_SIZE)\n        print(f"get data from tun. data size = {len(data)}")\n        udp_socket.sendto(data, peer_node_addr)\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n\n\n在Node1中运行该程序，设置Node2 IP\n\npython3 tun_app.py -p 10.65.132.188\n\n\n1\n\n\n可以看到已经创建了tun设备\n\n# ip link show flannel0\n...\n109: tun0: <POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 500\n    link/none \n    inet6 fe80::8e98:91a4:6537:d77a/64 scope link flags 800 \n       valid_lft forever preferred_lft forever\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n在设置宿主机的路由，将所有到Node2容器的IP包，都转发到flannel0设备中。\n\nip r add 172.19.2.0/24 dev flannel0\n\n\n1\n\n\n最后重复Node1的操作配置Node2\n\n# 创建net3\nip netns add net3\n\n# 创建veth pair\nip link add veth0 type veth peer name veth1\n\n# 设置net1网络\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.2.2/24 dev veth0\nip netns exec net3 ip link set veth0 up\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.2.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n# 配置net3路由\nip netns exec net3 ip r add default via 172.19.2.1 dev veth0\n\n# 创建flannel0\npython3 flanneld.py -p 10.65.132.187\n\n# 配置到flannel0的路由\nip r add 172.19.1.0/24 dev flannel0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# 2.4 分析\n\n在Node1的net1中ping Node2的net2的ip 172.19.2.2，可以看到是可以ping通的\n\n# ping 172.19.2.2 -c 1\nPING 172.19.2.2 (172.19.2.2) 56(84) bytes of data.\n64 bytes from 172.19.2.2: icmp_seq=1 ttl=63 time=0.641 ms\n\n--- 172.19.2.2 ping statistics ---\n1 packets transmitted, 1 received, 0% packet loss, time 0ms\nrtt min/avg/max/mdev = 0.641/0.641/0.641/0.000 ms\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n在Node1的flanneld.py中看到日志，从tun中收到了来自容器的IP数据包\n\n# python3 flanneld.py -p 10.65.132.188\nget data from tun. data size = 88\n\n\n1\n2\n\n\n在Node2的flanneld.py中看到日志，接收到了Node1发送过来的udp数据包。\n\n# python3 flanneld.py -p 10.65.132.187\nget data from udp.\n\n\n1\n2\n\n\n\n# 3. VXLAN模式\n\n\n# 3.1 简介\n\n在Flannel的VXLAN模式中，每个节点都会启动一个VXLAN隧道，用于将容器之间的数据包封装在VXLAN协议中进行传输。当一个容器向另一个容器发送数据包时，它会将数据包发送到目标容器的IP地址和虚拟网络ID。Flannel会将该数据包封装在一个VXLAN数据包中，并将其发送到目标节点的VXLAN隧道。目标节点的VXLAN隧道会解析该数据包，并将其传递给目标容器。\n\nvxlan模式也是通过封包与解包的形式来实现隧道达到容器的跨主机访问，那和UDP模式有什么区别呢？ 区别在于，VXLAN的封包与解包都是在内核态完成的，对比UDP模式用户态与内核态的切换来说，效率大大的提升了。\n\n\n# 3.3 flannel实现vxlan模式流程\n\n\n\n在Node1的net1中ping Node2的net3，数据流如下：\n\n 1. bridge作为net1的下一跳网关，所以会先发送ARP获取bridge的mac地址\n 2. 获取到后，然后发送ICMP数据包通过bridge进入到宿主机的网络协议栈中，通过路由表，会进入到flannel.1中，下一跳地址为Node2的flannel.1的地址\n 3. 本来是要发送ARP来获取Node2的flannel.1的地址，因为已经手动配置了ARP表，可以直接获取到到MAC地址，然后将其填充内层二层头中。\n 4. 再通过查询FDB表，找到外层UDP包中目的IP地址，也就是Node2的IP地址，填充到外部IP头中。最终通过物理网卡ens18走外部网络达到Node2中。\n 5. 达到Node2后，通过端口8472，将包转发给VTEP设备flannel.1进行解包，解封后的IP包经过路由表达到bridge中，最终转发到net3中。\n\n\n# 3.4 手动模拟flanneld维护VTEP组实践\n\n创建VTEP设备命名为flannel.1，然后flannel.1配置ip地址为172.19.1.0/32\n\n# 添加VTEP设备\nip link add flannel.1 type vxlan id 42 dstport 8472 local 10.65.132.187 dev ens18 nolearning proxy\n\n# 配置flannel.1\nip link set flannel.1 up\nip a add 172.19.1.0/32 dev flannel.1\n\n\n1\n2\n3\n4\n5\n6\n\n * 只需要填写local地址\n * nolearning，VTEP不要通过收到的报文学习FDB表项的内容，减少广播风暴，提高效率。\n * proxy，VTEP承担ARP代理功能，收到ARP请求时，如果有缓存则直接应答，减少广播风暴，提高效率。\n\n添加network namespace net1，创建veth pair，将其中一端放进net1中，并配置好ip地址，再添加默认路由都走veth0\n\nip netns add net1\nip link add veth0 type veth peer name veth1\nip link set dev veth0 up\n\n# 设置net1中网络配置\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n# 默认路由\nip netns exec net1 ip r add default via 172.19.1.1 dev veth0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n创建网桥设备命名为bridge0，并将veth1插到其上\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.1.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n到达net3的数据包下一跳为Node2的VTEP设备IP通过flannel.1设备，需要添加onlink，因为下一跳网关不和本地地址在同一网段，路由添加时输出路由不可达的错误，onlink的意义在于协议栈虽然找不到链路层直连路由，但是还是会发布针对via网关的arp请求的.\n\nip r add 172.19.2.0/24 via 172.19.2.0 dev flannel.1 onlink\n\n\n1\n\n\n在Node2节点中重复上面操作创建VETP设备和相关网络配置\n\n# 添加VTEP设备\nip link add flannel.1 type vxlan id 42 dstport 8472 local 10.65.132.188 dev ens18\nip link set flannel.1 up\nip a add 172.19.2.0/32 dev flannel.1\nip r add 172.19.1.0/24 via 172.19.1.0 dev flannel.1 onlink\n\n\n# 添加net3模拟容器\nip netns add net3\nip link add veth0 type veth peer name veth1\n\n# 设置net3中网络配置\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.2.2/24 dev veth0\nip netns exec net3 ip link set veth0 up\nip netns exec net3 ip r add default dev veth0\nip netns exec net3 ip r add default via 172.19.2.1 dev veth0\n\n# 添加网桥\nip link add bridge0 type bridge\nip a add 172.19.2.1/24 dev bridge0\nip link set bridge0 up\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n在Node1节点中需要再新增ARP缓存，Node1中添加路由的下一跳地址是Node2的VTEP设备，所以需要在arp添加VTEP IP和MAC地址的缓存。\n\narp -s 172.19.2.0 8a:8b:4d:10:82:56 dev flannel.1\n\n\n1\n\n\n再在节点FDB表中添加对端VETP MAC地址和对外IP（物理网卡IP）的映射关系表项\n\nbridge fdb add 8a:8b:4d:10:82:56 dev flannel.1 dst 10.65.132.188\n\n\n1\n\n\n重复Node1操作，配置Node2的ARP缓存和FDB表。\n\narp -s 172.19.1.0 1e:b7:5e:19:ab:90 dev flannel.1\nbridge fdb add 1e:b7:5e:19:ab:90 dev flannel.1 dst 10.65.132.187\n\n\n1\n2\n\n\n通过以上操作完成了环境的搭建，接下来，我们在Node1的net1中进行ping Node2的net3，可以发现是可以ping通的\n\n# ip netns exec net1 ping 172.19.2.2 -c 2\nPING 172.19.2.2 (172.19.2.2) 56(84) bytes of data.\n64 bytes from 172.19.2.2: icmp_seq=1 ttl=62 time=0.547 ms\n64 bytes from 172.19.2.2: icmp_seq=2 ttl=62 time=0.560 ms\n\n\n1\n2\n3\n4\n\n\n\n# 4. Host Gateway模式\n\n\n# 4.1 简介\n\n通过把主机当作网关实现跨节点网络通信的。因此通信双方的宿主机要求能够直接路由，必须在同一个网络，这个限制使得host-gw模式无法适用于集群规模较大且需要对节点进行网段划分的场景。host-gw的另外一个限制则是随着集群中节点规模的增大，flanneld维护主机上成千上万条路由表的动态更新也是一个不小的压力。\n\nflanneld的唯一作用就是负责主机上路由表的动态，但因为只能修改主机的路由，所以各个主机必须二层网络互通。\n\n跟VXLAN模式和UDP模式比较，优点主要是没有封包与解包的操作，大大的提高了性能。\n\n\n# 4.3 flannel实现Host Gateway模式流程\n\n\n\n在Node1的net1中ping Node2的net3，数据流如下：\n\n 1. 数据包从容器进入到宿主机网络协议栈逻辑与VXLAN模式一致\n 2. 通过路由表可知，该数据包通过ens18网卡到达下一跳网关Node2的ens18\n 3. 通过物理网络，达到Node2并进入网络协议栈，通过路由达到bridge进入到net3中\n\n\n# 4.4 手动模拟flannel实现Host Gateway模式实验\n\n在Node1中创建Network Namesapce net1、vethpair和网桥，并配置好其网络。\n\nip netns add net1\nip link add veth0 type veth peer name veth1\nip link set dev veth0 up\n\n# 设置net1中网络配置\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n# 默认路由\nip netns exec net1 ip r add default via 172.19.1.1 dev veth0\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.1.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n再添加路由，将Node2所分配到的容器网段为目的数据包都将Node2作为下一跳网关。\n\nip r add 172.19.2.0/24 via 10.65.132.188 dev ens18\n\n\n1\n\n\n重复Node1的配置，并添加将Node1所分配到的容器网段为目的数据包都将Node1作为下一跳网关。\n\n# 添加net3模拟容器\nip netns add net3\nip link add veth0 type veth peer name veth1\n\n# 设置net3中网络配置\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.2.2/24 dev veth0\nip netns exec net3 ip link set veth0 up\nip netns exec net3 ip r add default via 172.19.2.1 dev veth0\n\n# 添加网桥\nip link add bridge0 type bridge\nip a add 172.19.2.1/24 dev bridge0\nip link set bridge0 up\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n# 路由\nip r add 172.19.1.0/24 via 10.65.132.187 dev ens18\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n在Node1的net1中ping Node2的net2，是可以ping通的，说明网络互通了。\n\n在通过tcpdump抓取Node2 ens18网卡的包，可以看到ICMP数据包到了Node2节点。\n\n# tcpdump -i ens18 host 172.19.2.2\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type EN10MB (Ethernet), capture size 262144 bytes\n15:07:00.072677 IP 172.19.1.2 > 172.19.2.2: ICMP echo request, id 52240, seq 8, length 64\n15:07:00.072782 IP 172.19.2.2 > 172.19.1.2: ICMP echo reply, id 52240, seq 8, length 64\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 5. 巨人的肩膀\n\n * Flannel Vxlan封包原理剖析\n * 《kubernetes网络权威指南》\n * 《极客时间-深入剖析Kubernetes》',normalizedContent:'# 0. 前言\n\n本文主要介绍flannel在k8s网络中作为网络插件通过udp、vxlan、host-gateway三种模式来解决容器跨主机网络通信的，并通过手动实现这三种模式深入理解其原理。\n\n\n# 1. flannel全局网络地址分配机制\n\n每台节点上容器的ip地址是由所属节点自动分配的，那么会存在一个问题是，不同节点上的容器所分配的ip地址则可能会有重复的情况。\n\nflannel设计了一种全局的网络地址分配机制，flannel会为每台节点申请一个独一无二的网段，并存储在etcd中，flannel会将该网段配置到各个节点上的docker(或者其他容器工具)，当前节点上的容器 只从分配的网段里中获取ip地址。\n\n> 修改docker启动参数--bip来限制节点容器获得的ip范围。\n\n\n\n\n# 2. udp模式\n\n\n# 2.1 简介\n\n在flannel的udp模式中，每个节点都会启动一个udp服务器，用于监听来自其他节点的数据包。当一个容器向另一个容器发送数据包时，它会将数据包发送到目标容器的ip地址和端口号。flannel会将该数据包封装在一个udp数据包中，并将其发送到目标节点的udp服务器。目标节点的udp服务器会解析该数据包，并将其传递给目标容器。\n\n\n# 2.2 flannel实现udp流程\n\n\n\nflanneld启动后会通过打开/dev/net/tun的方式创建tun设备，名称为flannel0，该设备是用户空间与内核空间的数据包交互的通道。然后再将从tun设备获取的ip数据包封装到udp数据包中通过物理网卡发送到其他节点中，内核通过udp端口转发给flanneld然后解包，得到其中的ip数据包，然后再通过tun设备进入内核空间中，通过路由到达网桥，然后再到目的容器中。\n\nflanneld在其中主要做了：\n\n 1. 开启了udp服务，并对udp数据包封包和解包\n 2. 节点上路由表的动态更新，也就是从网桥出来的数据包目的ip为其他节点容器ip时，需要路由到flanneld中进行封包，并且在flanneld接收udp包后解封出来的ip包需要通过路由到网桥docker0中\n\n缺点很明显，仅一次网络传输的数据包经历了2次用户态与内核态的切换，而切换的效率是不高的，每一次的切换都是一次数据的复制。\n\n\n\n\n# 2.3 手动模拟flannel实现udp实验\n\n首先创建network namesapce net1用来模拟容器\n\nip netns add net1\n\n\n1\n\n\n然后创建一对veth pair网卡veth0和veth1，并将veth0放到net1中，拉起并设置veth0的ip地址为172.19.1.2/24\n\nip link add veth0 type veth peer name veth1\n\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n\n1\n2\n3\n4\n5\n\n\n创建网桥设备，拉起并设置ip地址为172.19.1.1/24，将veth1拉起并绑定到网桥bridge0中\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.1.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n在net1中添加默认路由，设置下一条地址为网桥bridge0的ip地址，从网桥进入到宿主机的网络协议栈中。\n\nip netns exec net1 ip r add default via 172.19.1.1 dev veth0\n\n\n1\n\n\n再运行以下代码，该代码是用来模拟flanneld程序，主要作用是创建了tun设备flannel0，开启了udp服务收发udp包，然后就是对容器ip包的封装与解封。\n\nimport os\nimport socket\nimport struct\nimport threading\nfrom fcntl import ioctl\nimport click\n\nbind_address = (\'0.0.0.0\', 8285)\nbuffer_size = 4096\n\ntunsetiff = 0x400454ca\niff_tun = 0x0001\niff_tap = 0x0002\n\n\ndef create_tunnel(tun_name=\'flannel%d\', tun_mode=iff_tun):\n    tun_fd = os.open("/dev/net/tun", os.o_rdwr)\n    ifn = ioctl(tun_fd, tunsetiff, struct.pack(b"16sh", tun_name.encode(), tun_mode))\n    tun_name = ifn[:16].decode().strip("\\x00")\n    return tun_fd, tun_name\n\n\ndef start_tunnel(tun_name):\n    os.popen(f"ip link set {tun_name} up")\n\n\ndef udp_server(udp_socket, tun_fd):\n    while true:\n        data, addr = udp_socket.recvfrom(2048)\n        print("get data from udp.")\n        if not data:\n            break\n\n        os.write(tun_fd, data)\n\n\n@click.command()\n@click.option("--peer_node_ip", "-p", required=true, help="对端节点ip")\ndef main(peer_node_ip):\n    peer_node_addr = (peer_node_ip, 7000)\n\n    tun_fd, tun_name = create_tunnel()\n    start_tunnel(tun_name)\n\n    udp_socket = socket.socket(socket.af_inet, socket.sock_dgram)\n    udp_socket.bind(bind_address)\n\n    t = threading.thread(target=udp_server, args=(udp_socket, tun_fd))\n    t.daemon = true\n    t.start()\n\n    while true:\n        data = os.read(tun_fd, buffer_size)\n        print(f"get data from tun. data size = {len(data)}")\n        udp_socket.sendto(data, peer_node_addr)\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n\n\n在node1中运行该程序，设置node2 ip\n\npython3 tun_app.py -p 10.65.132.188\n\n\n1\n\n\n可以看到已经创建了tun设备\n\n# ip link show flannel0\n...\n109: tun0: <pointopoint,multicast,noarp,up,lower_up> mtu 1500 qdisc pfifo_fast state unknown group default qlen 500\n    link/none \n    inet6 fe80::8e98:91a4:6537:d77a/64 scope link flags 800 \n       valid_lft forever preferred_lft forever\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n在设置宿主机的路由，将所有到node2容器的ip包，都转发到flannel0设备中。\n\nip r add 172.19.2.0/24 dev flannel0\n\n\n1\n\n\n最后重复node1的操作配置node2\n\n# 创建net3\nip netns add net3\n\n# 创建veth pair\nip link add veth0 type veth peer name veth1\n\n# 设置net1网络\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.2.2/24 dev veth0\nip netns exec net3 ip link set veth0 up\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.2.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n# 配置net3路由\nip netns exec net3 ip r add default via 172.19.2.1 dev veth0\n\n# 创建flannel0\npython3 flanneld.py -p 10.65.132.187\n\n# 配置到flannel0的路由\nip r add 172.19.1.0/24 dev flannel0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# 2.4 分析\n\n在node1的net1中ping node2的net2的ip 172.19.2.2，可以看到是可以ping通的\n\n# ping 172.19.2.2 -c 1\nping 172.19.2.2 (172.19.2.2) 56(84) bytes of data.\n64 bytes from 172.19.2.2: icmp_seq=1 ttl=63 time=0.641 ms\n\n--- 172.19.2.2 ping statistics ---\n1 packets transmitted, 1 received, 0% packet loss, time 0ms\nrtt min/avg/max/mdev = 0.641/0.641/0.641/0.000 ms\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n在node1的flanneld.py中看到日志，从tun中收到了来自容器的ip数据包\n\n# python3 flanneld.py -p 10.65.132.188\nget data from tun. data size = 88\n\n\n1\n2\n\n\n在node2的flanneld.py中看到日志，接收到了node1发送过来的udp数据包。\n\n# python3 flanneld.py -p 10.65.132.187\nget data from udp.\n\n\n1\n2\n\n\n\n# 3. vxlan模式\n\n\n# 3.1 简介\n\n在flannel的vxlan模式中，每个节点都会启动一个vxlan隧道，用于将容器之间的数据包封装在vxlan协议中进行传输。当一个容器向另一个容器发送数据包时，它会将数据包发送到目标容器的ip地址和虚拟网络id。flannel会将该数据包封装在一个vxlan数据包中，并将其发送到目标节点的vxlan隧道。目标节点的vxlan隧道会解析该数据包，并将其传递给目标容器。\n\nvxlan模式也是通过封包与解包的形式来实现隧道达到容器的跨主机访问，那和udp模式有什么区别呢？ 区别在于，vxlan的封包与解包都是在内核态完成的，对比udp模式用户态与内核态的切换来说，效率大大的提升了。\n\n\n# 3.3 flannel实现vxlan模式流程\n\n\n\n在node1的net1中ping node2的net3，数据流如下：\n\n 1. bridge作为net1的下一跳网关，所以会先发送arp获取bridge的mac地址\n 2. 获取到后，然后发送icmp数据包通过bridge进入到宿主机的网络协议栈中，通过路由表，会进入到flannel.1中，下一跳地址为node2的flannel.1的地址\n 3. 本来是要发送arp来获取node2的flannel.1的地址，因为已经手动配置了arp表，可以直接获取到到mac地址，然后将其填充内层二层头中。\n 4. 再通过查询fdb表，找到外层udp包中目的ip地址，也就是node2的ip地址，填充到外部ip头中。最终通过物理网卡ens18走外部网络达到node2中。\n 5. 达到node2后，通过端口8472，将包转发给vtep设备flannel.1进行解包，解封后的ip包经过路由表达到bridge中，最终转发到net3中。\n\n\n# 3.4 手动模拟flanneld维护vtep组实践\n\n创建vtep设备命名为flannel.1，然后flannel.1配置ip地址为172.19.1.0/32\n\n# 添加vtep设备\nip link add flannel.1 type vxlan id 42 dstport 8472 local 10.65.132.187 dev ens18 nolearning proxy\n\n# 配置flannel.1\nip link set flannel.1 up\nip a add 172.19.1.0/32 dev flannel.1\n\n\n1\n2\n3\n4\n5\n6\n\n * 只需要填写local地址\n * nolearning，vtep不要通过收到的报文学习fdb表项的内容，减少广播风暴，提高效率。\n * proxy，vtep承担arp代理功能，收到arp请求时，如果有缓存则直接应答，减少广播风暴，提高效率。\n\n添加network namespace net1，创建veth pair，将其中一端放进net1中，并配置好ip地址，再添加默认路由都走veth0\n\nip netns add net1\nip link add veth0 type veth peer name veth1\nip link set dev veth0 up\n\n# 设置net1中网络配置\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n# 默认路由\nip netns exec net1 ip r add default via 172.19.1.1 dev veth0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n创建网桥设备命名为bridge0，并将veth1插到其上\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.1.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n到达net3的数据包下一跳为node2的vtep设备ip通过flannel.1设备，需要添加onlink，因为下一跳网关不和本地地址在同一网段，路由添加时输出路由不可达的错误，onlink的意义在于协议栈虽然找不到链路层直连路由，但是还是会发布针对via网关的arp请求的.\n\nip r add 172.19.2.0/24 via 172.19.2.0 dev flannel.1 onlink\n\n\n1\n\n\n在node2节点中重复上面操作创建vetp设备和相关网络配置\n\n# 添加vtep设备\nip link add flannel.1 type vxlan id 42 dstport 8472 local 10.65.132.188 dev ens18\nip link set flannel.1 up\nip a add 172.19.2.0/32 dev flannel.1\nip r add 172.19.1.0/24 via 172.19.1.0 dev flannel.1 onlink\n\n\n# 添加net3模拟容器\nip netns add net3\nip link add veth0 type veth peer name veth1\n\n# 设置net3中网络配置\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.2.2/24 dev veth0\nip netns exec net3 ip link set veth0 up\nip netns exec net3 ip r add default dev veth0\nip netns exec net3 ip r add default via 172.19.2.1 dev veth0\n\n# 添加网桥\nip link add bridge0 type bridge\nip a add 172.19.2.1/24 dev bridge0\nip link set bridge0 up\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n在node1节点中需要再新增arp缓存，node1中添加路由的下一跳地址是node2的vtep设备，所以需要在arp添加vtep ip和mac地址的缓存。\n\narp -s 172.19.2.0 8a:8b:4d:10:82:56 dev flannel.1\n\n\n1\n\n\n再在节点fdb表中添加对端vetp mac地址和对外ip（物理网卡ip）的映射关系表项\n\nbridge fdb add 8a:8b:4d:10:82:56 dev flannel.1 dst 10.65.132.188\n\n\n1\n\n\n重复node1操作，配置node2的arp缓存和fdb表。\n\narp -s 172.19.1.0 1e:b7:5e:19:ab:90 dev flannel.1\nbridge fdb add 1e:b7:5e:19:ab:90 dev flannel.1 dst 10.65.132.187\n\n\n1\n2\n\n\n通过以上操作完成了环境的搭建，接下来，我们在node1的net1中进行ping node2的net3，可以发现是可以ping通的\n\n# ip netns exec net1 ping 172.19.2.2 -c 2\nping 172.19.2.2 (172.19.2.2) 56(84) bytes of data.\n64 bytes from 172.19.2.2: icmp_seq=1 ttl=62 time=0.547 ms\n64 bytes from 172.19.2.2: icmp_seq=2 ttl=62 time=0.560 ms\n\n\n1\n2\n3\n4\n\n\n\n# 4. host gateway模式\n\n\n# 4.1 简介\n\n通过把主机当作网关实现跨节点网络通信的。因此通信双方的宿主机要求能够直接路由，必须在同一个网络，这个限制使得host-gw模式无法适用于集群规模较大且需要对节点进行网段划分的场景。host-gw的另外一个限制则是随着集群中节点规模的增大，flanneld维护主机上成千上万条路由表的动态更新也是一个不小的压力。\n\nflanneld的唯一作用就是负责主机上路由表的动态，但因为只能修改主机的路由，所以各个主机必须二层网络互通。\n\n跟vxlan模式和udp模式比较，优点主要是没有封包与解包的操作，大大的提高了性能。\n\n\n# 4.3 flannel实现host gateway模式流程\n\n\n\n在node1的net1中ping node2的net3，数据流如下：\n\n 1. 数据包从容器进入到宿主机网络协议栈逻辑与vxlan模式一致\n 2. 通过路由表可知，该数据包通过ens18网卡到达下一跳网关node2的ens18\n 3. 通过物理网络，达到node2并进入网络协议栈，通过路由达到bridge进入到net3中\n\n\n# 4.4 手动模拟flannel实现host gateway模式实验\n\n在node1中创建network namesapce net1、vethpair和网桥，并配置好其网络。\n\nip netns add net1\nip link add veth0 type veth peer name veth1\nip link set dev veth0 up\n\n# 设置net1中网络配置\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n# 默认路由\nip netns exec net1 ip r add default via 172.19.1.1 dev veth0\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.1.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n再添加路由，将node2所分配到的容器网段为目的数据包都将node2作为下一跳网关。\n\nip r add 172.19.2.0/24 via 10.65.132.188 dev ens18\n\n\n1\n\n\n重复node1的配置，并添加将node1所分配到的容器网段为目的数据包都将node1作为下一跳网关。\n\n# 添加net3模拟容器\nip netns add net3\nip link add veth0 type veth peer name veth1\n\n# 设置net3中网络配置\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.2.2/24 dev veth0\nip netns exec net3 ip link set veth0 up\nip netns exec net3 ip r add default via 172.19.2.1 dev veth0\n\n# 添加网桥\nip link add bridge0 type bridge\nip a add 172.19.2.1/24 dev bridge0\nip link set bridge0 up\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n# 路由\nip r add 172.19.1.0/24 via 10.65.132.187 dev ens18\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n在node1的net1中ping node2的net2，是可以ping通的，说明网络互通了。\n\n在通过tcpdump抓取node2 ens18网卡的包，可以看到icmp数据包到了node2节点。\n\n# tcpdump -i ens18 host 172.19.2.2\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type en10mb (ethernet), capture size 262144 bytes\n15:07:00.072677 ip 172.19.1.2 > 172.19.2.2: icmp echo request, id 52240, seq 8, length 64\n15:07:00.072782 ip 172.19.2.2 > 172.19.1.2: icmp echo reply, id 52240, seq 8, length 64\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 5. 巨人的肩膀\n\n * flannel vxlan封包原理剖析\n * 《kubernetes网络权威指南》\n * 《极客时间-深入剖析kubernetes》',charsets:{cjk:!0},lastUpdated:"2023/06/06, 18:33:56",lastUpdatedTimestamp:1686047636e3},{title:"kubernetes service如何通过iptables转发",frontmatter:{title:"kubernetes service如何通过iptables转发",date:"2024-01-18T16:40:30.000Z",permalink:"/pages/b3955c/",categories:["云原生","k8s"],tags:["k8s","计算机网络"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文主要是介绍kubernetes的service是如何利用iptables来进行流量的转发达到流量的负载均衡的，并会通过实践操作来更好的理解与验证其原理。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/image-20240110142336-wl40wxw.png"},{name:"twitter:title",content:"kubernetes service如何通过iptables转发"},{name:"twitter:description",content:"本文主要是介绍kubernetes的service是如何利用iptables来进行流量的转发达到流量的负载均衡的，并会通过实践操作来更好的理解与验证其原理。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/image-20240110142336-wl40wxw.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/16.kubernetes%20service%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87iptables%E8%BD%AC%E5%8F%91.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kubernetes service如何通过iptables转发"},{property:"og:description",content:"本文主要是介绍kubernetes的service是如何利用iptables来进行流量的转发达到流量的负载均衡的，并会通过实践操作来更好的理解与验证其原理。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/image-20240110142336-wl40wxw.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/16.kubernetes%20service%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87iptables%E8%BD%AC%E5%8F%91.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2024-01-18T16:40:30.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"计算机网络"},{itemprop:"name",content:"kubernetes service如何通过iptables转发"},{itemprop:"description",content:"本文主要是介绍kubernetes的service是如何利用iptables来进行流量的转发达到流量的负载均衡的，并会通过实践操作来更好的理解与验证其原理。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/image-20240110142336-wl40wxw.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/16.kubernetes%20service%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87iptables%E8%BD%AC%E5%8F%91.html",relativePath:"01.云原生/07.k8s/16.kubernetes service如何通过iptables转发.md",key:"v-2f20c458",path:"/pages/b3955c/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:39},{level:2,title:"环境搭建",slug:"环境搭建",normalizedTitle:"环境搭建",charIndex:126},{level:2,title:"KUBE-SERVICES",slug:"kube-services",normalizedTitle:"kube-services",charIndex:2150},{level:2,title:"POSTROUTING",slug:"postrouting",normalizedTitle:"postrouting",charIndex:5322},{level:2,title:"SNAT",slug:"snat",normalizedTitle:"snat",charIndex:5941},{level:3,title:"为什么集群外部访问该service需要被SNAT？",slug:"为什么集群外部访问该service需要被snat",normalizedTitle:"为什么集群外部访问该service需要被snat？",charIndex:6449},{level:3,title:"conntrack",slug:"conntrack",normalizedTitle:"conntrack",charIndex:6624},{level:2,title:"源和目的IP相同",slug:"源和目的ip相同",normalizedTitle:"源和目的ip相同",charIndex:7440},{level:2,title:"NodePort",slug:"nodeport",normalizedTitle:"nodeport",charIndex:7954},{level:3,title:"搭建环境",slug:"搭建环境",normalizedTitle:"搭建环境",charIndex:132},{level:3,title:"请求clusterip",slug:"请求clusterip",normalizedTitle:"请求clusterip",charIndex:8672},{level:3,title:"请求节点IP",slug:"请求节点ip",normalizedTitle:"请求节点ip",charIndex:10190},{level:2,title:"参考链接",slug:"参考链接",normalizedTitle:"参考链接",charIndex:10887}],headersStr:"前言 环境搭建 KUBE-SERVICES POSTROUTING SNAT 为什么集群外部访问该service需要被SNAT？ conntrack 源和目的IP相同 NodePort 搭建环境 请求clusterip 请求节点IP 参考链接",content:"# kubernetes service如何通过iptables转发\n\n\n# 前言\n\n本文主要是介绍kubernetes的service是如何利用iptables来进行流量的转发达到流量的负载均衡的，并会通过实践操作来更好的理解与验证其原理。\n\n\n# 环境搭建\n\n搭建环境如下图所示：\n\n\n\n 1. 创建一个deploy，设置其副本数为3\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demoapp-deployment\n  labels:\n    app: demoapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: demoapp\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n        - name: ubuntu\n          image: ikubernetes/demoapp:v1.0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n 2. 创建service，为上面deployment的3个pod进行负载均衡访问\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: demoapp-service\nspec:\n  selector:\n    app: demoapp\n  clusterIP: 192.44.140.73\n  ports:\n    - name: http\n      protocol: TCP\n      port: 80\n      targetPort: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n 3. 验证\n\n创建完后，环境如下：\n\n# kubectl get pods -n zwf -o wide\nNAME                                  READY   STATUS    RESTARTS   AGE     IP\ndemoapp-deployment-64bdcb8666-4prbk   1/1     Running   0          7d17h   192.33.229.12   dmoc-fa163eee1e30\ndemoapp-deployment-64bdcb8666-cxmmz   1/1     Running   0          7d17h   192.33.73.139   dmoc-fa163e7188d6\ndemoapp-deployment-64bdcb8666-kkzsg   1/1     Running   0          7d17h   192.33.206.93   dmoc-fa163ee6bbe1\ndemoapp-pod                           1/1     Running   0          4d17h   192.33.73.172   dmoc-fa163e7188d6\n\n# kubectl get svc -n zwf\nNAME                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\ndemoapp-service            ClusterIP   192.44.140.73    <none>        80/TCP         7s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n可以直接在环境中请求service的clusterip地址，会随机访问到三个pod，输出的信息包含了请求IP和目的IP。\n\n# curl 192.44.140.73\niKubernetes demoapp v1.0 !! ClientIP: 10.10.10.16, ServerName: demoapp-deployment-64bdcb8666-kkzsg, ServerIP: 192.33.206.93!\n\n# curl 192.44.140.73\niKubernetes demoapp v1.0 !! ClientIP: 10.65.196.41, ServerName: demoapp-deployment-64bdcb8666-cxmmz, ServerIP: 192.33.73.139!\n\n# curl 192.44.140.73\niKubernetes demoapp v1.0 !! ClientIP: 10.10.10.16, ServerName: demoapp-deployment-64bdcb8666-4prbk, ServerIP: 192.33.229.12!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# KUBE-SERVICES\n\n在PREROUTING 和OUTPUT 链的nat表中，都包含了KUBE-SERVICES 子链，该子链中就包含了serivce的iptables规则的配置。\n\n# iptables -L PREROUTING -t nat\nChain PREROUTING (policy ACCEPT)\ntarget     prot opt source               destination       \nKUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */\ncali-PREROUTING  all  --  anywhere             anywhere             /* cali:6gwbT8clXdHdC1b1 */\n\n# iptables -L OUTPUT -t nat\nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination       \nKUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */\ncali-OUTPUT  all  --  anywhere             anywhere             /* cali:tVnHkvAo15HuiPy0 */\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n为什么在PREROUTING和OUTPUT链中添加service规则？\n\nservice的作用是负载均衡，也就是需要将IP包进行DNAT操作，而这个操作需要在最靠近发送的位置。网卡收到的包进入到网络协议栈时，最先进入的就是PREROUTING链，也就是节点外部的流量进入的入口。OUTPUT是本地进程发出的包最先进入的链。所以需要在这两条链中添加KUBE-SERVICES，详情可参考快速了解iptables\n\n为什么nat表？\n\n因为要做DNAT操作，所以在nat表。\n\nKUBE-SERVICES下面有许多KUBE-SVC-XXX的子链，每一条子链都是一个集群中一个service的配置，筛选一下\n\n通过筛选demoapp-service 得到下面的子链，只有访问目的地址为192.44.140.73才能进入到该子链中。\n\n# iptables -L KUBE-SERVICES -t nat | grep demoapp-service\nKUBE-SVC-FIHIHDNRZEG5VQEQ  tcp  --  anywhere             192.44.140.73        /* zwf/demoapp-service:http cluster IP */ tcp dpt:http\n\n\n1\n2\n\n\n查看UBE-SVC-FIHIHDNRZEG5VQEQ 链中内容，其中包含了四条子链。\n\n# iptables -L KUBE-SVC-FIHIHDNRZEG5VQEQ -t nat -n\nChain KUBE-SVC-FIHIHDNRZEG5VQEQ (1 references)\ntarget     prot opt source               destination       \nKUBE-MARK-MASQ  tcp  -- !192.33.0.0/16        192.44.140.73        /* zwf/demoapp-service:http cluster IP */ tcp dpt:80\nKUBE-SEP-FO7YK2K5DAKTCVSE  all  --  0.0.0.0/0            0.0.0.0/0            /* zwf/demoapp-service:http */ statistic mode random probability 0.33333333349\nKUBE-SEP-IPKL7NSNTVGKI4T5  all  --  0.0.0.0/0            0.0.0.0/0            /* zwf/demoapp-service:http */ statistic mode random probability 0.50000000000\nKUBE-SEP-BPER562ISF3UFYOQ  all  --  0.0.0.0/0            0.0.0.0/0            /* zwf/demoapp-service:http */\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n第一条链是，源IP不在192.33.0.0/16段、目的IP为192.44.140.73并且目的端口是80的数据包会匹配到该条子链进行跳转。其中192.33.0.0/16是pod的网段，如果不是集群内的流量，则会匹配上该条子链，会打上0x4000的标记。\n\n# iptables -L KUBE-MARK-MASQ -t nat -n\nChain KUBE-MARK-MASQ (548 references)\ntarget     prot opt source               destination       \nMARK       all  --  0.0.0.0/0            0.0.0.0/0            MARK or 0x4000\n\n\n1\n2\n3\n4\n\n\n后面的三条链是为了将流量随机的分配到任意一个pod中。第二条链代表着有1/3的概率会匹配到该链，而第三条链代表着1/2，最后一条链代表着百分百。\n\n看第二条链中的规则，第一条规则是跳转到子链KUBE-MARK-MASQ ，源IP为192.33.206.93的数据包打上了0x4000标记，再将目的IP DNAT成192.33.206.93，说明如果自己访问自己，也会被打上标记。\n\n这里的192.33.206.93是本身service所匹配上的pod IP地址，如果调用自己的service则会匹配上该链，打上0x4000标记。\n\n而第二条规则是一个DNAT操作，会将目标地址改为192.33.206.93:80，也就是pod的地址。\n\n # iptables -L KUBE-SEP-FO7YK2K5DAKTCVSE -t nat\nChain KUBE-SEP-FO7YK2K5DAKTCVSE (1 references)\ntarget     prot opt source               destination   \nKUBE-MARK-MASQ  all  --  192.33.206.93        anywhere             /* zwf/demoapp-service:http */\nDNAT       tcp  --  anywhere             anywhere             /* zwf/demoapp-service:http */ tcp to:192.33.206.93:80\n\n\n1\n2\n3\n4\n5\n\n\n剩下的第3、4条规则也是一样的操作，会将流量DNAT到对应的pod中。\n\n\n# POSTROUTING\n\nPOSTROUTING中包含了一条KUBE-POSTROUTING子链，子链也是由kube-porxy来写入的。\n\n# iptables -L POSTROUTING -t nat\nChain POSTROUTING (policy ACCEPT)\ntarget     prot opt source               destination       \nKUBE-POSTROUTING  all  --  anywhere             anywhere             /* kubernetes postrouting rules */\ncali-POSTROUTING  all  --  anywhere             anywhere             /* cali:O3lYWMrLQYEMJtB5 */\n\n\n1\n2\n3\n4\n5\n\n\n查看子链KUBE-POSTROUTING 内容：\n\n 1. 第一条规则是没有标记为0x400的数据包会return，不执行下面的子链。还记得在KUBE-PREROUTING 中有两次打上0x4000标记，代表着访问是集群外部访问该service或者是源和目的一样，都会往下走。\n 2. 第二条规则是对数据包的标记值进行异或，而这里是0x4000与0x4000进行异或，也就是0\n 3. 第三条规则时对该数据包进行SNAT，random-fully是对源端口进行随机获取。\n\n# iptables -L KUBE-POSTROUTING -t nat\nChain KUBE-POSTROUTING (1 references)\ntarget     prot opt source               destination       \nRETURN     all  --  anywhere             anywhere             mark match ! 0x4000/0x4000\nMARK       all  --  anywhere             anywhere             MARK xor 0x4000\nMASQUERADE  all  --  anywhere             anywhere             /* kubernetes service traffic requiring SNAT */ random-fully\n\n\n1\n2\n3\n4\n5\n6\n\n\n这里有两种情况会被SNAT，说说为什么。\n\n\n# SNAT\n\n\n# 为什么集群外部访问该service需要被SNAT？\n\n数据包需要回包，如果没有SNAT，那么回包的目的IP是客户端的IP，而源IP是Pod的IP，而客户端并不认该数据包，则会被丢弃。\n\n‍\n\n如果有发生SNAT，那么回包的时候可以回到Node1的节点，再回到client。\n\n‍\n\n但问题又来了，是怎么从Node1再回包到client的呢？\n\n\n# conntrack\n\nconntrack是一个追踪表，在每一个数据包进入到netfilter的时候，都会记录一条记录，当我们进行SNAT和DNAT的时候也都会更新该表中的记录。\n\n所以在Node1回包给client时候，可以通过查询这个表中的记录，然后再次SNAT和DNAT恢复回去就可以进行正常的回包了。\n\n\n\n可以看下conntrack里面的记录长什么样子。\n\n先在某一台节点上curl service的ip，上图的client其实也是在Node1上的，因为Node1上有两张网卡，Node1和Node2的通信使用的网卡eth2 ip为10.10.10.16，因为转发到其他节点，所以会被SNAT。\n\n# curl 192.44.140.73\niKubernetes demoapp v1.0 !! ClientIP: 10.10.10.16, ServerName: demoapp-deployment-64bdcb8666-4prbk, ServerIP: 192.33.229.12!\n\n\n1\n2\n\n\n这里主要是看src和dst分别是client请求service的目的IP，然后后面又有一个src和dst它是由Node2回包给Node1的源和目的IP，也就是源是pod的IP，dst是Node1节点IP。\n\n前面是发送包的方向，后面是回包的方向。通过查询该表，即可以从Node1回包给client\n\n# conntrack -L | grep 192.33.229.12\ntcp      6 107 TIME_WAIT src=10.65.196.41 dst=192.44.140.73 sport=33468 dport=80 src=192.33.229.12 dst=10.10.10.16 sport=80 dport=18623 [ASSURED] mark=0 use=1\n\n\n1\n2\n\n\n‍\n\n\n# 源和目的IP相同\n\n当pod访问service时，正好DNAT成自己的IP，那么就存在源和目的IP一样的情况。\n\n\n\n这种数据包是很特殊的存在，网络设备可能会将这种数据包视为无效或者异常的包被丢弃，最好不要一样，所以会将源IP SNAT为主机的IP，解决该问题。\n\n实验\n\n\n\n当前节点的IP为：10.65.196.41，然后进入在当前节点的Pod内，当前pod的ip为：192.33.73.139\n\nkubectl exec -it -n zwf demoapp-deployment-64bdcb8666-cxmmz -- sh\n\n\n\n1\n2\n\n\n进行多次curl service ip，当某一次请求到本POD的IP时，查看其ClientIP，发现其源IP是：10.65.196.41，这个当前节点的IP\n\n# curl 192.44.140.73\niKubernetes demoapp v1.0 !! ClientIP: 10.65.196.41, ServerName: demoapp-deployment-64bdcb8666-cxmmz, ServerIP: 192.33.73.139!\n\n\n1\n2\n\n\n\n# NodePort\n\n上面介绍的是serivi type=ClusterIP方式的，那么NodePort有什么区别呢？\n\n\n# 搭建环境\n\n先将clusterIP的service删了，防止干扰。\n\nkubectl delete svc -n zwf demoapp-service\n\n\n1\n\n\n创建NodePort的service文件demo_service_nodeport.yaml\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: demoapp-nodeport-service\nspec:\n  selector:\n    app: demoapp\n  ports:\n    - name: http\n      protocol: TCP\n      port: 80\n      targetPort: 80\n  type: NodePort\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n创建Service\n\n# kubectl apply -n zwf -f demo_service_nodeport.yaml \n\n# kubectl get svc -n zwf\nNAME                       TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\ndemoapp-nodeport-service   NodePort   192.44.152.223   <none>        80:30337/TCP   64s\n\n\n1\n2\n3\n4\n5\n\n\n\n# 请求clusterip\n\n通过clusterip+端口的方式请求service，原理和上面将是一样的。\n\n在POSTROUTING和OUTPUT中添加了KUBE-SERVICES链，其中包含了新增的service对应的KUBE-SVC-XXX子链，当访问的是其clusterip时，则匹配上该链。在其中包含了从多个pod中随机选择一个进行DNAT操作，打上标记，在POSTROUTING中再SNAT。\n\n# iptables -L PREROUTING -t nat\nChain PREROUTING (policy ACCEPT)\ntarget     prot opt source               destination       \nKUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */\ncali-PREROUTING  all  --  anywhere             anywhere             /* cali:6gwbT8clXdHdC1b1 */\n\n\n# iptables -L KUBE-SERVICES -t nat | grep zwf\nKUBE-SVC-YSWRJGOK5VEB6HOG  tcp  --  anywhere             192.44.152.223       /* zwf/demoapp-nodeport-service:http cluster IP */ tcp dpt:http\n\n# iptables -L KUBE-SVC-YSWRJGOK5VEB6HOG -t nat |grep zwf\nKUBE-MARK-MASQ  tcp  -- !192.33.0.0/16        192.44.152.223       /* zwf/demoapp-nodeport-service:http cluster IP */ tcp dpt:http\nKUBE-MARK-MASQ  tcp  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ tcp dpt:30337\nKUBE-SEP-NMMBRSZXI4OIWDPB  all  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ statistic mode random probability 0.33333333349\nKUBE-SEP-PXDORKZI3GD2RUMC  all  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ statistic mode random probability 0.50000000000\nKUBE-SEP-YLPOR67MTHPHIZAB  all  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n# 请求节点IP\n\n但是如果不是通过ClusterIP而是通过节点IP请求service呢，它是怎么做的？\n\n因为是节点IP，所以无法匹配上该service的KUBE-SVC-XXX子链，但是有一条KUBE-NODEPORTS\n\n# iptables -L KUBE-SERVICES  -t nat | grep KUBE-NODEPORTS\nKUBE-NODEPORTS  all  --  anywhere             anywhere             /* kubernetes service nodeports; NOTE: this must be the last rule in this chain */ ADDRTYPE match dst-type LOCAL\n\n\n1\n2\n\n\n在其中包含了一条子链KUBE-SVC-YSWRJGOK5VEB6HOG ，只要目的端口为30337就能匹配上，而这个端口正好就是demoapp-nodeport-service 的NodePort端口。\n\n这条子链和上面匹配clusterIP时是同一个链，都是进行一个DNAT操作。\n\n# # iptables -L KUBE-NODEPORTS -t nat | grep zwf\nKUBE-SVC-YSWRJGOK5VEB6HOG  tcp  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ tcp dpt:30337\n\n\n1\n2\n\n\n‍\n\n\n# 参考链接\n\n * netfilter 链接跟踪机制与NAT原理\n * k8s 之 service ip\n * 连接跟踪 conntrack",normalizedContent:"# kubernetes service如何通过iptables转发\n\n\n# 前言\n\n本文主要是介绍kubernetes的service是如何利用iptables来进行流量的转发达到流量的负载均衡的，并会通过实践操作来更好的理解与验证其原理。\n\n\n# 环境搭建\n\n搭建环境如下图所示：\n\n\n\n 1. 创建一个deploy，设置其副本数为3\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  name: demoapp-deployment\n  labels:\n    app: demoapp\nspec:\n  replicas: 3\n  selector:\n    matchlabels:\n      app: demoapp\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n        - name: ubuntu\n          image: ikubernetes/demoapp:v1.0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n 2. 创建service，为上面deployment的3个pod进行负载均衡访问\n\napiversion: v1\nkind: service\nmetadata:\n  name: demoapp-service\nspec:\n  selector:\n    app: demoapp\n  clusterip: 192.44.140.73\n  ports:\n    - name: http\n      protocol: tcp\n      port: 80\n      targetport: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n 3. 验证\n\n创建完后，环境如下：\n\n# kubectl get pods -n zwf -o wide\nname                                  ready   status    restarts   age     ip\ndemoapp-deployment-64bdcb8666-4prbk   1/1     running   0          7d17h   192.33.229.12   dmoc-fa163eee1e30\ndemoapp-deployment-64bdcb8666-cxmmz   1/1     running   0          7d17h   192.33.73.139   dmoc-fa163e7188d6\ndemoapp-deployment-64bdcb8666-kkzsg   1/1     running   0          7d17h   192.33.206.93   dmoc-fa163ee6bbe1\ndemoapp-pod                           1/1     running   0          4d17h   192.33.73.172   dmoc-fa163e7188d6\n\n# kubectl get svc -n zwf\nname                       type        cluster-ip       external-ip   port(s)        age\ndemoapp-service            clusterip   192.44.140.73    <none>        80/tcp         7s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n可以直接在环境中请求service的clusterip地址，会随机访问到三个pod，输出的信息包含了请求ip和目的ip。\n\n# curl 192.44.140.73\nikubernetes demoapp v1.0 !! clientip: 10.10.10.16, servername: demoapp-deployment-64bdcb8666-kkzsg, serverip: 192.33.206.93!\n\n# curl 192.44.140.73\nikubernetes demoapp v1.0 !! clientip: 10.65.196.41, servername: demoapp-deployment-64bdcb8666-cxmmz, serverip: 192.33.73.139!\n\n# curl 192.44.140.73\nikubernetes demoapp v1.0 !! clientip: 10.10.10.16, servername: demoapp-deployment-64bdcb8666-4prbk, serverip: 192.33.229.12!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# kube-services\n\n在prerouting 和output 链的nat表中，都包含了kube-services 子链，该子链中就包含了serivce的iptables规则的配置。\n\n# iptables -l prerouting -t nat\nchain prerouting (policy accept)\ntarget     prot opt source               destination       \nkube-services  all  --  anywhere             anywhere             /* kubernetes service portals */\ncali-prerouting  all  --  anywhere             anywhere             /* cali:6gwbt8clxdhdc1b1 */\n\n# iptables -l output -t nat\nchain output (policy accept)\ntarget     prot opt source               destination       \nkube-services  all  --  anywhere             anywhere             /* kubernetes service portals */\ncali-output  all  --  anywhere             anywhere             /* cali:tvnhkvao15huipy0 */\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n为什么在prerouting和output链中添加service规则？\n\nservice的作用是负载均衡，也就是需要将ip包进行dnat操作，而这个操作需要在最靠近发送的位置。网卡收到的包进入到网络协议栈时，最先进入的就是prerouting链，也就是节点外部的流量进入的入口。output是本地进程发出的包最先进入的链。所以需要在这两条链中添加kube-services，详情可参考快速了解iptables\n\n为什么nat表？\n\n因为要做dnat操作，所以在nat表。\n\nkube-services下面有许多kube-svc-xxx的子链，每一条子链都是一个集群中一个service的配置，筛选一下\n\n通过筛选demoapp-service 得到下面的子链，只有访问目的地址为192.44.140.73才能进入到该子链中。\n\n# iptables -l kube-services -t nat | grep demoapp-service\nkube-svc-fihihdnrzeg5vqeq  tcp  --  anywhere             192.44.140.73        /* zwf/demoapp-service:http cluster ip */ tcp dpt:http\n\n\n1\n2\n\n\n查看ube-svc-fihihdnrzeg5vqeq 链中内容，其中包含了四条子链。\n\n# iptables -l kube-svc-fihihdnrzeg5vqeq -t nat -n\nchain kube-svc-fihihdnrzeg5vqeq (1 references)\ntarget     prot opt source               destination       \nkube-mark-masq  tcp  -- !192.33.0.0/16        192.44.140.73        /* zwf/demoapp-service:http cluster ip */ tcp dpt:80\nkube-sep-fo7yk2k5daktcvse  all  --  0.0.0.0/0            0.0.0.0/0            /* zwf/demoapp-service:http */ statistic mode random probability 0.33333333349\nkube-sep-ipkl7nsntvgki4t5  all  --  0.0.0.0/0            0.0.0.0/0            /* zwf/demoapp-service:http */ statistic mode random probability 0.50000000000\nkube-sep-bper562isf3ufyoq  all  --  0.0.0.0/0            0.0.0.0/0            /* zwf/demoapp-service:http */\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n第一条链是，源ip不在192.33.0.0/16段、目的ip为192.44.140.73并且目的端口是80的数据包会匹配到该条子链进行跳转。其中192.33.0.0/16是pod的网段，如果不是集群内的流量，则会匹配上该条子链，会打上0x4000的标记。\n\n# iptables -l kube-mark-masq -t nat -n\nchain kube-mark-masq (548 references)\ntarget     prot opt source               destination       \nmark       all  --  0.0.0.0/0            0.0.0.0/0            mark or 0x4000\n\n\n1\n2\n3\n4\n\n\n后面的三条链是为了将流量随机的分配到任意一个pod中。第二条链代表着有1/3的概率会匹配到该链，而第三条链代表着1/2，最后一条链代表着百分百。\n\n看第二条链中的规则，第一条规则是跳转到子链kube-mark-masq ，源ip为192.33.206.93的数据包打上了0x4000标记，再将目的ip dnat成192.33.206.93，说明如果自己访问自己，也会被打上标记。\n\n这里的192.33.206.93是本身service所匹配上的pod ip地址，如果调用自己的service则会匹配上该链，打上0x4000标记。\n\n而第二条规则是一个dnat操作，会将目标地址改为192.33.206.93:80，也就是pod的地址。\n\n # iptables -l kube-sep-fo7yk2k5daktcvse -t nat\nchain kube-sep-fo7yk2k5daktcvse (1 references)\ntarget     prot opt source               destination   \nkube-mark-masq  all  --  192.33.206.93        anywhere             /* zwf/demoapp-service:http */\ndnat       tcp  --  anywhere             anywhere             /* zwf/demoapp-service:http */ tcp to:192.33.206.93:80\n\n\n1\n2\n3\n4\n5\n\n\n剩下的第3、4条规则也是一样的操作，会将流量dnat到对应的pod中。\n\n\n# postrouting\n\npostrouting中包含了一条kube-postrouting子链，子链也是由kube-porxy来写入的。\n\n# iptables -l postrouting -t nat\nchain postrouting (policy accept)\ntarget     prot opt source               destination       \nkube-postrouting  all  --  anywhere             anywhere             /* kubernetes postrouting rules */\ncali-postrouting  all  --  anywhere             anywhere             /* cali:o3lywmrlqyemjtb5 */\n\n\n1\n2\n3\n4\n5\n\n\n查看子链kube-postrouting 内容：\n\n 1. 第一条规则是没有标记为0x400的数据包会return，不执行下面的子链。还记得在kube-prerouting 中有两次打上0x4000标记，代表着访问是集群外部访问该service或者是源和目的一样，都会往下走。\n 2. 第二条规则是对数据包的标记值进行异或，而这里是0x4000与0x4000进行异或，也就是0\n 3. 第三条规则时对该数据包进行snat，random-fully是对源端口进行随机获取。\n\n# iptables -l kube-postrouting -t nat\nchain kube-postrouting (1 references)\ntarget     prot opt source               destination       \nreturn     all  --  anywhere             anywhere             mark match ! 0x4000/0x4000\nmark       all  --  anywhere             anywhere             mark xor 0x4000\nmasquerade  all  --  anywhere             anywhere             /* kubernetes service traffic requiring snat */ random-fully\n\n\n1\n2\n3\n4\n5\n6\n\n\n这里有两种情况会被snat，说说为什么。\n\n\n# snat\n\n\n# 为什么集群外部访问该service需要被snat？\n\n数据包需要回包，如果没有snat，那么回包的目的ip是客户端的ip，而源ip是pod的ip，而客户端并不认该数据包，则会被丢弃。\n\n‍\n\n如果有发生snat，那么回包的时候可以回到node1的节点，再回到client。\n\n‍\n\n但问题又来了，是怎么从node1再回包到client的呢？\n\n\n# conntrack\n\nconntrack是一个追踪表，在每一个数据包进入到netfilter的时候，都会记录一条记录，当我们进行snat和dnat的时候也都会更新该表中的记录。\n\n所以在node1回包给client时候，可以通过查询这个表中的记录，然后再次snat和dnat恢复回去就可以进行正常的回包了。\n\n\n\n可以看下conntrack里面的记录长什么样子。\n\n先在某一台节点上curl service的ip，上图的client其实也是在node1上的，因为node1上有两张网卡，node1和node2的通信使用的网卡eth2 ip为10.10.10.16，因为转发到其他节点，所以会被snat。\n\n# curl 192.44.140.73\nikubernetes demoapp v1.0 !! clientip: 10.10.10.16, servername: demoapp-deployment-64bdcb8666-4prbk, serverip: 192.33.229.12!\n\n\n1\n2\n\n\n这里主要是看src和dst分别是client请求service的目的ip，然后后面又有一个src和dst它是由node2回包给node1的源和目的ip，也就是源是pod的ip，dst是node1节点ip。\n\n前面是发送包的方向，后面是回包的方向。通过查询该表，即可以从node1回包给client\n\n# conntrack -l | grep 192.33.229.12\ntcp      6 107 time_wait src=10.65.196.41 dst=192.44.140.73 sport=33468 dport=80 src=192.33.229.12 dst=10.10.10.16 sport=80 dport=18623 [assured] mark=0 use=1\n\n\n1\n2\n\n\n‍\n\n\n# 源和目的ip相同\n\n当pod访问service时，正好dnat成自己的ip，那么就存在源和目的ip一样的情况。\n\n\n\n这种数据包是很特殊的存在，网络设备可能会将这种数据包视为无效或者异常的包被丢弃，最好不要一样，所以会将源ip snat为主机的ip，解决该问题。\n\n实验\n\n\n\n当前节点的ip为：10.65.196.41，然后进入在当前节点的pod内，当前pod的ip为：192.33.73.139\n\nkubectl exec -it -n zwf demoapp-deployment-64bdcb8666-cxmmz -- sh\n\n\n\n1\n2\n\n\n进行多次curl service ip，当某一次请求到本pod的ip时，查看其clientip，发现其源ip是：10.65.196.41，这个当前节点的ip\n\n# curl 192.44.140.73\nikubernetes demoapp v1.0 !! clientip: 10.65.196.41, servername: demoapp-deployment-64bdcb8666-cxmmz, serverip: 192.33.73.139!\n\n\n1\n2\n\n\n\n# nodeport\n\n上面介绍的是serivi type=clusterip方式的，那么nodeport有什么区别呢？\n\n\n# 搭建环境\n\n先将clusterip的service删了，防止干扰。\n\nkubectl delete svc -n zwf demoapp-service\n\n\n1\n\n\n创建nodeport的service文件demo_service_nodeport.yaml\n\napiversion: v1\nkind: service\nmetadata:\n  name: demoapp-nodeport-service\nspec:\n  selector:\n    app: demoapp\n  ports:\n    - name: http\n      protocol: tcp\n      port: 80\n      targetport: 80\n  type: nodeport\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n创建service\n\n# kubectl apply -n zwf -f demo_service_nodeport.yaml \n\n# kubectl get svc -n zwf\nname                       type       cluster-ip       external-ip   port(s)        age\ndemoapp-nodeport-service   nodeport   192.44.152.223   <none>        80:30337/tcp   64s\n\n\n1\n2\n3\n4\n5\n\n\n\n# 请求clusterip\n\n通过clusterip+端口的方式请求service，原理和上面将是一样的。\n\n在postrouting和output中添加了kube-services链，其中包含了新增的service对应的kube-svc-xxx子链，当访问的是其clusterip时，则匹配上该链。在其中包含了从多个pod中随机选择一个进行dnat操作，打上标记，在postrouting中再snat。\n\n# iptables -l prerouting -t nat\nchain prerouting (policy accept)\ntarget     prot opt source               destination       \nkube-services  all  --  anywhere             anywhere             /* kubernetes service portals */\ncali-prerouting  all  --  anywhere             anywhere             /* cali:6gwbt8clxdhdc1b1 */\n\n\n# iptables -l kube-services -t nat | grep zwf\nkube-svc-yswrjgok5veb6hog  tcp  --  anywhere             192.44.152.223       /* zwf/demoapp-nodeport-service:http cluster ip */ tcp dpt:http\n\n# iptables -l kube-svc-yswrjgok5veb6hog -t nat |grep zwf\nkube-mark-masq  tcp  -- !192.33.0.0/16        192.44.152.223       /* zwf/demoapp-nodeport-service:http cluster ip */ tcp dpt:http\nkube-mark-masq  tcp  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ tcp dpt:30337\nkube-sep-nmmbrszxi4oiwdpb  all  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ statistic mode random probability 0.33333333349\nkube-sep-pxdorkzi3gd2rumc  all  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ statistic mode random probability 0.50000000000\nkube-sep-ylpor67mthphizab  all  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n# 请求节点ip\n\n但是如果不是通过clusterip而是通过节点ip请求service呢，它是怎么做的？\n\n因为是节点ip，所以无法匹配上该service的kube-svc-xxx子链，但是有一条kube-nodeports\n\n# iptables -l kube-services  -t nat | grep kube-nodeports\nkube-nodeports  all  --  anywhere             anywhere             /* kubernetes service nodeports; note: this must be the last rule in this chain */ addrtype match dst-type local\n\n\n1\n2\n\n\n在其中包含了一条子链kube-svc-yswrjgok5veb6hog ，只要目的端口为30337就能匹配上，而这个端口正好就是demoapp-nodeport-service 的nodeport端口。\n\n这条子链和上面匹配clusterip时是同一个链，都是进行一个dnat操作。\n\n# # iptables -l kube-nodeports -t nat | grep zwf\nkube-svc-yswrjgok5veb6hog  tcp  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ tcp dpt:30337\n\n\n1\n2\n\n\n‍\n\n\n# 参考链接\n\n * netfilter 链接跟踪机制与nat原理\n * k8s 之 service ip\n * 连接跟踪 conntrack",charsets:{cjk:!0},lastUpdated:"2025/02/09, 23:47:02",lastUpdatedTimestamp:1739116022e3},{title:"一次服务升级时pg表DDL执行超时失败",frontmatter:{title:"一次服务升级时pg表DDL执行超时失败",date:"2025-09-14T10:07:39.000Z",permalink:"/pages/cf65ba/",categories:["Bug 通缉令"],tags:["PostgreSQL","sqlalchemy","python","数据库"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文详细分析了一次因PostgreSQL表DDL执行超时失败而导致的服务升级问题，通过SQL查询和代码审查定位到问题根源，揭示了数据库锁机制和资源管理的重要性。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17578168418231757816840915.png"},{name:"twitter:title",content:"一次服务升级时pg表DDL执行超时失败"},{name:"twitter:description",content:"本文详细分析了一次因PostgreSQL表DDL执行超时失败而导致的服务升级问题，通过SQL查询和代码审查定位到问题根源，揭示了数据库锁机制和资源管理的重要性。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17578168418231757816840915.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/02.Bug%20%E9%80%9A%E7%BC%89%E4%BB%A4/01.%E4%B8%80%E6%AC%A1%E6%9C%8D%E5%8A%A1%E5%8D%87%E7%BA%A7%E6%97%B6pg%E8%A1%A8DDL%E6%89%A7%E8%A1%8C%E8%B6%85%E6%97%B6%E5%A4%B1%E8%B4%A5.html"},{property:"og:type",content:"article"},{property:"og:title",content:"一次服务升级时pg表DDL执行超时失败"},{property:"og:description",content:"本文详细分析了一次因PostgreSQL表DDL执行超时失败而导致的服务升级问题，通过SQL查询和代码审查定位到问题根源，揭示了数据库锁机制和资源管理的重要性。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17578168418231757816840915.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/02.Bug%20%E9%80%9A%E7%BC%89%E4%BB%A4/01.%E4%B8%80%E6%AC%A1%E6%9C%8D%E5%8A%A1%E5%8D%87%E7%BA%A7%E6%97%B6pg%E8%A1%A8DDL%E6%89%A7%E8%A1%8C%E8%B6%85%E6%97%B6%E5%A4%B1%E8%B4%A5.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-09-14T10:07:39.000Z"},{property:"article:tag",content:"PostgreSQL"},{property:"article:tag",content:"sqlalchemy"},{property:"article:tag",content:"python"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"一次服务升级时pg表DDL执行超时失败"},{itemprop:"description",content:"本文详细分析了一次因PostgreSQL表DDL执行超时失败而导致的服务升级问题，通过SQL查询和代码审查定位到问题根源，揭示了数据库锁机制和资源管理的重要性。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17578168418231757816840915.png"}],readingShow:"top"},regularPath:"/02.Bug%20%E9%80%9A%E7%BC%89%E4%BB%A4/01.%E4%B8%80%E6%AC%A1%E6%9C%8D%E5%8A%A1%E5%8D%87%E7%BA%A7%E6%97%B6pg%E8%A1%A8DDL%E6%89%A7%E8%A1%8C%E8%B6%85%E6%97%B6%E5%A4%B1%E8%B4%A5.html",relativePath:"02.Bug 通缉令/01.一次服务升级时pg表DDL执行超时失败.md",key:"v-e543b750",path:"/pages/cf65ba/",headers:[{level:2,title:"背景",slug:"背景",normalizedTitle:"背景",charIndex:2},{level:2,title:"分析",slug:"分析",normalizedTitle:"分析",charIndex:126},{level:2,title:"原因",slug:"原因",normalizedTitle:"原因",charIndex:1260},{level:2,title:"结论",slug:"结论",normalizedTitle:"结论",charIndex:2327}],headersStr:"背景 分析 原因 结论",content:'# 背景\n\n在一次业务升级过程中，需要针对 Postgresql 使用 DDL 对某个表新增一个字段，升级过程中失败了，报错信息如下：\n\nERROR:  canceling statement due to lock tiemout\n\n\n1\n\n\n\n# 分析\n\nDDL 在执行的时候需要拿到 ACCESS EXCLUSIVE 锁，而它是最强的表级锁，只有当表中没有任何活动的事务时才能拿到该锁。\n\n查询 lock timeout 发现其设置为 2 分钟。\n\n通过报错信息可以看到它获取锁失败了，所以我们大胆的猜测一下是有业务中有事务超过 2 分钟，从而导致 DDL 一直无法拿到锁。\n\n通过下面的 SQL 来查询当前超过 2 分钟的活动查询，可以定位某条 SQL。\n\nSELECT \n    pid,\n    now() - query_start AS duration,\n    state,\n    query,\n    application_name,\n    client_addr,\n    client_application_name,\n    xact_start,\n    query_start\nFROM pg_stat_activity \nWHERE state = \'active\'\n  AND now() - query_start > interval \'2 minutes\'\n  AND pid <> pg_backend_pid()  -- 排除当前查询自身\n  AND datname = \'your_database_name\'  -- 替换为你的数据库名\nORDER BY query_start;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n最后找到了一条查询 SQL，查询时会拿 ACCESS SHARE 锁，所以其阻塞了 DDL 的执行。\n\n这里做一个测试 postgresql 拿锁失败的测试。\n\n使用 postgresql 客户端创建一个事务，对一个表进行查询，但是不关闭。\n\n# begin;\nBEGIN\n# select * from apollo.task limit 1;\n....\n\n\n1\n2\n3\n4\n\n\n而后在另一个客户端针对该表中执行一个 DDL 语句，发现其超时了。\n\n# ALTER TABLE apollo.task ADD COLUMN IF NOT EXISTS test int;\nERROR:  canceling statement due to lock timeout\n\n\n1\n2\n\n\n最后在第一个客户端中结束事务\n\n# end;\nCOMMIT\n\n\n1\n2\n\n\n再在第二个客户端再次执行 DDL 语句，显而易见的成功了。\n\n# ALTER TABLE apollo.task ADD COLUMN IF NOT EXISTS test2 int;\nALTER TABLE\n\n\n1\n2\n\n\n\n# 原因\n\n现在我们通过该条 SQL 从业务代码中去找到执行的地方。\n\n最后发现是在代码中使用了一个已经关闭的session，导致session 持续被打开而没有关闭，代码如下：\n\nfrom sqlalchemy.orm.session import sessionmaker\n_Session = sessionmaker()\n\n@contextmanager\ndef open_session():\n    """\n    通用psql的session上下文管理器\n    """\n\n    try:\n        session = _Session()\n        yield session\n        session.commit()\n    except OperationalError as e:\n        logging.error(f"Postgresql connection error: {e}, track: {traceback.format_exc()}")\n        reconnection()\n    except Exception:\n        session.rollback()\n        raise\n    finally:\n        session.close()\n\nwith open_session() as session:\n    pass\n\ntask = TaskModel.get_by_id(session, task_id)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n可以看到有使用一个上下文管理器来管理session的创建与关闭，而最后一行在 with 的作用域外面使用了 session，但是该session是在 with 结束时是调用了 session.close() 方法的。\n\n通过查看 sqlalchemy 官网查询，即使是 close() 依然可能再次被使用。\n\nhttps://docs.sqlalchemy.org/en/20/orm/session_api.html#sqlalchemy.orm.Session.close\n\n\n\n也就是说，最后一行使用了 session 但是没有再次对其进行关闭，导致其持续活动，导致执行 DDL 无法获取到 ACCESS EXCLUSIVE 锁，最终超时失败。\n\n\n# 结论\n\n 1. 即使是被close()的对象不能再次被使用，有隐藏的风险。\n 2. 使用完资源后，一定要记得关闭。',normalizedContent:'# 背景\n\n在一次业务升级过程中，需要针对 postgresql 使用 ddl 对某个表新增一个字段，升级过程中失败了，报错信息如下：\n\nerror:  canceling statement due to lock tiemout\n\n\n1\n\n\n\n# 分析\n\nddl 在执行的时候需要拿到 access exclusive 锁，而它是最强的表级锁，只有当表中没有任何活动的事务时才能拿到该锁。\n\n查询 lock timeout 发现其设置为 2 分钟。\n\n通过报错信息可以看到它获取锁失败了，所以我们大胆的猜测一下是有业务中有事务超过 2 分钟，从而导致 ddl 一直无法拿到锁。\n\n通过下面的 sql 来查询当前超过 2 分钟的活动查询，可以定位某条 sql。\n\nselect \n    pid,\n    now() - query_start as duration,\n    state,\n    query,\n    application_name,\n    client_addr,\n    client_application_name,\n    xact_start,\n    query_start\nfrom pg_stat_activity \nwhere state = \'active\'\n  and now() - query_start > interval \'2 minutes\'\n  and pid <> pg_backend_pid()  -- 排除当前查询自身\n  and datname = \'your_database_name\'  -- 替换为你的数据库名\norder by query_start;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n最后找到了一条查询 sql，查询时会拿 access share 锁，所以其阻塞了 ddl 的执行。\n\n这里做一个测试 postgresql 拿锁失败的测试。\n\n使用 postgresql 客户端创建一个事务，对一个表进行查询，但是不关闭。\n\n# begin;\nbegin\n# select * from apollo.task limit 1;\n....\n\n\n1\n2\n3\n4\n\n\n而后在另一个客户端针对该表中执行一个 ddl 语句，发现其超时了。\n\n# alter table apollo.task add column if not exists test int;\nerror:  canceling statement due to lock timeout\n\n\n1\n2\n\n\n最后在第一个客户端中结束事务\n\n# end;\ncommit\n\n\n1\n2\n\n\n再在第二个客户端再次执行 ddl 语句，显而易见的成功了。\n\n# alter table apollo.task add column if not exists test2 int;\nalter table\n\n\n1\n2\n\n\n\n# 原因\n\n现在我们通过该条 sql 从业务代码中去找到执行的地方。\n\n最后发现是在代码中使用了一个已经关闭的session，导致session 持续被打开而没有关闭，代码如下：\n\nfrom sqlalchemy.orm.session import sessionmaker\n_session = sessionmaker()\n\n@contextmanager\ndef open_session():\n    """\n    通用psql的session上下文管理器\n    """\n\n    try:\n        session = _session()\n        yield session\n        session.commit()\n    except operationalerror as e:\n        logging.error(f"postgresql connection error: {e}, track: {traceback.format_exc()}")\n        reconnection()\n    except exception:\n        session.rollback()\n        raise\n    finally:\n        session.close()\n\nwith open_session() as session:\n    pass\n\ntask = taskmodel.get_by_id(session, task_id)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n可以看到有使用一个上下文管理器来管理session的创建与关闭，而最后一行在 with 的作用域外面使用了 session，但是该session是在 with 结束时是调用了 session.close() 方法的。\n\n通过查看 sqlalchemy 官网查询，即使是 close() 依然可能再次被使用。\n\nhttps://docs.sqlalchemy.org/en/20/orm/session_api.html#sqlalchemy.orm.session.close\n\n\n\n也就是说，最后一行使用了 session 但是没有再次对其进行关闭，导致其持续活动，导致执行 ddl 无法获取到 access exclusive 锁，最终超时失败。\n\n\n# 结论\n\n 1. 即使是被close()的对象不能再次被使用，有隐藏的风险。\n 2. 使用完资源后，一定要记得关闭。',charsets:{cjk:!0},lastUpdated:"2025/09/14, 11:01:01",lastUpdatedTimestamp:1757818861e3},{title:"kube-proxy源码分析",frontmatter:{title:"kube-proxy源码分析",date:"2024-01-18T16:43:23.000Z",permalink:"/pages/6e0045/",categories:["云原生","k8s"],tags:["k8s","源码分析","go"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文主要是对kube-proxy的源码分析，了解其代码结构和实现原理。这里是根据[kubernetes1.23.9](https://github.com/kubernetes/kubernetes/tree/v1.23.9)版本来进行分析的。在下面贴上的代码会一定裁剪，主要用于理解主流程。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/image-20240118162033-mma8vs8.png"},{name:"twitter:title",content:"kube-proxy源码分析"},{name:"twitter:description",content:"本文主要是对kube-proxy的源码分析，了解其代码结构和实现原理。这里是根据[kubernetes1.23.9](https://github.com/kubernetes/kubernetes/tree/v1.23.9)版本来进行分析的。在下面贴上的代码会一定裁剪，主要用于理解主流程。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/image-20240118162033-mma8vs8.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/17.kube-proxy%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kube-proxy源码分析"},{property:"og:description",content:"本文主要是对kube-proxy的源码分析，了解其代码结构和实现原理。这里是根据[kubernetes1.23.9](https://github.com/kubernetes/kubernetes/tree/v1.23.9)版本来进行分析的。在下面贴上的代码会一定裁剪，主要用于理解主流程。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/image-20240118162033-mma8vs8.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/17.kube-proxy%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2024-01-18T16:43:23.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"源码分析"},{property:"article:tag",content:"go"},{itemprop:"name",content:"kube-proxy源码分析"},{itemprop:"description",content:"本文主要是对kube-proxy的源码分析，了解其代码结构和实现原理。这里是根据[kubernetes1.23.9](https://github.com/kubernetes/kubernetes/tree/v1.23.9)版本来进行分析的。在下面贴上的代码会一定裁剪，主要用于理解主流程。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/image-20240118162033-mma8vs8.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/17.kube-proxy%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html",relativePath:"01.云原生/07.k8s/17.kube-proxy源码分析.md",key:"v-3c54c66f",path:"/pages/6e0045/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:21},{level:2,title:"初始化",slug:"初始化",normalizedTitle:"初始化",charIndex:119},{level:2,title:"Run",slug:"run",normalizedTitle:"run",charIndex:225},{level:2,title:"service 和 endpointslice 变更事件",slug:"service-和-endpointslice-变更事件",normalizedTitle:"service 和 endpointslice 变更事件",charIndex:12013},{level:2,title:"BoundedFrequencyRunner",slug:"boundedfrequencyrunner",normalizedTitle:"boundedfrequencyrunner",charIndex:9187},{level:2,title:"syncProxyRules",slug:"syncproxyrules",normalizedTitle:"syncproxyrules",charIndex:9117},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:19890},{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:20381}],headersStr:"简介 初始化 Run service 和 endpointslice 变更事件 BoundedFrequencyRunner syncProxyRules 总结 相关链接",content:'# kube-proxy源码分析\n\n\n# 简介\n\n本文主要是对kube-proxy的源码分析，了解其代码结构和实现原理。这里是根据kubernetes1.23.9版本来进行分析的。在下面贴上的代码会一定裁剪，主要用于理解主流程。\n\n\n# 初始化\n\nkube-proxy入口文件在cmd/kube-proxy/proxy.go\n\nfunc main() {\n\tcommand := app.NewProxyCommand()\n\tcode := cli.Run(command)\n\tos.Exit(code)\n}\n\n\n1\n2\n3\n4\n5\n\n\n查看app.NewProxyCommand()方法，使用的cobra命令行解析库来作为程序入口\n\nfunc NewProxyCommand() *cobra.Command {\n\topts := NewOptions()\n\n\tcmd := &cobra.Command{\n\t\tUse: "kube-proxy",\n\t\tLong: `The Kubernetes network proxy runs on each node. This\nreflects services as defined in the Kubernetes API on each node and can do simple\nTCP, UDP, and SCTP stream forwarding or round robin TCP, UDP, and SCTP forwarding across a set of backends.\nService cluster IPs and ports are currently found through Docker-links-compatible\nenvironment variables specifying ports opened by the service proxy. There is an optional\naddon that provides cluster DNS for these cluster IPs. The user must create a service\nwith the apiserver API to configure the proxy.`,\n\t\tRunE: func(cmd *cobra.Command, args []string) error {\n\t\t\tverflag.PrintAndExitIfRequested()\n\t\t\tcliflag.PrintFlags(cmd.Flags())\n\n\t\t\tif err := initForOS(opts.WindowsService); err != nil {\n\t\t\t\treturn fmt.Errorf("failed os init: %w", err)\n\t\t\t}\n\n\t\t\t// 1. 加载配置文件kubeproxyconfig.KubeProxyConfiguration\n\t\t\t// 2. 监控文件变化\n\t\t\tif err := opts.Complete(); err != nil {\n\t\t\t\treturn fmt.Errorf("failed complete: %w", err)\n\t\t\t}\n\n\t\t\t// 配置参数的校验\n\t\t\tif err := opts.Validate(); err != nil {\n\t\t\t\treturn fmt.Errorf("failed validate: %w", err)\n\t\t\t}\n\n\t\t\t// 运行服务\n\t\t\tif err := opts.Run(); err != nil {\n\t\t\t\tklog.ErrorS(err, "Error running ProxyServer")\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\treturn nil\n\t\t},\n\t\tArgs: func(cmd *cobra.Command, args []string) error {\n\t\t\tfor _, arg := range args {\n\t\t\t\tif len(arg) > 0 {\n\t\t\t\t\treturn fmt.Errorf("%q does not take any arguments, got %q", cmd.CommandPath(), args)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil\n\t\t},\n\t}\n\n\tvar err error\n    // 填充一些默认配置\n\topts.config, err = opts.ApplyDefaults(opts.config)\n\tif err != nil {\n\t\tklog.ErrorS(err, "Unable to create flag defaults")\n\t\t// ACTION REQUIRED: Exit code changed from 255 to 1\n\t\tos.Exit(1)\n\t}\n\n\tfs := cmd.Flags()\n\topts.AddFlags(fs)\n\t// 将go的命令行参数也加到命令行参数中\n\tfs.AddGoFlagSet(goflag.CommandLine) // for --boot-id-file and --machine-id-file\n\n\t_ = cmd.MarkFlagFilename("config", "yaml", "yml", "json")\n\n\treturn cmd\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n\n 1. 读取配置文件KubeProxyConfiguration，并监听变化收到对应的事件\n 2. 对配置KubeProxyConfiguration进行校验\n 3. 启动服务\n\n再来看opts.Run() 服务启动的实现\n\nfunc (o *Options) Run() error {\n\tdefer close(o.errCh)\n\n    // 如果配置了该字段，将配置文件写入指定位置，然后退出\n\tif len(o.WriteConfigTo) > 0 {\n\t\treturn o.writeConfigFile()\n\t}\n\n    // 创建代理服务\n\tproxyServer, err := NewProxyServer(o)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// 清除所有的iptables规则\n\tif o.CleanupAndExit {\n\t\treturn proxyServer.CleanupAndExit()\n\t}\n\n\t// 启动代理服务\n\to.proxyServer = proxyServer\n\treturn o.runLoop()\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再看NewProxyServer() 的实现，主要是用来创建proxyServer对象，并且在其中根据当前的网络模式，通过iptables.NewProxier来创建proxier对象。\n\nfunc NewProxyServer(o *Options) (*ProxyServer, error) {\n\treturn newProxyServer(o.config, o.CleanupAndExit, o.master)\n}\n\nfunc newProxyServer(\n\tconfig *proxyconfigapi.KubeProxyConfiguration,\n\tcleanupAndExit bool,\n\tmaster string) (*ProxyServer, error) {\n\n\t// 执行本地命令的控制器\n\texecer := exec.New()\n\n\tkernelHandler = ipvs.NewLinuxKernelHandler() \n    // 创建ipset命令的执行器\n\tipsetInterface = utilipset.New(execer)\n    // 判断是否支持ipvs\n\tcanUseIPVS, err := ipvs.CanUseIPVSProxier(kernelHandler, ipsetInterface, config.IPVS.Scheduler)\n\tif string(config.Mode) == proxyModeIPVS && err != nil {\n\t\tklog.ErrorS(err, "Can\'t use the IPVS proxier")\n\t}\n\n\tif canUseIPVS {\n        // 如果支持的话，创建ipvs执行器\n\t\tipvsInterface = utilipvs.New()\n\t}\n\n\t// 创建事件记录器\n\teventBroadcaster := events.NewBroadcaster(&events.EventSinkImpl{Interface: client.EventsV1()})\n\trecorder := eventBroadcaster.NewRecorder(scheme.Scheme, "kube-proxy")\n\n\t// 创建健康检查服务\n\tvar healthzServer healthcheck.ProxierHealthUpdater\n\tif len(config.HealthzBindAddress) > 0 {\n\t\thealthzServer = healthcheck.NewProxierHealthServer(config.HealthzBindAddress, 2*config.IPTables.SyncPeriod.Duration, recorder, nodeRef)\n\t}\n\n    // 获取当前的代理模式\n\tproxyMode := getProxyMode(string(config.Mode), canUseIPVS, iptables.LinuxKernelCompatTester{})\n\t\n    // 获取当前的主要的IP协议\n\tprimaryProtocol := utiliptables.ProtocolIPv4\n\tif netutils.IsIPv6(nodeIP) {\n\t\tprimaryProtocol = utiliptables.ProtocolIPv6\n\t}\n\n\t// 创建iptables执行器\n\tiptInterface = utiliptables.New(execer, primaryProtocol)\n\n\t// 可能支持ipv4和ipv6两种执行器\n\tvar ipt [2]utiliptables.Interface\n\tdualStack := true // While we assume that node supports, we do further checks below\n\n\t// 如果支持的是iptables模式\n\tif proxyMode == proxyModeIPTables {\n\n\t\t// 双端模式，支持IP4和IPV6\n\t\tif dualStack {\n\t\t\tproxier, err = iptables.NewDualStackProxier(\n\t\t\t\tipt,\n\t\t\t\tutilsysctl.New(),\n\t\t\t\texecer,\n\t\t\t\tconfig.IPTables.SyncPeriod.Duration,\n\t\t\t\tconfig.IPTables.MinSyncPeriod.Duration,\n\t\t\t\tconfig.IPTables.MasqueradeAll,\n\t\t\t\tint(*config.IPTables.MasqueradeBit),\n\t\t\t\tlocalDetectors,\n\t\t\t\thostname,\n\t\t\t\tnodeIPTuple(config.BindAddress),\n\t\t\t\trecorder,\n\t\t\t\thealthzServer,\n\t\t\t\tconfig.NodePortAddresses,\n\t\t\t)\n\t\t} else {\n\t\t\tproxier, err = iptables.NewProxier(\n\t\t\t\tiptInterface,\n\t\t\t\tutilsysctl.New(),\n\t\t\t\texecer,\n\t\t\t\tconfig.IPTables.SyncPeriod.Duration,\n\t\t\t\tconfig.IPTables.MinSyncPeriod.Duration,\n\t\t\t\tconfig.IPTables.MasqueradeAll,\n\t\t\t\tint(*config.IPTables.MasqueradeBit),\n\t\t\t\tlocalDetector,\n\t\t\t\thostname,\n\t\t\t\tnodeIP,\n\t\t\t\trecorder,\n\t\t\t\thealthzServer,\n\t\t\t\tconfig.NodePortAddresses,\n\t\t\t)\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf("unable to create proxier: %v", err)\n\t\t}\n\t\tproxymetrics.RegisterMetrics()\n\n\telse if proxyMode == proxyModeIPVS {\n\t\t...\n\t}\n\n\treturn &ProxyServer{\n\t\tClient:                 client,\n\t\tEventClient:            eventClient,\n\t\tIptInterface:           iptInterface,\n\t\tIpvsInterface:          ipvsInterface,\n\t\tIpsetInterface:         ipsetInterface,\n\t\texecer:                 execer,\n\t\tProxier:                proxier,\n\t\tBroadcaster:            eventBroadcaster,\n\t\tRecorder:               recorder,\n\t\tConntrackConfiguration: config.Conntrack,\n\t\tConntracker:            &realConntracker{},\n\t\tProxyMode:              proxyMode,\n\t\tNodeRef:                nodeRef,\n\t\tMetricsBindAddress:     config.MetricsBindAddress,\n\t\tBindAddressHardFail:    config.BindAddressHardFail,\n\t\tEnableProfiling:        config.EnableProfiling,\n\t\tOOMScoreAdj:            config.OOMScoreAdj,\n\t\tConfigSyncPeriod:       config.ConfigSyncPeriod.Duration,\n\t\tHealthzServer:          healthzServer,\n\t\tUseEndpointSlices:      useEndpointSlices,\n\t}, nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n\n\n再来看iptables.NewProxier() 方法\n\nfunc NewProxier(ipt utiliptables.Interface,\n\tsysctl utilsysctl.Interface,\n\texec utilexec.Interface,\n\tsyncPeriod time.Duration,\n\tminSyncPeriod time.Duration,\n\tmasqueradeAll bool,\n\tmasqueradeBit int,\n\tlocalDetector proxyutiliptables.LocalTrafficDetector,\n\thostname string,\n\tnodeIP net.IP,\n\trecorder events.EventRecorder,\n\thealthzServer healthcheck.ProxierHealthUpdater,\n\tnodePortAddresses []string,\n) (*Proxier, error) {\n\n\t// 这个就是0x4000，也就是给数据包打上标记，在出主机的时候会进行SNAT\n\tmasqueradeValue := 1 << uint(masqueradeBit)\n\tmasqueradeMark := fmt.Sprintf("%#08x", masqueradeValue)\n\n    // 创建健康检查服务\n\tserviceHealthServer := healthcheck.NewServiceHealthServer(hostname, recorder, nodePortAddresses)\n\n\tproxier := &Proxier{\n\t\tserviceMap:               make(proxy.ServiceMap),\n\t\tserviceChanges:           proxy.NewServiceChangeTracker(newServiceInfo, ipFamily, recorder, nil),\n\t\tendpointsMap:             make(proxy.EndpointsMap),\n\t\tendpointsChanges:         proxy.NewEndpointChangeTracker(hostname, newEndpointInfo, ipFamily, recorder, nil),\n\t\tsyncPeriod:               syncPeriod,\n\t\tiptables:                 ipt,\n\t\tmasqueradeAll:            masqueradeAll,\n\t\tmasqueradeMark:           masqueradeMark,\n\t\texec:                     exec,\n\t\tlocalDetector:            localDetector,\n\t\thostname:                 hostname,\n\t\tnodeIP:                   nodeIP,\n\t\trecorder:                 recorder,\n\t\tserviceHealthServer:      serviceHealthServer,\n\t\thealthzServer:            healthzServer,\n\t\tprecomputedProbabilities: make([]string, 0, 1001),\n\t\tiptablesData:             bytes.NewBuffer(nil),\n\t\texistingFilterChainsData: bytes.NewBuffer(nil),\n\t\tfilterChains:             utilproxy.LineBuffer{},\n\t\tfilterRules:              utilproxy.LineBuffer{},\n\t\tnatChains:                utilproxy.LineBuffer{},\n\t\tnatRules:                 utilproxy.LineBuffer{},\n\t\tnodePortAddresses:        nodePortAddresses,\n\t\tnetworkInterfacer:        utilproxy.RealNetwork{},\n\t}\n\n\tburstSyncs := 2\n    // syncRunner是用来控制刷新iptables规则频率的运行器，proxier.syncProxyRules方法就是真正刷新iptables规则的方法\n   \tproxier.syncRunner = async.NewBoundedFrequencyRunner("sync-runner", proxier.syncProxyRules, minSyncPeriod, time.Hour, burstSyncs)\n\n\t// 这里启用一个goroutine。在三个表中都创建一个KUBE-PROXY-CANARY子链，通过子链是否存在来判断iptables是否被刷掉。\n\t// 如果该链不存在，说明iptables被刷掉了，再次执行syncProxyRules方法刷回来。\n\tgo ipt.Monitor(kubeProxyCanaryChain, []utiliptables.Table{utiliptables.TableMangle, utiliptables.TableNAT, utiliptables.TableFilter},\n\t\tproxier.syncProxyRules, syncPeriod, wait.NeverStop)\n\treturn proxier, nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n\n\n以上主要的对象已经初始化完成了。\n\n\n# Run\n\n回到o.Run() 方法中，先是创建ProxyServer对象，然后在其中又创建proxier对象，做了一系列初始化动作，接下来就是运行代理服务了，现在看向runLoop 方法\n\nfunc (o *Options) runLoop() error {\n\t// 开启文件监听\n\tif o.watcher != nil {\n\t\to.watcher.Run()\n\t}\n\n\t// run the proxy in goroutine\n\tgo func() {\n\t\terr := o.proxyServer.Run()\n\t\to.errCh <- err\n\t}()\n\n    // 如果接受到errCh则停止服务\n\tfor {\n\t\terr := <-o.errCh\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n再看向o.proxyServer.Run() 方法，运行代理服务的主流程。\n\nfunc (s *ProxyServer) Run() error {\n\t// 设置当前进程的OOM参数，资源紧张时，不优先kill掉kube-proxy\n\tvar oomAdjuster *oom.OOMAdjuster\n\tif s.OOMScoreAdj != nil {\n\t\toomAdjuster = oom.NewOOMAdjuster()\n\t\tif err := oomAdjuster.ApplyOOMScoreAdj(0, int(*s.OOMScoreAdj)); err != nil {\n\t\t\tklog.V(2).InfoS("Failed to apply OOMScore", "err", err)\n\t\t}\n\t}\n\n\t// 开启健康检查服务\n\tserveHealthz(s.HealthzServer, errCh)\n\n\t// 开启指标上报服务\n\tserveMetrics(s.MetricsBindAddress, s.ProxyMode, s.EnableProfiling, errCh)\n\n\t// 创建informer\n\tinformerFactory := informers.NewSharedInformerFactoryWithOptions(s.Client, s.ConfigSyncPeriod,\n\t\tinformers.WithTweakListOptions(func(options *metav1.ListOptions) {\n\t\t\toptions.LabelSelector = labelSelector.String()\n\t\t}))\n\n\t// 监听service和endpoint并注册事件，当发生变化时，则会进行刷新iptables规则\n\tserviceConfig := config.NewServiceConfig(informerFactory.Core().V1().Services(), s.ConfigSyncPeriod)\n\tserviceConfig.RegisterEventHandler(s.Proxier)\n\tgo serviceConfig.Run(wait.NeverStop)\n\n\tif endpointsHandler, ok := s.Proxier.(config.EndpointsHandler); ok && !s.UseEndpointSlices {\n\t\tendpointsConfig := config.NewEndpointsConfig(informerFactory.Core().V1().Endpoints(), s.ConfigSyncPeriod)\n\t\tendpointsConfig.RegisterEventHandler(endpointsHandler)\n\t\tgo endpointsConfig.Run(wait.NeverStop)\n\t} else {\n\t\tendpointSliceConfig := config.NewEndpointSliceConfig(informerFactory.Discovery().V1().EndpointSlices(), s.ConfigSyncPeriod)\n\t\tendpointSliceConfig.RegisterEventHandler(s.Proxier)\n\t\tgo endpointSliceConfig.Run(wait.NeverStop)\n\t}\n\n\tinformerFactory.Start(wait.NeverStop)\n\n\t// 发送启动事件\n\ts.birthCry()\n\n\tgo s.Proxier.SyncLoop()\n\n\treturn <-errCh\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n\n\n\n# service 和 endpointslice 变更事件\n\n程序中是通过informer来实现对service和endpoint发生变化的监听，感知变化，并触发事件并进行相应的处理。\n\n先看一下NewServiceConfig() 方法，其中注册了当service发生增、删、改事件时，分别执行result.handleAddService 、result.handleUpdateService 、result.handleDeleteService 方法。\n\nfunc NewServiceConfig(serviceInformer coreinformers.ServiceInformer, resyncPeriod time.Duration) *ServiceConfig {\n\tresult := &ServiceConfig{\n\t\tlisterSynced: serviceInformer.Informer().HasSynced,\n\t}\n\n\t// 注册变更事件\n\tserviceInformer.Informer().AddEventHandlerWithResyncPeriod(\n\t\tcache.ResourceEventHandlerFuncs{\n\t\t\tAddFunc:    result.handleAddService,\n\t\t\tUpdateFunc: result.handleUpdateService,\n\t\t\tDeleteFunc: result.handleDeleteService,\n\t\t},\n\t\tresyncPeriod,\n\t)\n\n\treturn result\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n再看看其中的handleAddService() 方法，传入的参数obj就是新增的service对象，然后传入eventHandler.OnServiceAdd()方法进行处理。\n\nfunc (c *ServiceConfig) handleAddService(obj interface{}) {\n\tservice, ok := obj.(*v1.Service)\n\tif !ok {\n\t\tutilruntime.HandleError(fmt.Errorf("unexpected object type: %v", obj))\n\t\treturn\n\t}\n\tfor i := range c.eventHandlers {\n\t\tklog.V(4).InfoS("Calling handler.OnServiceAdd")\n\t\tc.eventHandlers[i].OnServiceAdd(service)\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n这里c.eventHanlders其实就是proxier对象，在RegisterEventHandler()方法中将其添加进去的。\n\nserviceConfig.RegisterEventHandler(s.Proxier)\n\n\n1\n\n\n也就是说，proxier.OnServiceAdd()才是需要触发的处理方法\n\nfunc (proxier *Proxier) OnServiceAdd(service *v1.Service) {\n\tproxier.OnServiceUpdate(nil, service)\n}\n\n\n1\n2\n3\n\n\n第一个参数为旧的service，第二参数为新的参数。该方法给可以OnServiceAdd 复用，传入的第一个参数为nil，第二个参数不为nil，就是新增的操作。\n\nfunc (proxier *Proxier) OnServiceUpdate(oldService, service *v1.Service) {\n\tif proxier.serviceChanges.Update(oldService, service) && proxier.isInitialized() {\n\t\tproxier.Sync()\n\t}\n}\n\n\n1\n2\n3\n4\n5\n\n\n还可以看到删除操作也能复用，有旧的service，而新service为nil代表删除。\n\n// OnServiceDelete is called whenever deletion of an existing service\n// object is observed.\nfunc (proxier *Proxier) OnServiceDelete(service *v1.Service) {\n\tproxier.OnServiceUpdate(service, nil)\n}\n\n\n1\n2\n3\n4\n5\n\n\n无论是增、删、改都会执行到proxier.Sync()方法\n\nfunc (proxier *Proxier) Sync() {\n\tif proxier.healthzServer != nil {\n\t\tproxier.healthzServer.QueuedUpdate()\n\t}\n\tmetrics.SyncProxyRulesLastQueuedTimestamp.SetToCurrentTime()\n\tproxier.syncRunner.Run()\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n最终到proxier.syncRunner.Run() 方法，可以看出它会发送一个信号到bfr.run管道中。该方法除了是service发生事件执行操作的终点外，endpoint发生事件后最终也会执行到这里。\n\nfunc (bfr *BoundedFrequencyRunner) Run() {\n\t// If it takes a lot of time to run the underlying function, noone is really\n\t// processing elements from <run> channel. So to avoid blocking here on the\n\t// putting element to it, we simply skip it if there is already an element\n\t// in it.\n\tselect {\n\tcase bfr.run <- struct{}{}:\n\tdefault:\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# BoundedFrequencyRunner\n\n我们再回到代理服务的ProxyServe.Run 方法，最后执行了s.Proxier.SyncLoop()\n\nfunc (proxier *Proxier) SyncLoop() {\n\t// Update healthz timestamp at beginning in case Sync() never succeeds.\n\tif proxier.healthzServer != nil {\n\t\tproxier.healthzServer.Updated()\n\t}\n\n\t// synthesize "last change queued" time as the informers are syncing.\n\tmetrics.SyncProxyRulesLastQueuedTimestamp.SetToCurrentTime()\n\tproxier.syncRunner.Loop(wait.NeverStop)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n然后再执行proxier.syncRunner.Loop() 方法\n\nfunc (bfr *BoundedFrequencyRunner) Loop(stop <-chan struct{}) {\n\tklog.V(3).Infof("%s Loop running", bfr.name)\n\tbfr.timer.Reset(bfr.maxInterval)\n\tfor {\n\t\tselect {\n\t\tcase <-stop:\n\t\t\tbfr.stop()\n\t\t\tklog.V(3).Infof("%s Loop stopping", bfr.name)\n\t\t\treturn\n\t\tcase <-bfr.timer.C():\n\t\t\tbfr.tryRun()\n\t\tcase <-bfr.run:\n\t\t\tbfr.tryRun()\n\t\tcase <-bfr.retry:\n\t\t\tbfr.doRetry()\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n可以看到如果bfr.run管道接收到了信号，会执行brf.tryRun() 方法，在这个方法中会执行proxier.syncProxyRules() 进行刷新iptables规则。\n\n// assumes the lock is not held\nfunc (bfr *BoundedFrequencyRunner) tryRun() {\n\tbfr.mu.Lock()\n\tdefer bfr.mu.Unlock()\n\n    // 这里会限制访问速率，看是否可以执行。\n\tif bfr.limiter.TryAccept() {\n        // 这里的fn就是proxier.syncProxyRules方法\n\t\tbfr.fn()\n\t\tbfr.lastRun = bfr.timer.Now()\n\t\tbfr.timer.Stop()\n\t\tbfr.timer.Reset(bfr.maxInterval)\n\t\tklog.V(3).Infof("%s: ran, next possible in %v, periodic in %v", bfr.name, bfr.minInterval, bfr.maxInterval)\n\t\treturn\n\t}\n\n\t// It can\'t run right now, figure out when it can run next.\n\telapsed := bfr.timer.Since(bfr.lastRun)   // how long since last run\n\tnextPossible := bfr.minInterval - elapsed // time to next possible run\n\tnextScheduled := bfr.timer.Remaining()    // time to next scheduled run\n\tklog.V(4).Infof("%s: %v since last run, possible in %v, scheduled in %v", bfr.name, elapsed, nextPossible, nextScheduled)\n\n\t// It\'s hard to avoid race conditions in the unit tests unless we always reset\n\t// the timer here, even when it\'s unchanged\n\tif nextPossible < nextScheduled {\n\t\tnextScheduled = nextPossible\n\t}\n\tbfr.timer.Stop()\n\tbfr.timer.Reset(nextScheduled)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n\n# syncProxyRules\n\n该方法主要是更新节点上的iptables规则。\n\nfunc (proxier *Proxier) syncProxyRules() {\n\n\t// 获取service和endpoint发生变化的数据\n\tserviceUpdateResult := proxier.serviceMap.Update(proxier.serviceChanges)\n\tendpointUpdateResult := proxier.endpointsMap.Update(proxier.endpointsChanges)\n\n\n\t// 创建一些必要的iptables链\n\tfor _, jump := range iptablesJumpChains {\n\t\tif _, err := proxier.iptables.EnsureChain(jump.table, jump.dstChain); err != nil {\n\t\t\tklog.ErrorS(err, "Failed to ensure chain exists", "table", jump.table, "chain", jump.dstChain)\n\t\t\treturn\n\t\t}\n\t\targs := append(jump.extraArgs,\n\t\t\t"-m", "comment", "--comment", jump.comment,\n\t\t\t"-j", string(jump.dstChain),\n\t\t)\n\t\tif _, err := proxier.iptables.EnsureRule(utiliptables.Prepend, jump.table, jump.srcChain, args...); err != nil {\n\t\t\tklog.ErrorS(err, "Failed to ensure chain jumps", "table", jump.table, "srcChain", jump.srcChain, "dstChain", jump.dstChain)\n\t\t\treturn\n\t\t}\n\t}\n\n\tfor _, ch := range iptablesEnsureChains {\n\t\tif _, err := proxier.iptables.EnsureChain(ch.table, ch.chain); err != nil {\n\t\t\tklog.ErrorS(err, "Failed to ensure chain exists", "table", ch.table, "chain", ch.chain)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// 将当前filter表中所有存在的规则写入existingFilterChainsData中\n\tproxier.existingFilterChainsData.Reset()\n\terr := proxier.iptables.SaveInto(utiliptables.TableFilter, proxier.existingFilterChainsData)\n\n\t// 将nat表中所有存在的规则写入iptablesData中\n\tproxier.iptablesData.Reset()\n\terr = proxier.iptables.SaveInto(utiliptables.TableNAT, proxier.iptablesData)\n\n\t// 将filter和nat链中必要添加的子链，通过字符串拼接的方式写入变量filterChains和natChains中\n\tfor _, chainName := range []utiliptables.Chain{kubeServicesChain, kubeExternalServicesChain, kubeForwardChain, kubeNodePortsChain} {\n\t\tif chain, ok := existingFilterChains[chainName]; ok {\n\t\t\tproxier.filterChains.WriteBytes(chain)\n\t\t} else {\n\t\t\tproxier.filterChains.Write(utiliptables.MakeChainLine(chainName))\n\t\t}\n\t}\n\tfor _, chainName := range []utiliptables.Chain{kubeServicesChain, kubeNodePortsChain, kubePostroutingChain, KubeMarkMasqChain} {\n\t\tif chain, ok := existingNATChains[chainName]; ok {\n\t\t\tproxier.natChains.WriteBytes(chain)\n\t\t} else {\n\t\t\tproxier.natChains.Write(utiliptables.MakeChainLine(chainName))\n\t\t}\n\t}\n\n\t// 后面就是将各种的iptables规则通过字符串拼接起来\n    ...\n\n\t// 将所有链和规则的iptables全部集成到一起iptablesData，然后再通过iptables-restore命令刷新到节点中。\n\tproxier.iptablesData.Reset()\n\tproxier.iptablesData.Write(proxier.filterChains.Bytes())\n\tproxier.iptablesData.Write(proxier.filterRules.Bytes())\n\tproxier.iptablesData.Write(proxier.natChains.Bytes())\n\tproxier.iptablesData.Write(proxier.natRules.Bytes())\n\terr = proxier.iptables.RestoreAll(proxier.iptablesData.Bytes(), utiliptables.NoFlushTables, utiliptables.RestoreCounters)\n\tif err != nil {\n\t\tklog.ErrorS(err, "Failed to execute iptables-restore")\n\t\tmetrics.IptablesRestoreFailuresTotal.Inc()\n\t\treturn\n\t}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n\n\n总结\n\n 1. 获取发生变更的 service 和 endpoint 信息\n 2. 创建一些必要的链\n 3. 使用 iptables-save 命令，将当前环境中 nat 和 filter 表中的 iptables 规则全部加载到程序中。\n 4. 通过拼接字符串，构造出需要创建的 iptables 规则字符串。\n 5. 通过 iptables-restore 命令，将构造的 iptables 规则字符串全部再刷新到节点上\n\n思考\n\n因为每一次都会将当前所有的iptables规则全部刷新到节点上，如果规则量过大的话，性能会受到影响，所以才有ipvs模式。\n\n\n# 总结\n\n整体代码流程如下：\n\n 1. 首先是各种对象套娃式的初始化，Options->ProxyServier->proxier->syncRunner\n 2. 然后是向informer中注册service和endpoint事件，当发生改动时，会给bfr.run发送信号\n 3. syncRunner收到信号会去执行proxier.syncProxyRules()方法，刷新主机的iptables规则\n\n\n\n\n# 相关链接\n\nkubernetes 源码-kube-proxy 原理和源码分析（一）\n\nkube-proxy 源码解析\n\nkube-proxy 保姆级别源码阅读\n\n连接跟踪 conntrack\n\nkubernetes 之 client-go 之 informer 工作原理源码解析\n\nKubernetes EndpointSlice 和 Endpoint 对象的区别\n\n‍',normalizedContent:'# kube-proxy源码分析\n\n\n# 简介\n\n本文主要是对kube-proxy的源码分析，了解其代码结构和实现原理。这里是根据kubernetes1.23.9版本来进行分析的。在下面贴上的代码会一定裁剪，主要用于理解主流程。\n\n\n# 初始化\n\nkube-proxy入口文件在cmd/kube-proxy/proxy.go\n\nfunc main() {\n\tcommand := app.newproxycommand()\n\tcode := cli.run(command)\n\tos.exit(code)\n}\n\n\n1\n2\n3\n4\n5\n\n\n查看app.newproxycommand()方法，使用的cobra命令行解析库来作为程序入口\n\nfunc newproxycommand() *cobra.command {\n\topts := newoptions()\n\n\tcmd := &cobra.command{\n\t\tuse: "kube-proxy",\n\t\tlong: `the kubernetes network proxy runs on each node. this\nreflects services as defined in the kubernetes api on each node and can do simple\ntcp, udp, and sctp stream forwarding or round robin tcp, udp, and sctp forwarding across a set of backends.\nservice cluster ips and ports are currently found through docker-links-compatible\nenvironment variables specifying ports opened by the service proxy. there is an optional\naddon that provides cluster dns for these cluster ips. the user must create a service\nwith the apiserver api to configure the proxy.`,\n\t\trune: func(cmd *cobra.command, args []string) error {\n\t\t\tverflag.printandexitifrequested()\n\t\t\tcliflag.printflags(cmd.flags())\n\n\t\t\tif err := initforos(opts.windowsservice); err != nil {\n\t\t\t\treturn fmt.errorf("failed os init: %w", err)\n\t\t\t}\n\n\t\t\t// 1. 加载配置文件kubeproxyconfig.kubeproxyconfiguration\n\t\t\t// 2. 监控文件变化\n\t\t\tif err := opts.complete(); err != nil {\n\t\t\t\treturn fmt.errorf("failed complete: %w", err)\n\t\t\t}\n\n\t\t\t// 配置参数的校验\n\t\t\tif err := opts.validate(); err != nil {\n\t\t\t\treturn fmt.errorf("failed validate: %w", err)\n\t\t\t}\n\n\t\t\t// 运行服务\n\t\t\tif err := opts.run(); err != nil {\n\t\t\t\tklog.errors(err, "error running proxyserver")\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\treturn nil\n\t\t},\n\t\targs: func(cmd *cobra.command, args []string) error {\n\t\t\tfor _, arg := range args {\n\t\t\t\tif len(arg) > 0 {\n\t\t\t\t\treturn fmt.errorf("%q does not take any arguments, got %q", cmd.commandpath(), args)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil\n\t\t},\n\t}\n\n\tvar err error\n    // 填充一些默认配置\n\topts.config, err = opts.applydefaults(opts.config)\n\tif err != nil {\n\t\tklog.errors(err, "unable to create flag defaults")\n\t\t// action required: exit code changed from 255 to 1\n\t\tos.exit(1)\n\t}\n\n\tfs := cmd.flags()\n\topts.addflags(fs)\n\t// 将go的命令行参数也加到命令行参数中\n\tfs.addgoflagset(goflag.commandline) // for --boot-id-file and --machine-id-file\n\n\t_ = cmd.markflagfilename("config", "yaml", "yml", "json")\n\n\treturn cmd\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n\n 1. 读取配置文件kubeproxyconfiguration，并监听变化收到对应的事件\n 2. 对配置kubeproxyconfiguration进行校验\n 3. 启动服务\n\n再来看opts.run() 服务启动的实现\n\nfunc (o *options) run() error {\n\tdefer close(o.errch)\n\n    // 如果配置了该字段，将配置文件写入指定位置，然后退出\n\tif len(o.writeconfigto) > 0 {\n\t\treturn o.writeconfigfile()\n\t}\n\n    // 创建代理服务\n\tproxyserver, err := newproxyserver(o)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// 清除所有的iptables规则\n\tif o.cleanupandexit {\n\t\treturn proxyserver.cleanupandexit()\n\t}\n\n\t// 启动代理服务\n\to.proxyserver = proxyserver\n\treturn o.runloop()\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再看newproxyserver() 的实现，主要是用来创建proxyserver对象，并且在其中根据当前的网络模式，通过iptables.newproxier来创建proxier对象。\n\nfunc newproxyserver(o *options) (*proxyserver, error) {\n\treturn newproxyserver(o.config, o.cleanupandexit, o.master)\n}\n\nfunc newproxyserver(\n\tconfig *proxyconfigapi.kubeproxyconfiguration,\n\tcleanupandexit bool,\n\tmaster string) (*proxyserver, error) {\n\n\t// 执行本地命令的控制器\n\texecer := exec.new()\n\n\tkernelhandler = ipvs.newlinuxkernelhandler() \n    // 创建ipset命令的执行器\n\tipsetinterface = utilipset.new(execer)\n    // 判断是否支持ipvs\n\tcanuseipvs, err := ipvs.canuseipvsproxier(kernelhandler, ipsetinterface, config.ipvs.scheduler)\n\tif string(config.mode) == proxymodeipvs && err != nil {\n\t\tklog.errors(err, "can\'t use the ipvs proxier")\n\t}\n\n\tif canuseipvs {\n        // 如果支持的话，创建ipvs执行器\n\t\tipvsinterface = utilipvs.new()\n\t}\n\n\t// 创建事件记录器\n\teventbroadcaster := events.newbroadcaster(&events.eventsinkimpl{interface: client.eventsv1()})\n\trecorder := eventbroadcaster.newrecorder(scheme.scheme, "kube-proxy")\n\n\t// 创建健康检查服务\n\tvar healthzserver healthcheck.proxierhealthupdater\n\tif len(config.healthzbindaddress) > 0 {\n\t\thealthzserver = healthcheck.newproxierhealthserver(config.healthzbindaddress, 2*config.iptables.syncperiod.duration, recorder, noderef)\n\t}\n\n    // 获取当前的代理模式\n\tproxymode := getproxymode(string(config.mode), canuseipvs, iptables.linuxkernelcompattester{})\n\t\n    // 获取当前的主要的ip协议\n\tprimaryprotocol := utiliptables.protocolipv4\n\tif netutils.isipv6(nodeip) {\n\t\tprimaryprotocol = utiliptables.protocolipv6\n\t}\n\n\t// 创建iptables执行器\n\tiptinterface = utiliptables.new(execer, primaryprotocol)\n\n\t// 可能支持ipv4和ipv6两种执行器\n\tvar ipt [2]utiliptables.interface\n\tdualstack := true // while we assume that node supports, we do further checks below\n\n\t// 如果支持的是iptables模式\n\tif proxymode == proxymodeiptables {\n\n\t\t// 双端模式，支持ip4和ipv6\n\t\tif dualstack {\n\t\t\tproxier, err = iptables.newdualstackproxier(\n\t\t\t\tipt,\n\t\t\t\tutilsysctl.new(),\n\t\t\t\texecer,\n\t\t\t\tconfig.iptables.syncperiod.duration,\n\t\t\t\tconfig.iptables.minsyncperiod.duration,\n\t\t\t\tconfig.iptables.masqueradeall,\n\t\t\t\tint(*config.iptables.masqueradebit),\n\t\t\t\tlocaldetectors,\n\t\t\t\thostname,\n\t\t\t\tnodeiptuple(config.bindaddress),\n\t\t\t\trecorder,\n\t\t\t\thealthzserver,\n\t\t\t\tconfig.nodeportaddresses,\n\t\t\t)\n\t\t} else {\n\t\t\tproxier, err = iptables.newproxier(\n\t\t\t\tiptinterface,\n\t\t\t\tutilsysctl.new(),\n\t\t\t\texecer,\n\t\t\t\tconfig.iptables.syncperiod.duration,\n\t\t\t\tconfig.iptables.minsyncperiod.duration,\n\t\t\t\tconfig.iptables.masqueradeall,\n\t\t\t\tint(*config.iptables.masqueradebit),\n\t\t\t\tlocaldetector,\n\t\t\t\thostname,\n\t\t\t\tnodeip,\n\t\t\t\trecorder,\n\t\t\t\thealthzserver,\n\t\t\t\tconfig.nodeportaddresses,\n\t\t\t)\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn nil, fmt.errorf("unable to create proxier: %v", err)\n\t\t}\n\t\tproxymetrics.registermetrics()\n\n\telse if proxymode == proxymodeipvs {\n\t\t...\n\t}\n\n\treturn &proxyserver{\n\t\tclient:                 client,\n\t\teventclient:            eventclient,\n\t\tiptinterface:           iptinterface,\n\t\tipvsinterface:          ipvsinterface,\n\t\tipsetinterface:         ipsetinterface,\n\t\texecer:                 execer,\n\t\tproxier:                proxier,\n\t\tbroadcaster:            eventbroadcaster,\n\t\trecorder:               recorder,\n\t\tconntrackconfiguration: config.conntrack,\n\t\tconntracker:            &realconntracker{},\n\t\tproxymode:              proxymode,\n\t\tnoderef:                noderef,\n\t\tmetricsbindaddress:     config.metricsbindaddress,\n\t\tbindaddresshardfail:    config.bindaddresshardfail,\n\t\tenableprofiling:        config.enableprofiling,\n\t\toomscoreadj:            config.oomscoreadj,\n\t\tconfigsyncperiod:       config.configsyncperiod.duration,\n\t\thealthzserver:          healthzserver,\n\t\tuseendpointslices:      useendpointslices,\n\t}, nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n\n\n再来看iptables.newproxier() 方法\n\nfunc newproxier(ipt utiliptables.interface,\n\tsysctl utilsysctl.interface,\n\texec utilexec.interface,\n\tsyncperiod time.duration,\n\tminsyncperiod time.duration,\n\tmasqueradeall bool,\n\tmasqueradebit int,\n\tlocaldetector proxyutiliptables.localtrafficdetector,\n\thostname string,\n\tnodeip net.ip,\n\trecorder events.eventrecorder,\n\thealthzserver healthcheck.proxierhealthupdater,\n\tnodeportaddresses []string,\n) (*proxier, error) {\n\n\t// 这个就是0x4000，也就是给数据包打上标记，在出主机的时候会进行snat\n\tmasqueradevalue := 1 << uint(masqueradebit)\n\tmasquerademark := fmt.sprintf("%#08x", masqueradevalue)\n\n    // 创建健康检查服务\n\tservicehealthserver := healthcheck.newservicehealthserver(hostname, recorder, nodeportaddresses)\n\n\tproxier := &proxier{\n\t\tservicemap:               make(proxy.servicemap),\n\t\tservicechanges:           proxy.newservicechangetracker(newserviceinfo, ipfamily, recorder, nil),\n\t\tendpointsmap:             make(proxy.endpointsmap),\n\t\tendpointschanges:         proxy.newendpointchangetracker(hostname, newendpointinfo, ipfamily, recorder, nil),\n\t\tsyncperiod:               syncperiod,\n\t\tiptables:                 ipt,\n\t\tmasqueradeall:            masqueradeall,\n\t\tmasquerademark:           masquerademark,\n\t\texec:                     exec,\n\t\tlocaldetector:            localdetector,\n\t\thostname:                 hostname,\n\t\tnodeip:                   nodeip,\n\t\trecorder:                 recorder,\n\t\tservicehealthserver:      servicehealthserver,\n\t\thealthzserver:            healthzserver,\n\t\tprecomputedprobabilities: make([]string, 0, 1001),\n\t\tiptablesdata:             bytes.newbuffer(nil),\n\t\texistingfilterchainsdata: bytes.newbuffer(nil),\n\t\tfilterchains:             utilproxy.linebuffer{},\n\t\tfilterrules:              utilproxy.linebuffer{},\n\t\tnatchains:                utilproxy.linebuffer{},\n\t\tnatrules:                 utilproxy.linebuffer{},\n\t\tnodeportaddresses:        nodeportaddresses,\n\t\tnetworkinterfacer:        utilproxy.realnetwork{},\n\t}\n\n\tburstsyncs := 2\n    // syncrunner是用来控制刷新iptables规则频率的运行器，proxier.syncproxyrules方法就是真正刷新iptables规则的方法\n   \tproxier.syncrunner = async.newboundedfrequencyrunner("sync-runner", proxier.syncproxyrules, minsyncperiod, time.hour, burstsyncs)\n\n\t// 这里启用一个goroutine。在三个表中都创建一个kube-proxy-canary子链，通过子链是否存在来判断iptables是否被刷掉。\n\t// 如果该链不存在，说明iptables被刷掉了，再次执行syncproxyrules方法刷回来。\n\tgo ipt.monitor(kubeproxycanarychain, []utiliptables.table{utiliptables.tablemangle, utiliptables.tablenat, utiliptables.tablefilter},\n\t\tproxier.syncproxyrules, syncperiod, wait.neverstop)\n\treturn proxier, nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n\n\n以上主要的对象已经初始化完成了。\n\n\n# run\n\n回到o.run() 方法中，先是创建proxyserver对象，然后在其中又创建proxier对象，做了一系列初始化动作，接下来就是运行代理服务了，现在看向runloop 方法\n\nfunc (o *options) runloop() error {\n\t// 开启文件监听\n\tif o.watcher != nil {\n\t\to.watcher.run()\n\t}\n\n\t// run the proxy in goroutine\n\tgo func() {\n\t\terr := o.proxyserver.run()\n\t\to.errch <- err\n\t}()\n\n    // 如果接受到errch则停止服务\n\tfor {\n\t\terr := <-o.errch\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n再看向o.proxyserver.run() 方法，运行代理服务的主流程。\n\nfunc (s *proxyserver) run() error {\n\t// 设置当前进程的oom参数，资源紧张时，不优先kill掉kube-proxy\n\tvar oomadjuster *oom.oomadjuster\n\tif s.oomscoreadj != nil {\n\t\toomadjuster = oom.newoomadjuster()\n\t\tif err := oomadjuster.applyoomscoreadj(0, int(*s.oomscoreadj)); err != nil {\n\t\t\tklog.v(2).infos("failed to apply oomscore", "err", err)\n\t\t}\n\t}\n\n\t// 开启健康检查服务\n\tservehealthz(s.healthzserver, errch)\n\n\t// 开启指标上报服务\n\tservemetrics(s.metricsbindaddress, s.proxymode, s.enableprofiling, errch)\n\n\t// 创建informer\n\tinformerfactory := informers.newsharedinformerfactorywithoptions(s.client, s.configsyncperiod,\n\t\tinformers.withtweaklistoptions(func(options *metav1.listoptions) {\n\t\t\toptions.labelselector = labelselector.string()\n\t\t}))\n\n\t// 监听service和endpoint并注册事件，当发生变化时，则会进行刷新iptables规则\n\tserviceconfig := config.newserviceconfig(informerfactory.core().v1().services(), s.configsyncperiod)\n\tserviceconfig.registereventhandler(s.proxier)\n\tgo serviceconfig.run(wait.neverstop)\n\n\tif endpointshandler, ok := s.proxier.(config.endpointshandler); ok && !s.useendpointslices {\n\t\tendpointsconfig := config.newendpointsconfig(informerfactory.core().v1().endpoints(), s.configsyncperiod)\n\t\tendpointsconfig.registereventhandler(endpointshandler)\n\t\tgo endpointsconfig.run(wait.neverstop)\n\t} else {\n\t\tendpointsliceconfig := config.newendpointsliceconfig(informerfactory.discovery().v1().endpointslices(), s.configsyncperiod)\n\t\tendpointsliceconfig.registereventhandler(s.proxier)\n\t\tgo endpointsliceconfig.run(wait.neverstop)\n\t}\n\n\tinformerfactory.start(wait.neverstop)\n\n\t// 发送启动事件\n\ts.birthcry()\n\n\tgo s.proxier.syncloop()\n\n\treturn <-errch\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n\n\n\n# service 和 endpointslice 变更事件\n\n程序中是通过informer来实现对service和endpoint发生变化的监听，感知变化，并触发事件并进行相应的处理。\n\n先看一下newserviceconfig() 方法，其中注册了当service发生增、删、改事件时，分别执行result.handleaddservice 、result.handleupdateservice 、result.handledeleteservice 方法。\n\nfunc newserviceconfig(serviceinformer coreinformers.serviceinformer, resyncperiod time.duration) *serviceconfig {\n\tresult := &serviceconfig{\n\t\tlistersynced: serviceinformer.informer().hassynced,\n\t}\n\n\t// 注册变更事件\n\tserviceinformer.informer().addeventhandlerwithresyncperiod(\n\t\tcache.resourceeventhandlerfuncs{\n\t\t\taddfunc:    result.handleaddservice,\n\t\t\tupdatefunc: result.handleupdateservice,\n\t\t\tdeletefunc: result.handledeleteservice,\n\t\t},\n\t\tresyncperiod,\n\t)\n\n\treturn result\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n再看看其中的handleaddservice() 方法，传入的参数obj就是新增的service对象，然后传入eventhandler.onserviceadd()方法进行处理。\n\nfunc (c *serviceconfig) handleaddservice(obj interface{}) {\n\tservice, ok := obj.(*v1.service)\n\tif !ok {\n\t\tutilruntime.handleerror(fmt.errorf("unexpected object type: %v", obj))\n\t\treturn\n\t}\n\tfor i := range c.eventhandlers {\n\t\tklog.v(4).infos("calling handler.onserviceadd")\n\t\tc.eventhandlers[i].onserviceadd(service)\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n这里c.eventhanlders其实就是proxier对象，在registereventhandler()方法中将其添加进去的。\n\nserviceconfig.registereventhandler(s.proxier)\n\n\n1\n\n\n也就是说，proxier.onserviceadd()才是需要触发的处理方法\n\nfunc (proxier *proxier) onserviceadd(service *v1.service) {\n\tproxier.onserviceupdate(nil, service)\n}\n\n\n1\n2\n3\n\n\n第一个参数为旧的service，第二参数为新的参数。该方法给可以onserviceadd 复用，传入的第一个参数为nil，第二个参数不为nil，就是新增的操作。\n\nfunc (proxier *proxier) onserviceupdate(oldservice, service *v1.service) {\n\tif proxier.servicechanges.update(oldservice, service) && proxier.isinitialized() {\n\t\tproxier.sync()\n\t}\n}\n\n\n1\n2\n3\n4\n5\n\n\n还可以看到删除操作也能复用，有旧的service，而新service为nil代表删除。\n\n// onservicedelete is called whenever deletion of an existing service\n// object is observed.\nfunc (proxier *proxier) onservicedelete(service *v1.service) {\n\tproxier.onserviceupdate(service, nil)\n}\n\n\n1\n2\n3\n4\n5\n\n\n无论是增、删、改都会执行到proxier.sync()方法\n\nfunc (proxier *proxier) sync() {\n\tif proxier.healthzserver != nil {\n\t\tproxier.healthzserver.queuedupdate()\n\t}\n\tmetrics.syncproxyruleslastqueuedtimestamp.settocurrenttime()\n\tproxier.syncrunner.run()\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n最终到proxier.syncrunner.run() 方法，可以看出它会发送一个信号到bfr.run管道中。该方法除了是service发生事件执行操作的终点外，endpoint发生事件后最终也会执行到这里。\n\nfunc (bfr *boundedfrequencyrunner) run() {\n\t// if it takes a lot of time to run the underlying function, noone is really\n\t// processing elements from <run> channel. so to avoid blocking here on the\n\t// putting element to it, we simply skip it if there is already an element\n\t// in it.\n\tselect {\n\tcase bfr.run <- struct{}{}:\n\tdefault:\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# boundedfrequencyrunner\n\n我们再回到代理服务的proxyserve.run 方法，最后执行了s.proxier.syncloop()\n\nfunc (proxier *proxier) syncloop() {\n\t// update healthz timestamp at beginning in case sync() never succeeds.\n\tif proxier.healthzserver != nil {\n\t\tproxier.healthzserver.updated()\n\t}\n\n\t// synthesize "last change queued" time as the informers are syncing.\n\tmetrics.syncproxyruleslastqueuedtimestamp.settocurrenttime()\n\tproxier.syncrunner.loop(wait.neverstop)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n然后再执行proxier.syncrunner.loop() 方法\n\nfunc (bfr *boundedfrequencyrunner) loop(stop <-chan struct{}) {\n\tklog.v(3).infof("%s loop running", bfr.name)\n\tbfr.timer.reset(bfr.maxinterval)\n\tfor {\n\t\tselect {\n\t\tcase <-stop:\n\t\t\tbfr.stop()\n\t\t\tklog.v(3).infof("%s loop stopping", bfr.name)\n\t\t\treturn\n\t\tcase <-bfr.timer.c():\n\t\t\tbfr.tryrun()\n\t\tcase <-bfr.run:\n\t\t\tbfr.tryrun()\n\t\tcase <-bfr.retry:\n\t\t\tbfr.doretry()\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n可以看到如果bfr.run管道接收到了信号，会执行brf.tryrun() 方法，在这个方法中会执行proxier.syncproxyrules() 进行刷新iptables规则。\n\n// assumes the lock is not held\nfunc (bfr *boundedfrequencyrunner) tryrun() {\n\tbfr.mu.lock()\n\tdefer bfr.mu.unlock()\n\n    // 这里会限制访问速率，看是否可以执行。\n\tif bfr.limiter.tryaccept() {\n        // 这里的fn就是proxier.syncproxyrules方法\n\t\tbfr.fn()\n\t\tbfr.lastrun = bfr.timer.now()\n\t\tbfr.timer.stop()\n\t\tbfr.timer.reset(bfr.maxinterval)\n\t\tklog.v(3).infof("%s: ran, next possible in %v, periodic in %v", bfr.name, bfr.mininterval, bfr.maxinterval)\n\t\treturn\n\t}\n\n\t// it can\'t run right now, figure out when it can run next.\n\telapsed := bfr.timer.since(bfr.lastrun)   // how long since last run\n\tnextpossible := bfr.mininterval - elapsed // time to next possible run\n\tnextscheduled := bfr.timer.remaining()    // time to next scheduled run\n\tklog.v(4).infof("%s: %v since last run, possible in %v, scheduled in %v", bfr.name, elapsed, nextpossible, nextscheduled)\n\n\t// it\'s hard to avoid race conditions in the unit tests unless we always reset\n\t// the timer here, even when it\'s unchanged\n\tif nextpossible < nextscheduled {\n\t\tnextscheduled = nextpossible\n\t}\n\tbfr.timer.stop()\n\tbfr.timer.reset(nextscheduled)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n\n# syncproxyrules\n\n该方法主要是更新节点上的iptables规则。\n\nfunc (proxier *proxier) syncproxyrules() {\n\n\t// 获取service和endpoint发生变化的数据\n\tserviceupdateresult := proxier.servicemap.update(proxier.servicechanges)\n\tendpointupdateresult := proxier.endpointsmap.update(proxier.endpointschanges)\n\n\n\t// 创建一些必要的iptables链\n\tfor _, jump := range iptablesjumpchains {\n\t\tif _, err := proxier.iptables.ensurechain(jump.table, jump.dstchain); err != nil {\n\t\t\tklog.errors(err, "failed to ensure chain exists", "table", jump.table, "chain", jump.dstchain)\n\t\t\treturn\n\t\t}\n\t\targs := append(jump.extraargs,\n\t\t\t"-m", "comment", "--comment", jump.comment,\n\t\t\t"-j", string(jump.dstchain),\n\t\t)\n\t\tif _, err := proxier.iptables.ensurerule(utiliptables.prepend, jump.table, jump.srcchain, args...); err != nil {\n\t\t\tklog.errors(err, "failed to ensure chain jumps", "table", jump.table, "srcchain", jump.srcchain, "dstchain", jump.dstchain)\n\t\t\treturn\n\t\t}\n\t}\n\n\tfor _, ch := range iptablesensurechains {\n\t\tif _, err := proxier.iptables.ensurechain(ch.table, ch.chain); err != nil {\n\t\t\tklog.errors(err, "failed to ensure chain exists", "table", ch.table, "chain", ch.chain)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// 将当前filter表中所有存在的规则写入existingfilterchainsdata中\n\tproxier.existingfilterchainsdata.reset()\n\terr := proxier.iptables.saveinto(utiliptables.tablefilter, proxier.existingfilterchainsdata)\n\n\t// 将nat表中所有存在的规则写入iptablesdata中\n\tproxier.iptablesdata.reset()\n\terr = proxier.iptables.saveinto(utiliptables.tablenat, proxier.iptablesdata)\n\n\t// 将filter和nat链中必要添加的子链，通过字符串拼接的方式写入变量filterchains和natchains中\n\tfor _, chainname := range []utiliptables.chain{kubeserviceschain, kubeexternalserviceschain, kubeforwardchain, kubenodeportschain} {\n\t\tif chain, ok := existingfilterchains[chainname]; ok {\n\t\t\tproxier.filterchains.writebytes(chain)\n\t\t} else {\n\t\t\tproxier.filterchains.write(utiliptables.makechainline(chainname))\n\t\t}\n\t}\n\tfor _, chainname := range []utiliptables.chain{kubeserviceschain, kubenodeportschain, kubepostroutingchain, kubemarkmasqchain} {\n\t\tif chain, ok := existingnatchains[chainname]; ok {\n\t\t\tproxier.natchains.writebytes(chain)\n\t\t} else {\n\t\t\tproxier.natchains.write(utiliptables.makechainline(chainname))\n\t\t}\n\t}\n\n\t// 后面就是将各种的iptables规则通过字符串拼接起来\n    ...\n\n\t// 将所有链和规则的iptables全部集成到一起iptablesdata，然后再通过iptables-restore命令刷新到节点中。\n\tproxier.iptablesdata.reset()\n\tproxier.iptablesdata.write(proxier.filterchains.bytes())\n\tproxier.iptablesdata.write(proxier.filterrules.bytes())\n\tproxier.iptablesdata.write(proxier.natchains.bytes())\n\tproxier.iptablesdata.write(proxier.natrules.bytes())\n\terr = proxier.iptables.restoreall(proxier.iptablesdata.bytes(), utiliptables.noflushtables, utiliptables.restorecounters)\n\tif err != nil {\n\t\tklog.errors(err, "failed to execute iptables-restore")\n\t\tmetrics.iptablesrestorefailurestotal.inc()\n\t\treturn\n\t}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n\n\n总结\n\n 1. 获取发生变更的 service 和 endpoint 信息\n 2. 创建一些必要的链\n 3. 使用 iptables-save 命令，将当前环境中 nat 和 filter 表中的 iptables 规则全部加载到程序中。\n 4. 通过拼接字符串，构造出需要创建的 iptables 规则字符串。\n 5. 通过 iptables-restore 命令，将构造的 iptables 规则字符串全部再刷新到节点上\n\n思考\n\n因为每一次都会将当前所有的iptables规则全部刷新到节点上，如果规则量过大的话，性能会受到影响，所以才有ipvs模式。\n\n\n# 总结\n\n整体代码流程如下：\n\n 1. 首先是各种对象套娃式的初始化，options->proxyservier->proxier->syncrunner\n 2. 然后是向informer中注册service和endpoint事件，当发生改动时，会给bfr.run发送信号\n 3. syncrunner收到信号会去执行proxier.syncproxyrules()方法，刷新主机的iptables规则\n\n\n\n\n# 相关链接\n\nkubernetes 源码-kube-proxy 原理和源码分析（一）\n\nkube-proxy 源码解析\n\nkube-proxy 保姆级别源码阅读\n\n连接跟踪 conntrack\n\nkubernetes 之 client-go 之 informer 工作原理源码解析\n\nkubernetes endpointslice 和 endpoint 对象的区别\n\n‍',charsets:{cjk:!0},lastUpdated:"2025/02/09, 23:47:02",lastUpdatedTimestamp:1739116022e3},{title:"服务启动时出现 OOM",frontmatter:{title:"服务启动时出现 OOM",date:"2025-09-22T15:39:13.000Z",permalink:"/pages/de98b1/",categories:["Bug 通缉令"],tags:["go语言"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文详细记录了一次在Kubernetes环境中Golang服务启动时出现OOM（Out of Memory）问题的排查和解决过程。服务在启动约2分钟后出现内存溢出，通过pprof工具分析发现主要问题源于bytes.Buffer对象的频繁扩容。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17585287225681758528722158.png"},{name:"twitter:title",content:"服务启动时出现 OOM"},{name:"twitter:description",content:"本文详细记录了一次在Kubernetes环境中Golang服务启动时出现OOM（Out of Memory）问题的排查和解决过程。服务在启动约2分钟后出现内存溢出，通过pprof工具分析发现主要问题源于bytes.Buffer对象的频繁扩容。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17585287225681758528722158.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/02.Bug%20%E9%80%9A%E7%BC%89%E4%BB%A4/02.%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8%E6%97%B6%E5%87%BA%E7%8E%B0%20OOM.html"},{property:"og:type",content:"article"},{property:"og:title",content:"服务启动时出现 OOM"},{property:"og:description",content:"本文详细记录了一次在Kubernetes环境中Golang服务启动时出现OOM（Out of Memory）问题的排查和解决过程。服务在启动约2分钟后出现内存溢出，通过pprof工具分析发现主要问题源于bytes.Buffer对象的频繁扩容。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17585287225681758528722158.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/02.Bug%20%E9%80%9A%E7%BC%89%E4%BB%A4/02.%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8%E6%97%B6%E5%87%BA%E7%8E%B0%20OOM.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-09-22T15:39:13.000Z"},{property:"article:tag",content:"go语言"},{itemprop:"name",content:"服务启动时出现 OOM"},{itemprop:"description",content:"本文详细记录了一次在Kubernetes环境中Golang服务启动时出现OOM（Out of Memory）问题的排查和解决过程。服务在启动约2分钟后出现内存溢出，通过pprof工具分析发现主要问题源于bytes.Buffer对象的频繁扩容。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17585287225681758528722158.png"}],readingShow:"top"},regularPath:"/02.Bug%20%E9%80%9A%E7%BC%89%E4%BB%A4/02.%E6%9C%8D%E5%8A%A1%E5%90%AF%E5%8A%A8%E6%97%B6%E5%87%BA%E7%8E%B0%20OOM.html",relativePath:"02.Bug 通缉令/02.服务启动时出现 OOM.md",key:"v-7c3ad306",path:"/pages/de98b1/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"现象",slug:"现象",normalizedTitle:"现象",charIndex:132},{level:2,title:"分析",slug:"分析",normalizedTitle:"分析",charIndex:97},{level:2,title:"解决办法",slug:"解决办法",normalizedTitle:"解决办法",charIndex:1683},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:2414}],headersStr:"前言 现象 分析 解决办法 总结",content:'# 前言\n\n本文详细记录了一次在Kubernetes环境中Golang服务启动时出现OOM（Out of Memory）问题的排查和解决过程。服务在启动约2分钟后出现内存溢出，通过pprof工具分析发现主要问题源于bytes.Buffer对象的频繁扩容。\n\n\n# 现象\n\n有一个golang后台服务跑在了k8s集群上，在启动过程中，大约 2 分钟后，该服务所在的pod出现了 OOM，也就是超过了部署该 POD 的 limit 内存大小。\n\n\n# 分析\n\n该现象是可复现的，所以我通过重启该pod，在其还没出现 OOM 时使用 pprof 将服务的 profile 文件给获取到。\n\ncurl http://localhost:8080/debug/pprof/heap -o profile\n\n\n1\n\n\n然后使用下面的命令在网页上查看服务的内存使用情况。\n\ngo tool pprof -http=:8081 profile\n\n\n1\n\n\n在网页上，在顶部的导航栏中，选择 View -> Top，SAMPLES -> alloc_space，来查看从服务启动时，申请内存Top。\n\n\n\n首先可以看到第一名申请的内存是 bytes.makeSlice，看名字大胆的猜测，是因为切片内存申请过多导致的，接下来需要验证。\n\n选中该行，然后选择 View -> Graph，就会进入进入到一个函数调用链。\n\n\n\n我们先找到调用链的底端，可以看到 bytes.makeSlice 占用了1.12G 内存，调用者是 bytes(*Buffer).grow，通过源码分析是 Buffer 对象扩容导致的。\n\n\n\n通过调用链往上找到在业务代码上创建并使用 Buffer 对象的地方，最终找到了 Serialize 函数。\n\n\n\n我们看想该函数，该函数的作用是，将value对象序列化成byte数组。然后看到其创建了 Buffer 对象，并将 value 对象序列化存储到其中。\n\nfunc Serialize(value interface{}) ([]byte, error) {\n\t// gob.Register(value)\n\tbuf := bytes.Buffer{}\n\tif err := gob.NewEncoder(&buf).Encode(&value); err != nil {\n\t\treturn nil, err\n\t}\n\treturn buf.Bytes(), nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n但我们立马发现了问题，我们创建 Buffer{} 并没有指定其大小，可以看到其结构体也没有默认大小，当写入数据时，则会进行调用 grow 进行扩容。\n\ntype Buffer struct {\n\tbuf      []byte // contents are the bytes buf[off : len(buf)]\n\toff      int    // read at &buf[off], write at &buf[len(buf)]\n\tlastRead readOp // last read operation, so that Unread* can work correctly.\n}\n\nfunc (b *Buffer) Write(p []byte) (n int, err error) {\n\tb.lastRead = opInvalid\n\tm, ok := b.tryGrowByReslice(len(p))\n\tif !ok {\n\t\tm = b.grow(len(p))\n\t}\n\treturn copy(b.buf[m:], p), nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n再结合业务进行分析，服务启动时会有大量的数据需要进行序列化，每次调用该函数都是创建一个未指定大小的 Buffer 对象，然后序列化时进行不断地扩容，从而导致内存迅速增加，从而导致 OOM。\n\n\n# 解决办法\n\n使用 sync.Pool 来复用 Buffer 对象，并且在创建 Buffer 对象时指定一个合适的大小，这样就可以减少内存的申请从而避免了 OOM。\n\n// 缓冲区池，复用 bytes.Buffer 对象\nvar bufferPool = sync.Pool{\n\tNew: func() interface{} {\n\t\t// 预分配 1KB 容量，减少扩容次数\n\t\tbuf := make([]byte, 0, 1024)\n\t\treturn bytes.NewBuffer(buf)\n\t},\n}\n\nfunc Serialize(value interface{}) ([]byte, error) {\n\tif value == nil {\n\t\treturn nil, fmt.Errorf("input nil value")\n\t}\n\n\t// 从池中获取缓冲区\n\tbuf := bufferPool.Get().(*bytes.Buffer)\n\tdefer func() {\n\t\tbuf.Reset()\n\t\tbufferPool.Put(buf)\n\t}()\n\n\tencoder := gob.NewEncoder(buf)\n\tif err := encoder.Encode(&value); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// 高效的字节切片克隆返回数据\n\treturn bytesClone(buf.Bytes()), nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n\n# 总结\n\n 1. 在编码方面需要注意内存管理和对象复用对系统稳定性的重要性。\n 2. 善于利用工具来辅助排查问题。',normalizedContent:'# 前言\n\n本文详细记录了一次在kubernetes环境中golang服务启动时出现oom（out of memory）问题的排查和解决过程。服务在启动约2分钟后出现内存溢出，通过pprof工具分析发现主要问题源于bytes.buffer对象的频繁扩容。\n\n\n# 现象\n\n有一个golang后台服务跑在了k8s集群上，在启动过程中，大约 2 分钟后，该服务所在的pod出现了 oom，也就是超过了部署该 pod 的 limit 内存大小。\n\n\n# 分析\n\n该现象是可复现的，所以我通过重启该pod，在其还没出现 oom 时使用 pprof 将服务的 profile 文件给获取到。\n\ncurl http://localhost:8080/debug/pprof/heap -o profile\n\n\n1\n\n\n然后使用下面的命令在网页上查看服务的内存使用情况。\n\ngo tool pprof -http=:8081 profile\n\n\n1\n\n\n在网页上，在顶部的导航栏中，选择 view -> top，samples -> alloc_space，来查看从服务启动时，申请内存top。\n\n\n\n首先可以看到第一名申请的内存是 bytes.makeslice，看名字大胆的猜测，是因为切片内存申请过多导致的，接下来需要验证。\n\n选中该行，然后选择 view -> graph，就会进入进入到一个函数调用链。\n\n\n\n我们先找到调用链的底端，可以看到 bytes.makeslice 占用了1.12g 内存，调用者是 bytes(*buffer).grow，通过源码分析是 buffer 对象扩容导致的。\n\n\n\n通过调用链往上找到在业务代码上创建并使用 buffer 对象的地方，最终找到了 serialize 函数。\n\n\n\n我们看想该函数，该函数的作用是，将value对象序列化成byte数组。然后看到其创建了 buffer 对象，并将 value 对象序列化存储到其中。\n\nfunc serialize(value interface{}) ([]byte, error) {\n\t// gob.register(value)\n\tbuf := bytes.buffer{}\n\tif err := gob.newencoder(&buf).encode(&value); err != nil {\n\t\treturn nil, err\n\t}\n\treturn buf.bytes(), nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n但我们立马发现了问题，我们创建 buffer{} 并没有指定其大小，可以看到其结构体也没有默认大小，当写入数据时，则会进行调用 grow 进行扩容。\n\ntype buffer struct {\n\tbuf      []byte // contents are the bytes buf[off : len(buf)]\n\toff      int    // read at &buf[off], write at &buf[len(buf)]\n\tlastread readop // last read operation, so that unread* can work correctly.\n}\n\nfunc (b *buffer) write(p []byte) (n int, err error) {\n\tb.lastread = opinvalid\n\tm, ok := b.trygrowbyreslice(len(p))\n\tif !ok {\n\t\tm = b.grow(len(p))\n\t}\n\treturn copy(b.buf[m:], p), nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n再结合业务进行分析，服务启动时会有大量的数据需要进行序列化，每次调用该函数都是创建一个未指定大小的 buffer 对象，然后序列化时进行不断地扩容，从而导致内存迅速增加，从而导致 oom。\n\n\n# 解决办法\n\n使用 sync.pool 来复用 buffer 对象，并且在创建 buffer 对象时指定一个合适的大小，这样就可以减少内存的申请从而避免了 oom。\n\n// 缓冲区池，复用 bytes.buffer 对象\nvar bufferpool = sync.pool{\n\tnew: func() interface{} {\n\t\t// 预分配 1kb 容量，减少扩容次数\n\t\tbuf := make([]byte, 0, 1024)\n\t\treturn bytes.newbuffer(buf)\n\t},\n}\n\nfunc serialize(value interface{}) ([]byte, error) {\n\tif value == nil {\n\t\treturn nil, fmt.errorf("input nil value")\n\t}\n\n\t// 从池中获取缓冲区\n\tbuf := bufferpool.get().(*bytes.buffer)\n\tdefer func() {\n\t\tbuf.reset()\n\t\tbufferpool.put(buf)\n\t}()\n\n\tencoder := gob.newencoder(buf)\n\tif err := encoder.encode(&value); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// 高效的字节切片克隆返回数据\n\treturn bytesclone(buf.bytes()), nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n\n# 总结\n\n 1. 在编码方面需要注意内存管理和对象复用对系统稳定性的重要性。\n 2. 善于利用工具来辅助排查问题。',charsets:{cjk:!0},lastUpdated:"2025/09/22, 16:52:15",lastUpdatedTimestamp:1758531135e3},{title:"kafka中listener和advertised.listeners的作用",frontmatter:{title:"kafka中listener和advertised.listeners的作用",date:"2023-05-01T17:41:02.000Z",permalink:"/pages/fa114f/",categories:["中间件","kafka"],tags:["kafka","中间件"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"如下配置：",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"kafka中listener和advertised.listeners的作用"},{name:"twitter:description",content:"如下配置："},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/01.kafka/01.listener%E5%92%8Cadvertised.listeners%E7%9A%84%E4%BD%9C%E7%94%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kafka中listener和advertised.listeners的作用"},{property:"og:description",content:"如下配置："},{property:"og:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/01.kafka/01.listener%E5%92%8Cadvertised.listeners%E7%9A%84%E4%BD%9C%E7%94%A8.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-05-01T17:41:02.000Z"},{property:"article:tag",content:"kafka"},{property:"article:tag",content:"中间件"},{itemprop:"name",content:"kafka中listener和advertised.listeners的作用"},{itemprop:"description",content:"如下配置："}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/01.kafka/01.listener%E5%92%8Cadvertised.listeners%E7%9A%84%E4%BD%9C%E7%94%A8.html",relativePath:"03.中间件/01.kafka/01.listener和advertised.listeners的作用.md",key:"v-5793b4fb",path:"/pages/fa114f/",headers:[{level:2,title:"listener",slug:"listener",normalizedTitle:"listener",charIndex:2},{level:2,title:"advertised.listeners",slug:"advertised-listeners",normalizedTitle:"advertised.listeners",charIndex:630},{level:2,title:"内外网分流",slug:"内外网分流",normalizedTitle:"内外网分流",charIndex:1647},{level:2,title:"参考链接",slug:"参考链接",normalizedTitle:"参考链接",charIndex:2246}],headersStr:"listener advertised.listeners 内外网分流 参考链接",content:'# listener\n\nlistener配置是用来绑定BrokerIP+端口地址 的，也就是只有通过绑定的地址才能够访问到该Broker。除了绑定地址之外，还可以配置该监听地址的认证协议，也就是使用该地址连接Broker时需要指定使用何种协议方式进行连接。\n\n如下配置：\n\nlisteners: INTERNAL://172.17.0.10:9092,EXTERNAL://172.17.0.10:9094\nkafka_listener_security_protocol_map: "INTERNAL:SASL_PLAINTEXT,EXTERNAL:SASL_PLAINTEXT"\n\n\n1\n2\n\n\n连接该Broker的客户端只能通过172.17.0.10:9092 和172.17.0.10:9094 这两个地址访问kafka，并给前一个地址设置listener名称为INTERNAL ，后一个为EXTERNAL\n\n在kafka_listener_security_protocol_map 配置中设置listener所使用的通信协议，INTERNAL设置的是SASL_PLAINTEXT ，这也是常见的用户名和密码认证协议，EXTERNAL 设置也是该协议。\n\n最终，kafka 客户端连接该kafka broker，需要通过172.17.0.10:9092 或172.17.0.10:9094 地址进行连接，并且都需要使用用户名和密码进行认证。\n\n\n# advertised.listeners\n\n该配置指定Kafka Broker对外公开的网络IP和端口，用于告知客户端如何连接到Kafka Broker。公开的方式是通过存储在zookeeper中进行共享数据的。\n\n如下配置：\n\nlisteners: INTERNAL://172.17.0.10:9092,EXTERNAL://172.17.0.10:9094\nadvertised_listeners: INTERNAL://172.17.0.10:9092,EXTERNAL://公网IP:端口\nkafka_listener_security_protocol_map: "INTERNAL:SASL_PLAINTEXT,EXTERNAL:SASL_PLAINTEXT"\n\n\n1\n2\n3\n\n\nlisteners 和kafka_listener_security_protocol_map 的配置和上面讲的一样，而advertised_listeners 的配置和listeners 配置含义基本一致，但是它会保存在zookeeper中/brokers/ids/0 的endpoints里。\n\n...\n"endpoints":["INTERNAL://172.17.0.10:9092","EXTERNAL://172.17.0.10:9094"]\n...\n\n\n1\n2\n3\n\n\nkafka客户端连接kafka broker时，会先获取所有brokers的元数据信息，获取到endpoints的信息，然后再通过其中的endpint进行对broker进行连接操作。\n\n问题来了，我都知道了kafka broker的IP地址+端口了，为什么还需要advertised.listeners?\n\n在需要代理才能连接kafka broker时，在这种场景时，需要将advertised.listeners 设置为代理的地址。\n\n在公有云场景下部署kafka集群，公网IP不是在本节点网卡上的，所以无法通过listener进行绑定，所以只能通过0.0.0.0进行绑定。但是在集群外部时，kafka客户端进行连接，它是需要有能力访问kafka的每一个broker节点的，所以需要在advertised.listeners中配置公网IP，并存储在zookeeper中，这样kafka客户端就能拿到所有broker节点的公网IP并进行访问。\n\n\n# 内外网分流\n\n在公有云场景下，我们希望在集群内部客户端访问时不需要认证，而外部客户端访问时需要走认证加密访问。配置如下：\n\nlisteners: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094\nadvertised_listeners: INTERNAL://内网IP:9092,EXTERNAL://公网IP:9094\nkafka_listener_security_protocol_map: "INTERNAL:PLAINTEXT,EXTERNAL:SASL_PLAINTEXT"\n\n\n1\n2\n3\n\n\nlisteners都设置成对0.0.0.0进行监听也就是监听所有的网卡，但它们的端口不同，9092端口使用PLAINTEXT协议，而9094端口走的是SASL_PLAINTEXT协议\n\nadvertised_listeners，内网IP使用PLAINTEXT协议，公网IP使用SASL_PLAINTEXT协议。\n\n当内网客户端访问时，会先获取到所有brokers的advertised_listeners信息，然后通过PLAINTEXT协议走内网IP访问kafka集群。\n\n当公网客户端访问时，会先获取到所有brokers的advertised_listeners信息，然后通过SASL_PLAINTEXT走公网IP进行访问。\n\n‍\n\n\n# 参考链接\n\n * https://www.finclip.com/news/f/30226.html\n * https://juejin.cn/post/6893410969611927566',normalizedContent:'# listener\n\nlistener配置是用来绑定brokerip+端口地址 的，也就是只有通过绑定的地址才能够访问到该broker。除了绑定地址之外，还可以配置该监听地址的认证协议，也就是使用该地址连接broker时需要指定使用何种协议方式进行连接。\n\n如下配置：\n\nlisteners: internal://172.17.0.10:9092,external://172.17.0.10:9094\nkafka_listener_security_protocol_map: "internal:sasl_plaintext,external:sasl_plaintext"\n\n\n1\n2\n\n\n连接该broker的客户端只能通过172.17.0.10:9092 和172.17.0.10:9094 这两个地址访问kafka，并给前一个地址设置listener名称为internal ，后一个为external\n\n在kafka_listener_security_protocol_map 配置中设置listener所使用的通信协议，internal设置的是sasl_plaintext ，这也是常见的用户名和密码认证协议，external 设置也是该协议。\n\n最终，kafka 客户端连接该kafka broker，需要通过172.17.0.10:9092 或172.17.0.10:9094 地址进行连接，并且都需要使用用户名和密码进行认证。\n\n\n# advertised.listeners\n\n该配置指定kafka broker对外公开的网络ip和端口，用于告知客户端如何连接到kafka broker。公开的方式是通过存储在zookeeper中进行共享数据的。\n\n如下配置：\n\nlisteners: internal://172.17.0.10:9092,external://172.17.0.10:9094\nadvertised_listeners: internal://172.17.0.10:9092,external://公网ip:端口\nkafka_listener_security_protocol_map: "internal:sasl_plaintext,external:sasl_plaintext"\n\n\n1\n2\n3\n\n\nlisteners 和kafka_listener_security_protocol_map 的配置和上面讲的一样，而advertised_listeners 的配置和listeners 配置含义基本一致，但是它会保存在zookeeper中/brokers/ids/0 的endpoints里。\n\n...\n"endpoints":["internal://172.17.0.10:9092","external://172.17.0.10:9094"]\n...\n\n\n1\n2\n3\n\n\nkafka客户端连接kafka broker时，会先获取所有brokers的元数据信息，获取到endpoints的信息，然后再通过其中的endpint进行对broker进行连接操作。\n\n问题来了，我都知道了kafka broker的ip地址+端口了，为什么还需要advertised.listeners?\n\n在需要代理才能连接kafka broker时，在这种场景时，需要将advertised.listeners 设置为代理的地址。\n\n在公有云场景下部署kafka集群，公网ip不是在本节点网卡上的，所以无法通过listener进行绑定，所以只能通过0.0.0.0进行绑定。但是在集群外部时，kafka客户端进行连接，它是需要有能力访问kafka的每一个broker节点的，所以需要在advertised.listeners中配置公网ip，并存储在zookeeper中，这样kafka客户端就能拿到所有broker节点的公网ip并进行访问。\n\n\n# 内外网分流\n\n在公有云场景下，我们希望在集群内部客户端访问时不需要认证，而外部客户端访问时需要走认证加密访问。配置如下：\n\nlisteners: internal://0.0.0.0:9092,external://0.0.0.0:9094\nadvertised_listeners: internal://内网ip:9092,external://公网ip:9094\nkafka_listener_security_protocol_map: "internal:plaintext,external:sasl_plaintext"\n\n\n1\n2\n3\n\n\nlisteners都设置成对0.0.0.0进行监听也就是监听所有的网卡，但它们的端口不同，9092端口使用plaintext协议，而9094端口走的是sasl_plaintext协议\n\nadvertised_listeners，内网ip使用plaintext协议，公网ip使用sasl_plaintext协议。\n\n当内网客户端访问时，会先获取到所有brokers的advertised_listeners信息，然后通过plaintext协议走内网ip访问kafka集群。\n\n当公网客户端访问时，会先获取到所有brokers的advertised_listeners信息，然后通过sasl_plaintext走公网ip进行访问。\n\n‍\n\n\n# 参考链接\n\n * https://www.finclip.com/news/f/30226.html\n * https://juejin.cn/post/6893410969611927566',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"mysql之日志",frontmatter:{title:"mysql之日志",date:"2023-01-01T20:23:07.000Z",permalink:"/pages/2d69c7/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"一条数据在更新过程当中，如果中途 mysql crash 了，mysql 是如何保证数据的一致性和持久性的？在这个过程中 mysql 的日志系统起到了至关重要的作用。本文将会介绍 mysql 中的 undo log、redo log 和 bin log 在这其中的作用。",feed:{enable:!0},tags:["mysql","数据库"],categories:["数据库","mysql"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16699026890611669902688907.png"},{name:"twitter:title",content:"mysql之日志"},{name:"twitter:description",content:"一条数据在更新过程当中，如果中途 mysql crash 了，mysql 是如何保证数据的一致性和持久性的？在这个过程中 mysql 的日志系统起到了至关重要的作用。本文将会介绍 mysql 中的 undo log、redo log 和 bin log 在这其中的作用。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16699026890611669902688907.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.mysql/01.mysql%E4%B9%8B%E6%97%A5%E5%BF%97.html"},{property:"og:type",content:"article"},{property:"og:title",content:"mysql之日志"},{property:"og:description",content:"一条数据在更新过程当中，如果中途 mysql crash 了，mysql 是如何保证数据的一致性和持久性的？在这个过程中 mysql 的日志系统起到了至关重要的作用。本文将会介绍 mysql 中的 undo log、redo log 和 bin log 在这其中的作用。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16699026890611669902688907.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.mysql/01.mysql%E4%B9%8B%E6%97%A5%E5%BF%97.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-01-01T20:23:07.000Z"},{property:"article:tag",content:"mysql"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"mysql之日志"},{itemprop:"description",content:"一条数据在更新过程当中，如果中途 mysql crash 了，mysql 是如何保证数据的一致性和持久性的？在这个过程中 mysql 的日志系统起到了至关重要的作用。本文将会介绍 mysql 中的 undo log、redo log 和 bin log 在这其中的作用。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16699026890611669902688907.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.mysql/01.mysql%E4%B9%8B%E6%97%A5%E5%BF%97.html",relativePath:"03.中间件/03.mysql/01.mysql之日志.md",key:"v-967c62b6",path:"/pages/2d69c7/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"buffer pool",slug:"buffer-pool",normalizedTitle:"buffer pool",charIndex:146},{level:2,title:"undo log",slug:"undo-log",normalizedTitle:"undo log",charIndex:105},{level:2,title:"redo log",slug:"redo-log",normalizedTitle:"redo log",charIndex:114},{level:3,title:"redo log 的作用",slug:"redo-log-的作用",normalizedTitle:"redo log 的作用",charIndex:537},{level:3,title:"redo log文件结构",slug:"redo-log文件结构",normalizedTitle:"redo log文件结构",charIndex:1128},{level:2,title:"binlog",slug:"binlog",normalizedTitle:"binlog",charIndex:1333},{level:2,title:"两阶段提交",slug:"两阶段提交",normalizedTitle:"两阶段提交",charIndex:1764},{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:2647}],headersStr:"前言 buffer pool undo log redo log redo log 的作用 redo log文件结构 binlog 两阶段提交 相关链接",content:"# 前言\n\n一条数据在更新过程当中，如果中途 mysql crash 了，mysql 是如何保证数据的一致性和持久性的？在这个过程中 mysql 的日志系统起到了至关重要的作用。本文将会介绍 mysql 中的 undo log、redo log 和 bin log 在这其中的作用。\n\n\n# buffer pool\n\n在数据更新的时候，数据并不是实时同步到硬盘中，而是在一块缓存 buffer pool 中更新，如果缓存中没有查询到该数据，则从磁盘中加载到 buffer pool 中。\n\n当然，缓存的作用是为了提高 IO 性能，可以通过将数据先保留在缓存中，然后在适当的时机，批量写入到硬盘中。\n\n并且在查询数据时，先是从缓存中进行查询，不用去磁盘中查找，减少 IO 的操作，加快查询的速度。\n\n\n# undo log\n\n我们知道 InnoDB 是支持事务的，在事务提交失败时，是会回滚到执行之前的状态，那么肯定是需要保存之前的状态才可以进行恢复的，这个就是通过 undo log 来实现的。\n\n在数据写入 buffer pool 的同时会将更新前的数据保存在 undo log 中，通过该日志语句便可以在事务回滚时，恢复到之前的状态。\n\n\n# redo log\n\n\n# redo log 的作用\n\n再回到 buffer pool ，因为它是缓存，是在内存中，所有它的缺点也显而易见，那就是当服务器宕机中，缓存中的数据会丢失，那么 mysql 是如何保证数据的持久性呢？这个时候就要来介绍介绍 redo log 了。\n\n在数据更新到 buffer pool 后，这个时候会将更新后的数据记录到 redo log buffer 中，这个也是一个缓存区，它当然也具备了缓存优缺点，并且默认是在提交事务的时候写入到 redo log 中，刷盘的策略可以根据 innodb_flush_log_at_trx_commit 来设置\n\n * 0，不刷入磁盘\n * 1，立即刷入磁盘（默认）\n * 2，先刷入到 os cache 中\n\n因为 redo log 是顺序写入，所以 IO 性能不会太差。\n\n当 buffer pool 中的数据还没有写入到磁盘中时，发生了宕机，当 mysql 重启时，会读取已经持久化 redo log 中的数据，再恢复到 buffer pool 中。\n\n在开启事务准备更新一条记录时，InnoDB 会先在 buffer pool 中更新数据，然后将更新后的数据记录到 redo log buffer 中，这也是一个缓存。当然这个时候也是会发生宕机，但是没关系，如果该部分数据丢失，则认为该次事务提交失败，数据会恢复到之前的状态。\n\n\n# redo log文件结构\n\nredolog 是由多个固定大小的文件组成的一个环形结构，并在这个环形结构中不断的写入与覆盖的过程。\n\n * write pos：记录当前的位置\n * checkpoint：当前要擦除的位置\n\n当有新的 redo log 写入时，从 wirte pos 位置往后写，而 check point 是上一次已经刷入磁盘的数据的位置，也是要不断的往后推进，然后将数据刷入磁盘中。\n\n\n# binlog\n\n是在 mysql 层级记录的日志，主要是用于主从复制和数据恢复，可以通过某个时间的全量备份+binlog 来恢复到任意时间内的状态。\n\n和 redo log 的区别\n\n性质   REDO LOG                      BIN LOG                        \n实现   innodb 独有实现                   mysql server 层级实现，所有的引擎都可以使用   \n内容   物理 log, 记录的是“在某个数据页上做了什么修改”   逻辑 log，给 ID=2 这一行的 c 字段加 1     \n写入   循环写入                          追加写，写到一定大小切换下一个文件继续写           \n应用   崩溃恢复(crash-safe)              主从同步，数据恢复                      \n\n\n# 两阶段提交\n\n为什么需要两阶段提交？\n\n是为了让 redo log 和 bin log 保持逻辑一致性。\n\n 1. 如果先写 redolog 后写 bin log。假设 redo log 写完，写 bin log 时 crash 了。\n\n因为 redo log 写完了，所以即使系统崩溃，也可以恢复数据，但是 bin log 没写完 crash 了，这个时候 bin log 中少了该条语句，因此数据备份的时候，如果使用了该份 bin log 则会少一次更新。\n\n 2. 如果先写 bin log 后写 redo log。假设 bin log 写完，写 redo log 时 crash 了。\n\n因为 redo log 没写完，所以该事务没有生效，但是 binlog 中已经有该条记录，所以使用 bin log 时，会多出一个事务，与原来的数据不一致。\n\n所以使用两阶段提交可以解决上面两种场景。\n\n两阶段提交的实现逻辑\n\n 1. 在更新数据时，会先在 redo log 中记录当前更新的数据，并且标记为 prepare 状态\n 2. binlog 再进行写入\n 3. 事务提交时， redo log 再将该条记录标记为 commit 状态并且刷入到磁盘中。\n\n通过 prepare 和 commit 两种状态来完成两阶段的提交实现。\n\n验证两阶段提交\n\n 1. 如果在两阶段提交的第一步后发生 crash，也就是 redo log 已经更新了数据并且为 Prepare 状态，但是 binlog 还未写入就出现了 crash，这个时候，mysql 重启后，因为 redo log 未 commit，可以通过回滚将数据恢复。\n 2. 如果在第二步发生 crash，也就是 redo log 为 prepare 状态，并且 binlog 已经写入，但是这时候出现了 crash，在 mysql 重启后，因为 binlog 已经有了记录，所以会继续提交该事务，否则 bin log 中数据新增了一条，而 redo log 没提交则可能发生两者数据不一致的情况。\n\n\n# 相关链接\n\n * 一条 SQL 的执行过程详解\n * 基于Redo Log和Undo Log的MySQL崩溃恢复流程",normalizedContent:"# 前言\n\n一条数据在更新过程当中，如果中途 mysql crash 了，mysql 是如何保证数据的一致性和持久性的？在这个过程中 mysql 的日志系统起到了至关重要的作用。本文将会介绍 mysql 中的 undo log、redo log 和 bin log 在这其中的作用。\n\n\n# buffer pool\n\n在数据更新的时候，数据并不是实时同步到硬盘中，而是在一块缓存 buffer pool 中更新，如果缓存中没有查询到该数据，则从磁盘中加载到 buffer pool 中。\n\n当然，缓存的作用是为了提高 io 性能，可以通过将数据先保留在缓存中，然后在适当的时机，批量写入到硬盘中。\n\n并且在查询数据时，先是从缓存中进行查询，不用去磁盘中查找，减少 io 的操作，加快查询的速度。\n\n\n# undo log\n\n我们知道 innodb 是支持事务的，在事务提交失败时，是会回滚到执行之前的状态，那么肯定是需要保存之前的状态才可以进行恢复的，这个就是通过 undo log 来实现的。\n\n在数据写入 buffer pool 的同时会将更新前的数据保存在 undo log 中，通过该日志语句便可以在事务回滚时，恢复到之前的状态。\n\n\n# redo log\n\n\n# redo log 的作用\n\n再回到 buffer pool ，因为它是缓存，是在内存中，所有它的缺点也显而易见，那就是当服务器宕机中，缓存中的数据会丢失，那么 mysql 是如何保证数据的持久性呢？这个时候就要来介绍介绍 redo log 了。\n\n在数据更新到 buffer pool 后，这个时候会将更新后的数据记录到 redo log buffer 中，这个也是一个缓存区，它当然也具备了缓存优缺点，并且默认是在提交事务的时候写入到 redo log 中，刷盘的策略可以根据 innodb_flush_log_at_trx_commit 来设置\n\n * 0，不刷入磁盘\n * 1，立即刷入磁盘（默认）\n * 2，先刷入到 os cache 中\n\n因为 redo log 是顺序写入，所以 io 性能不会太差。\n\n当 buffer pool 中的数据还没有写入到磁盘中时，发生了宕机，当 mysql 重启时，会读取已经持久化 redo log 中的数据，再恢复到 buffer pool 中。\n\n在开启事务准备更新一条记录时，innodb 会先在 buffer pool 中更新数据，然后将更新后的数据记录到 redo log buffer 中，这也是一个缓存。当然这个时候也是会发生宕机，但是没关系，如果该部分数据丢失，则认为该次事务提交失败，数据会恢复到之前的状态。\n\n\n# redo log文件结构\n\nredolog 是由多个固定大小的文件组成的一个环形结构，并在这个环形结构中不断的写入与覆盖的过程。\n\n * write pos：记录当前的位置\n * checkpoint：当前要擦除的位置\n\n当有新的 redo log 写入时，从 wirte pos 位置往后写，而 check point 是上一次已经刷入磁盘的数据的位置，也是要不断的往后推进，然后将数据刷入磁盘中。\n\n\n# binlog\n\n是在 mysql 层级记录的日志，主要是用于主从复制和数据恢复，可以通过某个时间的全量备份+binlog 来恢复到任意时间内的状态。\n\n和 redo log 的区别\n\n性质   redo log                      bin log                        \n实现   innodb 独有实现                   mysql server 层级实现，所有的引擎都可以使用   \n内容   物理 log, 记录的是“在某个数据页上做了什么修改”   逻辑 log，给 id=2 这一行的 c 字段加 1     \n写入   循环写入                          追加写，写到一定大小切换下一个文件继续写           \n应用   崩溃恢复(crash-safe)              主从同步，数据恢复                      \n\n\n# 两阶段提交\n\n为什么需要两阶段提交？\n\n是为了让 redo log 和 bin log 保持逻辑一致性。\n\n 1. 如果先写 redolog 后写 bin log。假设 redo log 写完，写 bin log 时 crash 了。\n\n因为 redo log 写完了，所以即使系统崩溃，也可以恢复数据，但是 bin log 没写完 crash 了，这个时候 bin log 中少了该条语句，因此数据备份的时候，如果使用了该份 bin log 则会少一次更新。\n\n 2. 如果先写 bin log 后写 redo log。假设 bin log 写完，写 redo log 时 crash 了。\n\n因为 redo log 没写完，所以该事务没有生效，但是 binlog 中已经有该条记录，所以使用 bin log 时，会多出一个事务，与原来的数据不一致。\n\n所以使用两阶段提交可以解决上面两种场景。\n\n两阶段提交的实现逻辑\n\n 1. 在更新数据时，会先在 redo log 中记录当前更新的数据，并且标记为 prepare 状态\n 2. binlog 再进行写入\n 3. 事务提交时， redo log 再将该条记录标记为 commit 状态并且刷入到磁盘中。\n\n通过 prepare 和 commit 两种状态来完成两阶段的提交实现。\n\n验证两阶段提交\n\n 1. 如果在两阶段提交的第一步后发生 crash，也就是 redo log 已经更新了数据并且为 prepare 状态，但是 binlog 还未写入就出现了 crash，这个时候，mysql 重启后，因为 redo log 未 commit，可以通过回滚将数据恢复。\n 2. 如果在第二步发生 crash，也就是 redo log 为 prepare 状态，并且 binlog 已经写入，但是这时候出现了 crash，在 mysql 重启后，因为 binlog 已经有了记录，所以会继续提交该事务，否则 bin log 中数据新增了一条，而 redo log 没提交则可能发生两者数据不一致的情况。\n\n\n# 相关链接\n\n * 一条 sql 的执行过程详解\n * 基于redo log和undo log的mysql崩溃恢复流程",charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"mysql之MVCC原理",frontmatter:{title:"mysql之MVCC原理",date:"2023-01-01T20:23:21.000Z",permalink:"/pages/0d8f4a/",tags:["mysql","数据库"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"MVCC 的全称是 Multi- [Version](https://so.csdn.net/so/search?q=Version&spm=1001.2101.3001.7020) Concurrency Control，也就是多版本并发控制，该机制是只有支持事务的 InnoDB 引擎下才存在的，用来实现提高数据库的并发性能，可以做到：读不加锁，读写不冲突。",feed:{enable:!0},categories:["数据库","mysql"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210821150008.png"},{name:"twitter:title",content:"mysql之MVCC原理"},{name:"twitter:description",content:"MVCC 的全称是 Multi- [Version](https://so.csdn.net/so/search?q=Version&spm=1001.2101.3001.7020) Concurrency Control，也就是多版本并发控制，该机制是只有支持事务的 InnoDB 引擎下才存在的，用来实现提高数据库的并发性能，可以做到：读不加锁，读写不冲突。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210821150008.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.mysql/02.mysql%E4%B9%8BMVCC%E5%8E%9F%E7%90%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"mysql之MVCC原理"},{property:"og:description",content:"MVCC 的全称是 Multi- [Version](https://so.csdn.net/so/search?q=Version&spm=1001.2101.3001.7020) Concurrency Control，也就是多版本并发控制，该机制是只有支持事务的 InnoDB 引擎下才存在的，用来实现提高数据库的并发性能，可以做到：读不加锁，读写不冲突。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210821150008.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.mysql/02.mysql%E4%B9%8BMVCC%E5%8E%9F%E7%90%86.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-01-01T20:23:21.000Z"},{property:"article:tag",content:"mysql"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"mysql之MVCC原理"},{itemprop:"description",content:"MVCC 的全称是 Multi- [Version](https://so.csdn.net/so/search?q=Version&spm=1001.2101.3001.7020) Concurrency Control，也就是多版本并发控制，该机制是只有支持事务的 InnoDB 引擎下才存在的，用来实现提高数据库的并发性能，可以做到：读不加锁，读写不冲突。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210821150008.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.mysql/02.mysql%E4%B9%8BMVCC%E5%8E%9F%E7%90%86.html",relativePath:"03.中间件/03.mysql/02.mysql之MVCC原理.md",key:"v-097050d4",path:"/pages/0d8f4a/",headers:[{level:2,title:"什么是 MVCC?",slug:"什么是-mvcc",normalizedTitle:"什么是 mvcc?",charIndex:2},{level:2,title:"MVCC 的实现原理",slug:"mvcc-的实现原理",normalizedTitle:"mvcc 的实现原理",charIndex:145},{level:2,title:"ReadView",slug:"readview",normalizedTitle:"readview",charIndex:373},{level:2,title:"Undo 日志",slug:"undo-日志",normalizedTitle:"undo 日志",charIndex:824},{level:2,title:"快照读和当前读",slug:"快照读和当前读",normalizedTitle:"快照读和当前读",charIndex:1026},{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:1314}],headersStr:"什么是 MVCC? MVCC 的实现原理 ReadView Undo 日志 快照读和当前读 相关链接",content:"# 什么是 MVCC?\n\nMVCC 的全称是 Multi- Version Concurrency Control，也就是多版本并发控制，该机制是只有支持事务的 InnoDB 引擎下才存在的，用来实现提高数据库的并发性能，可以做到：读不加锁，读写不冲突。\n\n那么它是如何实现的呢？\n\n\n# MVCC 的实现原理\n\n在 Innodb 的每一行数据中都会保存多个版本，每个版本都有对应的事务 ID。\n\n在开启每一个事务时，都会生成当前事务的版本号，当在该事务中操作修改数据时，都会生成一个新的数据行，该数据行在提交之前对其他事务来说是不可见的，然后将版本号更新到数据行中，这样就保证了每个事务操作的数据都是互不影响的，也不存在锁的问题。\n\n在读操作时，我们只去快照读，而不读取正在修改的数据，这是两个不同版本的数据，所以操作上不会发生冲突。\n\n\n# ReadView\n\nRead View 是来表示当前事务的可见性的，通过上面的 MVCC 原理知道所有的行数据都是有版本的，那么哪些版本的数据在当前事务是可见的，也就是可读到的，哪些是不可见的。\n\n创建 Read View 时，会构造一个数组来保存当前事务启动瞬间启动了但是没有提交的事务 ID。\n\n * 如果小于最小值，则是已经提交的事务，是可见的\n * 如果大于最大值，则代表是将来启动的事务，不可见\n * 如果在数组列表中，表示还没提交的事务，不可见\n * 如果大于最小值，小于最大值，但不在数组中，表示是已经提交了的事务，可见\n\n创建 Read View 的时机在不同的隔离级别是不同。\n\n * 在读未提交中，直接读取的是最新版本的数据\n * 在读已提交中，在每次读取数据前，就会生成一个 Read View，然后再读取可见版本的数据。\n * 在可重复读中，在每次开启事务的时候，就会生成 Read View，在提交之前都一直如此使用。\n * 在串行化中，是通过加锁的方式来访问数据。\n\n\n# Undo 日志\n\n每条记录更新时，都会同时记录一条回滚操作。记录上的最新值都可通过回滚操作得到前一个状态值\n\n在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。系统会判断在没有事务需要用到回滚日志时，回滚日志会被删除\n\n不建议使用长事务的原因是，在事务提交之前，回滚日志都需要保存，导致占用大量存储空间。\n\n\n\n\n# 快照读和当前读\n\n快照读，就是当进行查询时，是根据 Read View 的视图可见性来读取对应版本的数据。\n\n有这么一个场景，当前是可重复读的隔离界别，开始事务的顺序分别是 A、B、C，事务 C 更新 K 之后，最新的版本 102，当事务 B，根据 Read View 是看不到 102 版本的数据，那么其更新只能在 90 版本上去+1，这样的结果肯定是不对的，因为不是在最新的结果上进行+1，所以这里需要用到 当前读，也就是去读取当前数据的最新版本的数据，然后再进行+1。该当前读会对该行数据进行加锁，在该事务 commit 之前，其他事务都不能对其进行操作。\n\n\n\n\n# 相关链接\n\n * https://blog.csdn.net/SIESTA030/article/details/123113437\n * https://blog.csdn.net/huaishu/article/details/89924250",normalizedContent:"# 什么是 mvcc?\n\nmvcc 的全称是 multi- version concurrency control，也就是多版本并发控制，该机制是只有支持事务的 innodb 引擎下才存在的，用来实现提高数据库的并发性能，可以做到：读不加锁，读写不冲突。\n\n那么它是如何实现的呢？\n\n\n# mvcc 的实现原理\n\n在 innodb 的每一行数据中都会保存多个版本，每个版本都有对应的事务 id。\n\n在开启每一个事务时，都会生成当前事务的版本号，当在该事务中操作修改数据时，都会生成一个新的数据行，该数据行在提交之前对其他事务来说是不可见的，然后将版本号更新到数据行中，这样就保证了每个事务操作的数据都是互不影响的，也不存在锁的问题。\n\n在读操作时，我们只去快照读，而不读取正在修改的数据，这是两个不同版本的数据，所以操作上不会发生冲突。\n\n\n# readview\n\nread view 是来表示当前事务的可见性的，通过上面的 mvcc 原理知道所有的行数据都是有版本的，那么哪些版本的数据在当前事务是可见的，也就是可读到的，哪些是不可见的。\n\n创建 read view 时，会构造一个数组来保存当前事务启动瞬间启动了但是没有提交的事务 id。\n\n * 如果小于最小值，则是已经提交的事务，是可见的\n * 如果大于最大值，则代表是将来启动的事务，不可见\n * 如果在数组列表中，表示还没提交的事务，不可见\n * 如果大于最小值，小于最大值，但不在数组中，表示是已经提交了的事务，可见\n\n创建 read view 的时机在不同的隔离级别是不同。\n\n * 在读未提交中，直接读取的是最新版本的数据\n * 在读已提交中，在每次读取数据前，就会生成一个 read view，然后再读取可见版本的数据。\n * 在可重复读中，在每次开启事务的时候，就会生成 read view，在提交之前都一直如此使用。\n * 在串行化中，是通过加锁的方式来访问数据。\n\n\n# undo 日志\n\n每条记录更新时，都会同时记录一条回滚操作。记录上的最新值都可通过回滚操作得到前一个状态值\n\n在视图 a、b、c 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（mvcc）。系统会判断在没有事务需要用到回滚日志时，回滚日志会被删除\n\n不建议使用长事务的原因是，在事务提交之前，回滚日志都需要保存，导致占用大量存储空间。\n\n\n\n\n# 快照读和当前读\n\n快照读，就是当进行查询时，是根据 read view 的视图可见性来读取对应版本的数据。\n\n有这么一个场景，当前是可重复读的隔离界别，开始事务的顺序分别是 a、b、c，事务 c 更新 k 之后，最新的版本 102，当事务 b，根据 read view 是看不到 102 版本的数据，那么其更新只能在 90 版本上去+1，这样的结果肯定是不对的，因为不是在最新的结果上进行+1，所以这里需要用到 当前读，也就是去读取当前数据的最新版本的数据，然后再进行+1。该当前读会对该行数据进行加锁，在该事务 commit 之前，其他事务都不能对其进行操作。\n\n\n\n\n# 相关链接\n\n * https://blog.csdn.net/siesta030/article/details/123113437\n * https://blog.csdn.net/huaishu/article/details/89924250",charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"redis之五种基本数据类型",frontmatter:{title:"redis之五种基本数据类型",date:"2022-12-01T15:16:14.000Z",permalink:"/pages/2bbeb3/",tags:["redis","数据库"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文主要讲解 redis 的五种基本数据类型：String、List、Set、Sorted Set、Hash。学习如何使用它们，并且了解它们的底层数据结构实现，这样我们才能在适当的应用场景选择最适合的数据类型来解决我们的需求。",feed:{enable:!0},categories:["数据库","redis"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210820163352.png"},{name:"twitter:title",content:"redis之五种基本数据类型"},{name:"twitter:description",content:"本文主要讲解 redis 的五种基本数据类型：String、List、Set、Sorted Set、Hash。学习如何使用它们，并且了解它们的底层数据结构实现，这样我们才能在适当的应用场景选择最适合的数据类型来解决我们的需求。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210820163352.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/01.redis%E4%B9%8B%E4%BA%94%E7%A7%8D%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html"},{property:"og:type",content:"article"},{property:"og:title",content:"redis之五种基本数据类型"},{property:"og:description",content:"本文主要讲解 redis 的五种基本数据类型：String、List、Set、Sorted Set、Hash。学习如何使用它们，并且了解它们的底层数据结构实现，这样我们才能在适当的应用场景选择最适合的数据类型来解决我们的需求。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210820163352.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/01.redis%E4%B9%8B%E4%BA%94%E7%A7%8D%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-12-01T15:16:14.000Z"},{property:"article:tag",content:"redis"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"redis之五种基本数据类型"},{itemprop:"description",content:"本文主要讲解 redis 的五种基本数据类型：String、List、Set、Sorted Set、Hash。学习如何使用它们，并且了解它们的底层数据结构实现，这样我们才能在适当的应用场景选择最适合的数据类型来解决我们的需求。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210820163352.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/01.redis%E4%B9%8B%E4%BA%94%E7%A7%8D%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html",relativePath:"03.中间件/05.redis/01.redis之五种基本数据类型.md",key:"v-2ecc148c",path:"/pages/2bbeb3/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. String",slug:"_1-string",normalizedTitle:"1. string",charIndex:127},{level:3,title:"1.1 简单使用",slug:"_1-1-简单使用",normalizedTitle:"1.1 简单使用",charIndex:141},{level:3,title:"1.2 数据编码",slug:"_1-2-数据编码",normalizedTitle:"1.2 数据编码",charIndex:843},{level:3,title:"1.3 简单动态字符串(SDS)",slug:"_1-3-简单动态字符串-sds",normalizedTitle:"1.3 简单动态字符串(sds)",charIndex:1330},{level:3,title:"1.4 使用场景",slug:"_1-4-使用场景",normalizedTitle:"1.4 使用场景",charIndex:2193},{level:2,title:"2. List",slug:"_2-list",normalizedTitle:"2. list",charIndex:2267},{level:3,title:"2.1 简单使用",slug:"_2-1-简单使用",normalizedTitle:"2.1 简单使用",charIndex:2279},{level:3,title:"2.2 数据编码",slug:"_2-2-数据编码",normalizedTitle:"2.2 数据编码",charIndex:2884},{level:3,title:"2.3 压缩列表(ziplist)",slug:"_2-3-压缩列表-ziplist",normalizedTitle:"2.3 压缩列表(ziplist)",charIndex:3066},{level:3,title:"2.4 快速列表(quicklist)",slug:"_2-4-快速列表-quicklist",normalizedTitle:"2.4 快速列表(quicklist)",charIndex:4017},{level:3,title:"2.5 使用场景",slug:"_2-5-使用场景",normalizedTitle:"2.5 使用场景",charIndex:4241},{level:2,title:"3. Set",slug:"_3-set",normalizedTitle:"3. set",charIndex:4274},{level:3,title:"3.1 简单使用",slug:"_3-1-简单使用",normalizedTitle:"3.1 简单使用",charIndex:4319},{level:3,title:"3.2 数据编码",slug:"_3-2-数据编码",normalizedTitle:"3.2 数据编码",charIndex:4685},{level:3,title:"3.3 整型数组(intset)",slug:"_3-3-整型数组-intset",normalizedTitle:"3.3 整型数组(intset)",charIndex:4986},{level:3,title:"3.4 使用场景",slug:"_3-4-使用场景",normalizedTitle:"3.4 使用场景",charIndex:5534},{level:2,title:"4. Sorted Set",slug:"_4-sorted-set",normalizedTitle:"4. sorted set",charIndex:5618},{level:3,title:"4.1 简单使用",slug:"_4-1-简单使用",normalizedTitle:"4.1 简单使用",charIndex:5680},{level:3,title:"4.2 数据编码",slug:"_4-2-数据编码",normalizedTitle:"4.2 数据编码",charIndex:6235},{level:3,title:"4.3 跳表(skiplist)",slug:"_4-3-跳表-skiplist",normalizedTitle:"4.3 跳表(skiplist)",charIndex:6528},{level:3,title:"4.4 使用场景",slug:"_4-4-使用场景",normalizedTitle:"4.4 使用场景",charIndex:6643},{level:2,title:"5. hash",slug:"_5-hash",normalizedTitle:"5. hash",charIndex:6684},{level:3,title:"5.1 简单使用",slug:"_5-1-简单使用",normalizedTitle:"5.1 简单使用",charIndex:6725},{level:3,title:"5.2 数据编码",slug:"_5-2-数据编码",normalizedTitle:"5.2 数据编码",charIndex:7229},{level:3,title:"5.3 使用场景",slug:"_5-3-使用场景",normalizedTitle:"5.3 使用场景",charIndex:7365},{level:2,title:"6. 总结",slug:"_6-总结",normalizedTitle:"6. 总结",charIndex:7391},{level:2,title:"7. 相关链接",slug:"_7-相关链接",normalizedTitle:"7. 相关链接",charIndex:7469}],headersStr:"0. 前言 1. String 1.1 简单使用 1.2 数据编码 1.3 简单动态字符串(SDS) 1.4 使用场景 2. List 2.1 简单使用 2.2 数据编码 2.3 压缩列表(ziplist) 2.4 快速列表(quicklist) 2.5 使用场景 3. Set 3.1 简单使用 3.2 数据编码 3.3 整型数组(intset) 3.4 使用场景 4. Sorted Set 4.1 简单使用 4.2 数据编码 4.3 跳表(skiplist) 4.4 使用场景 5. hash 5.1 简单使用 5.2 数据编码 5.3 使用场景 6. 总结 7. 相关链接",content:'# 0. 前言\n\n本文主要讲解 redis 的五种基本数据类型：String、List、Set、Sorted Set、Hash。学习如何使用它们，并且了解它们的底层数据结构实现，这样我们才能在适当的应用场景选择最适合的数据类型来解决我们的需求。\n\n\n# 1. String\n\n\n# 1.1 简单使用\n\nString 是 redis 最简单的且最常用的数据类型，可以用来存储字符串、整型以及浮点型。\n\n * 字符串\n\n127.0.0.1:6379> set name zhangsan\nOK\n127.0.0.1:6379> get name\n"zhangsan"\n\n\n1\n2\n3\n4\n\n * 整型\n\n虽然 get age 时返回的是字符串，但是可以通过 object encoding age 看到其真正的类型。\n\n127.0.0.1:6379> set age 18\nOK\n127.0.0.1:6379> get age\n"18"\n127.0.0.1:6379> object encoding age\n"int"\n\n# 自增\n127.0.0.1:6379> incr age\n(integer) 19\n\n# 自减\n127.0.0.1:6379> decr age\n(integer) 18\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n * 浮点型\n\n写入的浮点型，但还是通过字符串来保存的，但是在使用的时候，会将字符串转换成浮点数。\n\n127.0.0.1:6379> set height 1.77\nOK\n127.0.0.1:6379> get height\n"1.77"\n127.0.0.1:6379> object encoding height\n"embstr"\n\n# 浮点数操作\n127.0.0.1:6379> incrbyfloat height 1\n"2.77"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n更多的操作请参考官网\n\n\n# 1.2 数据编码\n\nString 支持的编码类型有 int、embstr 和 raw，在不同条件时，会转换成对应的编码。\n\n * int 当存储的数据为整型时，会使用 int 编码。其实现是，会直接将整型值存储在 redisObject 的 ptr（将 void* 转换成 long） 中，并且将字符串的对象的编码设置为 int。\n\n * raw 该种编码是使用一种简单动态字符串(SDS)的数据结构存储，当字符串的长度大于 44 时，会使用该种数据编码方式。\n\n * embstr 也是使用 简单动态字符串(SDS)的数据结构存储，是当字符串长度小于等于 44 时使用。\n\nembstr 和 raw 的区别是什么呢？\n\n创建 string 使用 raw 编码时，会调用两次内存分配来创建 redisObject 和 sds 的数据结构，而 embstr 只会调用一次来创建连续的内存空间来存储 redisObject 和 sds 。\n\n当字符串较小时，embstr 少调用一次内存分配，释放也只需要一次，明显更快，并且连续的内存空间可以更好的利用 cpu 缓存。\n\n\n# 1.3 简单动态字符串(SDS)\n\n在数据编码中提到 embstr 和 raw 都是使用 SDS 数据结构，那么这种数据结构的是怎么样的，有什么好处呢？\n\n数据结构如下图所示：\n\nstruct sdshdr {\n    //记录buf数组中已使用字节的数量，等于SDS所保存字符串的长度\n    int len;\n \n    //记录buf 数组中未使用字节的数量\n    int free;\n \n    //字节数组，用于保存字符串\n    char buf[];\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n * free: 表示还有多少空余空间\n * len: 已使用多少空间\n * buf: 存储字符串的数组\n\n问题：String 为什么使用简单动态字符串来实现，而不是使用 C 传统字符串来实现呢？\n\n * 防止缓存区溢出\n\n在扩充字符串时，需要考虑缓冲区是否足够，SDS 提供 API 来帮助我们判断并扩充空间。\n\n * 常数获取字符串长度\n\nC 传统字符串需要遍历才能知道具体的长度，时间复杂度为 O(n)，而 SDS 可以直接读 len 属性获取长度，时间复杂度为 O(1)\n\n * 减少内存分配的次数\n\n在扩大字符串长度时，需要重新申请更大的内存空间，然后拷贝到新的内存空间中，然后再释放旧的内存空间。\n\n在缩小时也是一样，需要申请新的空间，再释放旧的空间。\n\n在 SDS 中可以通过以下的方式来减少内存分配和释放，提高效率。\n\n 1. 空间预分配，在分配空间时，除了必要的空间外，可以额外的分配未使用的空间，在下次使用，可以快速使用这部分的空间，而不必重新分配。\n 2. 惰性释放空间，在缩小字符串时，不需要马上释放多余的空间，可以预留给下次使用。\n\n * 二进制安全\n\nC 语言中是以空字符来表示字符串的结束，而一些二进制文件内容可能是包含空字符串的，因此 C 语言字符串无法正确读取，所以 SDS 都是以二进制方式处理 buf，并且不以空字符串判断是否结束，而是用 len 来判断。\n\n\n# 1.4 使用场景\n\n * 缓存，存储热点数据作为缓存，降低持久化数据库的读写压力。\n * 分布式锁\n * 计数器，可以使用 incr 命令\n\n\n# 2. List\n\n\n# 2.1 简单使用\n\n命令       说明\nlpush    将值从左边推入列表\nrpush    将值从右边推入列表\nlpop     将值从列表左边弹出返回\nrpop     将值从列表右边弹出返回\nlrange   根据索引查看列表中的数据\n\n127.0.0.1:6379> lpush mylist 1 2 3\n(integer) 3\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "3"\n2) "2"\n3) "1"\n\n127.0.0.1:6379> rpush mylist 4\n(integer) 4\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "3"\n2) "2"\n3) "1"\n4) "4"\n\n127.0.0.1:6379> lpop mylist\n"3"\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "2"\n2) "1"\n3) "4"\n\n127.0.0.1:6379> rpop mylist\n"4"\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "2"\n2) "1"\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 2.2 数据编码\n\n在 redis3.2 之前使用的是 ziplist 和 linkedlist 两种编码方式。在数据量少的时候使用 ziplist，而数据多的时候使用 linkedlist。\n\n而之后的版本使用的是 quicklist\n\n127.0.0.1:6379> object encoding mylist\n"quicklist"\n\n\n1\n2\n\n\n\n# 2.3 压缩列表(ziplist)\n\n该数据结构类似于一个数组，在数组的表头添加三个字段 zlbytes、zltail、zlen，再在表尾添加 zlend 表示列表结束。\n\n\n\n * zlbytes：内存字节数\n * zltail：列表尾偏移量\n * zllen：列表元素个数\n * zlend：列表结束标记\n\n通过这几个字段可以快速定位第一个元素和最后元素，时间复杂度为 O(1)。\n\n除了表头与表尾之外，其他元素都是节点，节点的数据结构如下图：\n\n\n\n * previous_entry_length : 上一个节点的长度。可以推算出上一个节点的地址\n * encoding: 该节点的数据类型及长度\n * content: 节点的值\n\n连锁更新问题\n\n对于 previous_entry_length：\n\n * 前一个节点长度小于 254 字节，previous_entry_length 长度需要用 1 字节保存长度值\n * 前一个节点长度大于 254 字节，previous_entry_length 长度需要用 5 字节保存长度值\n\n有这一种场景，如果压缩列表中有多个连续的节点长度在 250-253 字节之间，这些节点 previous_entry_length 使用 1 个字节存储大小。\n\n * 当在最前方添加一个节点大于等于 254 字节的节点时，后面的节点 previous_entry_length 都需要从 1 字节扩充到 5 字节，起到连锁更新，后面的节点都需要更新。\n\n\n\n * 当删除其中 small 节点时，其后节点 previous_entry_length 需要保存前面的 big 节点，需要扩充节点空间，并且后面发生连锁更新\n\n\n\n虽然连锁更新复杂度很高，但是造成的可能性很低。\n\n * 长度需要在 250 到 253 字节之间\n * 被更新的节点数量不多，也不会造成性能影响\n\n优点\n\n * 内存地址连续，减少了内存碎片化，可以使用到缓存进行优化\n * 如果是双向链表，节点的头尾都需要指针来指向上一个或者下一个节点，而压缩列表省去了该部分内存空间的占用。\n\n缺点\n\n * 对于删除和插入操作都需要移动该节点位置后面的元素，并且可能会触发连锁更新反应\n\n\n# 2.4 快速列表(quicklist)\n\nquicklist 是压缩列表和双向链表结合实现的，在宏观上它是一个双向链表，然后其每个结点上都挂了一个 ziplist。如下图所示：\n\nziplist 在列表数量大的时候性能会下降，很难分配一大块连续的内存空间，并且在删除和插入操作性能下降的更为厉害。\n\n而双向链表会导致大量的碎片化空间，而且每个节点的头尾指针都会占用一定的内存空间。\n\n而 quicklist 算是在两者之间取得了一个平衡。\n\n\n# 2.5 使用场景\n\n * 消息队列\n * 列表及分页展示\n\n\n# 3. Set\n\n是一个无序的集合，集合元素是唯一的，会自动对添加的数据进行去重。\n\n\n# 3.1 简单使用\n\n命令          说明\nSADD        向集合添加一个或多个元素\nSCARD       获取集合的数量\nSMEMBERS    获取集合全部元素\nSISMEMBER   判断集合中是否指定元素\n\n127.0.0.1:6379> sadd myset zheng wen feng zheng\n(integer) 3\n\n127.0.0.1:6379> scard myset\n(integer) 3\n\n127.0.0.1:6379> smembers myset\n1) "zheng"\n2) "feng"\n3) "wen"\n\n127.0.0.1:6379> sismember myset feng\n(integer) 1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 3.2 数据编码\n\n该数据类型使用数据编码的是 intset 或者 hashtable，当 set 满足以下条件时，使用的 inset，其他情况都是 hashtable。\n\n * 当所有的元素都是整数值时\n * 元素个数不超过 512 个时\n\n127.0.0.1:6379> sadd myset2 1 2 4 4\n(integer) 3\n\n127.0.0.1:6379> SMEMBERS myset2\n1) "1"\n2) "2"\n3) "4"\n\n127.0.0.1:6379> OBJECT ENCODING myset2\n"intset"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 3.3 整型数组(intset)\n\nintset 数据结构如下所示：\n\ntypedef struct intset {\n    // 编码方式\n    uint32_t encoding;\n    // 集合包含的元素数量\n    uint32_t length;\n    // 保存元素的数组\n    int8_t contents[];\n} intset;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * encoding：contents 中存储的数据类型取决于该字段\n * length: 数组长度\n * contnets: 存储数据的整型数组，数据的数据类型取决于 encoding，从小到大排序\n\ncontents 数组中每一个元素的类型都是由 encoding 决定的，但是当原来的数据类型是 int16 时，现在要插入一个 int32 时，该如何操作呢？\n\n升级\n\n这个时候需要对 contents 中的每个元素都进行升级：\n\n * 根据新元素的类型，扩大 contents 数组的空间大小\n * 将数组的所有元素转换成新元素相同的类型并放入数组中\n * 最后改变 encoding 的值\n\n这么做的好处是，当所有的数据都是小整型时，可以节省内存的开销。\n\n目前不支持降级。\n\n\n# 3.4 使用场景\n\n * 标签，给用户打上标签，以标签为 key，用户 ID 为 value 放入 set 中\n * 点赞，收藏等，利用 set 的唯一特性。\n\n\n# 4. Sorted Set\n\n是一个不允许重复元素的集合，但是每个元素会关联一个分数，可以通过分数对集合进行排序。\n\n\n# 4.1 简单使用\n\n命令       说明\nZADD     向集合添加一个或多个元素\nZRANGE   根据位置查询获取集合多个元素\nZREM     如果元素存在集合中，则进行删除\n\n127.0.0.1:6379> zadd myzset 100 zheng 99 wen 80 feng\n(integer) 3\n\n127.0.0.1:6379> zrange myzset 0 -1\n1) "feng"\n2) "wen"\n3) "zheng"\n\n127.0.0.1:6379> zadd myzset 91 hello\n(integer) 1\n\n# 默认是根据score升序查询\n127.0.0.1:6379> zrange myzset 0 -1\n1) "feng"\n2) "hello"\n3) "wen"\n4) "zheng"\n\n127.0.0.1:6379> zrem myzset wen\n(integer) 1\n\n127.0.0.1:6379> zrange myzset 0 -1\n1) "feng"\n2) "hello"\n3) "zheng"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# 4.2 数据编码\n\n该类型的数据编码可以为 ziplist 或者 skiplist，当满足以下条件时，使用的 ziplist，其他情况是 skiplist\n\n * 元素数量小于 128\n * 搜索元素长度小于 64\n\n当数据编码为 skiplist 时，redis 中使用的存储结构是 zset 数据结构，其中包含了 zskiplist 和 dict\n\ntypedef struct zset {\n    zskiplist *zs1;\n    dict *dict;\n}\n\n\n1\n2\n3\n4\n\n\n通过 zskiplist 可以快速的范围查询，dict 可以快速定位单个元素。\n\n\n# 4.3 跳表(skiplist)\n\n在有序的链表上添加了多级索引，通过索引位置的跳转，实现数据的快速定位。如下图所示：\n\n优点：\n\n 1. 在通过范围查询或排序时，可以在跳表中先找到最小值，然后再在最底层链表中遍历获取。\n\n\n# 4.4 使用场景\n\n * 排行榜，通过给视频、文章打分，然后进行排序展示\n\n\n# 5. hash\n\n用于存储 string 类型的键值对，适用于存储对象。\n\n\n# 5.1 简单使用\n\n命令        说明\nhset      设置键值对\nhget      获取指定 hash 的键对应的值\nhgetall   获取指定 hash 中的所有键值对\nhdel      删除指定 hash 中的键值对\n\n127.0.0.1:6379> hset person name zhangsan\n(integer) 1\n\n127.0.0.1:6379> hset person age 18\n(integer) 1\n\n127.0.0.1:6379> hget persion name\n"zhangsan"\n\n127.0.0.1:6379> hgetall person\n1) "name"\n2) "zhangsan"\n3) "age"\n4) "18"\n\n127.0.0.1:6379> hdel person age\n(integer) 1\n\n127.0.0.1:6379> hgetall person\n1) "name"\n2) "zhangsan"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n\n# 5.2 数据编码\n\n使用的数据编码是 ziplist 或 hashtable，满足以下条件选择使用 ziplist，其他情况使用 hashtable\n\n * hash 对象保存的键和值字符串长度都小于 64 字节\n * hash 对象保存的键值对数量小于 512\n\n\n# 5.3 使用场景\n\n * 用来存储对象信息\n\n\n# 6. 总结\n\nredis 之所以快，正是因为其有着丰富的数据结构，所以我们需要理解它们，在设计方案时，就能正确的选择数据类型来实现我们的业务需求。\n\n\n# 7. 相关链接\n\n * Redis 设计与实现\n * 图解 redis 五种数据结构底层实现\n * Redis 设计与实现\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来',normalizedContent:'# 0. 前言\n\n本文主要讲解 redis 的五种基本数据类型：string、list、set、sorted set、hash。学习如何使用它们，并且了解它们的底层数据结构实现，这样我们才能在适当的应用场景选择最适合的数据类型来解决我们的需求。\n\n\n# 1. string\n\n\n# 1.1 简单使用\n\nstring 是 redis 最简单的且最常用的数据类型，可以用来存储字符串、整型以及浮点型。\n\n * 字符串\n\n127.0.0.1:6379> set name zhangsan\nok\n127.0.0.1:6379> get name\n"zhangsan"\n\n\n1\n2\n3\n4\n\n * 整型\n\n虽然 get age 时返回的是字符串，但是可以通过 object encoding age 看到其真正的类型。\n\n127.0.0.1:6379> set age 18\nok\n127.0.0.1:6379> get age\n"18"\n127.0.0.1:6379> object encoding age\n"int"\n\n# 自增\n127.0.0.1:6379> incr age\n(integer) 19\n\n# 自减\n127.0.0.1:6379> decr age\n(integer) 18\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n * 浮点型\n\n写入的浮点型，但还是通过字符串来保存的，但是在使用的时候，会将字符串转换成浮点数。\n\n127.0.0.1:6379> set height 1.77\nok\n127.0.0.1:6379> get height\n"1.77"\n127.0.0.1:6379> object encoding height\n"embstr"\n\n# 浮点数操作\n127.0.0.1:6379> incrbyfloat height 1\n"2.77"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n更多的操作请参考官网\n\n\n# 1.2 数据编码\n\nstring 支持的编码类型有 int、embstr 和 raw，在不同条件时，会转换成对应的编码。\n\n * int 当存储的数据为整型时，会使用 int 编码。其实现是，会直接将整型值存储在 redisobject 的 ptr（将 void* 转换成 long） 中，并且将字符串的对象的编码设置为 int。\n\n * raw 该种编码是使用一种简单动态字符串(sds)的数据结构存储，当字符串的长度大于 44 时，会使用该种数据编码方式。\n\n * embstr 也是使用 简单动态字符串(sds)的数据结构存储，是当字符串长度小于等于 44 时使用。\n\nembstr 和 raw 的区别是什么呢？\n\n创建 string 使用 raw 编码时，会调用两次内存分配来创建 redisobject 和 sds 的数据结构，而 embstr 只会调用一次来创建连续的内存空间来存储 redisobject 和 sds 。\n\n当字符串较小时，embstr 少调用一次内存分配，释放也只需要一次，明显更快，并且连续的内存空间可以更好的利用 cpu 缓存。\n\n\n# 1.3 简单动态字符串(sds)\n\n在数据编码中提到 embstr 和 raw 都是使用 sds 数据结构，那么这种数据结构的是怎么样的，有什么好处呢？\n\n数据结构如下图所示：\n\nstruct sdshdr {\n    //记录buf数组中已使用字节的数量，等于sds所保存字符串的长度\n    int len;\n \n    //记录buf 数组中未使用字节的数量\n    int free;\n \n    //字节数组，用于保存字符串\n    char buf[];\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n * free: 表示还有多少空余空间\n * len: 已使用多少空间\n * buf: 存储字符串的数组\n\n问题：string 为什么使用简单动态字符串来实现，而不是使用 c 传统字符串来实现呢？\n\n * 防止缓存区溢出\n\n在扩充字符串时，需要考虑缓冲区是否足够，sds 提供 api 来帮助我们判断并扩充空间。\n\n * 常数获取字符串长度\n\nc 传统字符串需要遍历才能知道具体的长度，时间复杂度为 o(n)，而 sds 可以直接读 len 属性获取长度，时间复杂度为 o(1)\n\n * 减少内存分配的次数\n\n在扩大字符串长度时，需要重新申请更大的内存空间，然后拷贝到新的内存空间中，然后再释放旧的内存空间。\n\n在缩小时也是一样，需要申请新的空间，再释放旧的空间。\n\n在 sds 中可以通过以下的方式来减少内存分配和释放，提高效率。\n\n 1. 空间预分配，在分配空间时，除了必要的空间外，可以额外的分配未使用的空间，在下次使用，可以快速使用这部分的空间，而不必重新分配。\n 2. 惰性释放空间，在缩小字符串时，不需要马上释放多余的空间，可以预留给下次使用。\n\n * 二进制安全\n\nc 语言中是以空字符来表示字符串的结束，而一些二进制文件内容可能是包含空字符串的，因此 c 语言字符串无法正确读取，所以 sds 都是以二进制方式处理 buf，并且不以空字符串判断是否结束，而是用 len 来判断。\n\n\n# 1.4 使用场景\n\n * 缓存，存储热点数据作为缓存，降低持久化数据库的读写压力。\n * 分布式锁\n * 计数器，可以使用 incr 命令\n\n\n# 2. list\n\n\n# 2.1 简单使用\n\n命令       说明\nlpush    将值从左边推入列表\nrpush    将值从右边推入列表\nlpop     将值从列表左边弹出返回\nrpop     将值从列表右边弹出返回\nlrange   根据索引查看列表中的数据\n\n127.0.0.1:6379> lpush mylist 1 2 3\n(integer) 3\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "3"\n2) "2"\n3) "1"\n\n127.0.0.1:6379> rpush mylist 4\n(integer) 4\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "3"\n2) "2"\n3) "1"\n4) "4"\n\n127.0.0.1:6379> lpop mylist\n"3"\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "2"\n2) "1"\n3) "4"\n\n127.0.0.1:6379> rpop mylist\n"4"\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "2"\n2) "1"\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 2.2 数据编码\n\n在 redis3.2 之前使用的是 ziplist 和 linkedlist 两种编码方式。在数据量少的时候使用 ziplist，而数据多的时候使用 linkedlist。\n\n而之后的版本使用的是 quicklist\n\n127.0.0.1:6379> object encoding mylist\n"quicklist"\n\n\n1\n2\n\n\n\n# 2.3 压缩列表(ziplist)\n\n该数据结构类似于一个数组，在数组的表头添加三个字段 zlbytes、zltail、zlen，再在表尾添加 zlend 表示列表结束。\n\n\n\n * zlbytes：内存字节数\n * zltail：列表尾偏移量\n * zllen：列表元素个数\n * zlend：列表结束标记\n\n通过这几个字段可以快速定位第一个元素和最后元素，时间复杂度为 o(1)。\n\n除了表头与表尾之外，其他元素都是节点，节点的数据结构如下图：\n\n\n\n * previous_entry_length : 上一个节点的长度。可以推算出上一个节点的地址\n * encoding: 该节点的数据类型及长度\n * content: 节点的值\n\n连锁更新问题\n\n对于 previous_entry_length：\n\n * 前一个节点长度小于 254 字节，previous_entry_length 长度需要用 1 字节保存长度值\n * 前一个节点长度大于 254 字节，previous_entry_length 长度需要用 5 字节保存长度值\n\n有这一种场景，如果压缩列表中有多个连续的节点长度在 250-253 字节之间，这些节点 previous_entry_length 使用 1 个字节存储大小。\n\n * 当在最前方添加一个节点大于等于 254 字节的节点时，后面的节点 previous_entry_length 都需要从 1 字节扩充到 5 字节，起到连锁更新，后面的节点都需要更新。\n\n\n\n * 当删除其中 small 节点时，其后节点 previous_entry_length 需要保存前面的 big 节点，需要扩充节点空间，并且后面发生连锁更新\n\n\n\n虽然连锁更新复杂度很高，但是造成的可能性很低。\n\n * 长度需要在 250 到 253 字节之间\n * 被更新的节点数量不多，也不会造成性能影响\n\n优点\n\n * 内存地址连续，减少了内存碎片化，可以使用到缓存进行优化\n * 如果是双向链表，节点的头尾都需要指针来指向上一个或者下一个节点，而压缩列表省去了该部分内存空间的占用。\n\n缺点\n\n * 对于删除和插入操作都需要移动该节点位置后面的元素，并且可能会触发连锁更新反应\n\n\n# 2.4 快速列表(quicklist)\n\nquicklist 是压缩列表和双向链表结合实现的，在宏观上它是一个双向链表，然后其每个结点上都挂了一个 ziplist。如下图所示：\n\nziplist 在列表数量大的时候性能会下降，很难分配一大块连续的内存空间，并且在删除和插入操作性能下降的更为厉害。\n\n而双向链表会导致大量的碎片化空间，而且每个节点的头尾指针都会占用一定的内存空间。\n\n而 quicklist 算是在两者之间取得了一个平衡。\n\n\n# 2.5 使用场景\n\n * 消息队列\n * 列表及分页展示\n\n\n# 3. set\n\n是一个无序的集合，集合元素是唯一的，会自动对添加的数据进行去重。\n\n\n# 3.1 简单使用\n\n命令          说明\nsadd        向集合添加一个或多个元素\nscard       获取集合的数量\nsmembers    获取集合全部元素\nsismember   判断集合中是否指定元素\n\n127.0.0.1:6379> sadd myset zheng wen feng zheng\n(integer) 3\n\n127.0.0.1:6379> scard myset\n(integer) 3\n\n127.0.0.1:6379> smembers myset\n1) "zheng"\n2) "feng"\n3) "wen"\n\n127.0.0.1:6379> sismember myset feng\n(integer) 1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 3.2 数据编码\n\n该数据类型使用数据编码的是 intset 或者 hashtable，当 set 满足以下条件时，使用的 inset，其他情况都是 hashtable。\n\n * 当所有的元素都是整数值时\n * 元素个数不超过 512 个时\n\n127.0.0.1:6379> sadd myset2 1 2 4 4\n(integer) 3\n\n127.0.0.1:6379> smembers myset2\n1) "1"\n2) "2"\n3) "4"\n\n127.0.0.1:6379> object encoding myset2\n"intset"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 3.3 整型数组(intset)\n\nintset 数据结构如下所示：\n\ntypedef struct intset {\n    // 编码方式\n    uint32_t encoding;\n    // 集合包含的元素数量\n    uint32_t length;\n    // 保存元素的数组\n    int8_t contents[];\n} intset;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * encoding：contents 中存储的数据类型取决于该字段\n * length: 数组长度\n * contnets: 存储数据的整型数组，数据的数据类型取决于 encoding，从小到大排序\n\ncontents 数组中每一个元素的类型都是由 encoding 决定的，但是当原来的数据类型是 int16 时，现在要插入一个 int32 时，该如何操作呢？\n\n升级\n\n这个时候需要对 contents 中的每个元素都进行升级：\n\n * 根据新元素的类型，扩大 contents 数组的空间大小\n * 将数组的所有元素转换成新元素相同的类型并放入数组中\n * 最后改变 encoding 的值\n\n这么做的好处是，当所有的数据都是小整型时，可以节省内存的开销。\n\n目前不支持降级。\n\n\n# 3.4 使用场景\n\n * 标签，给用户打上标签，以标签为 key，用户 id 为 value 放入 set 中\n * 点赞，收藏等，利用 set 的唯一特性。\n\n\n# 4. sorted set\n\n是一个不允许重复元素的集合，但是每个元素会关联一个分数，可以通过分数对集合进行排序。\n\n\n# 4.1 简单使用\n\n命令       说明\nzadd     向集合添加一个或多个元素\nzrange   根据位置查询获取集合多个元素\nzrem     如果元素存在集合中，则进行删除\n\n127.0.0.1:6379> zadd myzset 100 zheng 99 wen 80 feng\n(integer) 3\n\n127.0.0.1:6379> zrange myzset 0 -1\n1) "feng"\n2) "wen"\n3) "zheng"\n\n127.0.0.1:6379> zadd myzset 91 hello\n(integer) 1\n\n# 默认是根据score升序查询\n127.0.0.1:6379> zrange myzset 0 -1\n1) "feng"\n2) "hello"\n3) "wen"\n4) "zheng"\n\n127.0.0.1:6379> zrem myzset wen\n(integer) 1\n\n127.0.0.1:6379> zrange myzset 0 -1\n1) "feng"\n2) "hello"\n3) "zheng"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# 4.2 数据编码\n\n该类型的数据编码可以为 ziplist 或者 skiplist，当满足以下条件时，使用的 ziplist，其他情况是 skiplist\n\n * 元素数量小于 128\n * 搜索元素长度小于 64\n\n当数据编码为 skiplist 时，redis 中使用的存储结构是 zset 数据结构，其中包含了 zskiplist 和 dict\n\ntypedef struct zset {\n    zskiplist *zs1;\n    dict *dict;\n}\n\n\n1\n2\n3\n4\n\n\n通过 zskiplist 可以快速的范围查询，dict 可以快速定位单个元素。\n\n\n# 4.3 跳表(skiplist)\n\n在有序的链表上添加了多级索引，通过索引位置的跳转，实现数据的快速定位。如下图所示：\n\n优点：\n\n 1. 在通过范围查询或排序时，可以在跳表中先找到最小值，然后再在最底层链表中遍历获取。\n\n\n# 4.4 使用场景\n\n * 排行榜，通过给视频、文章打分，然后进行排序展示\n\n\n# 5. hash\n\n用于存储 string 类型的键值对，适用于存储对象。\n\n\n# 5.1 简单使用\n\n命令        说明\nhset      设置键值对\nhget      获取指定 hash 的键对应的值\nhgetall   获取指定 hash 中的所有键值对\nhdel      删除指定 hash 中的键值对\n\n127.0.0.1:6379> hset person name zhangsan\n(integer) 1\n\n127.0.0.1:6379> hset person age 18\n(integer) 1\n\n127.0.0.1:6379> hget persion name\n"zhangsan"\n\n127.0.0.1:6379> hgetall person\n1) "name"\n2) "zhangsan"\n3) "age"\n4) "18"\n\n127.0.0.1:6379> hdel person age\n(integer) 1\n\n127.0.0.1:6379> hgetall person\n1) "name"\n2) "zhangsan"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n\n# 5.2 数据编码\n\n使用的数据编码是 ziplist 或 hashtable，满足以下条件选择使用 ziplist，其他情况使用 hashtable\n\n * hash 对象保存的键和值字符串长度都小于 64 字节\n * hash 对象保存的键值对数量小于 512\n\n\n# 5.3 使用场景\n\n * 用来存储对象信息\n\n\n# 6. 总结\n\nredis 之所以快，正是因为其有着丰富的数据结构，所以我们需要理解它们，在设计方案时，就能正确的选择数据类型来实现我们的业务需求。\n\n\n# 7. 相关链接\n\n * redis 设计与实现\n * 图解 redis 五种数据结构底层实现\n * redis 设计与实现\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来',charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"redis之持久化",frontmatter:{title:"redis之持久化",date:"2022-12-01T15:18:02.000Z",permalink:"/pages/4c6b13/",tags:["redis","数据库"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文主要是介绍 redis 是如何进行持久化数据的，我们知道 redis 是基于内存的数据库，那么只要服务器一旦宕机，那么数据则将全部丢失，如果从后端数据库进行恢复，则可能导致性能变慢，那么 redis 需要自身持久化，而不通过后端数据库来恢复数据是重要的。",feed:{enable:!0},categories:["数据库","redis"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210805185829.png"},{name:"twitter:title",content:"redis之持久化"},{name:"twitter:description",content:"本文主要是介绍 redis 是如何进行持久化数据的，我们知道 redis 是基于内存的数据库，那么只要服务器一旦宕机，那么数据则将全部丢失，如果从后端数据库进行恢复，则可能导致性能变慢，那么 redis 需要自身持久化，而不通过后端数据库来恢复数据是重要的。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210805185829.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/02.redis%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96.html"},{property:"og:type",content:"article"},{property:"og:title",content:"redis之持久化"},{property:"og:description",content:"本文主要是介绍 redis 是如何进行持久化数据的，我们知道 redis 是基于内存的数据库，那么只要服务器一旦宕机，那么数据则将全部丢失，如果从后端数据库进行恢复，则可能导致性能变慢，那么 redis 需要自身持久化，而不通过后端数据库来恢复数据是重要的。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210805185829.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/02.redis%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-12-01T15:18:02.000Z"},{property:"article:tag",content:"redis"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"redis之持久化"},{itemprop:"description",content:"本文主要是介绍 redis 是如何进行持久化数据的，我们知道 redis 是基于内存的数据库，那么只要服务器一旦宕机，那么数据则将全部丢失，如果从后端数据库进行恢复，则可能导致性能变慢，那么 redis 需要自身持久化，而不通过后端数据库来恢复数据是重要的。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210805185829.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/02.redis%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96.html",relativePath:"03.中间件/05.redis/02.redis之持久化.md",key:"v-278df89e",path:"/pages/4c6b13/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. AOF",slug:"_1-aof",normalizedTitle:"1. aof",charIndex:143},{level:3,title:"1.1 为什么是 AOF ?",slug:"_1-1-为什么是-aof",normalizedTitle:"1.1 为什么是 aof ?",charIndex:204},{level:3,title:"1.2 AOF 重写机制",slug:"_1-2-aof-重写机制",normalizedTitle:"1.2 aof 重写机制",charIndex:461},{level:2,title:"2. RDB 内存快照",slug:"_2-rdb-内存快照",normalizedTitle:"2. rdb 内存快照",charIndex:1331},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:2178},{level:2,title:"4. 参考文章",slug:"_4-参考文章",normalizedTitle:"4. 参考文章",charIndex:2449}],headersStr:"0. 前言 1. AOF 1.1 为什么是 AOF ? 1.2 AOF 重写机制 2. RDB 内存快照 3. 总结 4. 参考文章",content:"# 0. 前言\n\n本文主要是介绍 redis 是如何进行持久化数据的，我们知道 redis 是基于内存的数据库，那么只要服务器一旦宕机，那么数据则将全部丢失，如果从后端数据库进行恢复，则可能导致性能变慢，那么 redis 需要自身持久化，而不通过后端数据库来恢复数据是重要的。\n\n\n# 1. AOF\n\nAOF，称为后写日志，就是先执行命令，把数据写入到数据库中之后，再进行记录日志。过程如下图所示：\n\n\n# 1.1 为什么是 AOF ?\n\nRedis 向 AOF 写日志时，并不会校验命令的语法，如果先记日志，则可能保存了错误的命令导致出错。所以让系统先执行命令，执行成功后再记录日志。\n\n后写日志也不会阻塞当前操作，但是下一次操作有阻塞风险。AOF 也是在主线程执行，如果写入的时候磁盘压力过大，就可能会大致阻塞。\n\n但该种方式有风险，如果写入内存成功，记日志时发生宕机，则会丢失日志。\n\n正因为有这个风险，所以 redis 提供三种写入策略：\n\n这三种策略就是性能与可靠性的权衡，可以根据具体的业务进行选择。\n\n\n# 1.2 AOF 重写机制\n\nAOF 记录的是 Redis 的每一条命令，以文本形式保存，那么当 AOF 日志写的越来越多的时候，AOF 文件越来越大，以后通过 AOF 恢复数据也会变得很慢，redis 提供了 AOF 重写机制来减小 AOF 日志文件。\n\n将 AOF 文件生成的最新数据生成最新的操作日志并记录到新的 AOF 文件中，这样新的 AOF 文件中就没有了冗余命令，再替换掉旧的 AOF 文件。\n\nAOF 重写过程\n\nAOF 重写的过程会 fork 出 bgrewriteof 后台子进程，fork 会将主线程的数据内存拷贝到子进程，子进程在不影响主线程的情况下将拷贝的数据转换成操作写入到重写日志中。\n\n在重写日志时，主线程任然接受新的操作，操作会记录到 AOF 缓冲和 AOF 重写缓冲区，AOF 日志不会丢失最新的操作，在拷贝数据重写完成后，再将 AOF 重写缓冲区的日志记录写入新的 AOF 文件中，保证新的 AOF 文件的数据也是最新的状态。此时就可以放心将新写入的 AOF 文件代替旧文件。\n\n\n\n写时复制 copy on write\n\nfork 采用操作系统的 写时复制机制，避免一次性拷贝大量内存数据给子进程。fork 子进程时，子进程会拷贝父进程的内存页表(虚拟内存和物理内存的映射索引表)而不会拷贝其所有的物理内存数据，这样两个进程使用的数据是同一份内存空间。当主线程写入新数据时，会拷贝一份新数据并进行修改，这样并不影响子进程的读取。\n\nAOF 重写阻塞点\n\n * 在 fork 子进程时，即使是拷贝页表和一些必要的数据结构也是需要消耗大量的 CPU，会对主线程进行阻塞\n * 在 AOF 重写过程中，如果有 big key 写入时，会拷贝旧数据到创建的新内存空间中，也会进行阻塞。\n\nAOF 重写日志为什么不共享 AOF 本身日志？\n\n * 两个进程操作同一个文件，存在竞争问题，影响父进程性能\n * 如果重写失败，AOF 日志则被污染了，无法恢复使用。重写一个文件，如果重写失败，删除重来即可。\n\n\n# 2. RDB 内存快照\n\nAOF 方法恢复数据需要将操作日志全部执行一遍，如果日志非常多，则恢复的过程缓慢。而内存快照是将某一时刻的数据以文件(RDB)记录到磁盘上，在恢复的时候，直接读入内存即可。\n\n会不会阻塞主线程?\n\nRedis 提供 save 和 bgsave 两个命令生成 RDB 文件\n\n * save 是在主线程执行会阻塞，不建议在线上使用\n * bgsave 会创建子进程生成 RDB，默认。\n\n如果在触发快照时，能修改数据吗？\n\n如果在 t 时刻，需要快照数据 A，在快照时修改了 A 数据为 A'，这时破坏了快照的完整性，这时 A'并不是 t 时刻的状态。\n\n如果在快照时，不允许修改，虽然解决了上面的问题，但是会影响业务。\n\n这里解决办法还是使用了操作系统的 写时复制机制，在新的数据需要写入时，主线程会将该数据复制一份，然后对该副本进行修改，而子进程使用原来的数据进行快照。\n\n\n\n既然可以使用 RDB 快速恢复数据，那么是否可以每秒做一次快照呢？\n\n两次快照之间的数据，如果遇到宕机，可能会发生丢失，所以需要尽量短的时间做快照。\n\n但虽然生成 RDB 文件使用子进程，但是频繁的执行全量快照还是会带来额外的开销：\n\n * 频繁的写磁盘，增大磁盘压力\n * fork 子进程时，如果数据内存过大，是会阻塞主线程的。\n\n如何解决快照间丢失数据？\n\n增量快照。混合使用 AOF 日志和内存快照。\n\n使用 AOF 记录两次快照间的操作。在生成快照时，使用 AOF 日志记录新进入的修改操作，在下一次快照前宕机都可以通过 AOF 日志进行恢复。下一次快照时可以再清空 AOF 日志重新记录\n\n\n\n如何在 AOF 和 RDB 进行选择?\n\n * 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；\n * 如果允许分钟级别的数据丢失，可以只使用 RDB；\n * 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。\n\n\n# 3. 总结\n\n通过上面的介绍，了解到 RDB 和 AOF 都是通过 fork 子进程来完成的，是为了不会造成主线程的阻塞，但是也并不能完全避免，所以我们需要尽可能的降低 fork 的频率。\n\n并且都使用了操作系统的 COW 机制，该机制可以大大的减少 cpu 与内存的消耗，我们在很多组件中会发现它们都用到了 linux 的一些好用的机制，像 Kafka 用到的零拷贝和 PageCache 等等。我们在设计中需要善用这些机制，可以非常大的优化程序的性能，并且简化我们需要做的时候交给操作系统去完成，并且完成的比我们做的更好更稳定。\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",normalizedContent:"# 0. 前言\n\n本文主要是介绍 redis 是如何进行持久化数据的，我们知道 redis 是基于内存的数据库，那么只要服务器一旦宕机，那么数据则将全部丢失，如果从后端数据库进行恢复，则可能导致性能变慢，那么 redis 需要自身持久化，而不通过后端数据库来恢复数据是重要的。\n\n\n# 1. aof\n\naof，称为后写日志，就是先执行命令，把数据写入到数据库中之后，再进行记录日志。过程如下图所示：\n\n\n# 1.1 为什么是 aof ?\n\nredis 向 aof 写日志时，并不会校验命令的语法，如果先记日志，则可能保存了错误的命令导致出错。所以让系统先执行命令，执行成功后再记录日志。\n\n后写日志也不会阻塞当前操作，但是下一次操作有阻塞风险。aof 也是在主线程执行，如果写入的时候磁盘压力过大，就可能会大致阻塞。\n\n但该种方式有风险，如果写入内存成功，记日志时发生宕机，则会丢失日志。\n\n正因为有这个风险，所以 redis 提供三种写入策略：\n\n这三种策略就是性能与可靠性的权衡，可以根据具体的业务进行选择。\n\n\n# 1.2 aof 重写机制\n\naof 记录的是 redis 的每一条命令，以文本形式保存，那么当 aof 日志写的越来越多的时候，aof 文件越来越大，以后通过 aof 恢复数据也会变得很慢，redis 提供了 aof 重写机制来减小 aof 日志文件。\n\n将 aof 文件生成的最新数据生成最新的操作日志并记录到新的 aof 文件中，这样新的 aof 文件中就没有了冗余命令，再替换掉旧的 aof 文件。\n\naof 重写过程\n\naof 重写的过程会 fork 出 bgrewriteof 后台子进程，fork 会将主线程的数据内存拷贝到子进程，子进程在不影响主线程的情况下将拷贝的数据转换成操作写入到重写日志中。\n\n在重写日志时，主线程任然接受新的操作，操作会记录到 aof 缓冲和 aof 重写缓冲区，aof 日志不会丢失最新的操作，在拷贝数据重写完成后，再将 aof 重写缓冲区的日志记录写入新的 aof 文件中，保证新的 aof 文件的数据也是最新的状态。此时就可以放心将新写入的 aof 文件代替旧文件。\n\n\n\n写时复制 copy on write\n\nfork 采用操作系统的 写时复制机制，避免一次性拷贝大量内存数据给子进程。fork 子进程时，子进程会拷贝父进程的内存页表(虚拟内存和物理内存的映射索引表)而不会拷贝其所有的物理内存数据，这样两个进程使用的数据是同一份内存空间。当主线程写入新数据时，会拷贝一份新数据并进行修改，这样并不影响子进程的读取。\n\naof 重写阻塞点\n\n * 在 fork 子进程时，即使是拷贝页表和一些必要的数据结构也是需要消耗大量的 cpu，会对主线程进行阻塞\n * 在 aof 重写过程中，如果有 big key 写入时，会拷贝旧数据到创建的新内存空间中，也会进行阻塞。\n\naof 重写日志为什么不共享 aof 本身日志？\n\n * 两个进程操作同一个文件，存在竞争问题，影响父进程性能\n * 如果重写失败，aof 日志则被污染了，无法恢复使用。重写一个文件，如果重写失败，删除重来即可。\n\n\n# 2. rdb 内存快照\n\naof 方法恢复数据需要将操作日志全部执行一遍，如果日志非常多，则恢复的过程缓慢。而内存快照是将某一时刻的数据以文件(rdb)记录到磁盘上，在恢复的时候，直接读入内存即可。\n\n会不会阻塞主线程?\n\nredis 提供 save 和 bgsave 两个命令生成 rdb 文件\n\n * save 是在主线程执行会阻塞，不建议在线上使用\n * bgsave 会创建子进程生成 rdb，默认。\n\n如果在触发快照时，能修改数据吗？\n\n如果在 t 时刻，需要快照数据 a，在快照时修改了 a 数据为 a'，这时破坏了快照的完整性，这时 a'并不是 t 时刻的状态。\n\n如果在快照时，不允许修改，虽然解决了上面的问题，但是会影响业务。\n\n这里解决办法还是使用了操作系统的 写时复制机制，在新的数据需要写入时，主线程会将该数据复制一份，然后对该副本进行修改，而子进程使用原来的数据进行快照。\n\n\n\n既然可以使用 rdb 快速恢复数据，那么是否可以每秒做一次快照呢？\n\n两次快照之间的数据，如果遇到宕机，可能会发生丢失，所以需要尽量短的时间做快照。\n\n但虽然生成 rdb 文件使用子进程，但是频繁的执行全量快照还是会带来额外的开销：\n\n * 频繁的写磁盘，增大磁盘压力\n * fork 子进程时，如果数据内存过大，是会阻塞主线程的。\n\n如何解决快照间丢失数据？\n\n增量快照。混合使用 aof 日志和内存快照。\n\n使用 aof 记录两次快照间的操作。在生成快照时，使用 aof 日志记录新进入的修改操作，在下一次快照前宕机都可以通过 aof 日志进行恢复。下一次快照时可以再清空 aof 日志重新记录\n\n\n\n如何在 aof 和 rdb 进行选择?\n\n * 数据不能丢失时，内存快照和 aof 的混合使用是一个很好的选择；\n * 如果允许分钟级别的数据丢失，可以只使用 rdb；\n * 如果只用 aof，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。\n\n\n# 3. 总结\n\n通过上面的介绍，了解到 rdb 和 aof 都是通过 fork 子进程来完成的，是为了不会造成主线程的阻塞，但是也并不能完全避免，所以我们需要尽可能的降低 fork 的频率。\n\n并且都使用了操作系统的 cow 机制，该机制可以大大的减少 cpu 与内存的消耗，我们在很多组件中会发现它们都用到了 linux 的一些好用的机制，像 kafka 用到的零拷贝和 pagecache 等等。我们在设计中需要善用这些机制，可以非常大的优化程序的性能，并且简化我们需要做的时候交给操作系统去完成，并且完成的比我们做的更好更稳定。\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"redis之主从库同步",frontmatter:{title:"redis之主从库同步",date:"2022-12-01T15:18:20.000Z",permalink:"/pages/8072eb/",tags:["redis","数据库"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"在单点故障后，我们需要保证服务不间断，所以需要使用冗余的副本提供集群服务，从而达到服务的高可用。redis 提供了主从库数据同步机制，从而保证数据副本的一致性，而主从库使用的是读写分离的机制。",feed:{enable:!0},categories:["数据库","redis"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210806172905.png"},{name:"twitter:title",content:"redis之主从库同步"},{name:"twitter:description",content:"在单点故障后，我们需要保证服务不间断，所以需要使用冗余的副本提供集群服务，从而达到服务的高可用。redis 提供了主从库数据同步机制，从而保证数据副本的一致性，而主从库使用的是读写分离的机制。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210806172905.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/03.%20redis%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%90%8C%E6%AD%A5.html"},{property:"og:type",content:"article"},{property:"og:title",content:"redis之主从库同步"},{property:"og:description",content:"在单点故障后，我们需要保证服务不间断，所以需要使用冗余的副本提供集群服务，从而达到服务的高可用。redis 提供了主从库数据同步机制，从而保证数据副本的一致性，而主从库使用的是读写分离的机制。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210806172905.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/03.%20redis%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%90%8C%E6%AD%A5.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-12-01T15:18:20.000Z"},{property:"article:tag",content:"redis"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"redis之主从库同步"},{itemprop:"description",content:"在单点故障后，我们需要保证服务不间断，所以需要使用冗余的副本提供集群服务，从而达到服务的高可用。redis 提供了主从库数据同步机制，从而保证数据副本的一致性，而主从库使用的是读写分离的机制。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210806172905.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/03.%20redis%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%90%8C%E6%AD%A5.html",relativePath:"03.中间件/05.redis/03. redis之主从库同步.md",key:"v-61296d7f",path:"/pages/8072eb/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 读写分离模式",slug:"_1-读写分离模式",normalizedTitle:"1. 读写分离模式",charIndex:110},{level:2,title:"2. 全量复制",slug:"_2-全量复制",normalizedTitle:"2. 全量复制",charIndex:314},{level:3,title:"2.1 主从库同步的过程",slug:"_2-1-主从库同步的过程",normalizedTitle:"2.1 主从库同步的过程",charIndex:326},{level:3,title:"2.2 如何减少主从同步时，对主库的压力?",slug:"_2-2-如何减少主从同步时-对主库的压力",normalizedTitle:"2.2 如何减少主从同步时，对主库的压力?",charIndex:692},{level:2,title:"3. 增量复制",slug:"_3-增量复制",normalizedTitle:"3. 增量复制",charIndex:905},{level:3,title:"3.1 增量复制的过程",slug:"_3-1-增量复制的过程",normalizedTitle:"3.1 增量复制的过程",charIndex:1106},{level:2,title:"4. 参考文章",slug:"_4-参考文章",normalizedTitle:"4. 参考文章",charIndex:1760}],headersStr:"0. 前言 1. 读写分离模式 2. 全量复制 2.1 主从库同步的过程 2.2 如何减少主从同步时，对主库的压力? 3. 增量复制 3.1 增量复制的过程 4. 参考文章",content:"# 0. 前言\n\n在单点故障后，我们需要保证服务不间断，所以需要使用冗余的副本提供集群服务，从而达到服务的高可用。redis 提供了主从库数据同步机制，从而保证数据副本的一致性，而主从库使用的是读写分离的机制。\n\n\n# 1. 读写分离模式\n\n通过该模式构建多个数据副本，使用读写分离的方式\n\n * 读操作: 主从库都可以进行读取。\n * 写操作: 先写入到主库，在同步到从库。\n\n\n\n为什么要读写分离呢？\n\n如果从库也可以进行写操作，那么主从库在同一个 key 中存储的值可能会不一致，如果要保证一致性，需要通过加锁来解决，但这样会造成性能的损耗。\n\n但如果只有主库写入，在同步给从库，则能保证所有实例中数据的一致性。\n\n\n# 2. 全量复制\n\n\n# 2.1 主从库同步的过程\n\n第一阶段\n\n从库向主库发送psync命令进行数据同步，该命令包含主库的runID和复制进度offset\n\n * runID，每个实例自动生成的随机 ID，第一次从库不知道主库 runID，设置为?\n * offset，记录复制的进度，第一次进度设置为-1\n\n主库会回复 runID 和 offset 给从库\n\n第二阶段\n\n主从第一次同步是采用全量复制的方式，主库生成 RDB 文件，然后发送给从库，从库清空当前数据再读入 RDB 文件完成第一次同步。\n\n在生成 RDB 文件时，还是会有新的操作的会进行，为了保持数据的一致性，会将新的操作记录到 replication buffer 中。\n\n第三阶段\n\nRDB 文件发送到从库后，再 replication buffer 中的操作再发送给从库。\n\n\n# 2.2 如何减少主从同步时，对主库的压力?\n\n主从同步有哪些压力？\n\n * 生成 RDB，这个操作会 fork 子进程，会阻塞主线程的正常请求。\n * 传输 RDB，会占用主库的网络带宽\n\n主-从-从模式\n\n可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。由从库生成 RDB 再传输给从库，减少了主库的压力。\n\n在主库全量复制之后，会维护一个长连接，后需的操作命令通过该连接同步给从库\n\n\n\n\n# 3. 增量复制\n\n全量复制是通过生成 RDB 发送到从库然后进行读取后进行同步。我们知道生成 RDB 本身就是一个消耗 CPU 的操作，并且存在阻塞主线程的风险，所以我们需要尽量少的执行全量复制的操作。\n\n所以在第一次使用 RDB 全量复制后，主从库会建立一个长连接，主库收到的新命令会再同步到从库，这样就避免频繁全量复制。\n\n但是有一个风险点是，如果过程发生了网络中断或者阻塞，该如何解决？\n\n\n# 3.1 增量复制的过程\n\n当主从连接时，会将新的操作的命令写入 replication buffer 和 repl_backlog_buffer 缓冲区中\n\nrepl_backlog_buffer 是一个环形缓冲区，主库会记录当前的偏移量 master_repl_offset，记录自己写到的位置，而从库在上面也有对应的偏移量 slave_repl_offset，记录自己正在读到的偏移量。\n\n在恢复连接时，从库会通过 psync 命令将自己的偏移量 slave_repl_offset 发送给主库，主库会将 slave_repl_offset 和 master_repl_offset 之间的命令同步给从库即可。\n\n\n\n举了例子： 主库和从库之间相差了 put d e 和 put d f 两个操作，在增量复制时，主库只需要把它们同步给从库，就行了。\n\n因为 replication buffer 是一个环形的缓存，当主从库长期断开时，是有可能被覆盖掉旧的数据，这个时候是会重新发起全量复制，主库根据从库发送的 slave_repl_offset 来判断是增量还是全量的复制。\n\n那为什么全量复制使用 RDB 而不是使用 AOF 呢？\n\n * RDB 文件是经过压缩的二进制文件，AOF 文件是记录每一次的操作，包含对同一个 key 的多次冗余操作，文件比 RDB 要大的多，使用 AOF 可以减少带宽\n * RDB 是二进制数据，从库还原速度快。而 AOF 需要依次重放每一个命令，恢复速度慢。\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",normalizedContent:"# 0. 前言\n\n在单点故障后，我们需要保证服务不间断，所以需要使用冗余的副本提供集群服务，从而达到服务的高可用。redis 提供了主从库数据同步机制，从而保证数据副本的一致性，而主从库使用的是读写分离的机制。\n\n\n# 1. 读写分离模式\n\n通过该模式构建多个数据副本，使用读写分离的方式\n\n * 读操作: 主从库都可以进行读取。\n * 写操作: 先写入到主库，在同步到从库。\n\n\n\n为什么要读写分离呢？\n\n如果从库也可以进行写操作，那么主从库在同一个 key 中存储的值可能会不一致，如果要保证一致性，需要通过加锁来解决，但这样会造成性能的损耗。\n\n但如果只有主库写入，在同步给从库，则能保证所有实例中数据的一致性。\n\n\n# 2. 全量复制\n\n\n# 2.1 主从库同步的过程\n\n第一阶段\n\n从库向主库发送psync命令进行数据同步，该命令包含主库的runid和复制进度offset\n\n * runid，每个实例自动生成的随机 id，第一次从库不知道主库 runid，设置为?\n * offset，记录复制的进度，第一次进度设置为-1\n\n主库会回复 runid 和 offset 给从库\n\n第二阶段\n\n主从第一次同步是采用全量复制的方式，主库生成 rdb 文件，然后发送给从库，从库清空当前数据再读入 rdb 文件完成第一次同步。\n\n在生成 rdb 文件时，还是会有新的操作的会进行，为了保持数据的一致性，会将新的操作记录到 replication buffer 中。\n\n第三阶段\n\nrdb 文件发送到从库后，再 replication buffer 中的操作再发送给从库。\n\n\n# 2.2 如何减少主从同步时，对主库的压力?\n\n主从同步有哪些压力？\n\n * 生成 rdb，这个操作会 fork 子进程，会阻塞主线程的正常请求。\n * 传输 rdb，会占用主库的网络带宽\n\n主-从-从模式\n\n可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。由从库生成 rdb 再传输给从库，减少了主库的压力。\n\n在主库全量复制之后，会维护一个长连接，后需的操作命令通过该连接同步给从库\n\n\n\n\n# 3. 增量复制\n\n全量复制是通过生成 rdb 发送到从库然后进行读取后进行同步。我们知道生成 rdb 本身就是一个消耗 cpu 的操作，并且存在阻塞主线程的风险，所以我们需要尽量少的执行全量复制的操作。\n\n所以在第一次使用 rdb 全量复制后，主从库会建立一个长连接，主库收到的新命令会再同步到从库，这样就避免频繁全量复制。\n\n但是有一个风险点是，如果过程发生了网络中断或者阻塞，该如何解决？\n\n\n# 3.1 增量复制的过程\n\n当主从连接时，会将新的操作的命令写入 replication buffer 和 repl_backlog_buffer 缓冲区中\n\nrepl_backlog_buffer 是一个环形缓冲区，主库会记录当前的偏移量 master_repl_offset，记录自己写到的位置，而从库在上面也有对应的偏移量 slave_repl_offset，记录自己正在读到的偏移量。\n\n在恢复连接时，从库会通过 psync 命令将自己的偏移量 slave_repl_offset 发送给主库，主库会将 slave_repl_offset 和 master_repl_offset 之间的命令同步给从库即可。\n\n\n\n举了例子： 主库和从库之间相差了 put d e 和 put d f 两个操作，在增量复制时，主库只需要把它们同步给从库，就行了。\n\n因为 replication buffer 是一个环形的缓存，当主从库长期断开时，是有可能被覆盖掉旧的数据，这个时候是会重新发起全量复制，主库根据从库发送的 slave_repl_offset 来判断是增量还是全量的复制。\n\n那为什么全量复制使用 rdb 而不是使用 aof 呢？\n\n * rdb 文件是经过压缩的二进制文件，aof 文件是记录每一次的操作，包含对同一个 key 的多次冗余操作，文件比 rdb 要大的多，使用 aof 可以减少带宽\n * rdb 是二进制数据，从库还原速度快。而 aof 需要依次重放每一个命令，恢复速度慢。\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"redis之哨兵机制",frontmatter:{title:"redis之哨兵机制",date:"2022-12-01T15:18:35.000Z",permalink:"/pages/ffee9e/",tags:["redis","数据库"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文主要介绍的是 Redis 提供的哨兵机制，通过哨兵监控主库的状况，如果发现主库下线，则会从从库中选择一个状态优秀的当做主库，从而保证服务的高可用。",feed:{enable:!0},categories:["数据库","redis"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210807101732.png"},{name:"twitter:title",content:"redis之哨兵机制"},{name:"twitter:description",content:"本文主要介绍的是 Redis 提供的哨兵机制，通过哨兵监控主库的状况，如果发现主库下线，则会从从库中选择一个状态优秀的当做主库，从而保证服务的高可用。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210807101732.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/04.%20redis%E4%B9%8B%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"redis之哨兵机制"},{property:"og:description",content:"本文主要介绍的是 Redis 提供的哨兵机制，通过哨兵监控主库的状况，如果发现主库下线，则会从从库中选择一个状态优秀的当做主库，从而保证服务的高可用。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210807101732.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/04.%20redis%E4%B9%8B%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-12-01T15:18:35.000Z"},{property:"article:tag",content:"redis"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"redis之哨兵机制"},{itemprop:"description",content:"本文主要介绍的是 Redis 提供的哨兵机制，通过哨兵监控主库的状况，如果发现主库下线，则会从从库中选择一个状态优秀的当做主库，从而保证服务的高可用。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210807101732.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/04.%20redis%E4%B9%8B%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6.html",relativePath:"03.中间件/05.redis/04. redis之哨兵机制.md",key:"v-be37f416",path:"/pages/ffee9e/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 哨兵如何保证高可用？",slug:"_1-哨兵如何保证高可用",normalizedTitle:"1. 哨兵如何保证高可用？",charIndex:140},{level:3,title:"1.1 监控",slug:"_1-1-监控",normalizedTitle:"1.1 监控",charIndex:158},{level:3,title:"1.2 选择新主库",slug:"_1-2-选择新主库",normalizedTitle:"1.2 选择新主库",charIndex:297},{level:3,title:"1.3 通知",slug:"_1-3-通知",normalizedTitle:"1.3 通知",charIndex:457},{level:2,title:"2. 哨兵集群的组建",slug:"_2-哨兵集群的组建",normalizedTitle:"2. 哨兵集群的组建",charIndex:562},{level:3,title:"2.1 哨兵与从库建立连接",slug:"_2-1-哨兵与从库建立连接",normalizedTitle:"2.1 哨兵与从库建立连接",charIndex:748},{level:3,title:"2.2 哨兵与客户端建立连接",slug:"_2-2-哨兵与客户端建立连接",normalizedTitle:"2.2 哨兵与客户端建立连接",charIndex:868},{level:2,title:"3. 由哪个哨兵来执行主从切换 ？",slug:"_3-由哪个哨兵来执行主从切换",normalizedTitle:"3. 由哪个哨兵来执行主从切换 ？",charIndex:1019},{level:2,title:"4. 参考文章",slug:"_4-参考文章",normalizedTitle:"4. 参考文章",charIndex:1248}],headersStr:"0. 前言 1. 哨兵如何保证高可用？ 1.1 监控 1.2 选择新主库 1.3 通知 2. 哨兵集群的组建 2.1 哨兵与从库建立连接 2.2 哨兵与客户端建立连接 3. 由哪个哨兵来执行主从切换 ？ 4. 参考文章",content:'# 0. 前言\n\n我们知道，只有主库才能有写操作，而从库只能进行读操作，那么当主库宕机后，如何保证服务的正常进行呢？\n\n本文主要介绍的是 Redis 提供的哨兵机制，通过哨兵监控主库的状况，如果发现主库下线，则会从从库中选择一个状态优秀的当做主库，从而保证服务的高可用。\n\n\n# 1. 哨兵如何保证高可用？\n\n\n# 1.1 监控\n\n哨兵进程会发送 PING 命令给主从库检测网络连接，如果超时，则判断为"主观下线"。\n\n但是如果哨兵误判可能会导致主从切换，导致性能的额外开销，所以引入了哨兵集群，只有多数哨兵认为主库已经主观下线，主库会被标记为"客观下线"，这时才会进行主从切换。\n\n\n\n\n# 1.2 选择新主库\n\n通过一定的筛选条件，把不符合条件的从库去掉，再按照一定规则给从库打分，得分最高的为新主库\n\n\n\n筛选条件：\n\n * 当前从库的状态\n * 之前一段时间的网络状态\n\n打分规则：\n\n * 用户可以给从库 slave-priority 配置优先级\n * 主从库同步程度\n * ID 号小的得分高\n\n\n# 1.3 通知\n\n哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。\n\n\n# 2. 哨兵集群的组建\n\n哨兵实例之间互相发现是基于 Redis 提供的 pub/sub 机制，发布/订阅机制。\n\n哨兵只要与主库建立连接，会在主库 __sentinel__:hello 频道上发布消息，比如自己的 ip 地址和端口信息，订阅了该频道的其他哨兵会获取到发布消息哨兵的 IP 和端口，即可以与其建立网络连接，之后相互间就可以通过网络连接进行通信。\n\n\n\n\n# 2.1 哨兵与从库建立连接\n\n哨兵还需要和从库建立连接，这样才能监控从库的连接状态，当主库下线后，才能从它们中选举出新的主库。\n\n哨兵使用 INFO 命令发送给主库，主库会返回从库列表连接信息，这样也能和从库建立连接并进行监控\n\n\n\n\n# 2.2 哨兵与客户端建立连接\n\n当主库下线后，客户端需要得知主库下线的消息，写操作需要切换到新的主库中，所以哨兵需要与客户端建立连接，并及时通知客户端。\n\n客户端可以从哨兵订阅消息，获取到主从切换的各种事件。\n\n客户端读取哨兵的配置文件，获取哨兵的地址和端口，建立连接，然后即可订阅消息。\n\n\n\n\n# 3. 由哪个哨兵来执行主从切换 ？\n\n任何一个哨兵判断主库 主观下线 就会向其他哨兵发送 is-master-down-by-addr 命令。其他实例会更具自己与主库的连接情况投出赞成票或反对票。当多数哨兵投赞成票时，则主库被认为 客观下线。\n\n此时，该哨兵再发命令给其他哨兵进行 leader选举，希望由自己来进行主从切换。在这个过程中，任何一个哨兵都可以参与选举，只要票数半数以上并且大于等于 quorum 值，则可以成为 leader\n\n\n\n\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来',normalizedContent:'# 0. 前言\n\n我们知道，只有主库才能有写操作，而从库只能进行读操作，那么当主库宕机后，如何保证服务的正常进行呢？\n\n本文主要介绍的是 redis 提供的哨兵机制，通过哨兵监控主库的状况，如果发现主库下线，则会从从库中选择一个状态优秀的当做主库，从而保证服务的高可用。\n\n\n# 1. 哨兵如何保证高可用？\n\n\n# 1.1 监控\n\n哨兵进程会发送 ping 命令给主从库检测网络连接，如果超时，则判断为"主观下线"。\n\n但是如果哨兵误判可能会导致主从切换，导致性能的额外开销，所以引入了哨兵集群，只有多数哨兵认为主库已经主观下线，主库会被标记为"客观下线"，这时才会进行主从切换。\n\n\n\n\n# 1.2 选择新主库\n\n通过一定的筛选条件，把不符合条件的从库去掉，再按照一定规则给从库打分，得分最高的为新主库\n\n\n\n筛选条件：\n\n * 当前从库的状态\n * 之前一段时间的网络状态\n\n打分规则：\n\n * 用户可以给从库 slave-priority 配置优先级\n * 主从库同步程度\n * id 号小的得分高\n\n\n# 1.3 通知\n\n哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。\n\n\n# 2. 哨兵集群的组建\n\n哨兵实例之间互相发现是基于 redis 提供的 pub/sub 机制，发布/订阅机制。\n\n哨兵只要与主库建立连接，会在主库 __sentinel__:hello 频道上发布消息，比如自己的 ip 地址和端口信息，订阅了该频道的其他哨兵会获取到发布消息哨兵的 ip 和端口，即可以与其建立网络连接，之后相互间就可以通过网络连接进行通信。\n\n\n\n\n# 2.1 哨兵与从库建立连接\n\n哨兵还需要和从库建立连接，这样才能监控从库的连接状态，当主库下线后，才能从它们中选举出新的主库。\n\n哨兵使用 info 命令发送给主库，主库会返回从库列表连接信息，这样也能和从库建立连接并进行监控\n\n\n\n\n# 2.2 哨兵与客户端建立连接\n\n当主库下线后，客户端需要得知主库下线的消息，写操作需要切换到新的主库中，所以哨兵需要与客户端建立连接，并及时通知客户端。\n\n客户端可以从哨兵订阅消息，获取到主从切换的各种事件。\n\n客户端读取哨兵的配置文件，获取哨兵的地址和端口，建立连接，然后即可订阅消息。\n\n\n\n\n# 3. 由哪个哨兵来执行主从切换 ？\n\n任何一个哨兵判断主库 主观下线 就会向其他哨兵发送 is-master-down-by-addr 命令。其他实例会更具自己与主库的连接情况投出赞成票或反对票。当多数哨兵投赞成票时，则主库被认为 客观下线。\n\n此时，该哨兵再发命令给其他哨兵进行 leader选举，希望由自己来进行主从切换。在这个过程中，任何一个哨兵都可以参与选举，只要票数半数以上并且大于等于 quorum 值，则可以成为 leader\n\n\n\n\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来',charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"redis之分片集群",frontmatter:{title:"redis之分片集群",date:"2022-12-01T15:18:45.000Z",permalink:"/pages/1c2914/",tags:["redis","数据库"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"在海量的数据面前，单个 redis 实例的能力是有限的，无可能无限增大的内存，所以必须要构建分片集群，来横向拓展来支持保存更多的数据。",feed:{enable:!0},categories:["数据库","redis"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210808133416.png"},{name:"twitter:title",content:"redis之分片集群"},{name:"twitter:description",content:"在海量的数据面前，单个 redis 实例的能力是有限的，无可能无限增大的内存，所以必须要构建分片集群，来横向拓展来支持保存更多的数据。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210808133416.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/05.%20redis%E4%B9%8B%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4.html"},{property:"og:type",content:"article"},{property:"og:title",content:"redis之分片集群"},{property:"og:description",content:"在海量的数据面前，单个 redis 实例的能力是有限的，无可能无限增大的内存，所以必须要构建分片集群，来横向拓展来支持保存更多的数据。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210808133416.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/05.%20redis%E4%B9%8B%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-12-01T15:18:45.000Z"},{property:"article:tag",content:"redis"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"redis之分片集群"},{itemprop:"description",content:"在海量的数据面前，单个 redis 实例的能力是有限的，无可能无限增大的内存，所以必须要构建分片集群，来横向拓展来支持保存更多的数据。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20210808133416.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/05.%20redis%E4%B9%8B%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4.html",relativePath:"03.中间件/05.redis/05. redis之分片集群.md",key:"v-ae93950e",path:"/pages/1c2914/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 分片集群是什么？",slug:"_1-分片集群是什么",normalizedTitle:"1. 分片集群是什么？",charIndex:81},{level:2,title:"2. 分片集群的组建",slug:"_2-分片集群的组建",normalizedTitle:"2. 分片集群的组建",charIndex:279},{level:2,title:"3. 客户端如何读取分片集群",slug:"_3-客户端如何读取分片集群",normalizedTitle:"3. 客户端如何读取分片集群",charIndex:587},{level:2,title:"4. 参考文章",slug:"_4-参考文章",normalizedTitle:"4. 参考文章",charIndex:1418}],headersStr:"0. 前言 1. 分片集群是什么？ 2. 分片集群的组建 3. 客户端如何读取分片集群 4. 参考文章",content:"# 0. 前言\n\n在海量的数据面前，单个 redis 实例的能力是有限的，无可能无限增大的内存，所以必须要构建分片集群，来横向拓展来支持保存更多的数据。\n\n\n# 1. 分片集群是什么？\n\n分片集群主要是将 redis 的数据划分成多份，每一份都由一个实例来保存，然后由多个实例来组成一个一个集群。\n\n为什么使用分片集群而不是增加内存？\n\n * 在 RDB 进行持久化时，会 fork 子进程来完成，fork 操作会阻塞主线程的时长与数据量成正比。\n * 硬件成本，把内存从 32GB 扩展到 64GB 还算容易，但是，要想扩充到 1TB，成本太高。\n\n\n# 2. 分片集群的组建\n\n在 Redis Cluster 方案中，一个切片集群有 16384 个哈希槽，每个键值对的 key 会进行计算并对 16384 取模，分配到一个对应编号的哈希槽。\n\n在使用 cluster create 命令创建集群时，会自动将 16384 个槽平均分配到集群实例中。也可以通过 cluster meet 命令手动建立实例间的连接形成集群，再使用 cluster addslots 命令指定每个实例上的哈希槽的个数。\n\n在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。\n\n数据分配到哪个实例?\n\n数据根据分配到哈希槽编号写入到对应的实例中。\n\n\n# 3. 客户端如何读取分片集群\n\n客户端从哪个实例中读取数据？\n\n客户端与集群建立连接后，实例会将哈希槽的分配信息发送给客户端。客户端将哈希槽信息缓存在本地，当客户端操作键值对时，先计算得到对应的哈希槽，再发送请求到相应的实例。\n\n但哈希槽与实例的映射关系并不是一成不变的，可能会发生变化：\n\n * 集群中，实例有新增或删除，redis 会重新分配哈希槽\n * 为了负载均衡，redis 会将哈希槽在所有实例中重新分布。\n\n当映射关系变化时，客户端如何感知？\n\n重定向机制。客户端发送数据给一个实例，但是并没有这个键值对的哈希槽信息，则实例会发送 MOVED 命令结果给客户端，包含新实例的访问地址。客户端更新本地缓存实例与哈希槽的映射关系，并向新实例发送请求。\n\nGET hello:key\n(error) MOVED 13320 172.16.19.5:6379\n\n\n1\n2\n\n\n客户端请求的哈希槽 13320 在 172.16.19.5 这个实例上\n\n\n\n如果访问的数据正在迁移的哈希槽，该如何访问数据?\n\nSlot 2 正在从实例 2 往实例 3 迁移，key1 和 key2 已经迁移过去，key3 和 key4 还在实例 2。客户端向实例 2 请求 key2 后，就会收到实例 2 返回的 ASK 命令。\n\nASK 命令表示两层含义：第一，表明 Slot 数据还在迁移中；第二，ASK 命令把客户端所请求数据的最新实例地址返回给客户端，此时，客户端需要给实例 3 发送 ASKING 命令，然后再发送操作命令。\n\n和 MOVED 命令不同，ASK 命令并不会更新客户端缓存的哈希槽分配信息。\n\nASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例。\n\n\n\n客户端为什么可以在任意一个实例获取所有的哈希槽信息？\n\nredis 实例之间也会建立连接，分享自己的哈希槽信息。\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",normalizedContent:"# 0. 前言\n\n在海量的数据面前，单个 redis 实例的能力是有限的，无可能无限增大的内存，所以必须要构建分片集群，来横向拓展来支持保存更多的数据。\n\n\n# 1. 分片集群是什么？\n\n分片集群主要是将 redis 的数据划分成多份，每一份都由一个实例来保存，然后由多个实例来组成一个一个集群。\n\n为什么使用分片集群而不是增加内存？\n\n * 在 rdb 进行持久化时，会 fork 子进程来完成，fork 操作会阻塞主线程的时长与数据量成正比。\n * 硬件成本，把内存从 32gb 扩展到 64gb 还算容易，但是，要想扩充到 1tb，成本太高。\n\n\n# 2. 分片集群的组建\n\n在 redis cluster 方案中，一个切片集群有 16384 个哈希槽，每个键值对的 key 会进行计算并对 16384 取模，分配到一个对应编号的哈希槽。\n\n在使用 cluster create 命令创建集群时，会自动将 16384 个槽平均分配到集群实例中。也可以通过 cluster meet 命令手动建立实例间的连接形成集群，再使用 cluster addslots 命令指定每个实例上的哈希槽的个数。\n\n在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 redis 集群无法正常工作。\n\n数据分配到哪个实例?\n\n数据根据分配到哈希槽编号写入到对应的实例中。\n\n\n# 3. 客户端如何读取分片集群\n\n客户端从哪个实例中读取数据？\n\n客户端与集群建立连接后，实例会将哈希槽的分配信息发送给客户端。客户端将哈希槽信息缓存在本地，当客户端操作键值对时，先计算得到对应的哈希槽，再发送请求到相应的实例。\n\n但哈希槽与实例的映射关系并不是一成不变的，可能会发生变化：\n\n * 集群中，实例有新增或删除，redis 会重新分配哈希槽\n * 为了负载均衡，redis 会将哈希槽在所有实例中重新分布。\n\n当映射关系变化时，客户端如何感知？\n\n重定向机制。客户端发送数据给一个实例，但是并没有这个键值对的哈希槽信息，则实例会发送 moved 命令结果给客户端，包含新实例的访问地址。客户端更新本地缓存实例与哈希槽的映射关系，并向新实例发送请求。\n\nget hello:key\n(error) moved 13320 172.16.19.5:6379\n\n\n1\n2\n\n\n客户端请求的哈希槽 13320 在 172.16.19.5 这个实例上\n\n\n\n如果访问的数据正在迁移的哈希槽，该如何访问数据?\n\nslot 2 正在从实例 2 往实例 3 迁移，key1 和 key2 已经迁移过去，key3 和 key4 还在实例 2。客户端向实例 2 请求 key2 后，就会收到实例 2 返回的 ask 命令。\n\nask 命令表示两层含义：第一，表明 slot 数据还在迁移中；第二，ask 命令把客户端所请求数据的最新实例地址返回给客户端，此时，客户端需要给实例 3 发送 asking 命令，然后再发送操作命令。\n\n和 moved 命令不同，ask 命令并不会更新客户端缓存的哈希槽分配信息。\n\nask 命令的作用只是让客户端能给新实例发送一次请求，而不像 moved 命令那样，会更改本地缓存，让后续所有命令都发往新实例。\n\n\n\n客户端为什么可以在任意一个实例获取所有的哈希槽信息？\n\nredis 实例之间也会建立连接，分享自己的哈希槽信息。\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"redis之缓存",frontmatter:{title:"redis之缓存",date:"2022-12-01T15:18:55.000Z",permalink:"/pages/0d7b25/",tags:["redis","数据库"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"reids 是基于内存的数据库，它的特性之一就快，缓存是其最主要的应用场景，本文主要介绍 redis 的缓存特性，以及该如何正确的使用它。",feed:{enable:!0},categories:["数据库","redis"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16698736280551669873627898.png"},{name:"twitter:title",content:"redis之缓存"},{name:"twitter:description",content:"reids 是基于内存的数据库，它的特性之一就快，缓存是其最主要的应用场景，本文主要介绍 redis 的缓存特性，以及该如何正确的使用它。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16698736280551669873627898.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/06.%20redis%E4%B9%8B%E7%BC%93%E5%AD%98.html"},{property:"og:type",content:"article"},{property:"og:title",content:"redis之缓存"},{property:"og:description",content:"reids 是基于内存的数据库，它的特性之一就快，缓存是其最主要的应用场景，本文主要介绍 redis 的缓存特性，以及该如何正确的使用它。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16698736280551669873627898.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/06.%20redis%E4%B9%8B%E7%BC%93%E5%AD%98.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-12-01T15:18:55.000Z"},{property:"article:tag",content:"redis"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"redis之缓存"},{itemprop:"description",content:"reids 是基于内存的数据库，它的特性之一就快，缓存是其最主要的应用场景，本文主要介绍 redis 的缓存特性，以及该如何正确的使用它。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/16698736280551669873627898.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/06.%20redis%E4%B9%8B%E7%BC%93%E5%AD%98.html",relativePath:"03.中间件/05.redis/06. redis之缓存.md",key:"v-834e066a",path:"/pages/0d7b25/",headers:[{level:2,title:"1. 前言",slug:"_1-前言",normalizedTitle:"1. 前言",charIndex:2},{level:2,title:"2. 缓存类型",slug:"_2-缓存类型",normalizedTitle:"2. 缓存类型",charIndex:83},{level:3,title:"2.1 只读缓存",slug:"_2-1-只读缓存",normalizedTitle:"2.1 只读缓存",charIndex:95},{level:3,title:"2.2 读写缓存",slug:"_2-2-读写缓存",normalizedTitle:"2.2 读写缓存",charIndex:250},{level:2,title:"2. 缓存和数据库的数据一致性",slug:"_2-缓存和数据库的数据一致性",normalizedTitle:"2. 缓存和数据库的数据一致性",charIndex:468},{level:3,title:"2.1 哪些情况会导致数据不一致 ？",slug:"_2-1-哪些情况会导致数据不一致",normalizedTitle:"2.1 哪些情况会导致数据不一致 ？",charIndex:488},{level:3,title:"2.3 队列+重试机制",slug:"_2-3-队列-重试机制",normalizedTitle:"2.3 队列+重试机制",charIndex:738},{level:2,title:"3. 淘汰策略",slug:"_3-淘汰策略",normalizedTitle:"3. 淘汰策略",charIndex:1364},{level:2,title:"4. 缓存雪崩",slug:"_4-缓存雪崩",normalizedTitle:"4. 缓存雪崩",charIndex:1896},{level:2,title:"5. 缓存击穿",slug:"_5-缓存击穿",normalizedTitle:"5. 缓存击穿",charIndex:2234},{level:2,title:"6. 缓存穿透",slug:"_6-缓存穿透",normalizedTitle:"6. 缓存穿透",charIndex:2445},{level:2,title:"7. 参考文章",slug:"_7-参考文章",normalizedTitle:"7. 参考文章",charIndex:2741}],headersStr:"1. 前言 2. 缓存类型 2.1 只读缓存 2.2 读写缓存 2. 缓存和数据库的数据一致性 2.1 哪些情况会导致数据不一致 ？ 2.3 队列+重试机制 3. 淘汰策略 4. 缓存雪崩 5. 缓存击穿 6. 缓存穿透 7. 参考文章",content:"# 1. 前言\n\nreids 是基于内存的数据库，它的特性之一就快，缓存是其最主要的应用场景，本文主要介绍 redis 的缓存特性，以及该如何正确的使用它。\n\n\n# 2. 缓存类型\n\n\n# 2.1 只读缓存\n\n当写入数据时，直接操作后端数据库，进行增删改。删和改操作，如果 redis 已经缓存了对应的数据，则需要进行删除。当应用读取数据时，发生缓存缺失，则会从后端数据库读取到 redis 中使用。\n\n\n\n好处是所有的数据都在后端数据库中，而后端数据提供可靠性保障，不会有丢失数据的风险。\n\n\n# 2.2 读写缓存\n\n最新的数据在 redis 中。在写入数据时，优先写入到 redis，并且因为缓存的高性能访问，可以快速返回给业务应用。\n\n但是由于 redis 是内存数据库存在数据丢失的风险，所以还是需要写入到后端数据库中保证可靠性。有两种写入策略：\n\n * 同步直写：在写 redis 时，同步写入到后端数据库，完成后再返回给业务。会增加响应延迟。\n * 异步直写：等待增改的数据要被从缓存淘汰时。再写回后端数据库。\n\n\n\n\n# 2. 缓存和数据库的数据一致性\n\n\n# 2.1 哪些情况会导致数据不一致 ？\n\n * 我们假设应用先删除缓存，再更新数据库，如果缓存删除成功，但是数据库更新失败，那么，应用再访问数据时，缓存中没有数据，就会发生缓存缺失。然后，应用再访问数据库，但是数据库中的值为旧值，应用就访问到旧值了。\n\n * 如果应用先完成了数据库的更新，但是，在删除缓存时失败了，那么，数据库中的值是新值，而缓存中的是旧值，这肯定是不一致的。这个时候，如果有其他的并发请求来访问数据，按照正常的缓存访问流程，就会先在缓存中查询，但此时，就会读到旧值了。\n\n\n\n\n# 2.3 队列+重试机制\n\n可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。\n\n如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作\n\n但是在并发情况下，无论是先删数据库还是先删缓存操作失败的情况下，还是会有读取到不一致数据的情况。\n\n * 情况一，先删除缓存，再更新数据库。\n\n在更新数据库失败的情况下，另一个线程进来读取数据，发现缓存缺失，查询数据库的数据，并更新到缓存中，最终缓存中存储的是旧的数据。\n\n延迟双删\n\n在线程 A 更新完数据库的值以后，再让它 sleep 一会儿，再删除缓存。目的是为了让线程 B 可以将数据库的值写入到缓存中，然后再删除它。 伪代码如下：\n\nredis.delKey(X)\ndb.update(X)\nThread.sleep(N)\nredis.delKey(X)\n\n\n1\n2\n3\n4\n\n\n网上有使用这种方案来解决，个人是不推荐这种方案，在高并发的情况下，这个 sleep 时间不好确定，并不知道其他线程什么时候执行和结束。\n\n * 情况二，先更新数据库值，再删除缓存值。\n\n在删除缓存值失败的情况下，并发时，会有多个线程拿到旧的数据情况。\n\n这两种并发场景，个人感觉唯一的办法就是使用同步来完成这两个操作，可以使用分布式锁或者其他。\n\n\n# 3. 淘汰策略\n\n缓存的容量是有限的，那么当缓存满了，可以是用淘汰策略来将部分数据淘汰。\n\n缓存设置成多大比较合适？ 按照二八原理，一般 20%数据会占用 80%的访问，所以建议将缓存的容量设置为总数据量的 15%或者 30%会比较合理。\n\n淘汰策略有哪些?\n\n * 不淘汰\n   * noeviction，如果缓存已满再有写请求，则返回错误\n * 对设置过期时间的数据进行淘汰\n   * volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。\n   * volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。\n   * volatile-lru 会使用 LRU 算法筛选设置了过期时间的键值对。\n   * volatile-lfu 会使用 LFU 算法选择设置了过期时间的键值对。\n * 对所有数据进行淘汰\n   * allkeys-random 策略，从所有键值对中随机选择并删除数据；\n   * allkeys-lru 策略，使用 LRU 算法在所有数据中进行筛选。\n   * allkeys-lfu 策略，使用 LFU 算法在所有数据中进行筛选。\n\n\n# 4. 缓存雪崩\n\n缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。\n\n产生的原因\n\n * 缓存中有大量数据同时过期，导致大量请求无法得到处理\n * redis服务宕机\n\n发生后有损解决办法\n\n 1. 是在业务系统中实现服务熔断或请求限流机制。\n\n\n\n 2. 服务降级。非核心数据，直接返回预定义信息，错误或空值。核心业务仍然查询缓存。减少数据库压力\n\n提前预防\n\n上面的都是发生后有损的解决措施，所以最好的办法是提前预防，让它不要发生。\n\n 1. 避免大量数据设置相同点额过期时间，如果有，可以加个随机数。\n 2. 搭建高可用集群，主节点故障宕机，从节点可以切换成主节点，继续提供缓存服务。\n\n\n# 5. 缓存击穿\n\n缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时\n\n\n\n产生的原因\n\n * 热点数据发生过期被淘汰导致访问后端数据库\n\n发生后有损的解决办法\n\n * 接口限流与熔断，降级。\n\n提前预防\n\n * 设置热点数据永远不过期。\n\n\n# 6. 缓存穿透\n\n缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。\n\n产生的原因\n\n * 业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；\n * 恶意攻击：专门访问数据库中没有的数据。\n\n\n\n应对方案\n\n * 在请求入口做合法性校验，把恶意请求过滤掉。\n * 布隆过滤器，快速校验数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。\n * 一旦发生数据不存在的情况，可以缓存一个缺省值，下次还使用该 ID 访问时，可以返回缺省值。\n\n\n# 7. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",normalizedContent:"# 1. 前言\n\nreids 是基于内存的数据库，它的特性之一就快，缓存是其最主要的应用场景，本文主要介绍 redis 的缓存特性，以及该如何正确的使用它。\n\n\n# 2. 缓存类型\n\n\n# 2.1 只读缓存\n\n当写入数据时，直接操作后端数据库，进行增删改。删和改操作，如果 redis 已经缓存了对应的数据，则需要进行删除。当应用读取数据时，发生缓存缺失，则会从后端数据库读取到 redis 中使用。\n\n\n\n好处是所有的数据都在后端数据库中，而后端数据提供可靠性保障，不会有丢失数据的风险。\n\n\n# 2.2 读写缓存\n\n最新的数据在 redis 中。在写入数据时，优先写入到 redis，并且因为缓存的高性能访问，可以快速返回给业务应用。\n\n但是由于 redis 是内存数据库存在数据丢失的风险，所以还是需要写入到后端数据库中保证可靠性。有两种写入策略：\n\n * 同步直写：在写 redis 时，同步写入到后端数据库，完成后再返回给业务。会增加响应延迟。\n * 异步直写：等待增改的数据要被从缓存淘汰时。再写回后端数据库。\n\n\n\n\n# 2. 缓存和数据库的数据一致性\n\n\n# 2.1 哪些情况会导致数据不一致 ？\n\n * 我们假设应用先删除缓存，再更新数据库，如果缓存删除成功，但是数据库更新失败，那么，应用再访问数据时，缓存中没有数据，就会发生缓存缺失。然后，应用再访问数据库，但是数据库中的值为旧值，应用就访问到旧值了。\n\n * 如果应用先完成了数据库的更新，但是，在删除缓存时失败了，那么，数据库中的值是新值，而缓存中的是旧值，这肯定是不一致的。这个时候，如果有其他的并发请求来访问数据，按照正常的缓存访问流程，就会先在缓存中查询，但此时，就会读到旧值了。\n\n\n\n\n# 2.3 队列+重试机制\n\n可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。\n\n如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作\n\n但是在并发情况下，无论是先删数据库还是先删缓存操作失败的情况下，还是会有读取到不一致数据的情况。\n\n * 情况一，先删除缓存，再更新数据库。\n\n在更新数据库失败的情况下，另一个线程进来读取数据，发现缓存缺失，查询数据库的数据，并更新到缓存中，最终缓存中存储的是旧的数据。\n\n延迟双删\n\n在线程 a 更新完数据库的值以后，再让它 sleep 一会儿，再删除缓存。目的是为了让线程 b 可以将数据库的值写入到缓存中，然后再删除它。 伪代码如下：\n\nredis.delkey(x)\ndb.update(x)\nthread.sleep(n)\nredis.delkey(x)\n\n\n1\n2\n3\n4\n\n\n网上有使用这种方案来解决，个人是不推荐这种方案，在高并发的情况下，这个 sleep 时间不好确定，并不知道其他线程什么时候执行和结束。\n\n * 情况二，先更新数据库值，再删除缓存值。\n\n在删除缓存值失败的情况下，并发时，会有多个线程拿到旧的数据情况。\n\n这两种并发场景，个人感觉唯一的办法就是使用同步来完成这两个操作，可以使用分布式锁或者其他。\n\n\n# 3. 淘汰策略\n\n缓存的容量是有限的，那么当缓存满了，可以是用淘汰策略来将部分数据淘汰。\n\n缓存设置成多大比较合适？ 按照二八原理，一般 20%数据会占用 80%的访问，所以建议将缓存的容量设置为总数据量的 15%或者 30%会比较合理。\n\n淘汰策略有哪些?\n\n * 不淘汰\n   * noeviction，如果缓存已满再有写请求，则返回错误\n * 对设置过期时间的数据进行淘汰\n   * volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。\n   * volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。\n   * volatile-lru 会使用 lru 算法筛选设置了过期时间的键值对。\n   * volatile-lfu 会使用 lfu 算法选择设置了过期时间的键值对。\n * 对所有数据进行淘汰\n   * allkeys-random 策略，从所有键值对中随机选择并删除数据；\n   * allkeys-lru 策略，使用 lru 算法在所有数据中进行筛选。\n   * allkeys-lfu 策略，使用 lfu 算法在所有数据中进行筛选。\n\n\n# 4. 缓存雪崩\n\n缓存雪崩是指大量的应用请求无法在 redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。\n\n产生的原因\n\n * 缓存中有大量数据同时过期，导致大量请求无法得到处理\n * redis服务宕机\n\n发生后有损解决办法\n\n 1. 是在业务系统中实现服务熔断或请求限流机制。\n\n\n\n 2. 服务降级。非核心数据，直接返回预定义信息，错误或空值。核心业务仍然查询缓存。减少数据库压力\n\n提前预防\n\n上面的都是发生后有损的解决措施，所以最好的办法是提前预防，让它不要发生。\n\n 1. 避免大量数据设置相同点额过期时间，如果有，可以加个随机数。\n 2. 搭建高可用集群，主节点故障宕机，从节点可以切换成主节点，继续提供缓存服务。\n\n\n# 5. 缓存击穿\n\n缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时\n\n\n\n产生的原因\n\n * 热点数据发生过期被淘汰导致访问后端数据库\n\n发生后有损的解决办法\n\n * 接口限流与熔断，降级。\n\n提前预防\n\n * 设置热点数据永远不过期。\n\n\n# 6. 缓存穿透\n\n缓存穿透是指要访问的数据既不在 redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。\n\n产生的原因\n\n * 业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；\n * 恶意攻击：专门访问数据库中没有的数据。\n\n\n\n应对方案\n\n * 在请求入口做合法性校验，把恶意请求过滤掉。\n * 布隆过滤器，快速校验数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。\n * 一旦发生数据不存在的情况，可以缓存一个缺省值，下次还使用该 id 访问时，可以返回缺省值。\n\n\n# 7. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"python迭代器与生成器",frontmatter:{title:"python迭代器与生成器",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/e31b06/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文介绍了python的迭代器与生成器的用法与原理",feed:{enable:!0},tags:["python"],categories:["编程","python","基础"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604801659428.png#crop=0&crop=0&crop=1&crop=1&id=Wm3Ir&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{name:"twitter:title",content:"python迭代器与生成器"},{name:"twitter:description",content:"本文介绍了python的迭代器与生成器的用法与原理"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604801659428.png#crop=0&crop=0&crop=1&crop=1&id=Wm3Ir&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/01.python%E8%BF%AD%E4%BB%A3%E5%99%A8%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python迭代器与生成器"},{property:"og:description",content:"本文介绍了python的迭代器与生成器的用法与原理"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604801659428.png#crop=0&crop=0&crop=1&crop=1&id=Wm3Ir&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/01.python%E8%BF%AD%E4%BB%A3%E5%99%A8%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python迭代器与生成器"},{itemprop:"description",content:"本文介绍了python的迭代器与生成器的用法与原理"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604801659428.png#crop=0&crop=0&crop=1&crop=1&id=Wm3Ir&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/01.python%E8%BF%AD%E4%BB%A3%E5%99%A8%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8.html",relativePath:"04.编程/01.python/01.基础/01.python迭代器与生成器.md",key:"v-b9336fc4",path:"/pages/e31b06/",headers:[{level:2,title:"迭代器和可迭代对象",slug:"迭代器和可迭代对象",normalizedTitle:"迭代器和可迭代对象",charIndex:2},{level:2,title:"如何实现迭代器？",slug:"如何实现迭代器",normalizedTitle:"如何实现迭代器？",charIndex:146},{level:2,title:"生成器和生成器函数",slug:"生成器和生成器函数",normalizedTitle:"生成器和生成器函数",charIndex:661},{level:3,title:"生成器函数创建生成器",slug:"生成器函数创建生成器",normalizedTitle:"生成器函数创建生成器",charIndex:698},{level:3,title:"生成器表达式创建生成器",slug:"生成器表达式创建生成器",normalizedTitle:"生成器表达式创建生成器",charIndex:1146}],headersStr:"迭代器和可迭代对象 如何实现迭代器？ 生成器和生成器函数 生成器函数创建生成器 生成器表达式创建生成器",content:'# 迭代器和可迭代对象\n\n实现了__iter__的对象是可迭代对象.\n\n实现了__iter__和__next__的是迭代器.\n\n两者之间的关系: Python从可迭代的对象中获取迭代器\n\n可迭代对象的抽象基类是abc.Iterable 迭代器的抽象基类是abc.Iterator\n\n\n\n\n# 如何实现迭代器？\n\n定义__iter__方法返回带有__next__方法的对象，__iter__可以简单的返回self.\n\n当没有数据返回时，会抛出StopIteration异常停止返回数据。\n\n\nclass MyIter():\n    def __init__(self, data):\n        self.data = data\n        self.index = len(data)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.index == 0:\n            raise StopIteration\n        \n        self.index = self.index - 1\n        return self.data[self.index]\n\nmy_iter = MyIter()\niter(my_iter)   # 返回一个迭代器\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n\n# 生成器和生成器函数\n\n函数中有yield关键字的，就是生成器函数\n\n\n# 生成器函数创建生成器\n\n下面的__iter__是一个生成器函数，通过该生成器函数创建生成器对象，包装生成器函数的定义。把生成器传给next(...)函数时，生成器函数会向前，执行函数定义体中的下一个yield语句，返回产出的值，并在函数定义体的当前位置暂停。当无数据返回时，生成器对象会抛出StopIteration异常。\n\n\n\n例子:\n\n\nimport re\nimport reprlib\n\nRE_WORD = re.compile("\\w+")\n\nclass Sentence:\n    def __init__(self, text):\n        self.text = text\n        \n    def __iter__(self):\n        for match in RE_WORD.finditer(self.text):\n            yield matc.group()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 生成器表达式创建生成器\n\n生成器表达式可以理解为列表推导的惰性版本: 不会迫切地构建列表，而是返回一个生成器，按需惰性生成元素。\n\n列表表达式。 会马上加载所有的元素到内存中\n\n[i for i in range(10)]\n\n\n1\n\n\n生成器表达式: 会得到一个生成器对象，可以通过next或者循环的方式惰性求值。\n\n(i for i in range(10))\n\n\n1\n\n\n虽然下面的__iter__没有yield关键字，但是却有具有生成器表达式，所以__iter__得到的也是一个生成器对象。\n\n例子:\n\nclass A:\n    def __iter__(self):\n        return (x*3 for x in range(10))\n\n\n1\n2\n3\n',normalizedContent:'# 迭代器和可迭代对象\n\n实现了__iter__的对象是可迭代对象.\n\n实现了__iter__和__next__的是迭代器.\n\n两者之间的关系: python从可迭代的对象中获取迭代器\n\n可迭代对象的抽象基类是abc.iterable 迭代器的抽象基类是abc.iterator\n\n\n\n\n# 如何实现迭代器？\n\n定义__iter__方法返回带有__next__方法的对象，__iter__可以简单的返回self.\n\n当没有数据返回时，会抛出stopiteration异常停止返回数据。\n\n\nclass myiter():\n    def __init__(self, data):\n        self.data = data\n        self.index = len(data)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.index == 0:\n            raise stopiteration\n        \n        self.index = self.index - 1\n        return self.data[self.index]\n\nmy_iter = myiter()\niter(my_iter)   # 返回一个迭代器\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n\n# 生成器和生成器函数\n\n函数中有yield关键字的，就是生成器函数\n\n\n# 生成器函数创建生成器\n\n下面的__iter__是一个生成器函数，通过该生成器函数创建生成器对象，包装生成器函数的定义。把生成器传给next(...)函数时，生成器函数会向前，执行函数定义体中的下一个yield语句，返回产出的值，并在函数定义体的当前位置暂停。当无数据返回时，生成器对象会抛出stopiteration异常。\n\n\n\n例子:\n\n\nimport re\nimport reprlib\n\nre_word = re.compile("\\w+")\n\nclass sentence:\n    def __init__(self, text):\n        self.text = text\n        \n    def __iter__(self):\n        for match in re_word.finditer(self.text):\n            yield matc.group()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 生成器表达式创建生成器\n\n生成器表达式可以理解为列表推导的惰性版本: 不会迫切地构建列表，而是返回一个生成器，按需惰性生成元素。\n\n列表表达式。 会马上加载所有的元素到内存中\n\n[i for i in range(10)]\n\n\n1\n\n\n生成器表达式: 会得到一个生成器对象，可以通过next或者循环的方式惰性求值。\n\n(i for i in range(10))\n\n\n1\n\n\n虽然下面的__iter__没有yield关键字，但是却有具有生成器表达式，所以__iter__得到的也是一个生成器对象。\n\n例子:\n\nclass a:\n    def __iter__(self):\n        return (x*3 for x in range(10))\n\n\n1\n2\n3\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"python元编程",frontmatter:{title:"python元编程",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/5fa368/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文介绍python中元编程的属性及使用方法",feed:{enable:!0},tags:["python"],categories:["编程","python","基础"],comment:!0,meta:[{name:"twitter:title",content:"python元编程"},{name:"twitter:description",content:"本文介绍python中元编程的属性及使用方法"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/02.python%E5%85%83%E7%BC%96%E7%A8%8B.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python元编程"},{property:"og:description",content:"本文介绍python中元编程的属性及使用方法"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/02.python%E5%85%83%E7%BC%96%E7%A8%8B.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python元编程"},{itemprop:"description",content:"本文介绍python中元编程的属性及使用方法"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/02.python%E5%85%83%E7%BC%96%E7%A8%8B.html",relativePath:"04.编程/01.python/01.基础/02.python元编程.md",key:"v-300c8022",path:"/pages/5fa368/",headers:[{level:2,title:"property动态属性",slug:"property动态属性",normalizedTitle:"property动态属性",charIndex:2},{level:2,title:"_getattribute 和 getattr_",slug:"getattribute-和-getattr",normalizedTitle:"<em>getattribute 和 getattr</em>",charIndex:null},{level:2,title:"属性描述符",slug:"属性描述符",normalizedTitle:"属性描述符",charIndex:744},{level:3,title:"属性描述符查找过程",slug:"属性描述符查找过程",normalizedTitle:"属性描述符查找过程",charIndex:1032},{level:2,title:"元类",slug:"元类",normalizedTitle:"元类",charIndex:2152},{level:3,title:"通过type创建class",slug:"通过type创建class",normalizedTitle:"通过type创建class",charIndex:2211},{level:3,title:"自定义元类",slug:"自定义元类",normalizedTitle:"自定义元类",charIndex:2588}],headersStr:"property动态属性 _getattribute 和 getattr_ 属性描述符 属性描述符查找过程 元类 通过type创建class 自定义元类",content:'# property动态属性\n\n通过使用property可以将方法像属性一样获取值。使用setter对方法进行赋值操作\n\n\nfrom datetime import datetime, date\nclass Student:\n\n    def __init__(self, name, birthday):\n        self.name = name\n        self.birthday = birthday\n        self._age = 0\n    \n    @property\n    def age(self):\n        return datetime.now().year - self.birthday.year\n    \n    @age.setter\n    def age(self, value):\n        self._age = value\n    \nstu = Student("zhangsan", date(year=1995, month=3, day=7))\nstu.age = 4\nprint(stu.age)\n\noutput: 24\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n\n# getattribute 和 getattr\n\n__getattr__在类中找不到属性时，调用该函数。 __getattribute__首先调用该函数，然后找属性.\n\n在__getattribute__中抛出AttributeError时，会调用__getattr__\n\n调用顺序 __getattribute__ > __getattr__\n\n\n# 属性描述符\n\n在类中只要实现了__get__、__set__、__delete__方法中的一个就认为是描述符. 只实现了__get__的对象是非数据描述符. 只读 实现了__get__和__set__的对象是数据描述符. 可读可写.\n\nclass IntField:\n    def __get__(self):\n        pass\n        \n    def __set__(self):\n        pass\n        \n    def __delete__(self):\n        pass\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 属性描述符查找过程\n\n属性描述符发生的过程在__getattribute__中.\n\n如果age是属性描述符，则调用IntField中的__get__获得属性值，如果获取失败，则调用__dict__获取值。如果age不是属性描述符，则直接获取__dict__对应的值。\n\n\nimport numbers\nclass IntField:\n    # 数据描述符\n    def __get__(self, instance, owner):\n        return self.value\n        \n    def __set__(self, instance, value):\n        if not isinstance(value, numbers.Integral):\n            raise ValueError("int value need")\n        if value < 0:\n            raise ValueError("positive value need")\n        self.value = value\n        \n    def __delete__(self, instance):\n        pass\n    \nclass NonDataIntField:\n    # 非数据属性描述符\n    def __get__(self, instance, owner):\n        return "NonDataIntField = {}".format(self.value)\n\nclass User:\n    age = IntField()\n    #age = NonDataIntField()\n\nuser = User()\nuser.name = "zhangsan"    # name不是属性描述符，所以直接加入到`__dict__`中\nprint(user.__dict__)\n\nuser.age = 12               # age是属性描述符, 调用`IntField`中的`__set__`方法， 而不会加入到`__dict__`中\nprint(user.__dict__)\nprint(user.age)              # 调用`IntField`中的`__get__`方法\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n\n# 元类\n\n元类是创建类的类. type -> class -> 对象\n\n所有的类都是通过type实例化得到的。\n\n\n# 通过type创建class\n\n使用type创建User类，该类继承Base类，并且有test方法和name属性\n\n\nclass Base:\n    def __init__(self, *args, **kwargs):\n        print("Base __init__")\n        super().__init__(*args, **kwargs)\n\ndef test(self):\n    print("test = {}".format(self.name))\n \nUser = type("User", (Base,), {"test": test, "name": "zhangsan"})\nuser = User()\nuser.test()\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# 自定义元类\n\n自定义元类需要通过继承type实现\n\n如果父类有metaclass，则子类和父类的创建都需要通过该元类实例化得到。\n\n\n\nclass BaseMeta(type):\n\n    def __new__(cls, name, bases, args, **kwargs):\n        # print(name)\n        # print(bases)\n        # print(args)\n        print("BaseMeta __new__..")\n        \n        if name == "Base":\n            return super().__new__(cls, name, bases, args, **kwargs)\n            \n        meta = args[\'Meta\']\n        name = getattr(meta, "name")    # 获取到A中meta的name的值. django的orm也是这样实现的\n        print(name)\n        \n        return super().__new__(cls, name, bases, args, **kwargs)\n\n\n\nclass Base(metaclass=BaseMeta):\n\n    def __new__(cls, *args, **kwargs):\n        print("Base __new__..")\n        return super().__new__(cls, *args, **kwargs)\n        \n    def __init__(self, *args, **kwargs):\n        print("Base init..")\n        super().__init__(*args, **kwargs)\n    \nclass A(Base):\n\n    def __new__(cls, *args, **kwargs):\n        print("A __new__..")\n        return super().__new__(cls, *args, **kwargs)\n        \n    def __init__(self, *args, **kwargs):\n        print("A init..")\n        super().__init__(*args, **kwargs)\n        \n    class Meta:\n        name = "zhangsan"\n\n\n# A和Base都会通过BaseMeta创建，所以会调用两次__new__创建实例\noutput:\n\nBaseMeta __new__..\nBaseMeta __new__..\nzhangsan\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n\n\n元类的经典例子是django ORM',normalizedContent:'# property动态属性\n\n通过使用property可以将方法像属性一样获取值。使用setter对方法进行赋值操作\n\n\nfrom datetime import datetime, date\nclass student:\n\n    def __init__(self, name, birthday):\n        self.name = name\n        self.birthday = birthday\n        self._age = 0\n    \n    @property\n    def age(self):\n        return datetime.now().year - self.birthday.year\n    \n    @age.setter\n    def age(self, value):\n        self._age = value\n    \nstu = student("zhangsan", date(year=1995, month=3, day=7))\nstu.age = 4\nprint(stu.age)\n\noutput: 24\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n\n# getattribute 和 getattr\n\n__getattr__在类中找不到属性时，调用该函数。 __getattribute__首先调用该函数，然后找属性.\n\n在__getattribute__中抛出attributeerror时，会调用__getattr__\n\n调用顺序 __getattribute__ > __getattr__\n\n\n# 属性描述符\n\n在类中只要实现了__get__、__set__、__delete__方法中的一个就认为是描述符. 只实现了__get__的对象是非数据描述符. 只读 实现了__get__和__set__的对象是数据描述符. 可读可写.\n\nclass intfield:\n    def __get__(self):\n        pass\n        \n    def __set__(self):\n        pass\n        \n    def __delete__(self):\n        pass\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 属性描述符查找过程\n\n属性描述符发生的过程在__getattribute__中.\n\n如果age是属性描述符，则调用intfield中的__get__获得属性值，如果获取失败，则调用__dict__获取值。如果age不是属性描述符，则直接获取__dict__对应的值。\n\n\nimport numbers\nclass intfield:\n    # 数据描述符\n    def __get__(self, instance, owner):\n        return self.value\n        \n    def __set__(self, instance, value):\n        if not isinstance(value, numbers.integral):\n            raise valueerror("int value need")\n        if value < 0:\n            raise valueerror("positive value need")\n        self.value = value\n        \n    def __delete__(self, instance):\n        pass\n    \nclass nondataintfield:\n    # 非数据属性描述符\n    def __get__(self, instance, owner):\n        return "nondataintfield = {}".format(self.value)\n\nclass user:\n    age = intfield()\n    #age = nondataintfield()\n\nuser = user()\nuser.name = "zhangsan"    # name不是属性描述符，所以直接加入到`__dict__`中\nprint(user.__dict__)\n\nuser.age = 12               # age是属性描述符, 调用`intfield`中的`__set__`方法， 而不会加入到`__dict__`中\nprint(user.__dict__)\nprint(user.age)              # 调用`intfield`中的`__get__`方法\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n\n# 元类\n\n元类是创建类的类. type -> class -> 对象\n\n所有的类都是通过type实例化得到的。\n\n\n# 通过type创建class\n\n使用type创建user类，该类继承base类，并且有test方法和name属性\n\n\nclass base:\n    def __init__(self, *args, **kwargs):\n        print("base __init__")\n        super().__init__(*args, **kwargs)\n\ndef test(self):\n    print("test = {}".format(self.name))\n \nuser = type("user", (base,), {"test": test, "name": "zhangsan"})\nuser = user()\nuser.test()\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# 自定义元类\n\n自定义元类需要通过继承type实现\n\n如果父类有metaclass，则子类和父类的创建都需要通过该元类实例化得到。\n\n\n\nclass basemeta(type):\n\n    def __new__(cls, name, bases, args, **kwargs):\n        # print(name)\n        # print(bases)\n        # print(args)\n        print("basemeta __new__..")\n        \n        if name == "base":\n            return super().__new__(cls, name, bases, args, **kwargs)\n            \n        meta = args[\'meta\']\n        name = getattr(meta, "name")    # 获取到a中meta的name的值. django的orm也是这样实现的\n        print(name)\n        \n        return super().__new__(cls, name, bases, args, **kwargs)\n\n\n\nclass base(metaclass=basemeta):\n\n    def __new__(cls, *args, **kwargs):\n        print("base __new__..")\n        return super().__new__(cls, *args, **kwargs)\n        \n    def __init__(self, *args, **kwargs):\n        print("base init..")\n        super().__init__(*args, **kwargs)\n    \nclass a(base):\n\n    def __new__(cls, *args, **kwargs):\n        print("a __new__..")\n        return super().__new__(cls, *args, **kwargs)\n        \n    def __init__(self, *args, **kwargs):\n        print("a init..")\n        super().__init__(*args, **kwargs)\n        \n    class meta:\n        name = "zhangsan"\n\n\n# a和base都会通过basemeta创建，所以会调用两次__new__创建实例\noutput:\n\nbasemeta __new__..\nbasemeta __new__..\nzhangsan\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n\n\n元类的经典例子是django orm',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"pulsar阻塞导致logstash无法接入日志",frontmatter:{title:"pulsar阻塞导致logstash无法接入日志",date:"2024-10-30T10:34:05.000Z",permalink:"/pages/adedbd/",categories:["中间件","logstash"],tags:["logstash","计算机网络","pular"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"在使用tcp和udp接入方式接入一段时间日志之后，日志突然无法接入了，在pulsar中的对应topic没有新的日志生产进来了。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17302568788191730256878496.png"},{name:"twitter:title",content:"pulsar阻塞导致logstash无法接入日志"},{name:"twitter:description",content:"在使用tcp和udp接入方式接入一段时间日志之后，日志突然无法接入了，在pulsar中的对应topic没有新的日志生产进来了。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17302568788191730256878496.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/06.logstash/01.pulsar%E9%98%BB%E5%A1%9E%E5%AF%BC%E8%87%B4logstash%E6%97%A0%E6%B3%95%E6%8E%A5%E5%85%A5%E6%97%A5%E5%BF%97.html"},{property:"og:type",content:"article"},{property:"og:title",content:"pulsar阻塞导致logstash无法接入日志"},{property:"og:description",content:"在使用tcp和udp接入方式接入一段时间日志之后，日志突然无法接入了，在pulsar中的对应topic没有新的日志生产进来了。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17302568788191730256878496.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/06.logstash/01.pulsar%E9%98%BB%E5%A1%9E%E5%AF%BC%E8%87%B4logstash%E6%97%A0%E6%B3%95%E6%8E%A5%E5%85%A5%E6%97%A5%E5%BF%97.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2024-10-30T10:34:05.000Z"},{property:"article:tag",content:"logstash"},{property:"article:tag",content:"计算机网络"},{property:"article:tag",content:"pular"},{itemprop:"name",content:"pulsar阻塞导致logstash无法接入日志"},{itemprop:"description",content:"在使用tcp和udp接入方式接入一段时间日志之后，日志突然无法接入了，在pulsar中的对应topic没有新的日志生产进来了。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17302568788191730256878496.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/06.logstash/01.pulsar%E9%98%BB%E5%A1%9E%E5%AF%BC%E8%87%B4logstash%E6%97%A0%E6%B3%95%E6%8E%A5%E5%85%A5%E6%97%A5%E5%BF%97.html",relativePath:"03.中间件/06.logstash/01.pulsar阻塞导致logstash无法接入日志.md",key:"v-450eddde",path:"/pages/adedbd/",headers:[{level:2,title:"背景",slug:"背景",normalizedTitle:"背景",charIndex:2},{level:2,title:"检查网络情况",slug:"检查网络情况",normalizedTitle:"检查网络情况",charIndex:149},{level:2,title:"检查logstash管道信息",slug:"检查logstash管道信息",normalizedTitle:"检查logstash管道信息",charIndex:809},{level:2,title:"从堆栈中找到蛛丝马迹",slug:"从堆栈中找到蛛丝马迹",normalizedTitle:"从堆栈中找到蛛丝马迹",charIndex:1604},{level:2,title:"复现",slug:"复现",normalizedTitle:"复现",charIndex:2266},{level:2,title:"修复",slug:"修复",normalizedTitle:"修复",charIndex:2404},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:2588}],headersStr:"背景 检查网络情况 检查logstash管道信息 从堆栈中找到蛛丝马迹 复现 修复 总结",content:'# 背景\n\n在logstash中，input管道接收tcp和udp的日志，然后再通过output管道将日志输出到pulsar中，如下图所示：\n\n\n\n当前的问题是，在使用tcp和udp接入方式接入一段时间日志之后，日志突然无法接入了，在pulsar中的对应topic没有新的日志生产进来了。\n\n\n# 检查网络情况\n\n 1. 在容器中抓包，判断数据包是否进入到容器中\n\n因为服务都是容器化部署的，所以可以使用nsenter -t $Pid -n来进入到容器的network namespace中，然后再使用tcpdump -i any port 514 -vvnn来抓取514端口的数据包。\n\n通过抓包是可以抓到数据包，并且看三次握手和数据包都是正常的，说明流量已经进入到容器中了。\n\n 2. 查看tcp和udp缓存队列\n\n使用netstat -anp查看tcp和upd缓存队列，发现Recv-Q是一直有堆积的，也就是说，服务端没有在从缓存队列中消费日志，服务端卡住了。\n\n# netstat -anp\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name  \ntcp   286138      0 14.2.19.144:514         10.65.132.32:46778      ESTABLISHED 538152/java   \nudp   152543      0 14.2.19.144:514         10.65.132.32:46774      ESTABLISHED 538152/java  \n\n\n1\n2\n3\n4\n5\n\n\n\n# 检查logstash管道信息\n\n进入到容器中执行以下命令来获取logstash对应管道的信息\n\ncurl -XGET \'localhost:9600/_node/stats/pipelines/syslog?pretty\'\n\n\n1\n\n\n可以看到input管道中tcp插件的out的数量一直保持不变，说明已经没有接收新的数据包了。\n\n{\n    "id": "d1a2689850bcefed823d25f0ae0ee7b863f3843474c6eafd3d3fe5aa7babcded",\n    "name": "tcp",\n    "events": {\n        "queue_push_duration_in_millis": 3728,\n        "out": 6680\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n再看output管道的pulsar插件信息，可以看到in比out多了150，这是因为pipeline.batch.size=50，并且pipeline.workers=3，所以一共有150条日志阻塞在队列中，pulsar-client法发送出去，阻塞了。\n\n{\n    "id": "4acf48fc134b333ecb24218723c8fd36d54dc3713cbe66bd199ce4ccb09f2cd1",\n    "name": "pulsar",\n    "events": {\n        "duration_in_millis": 9923,\n        "in": 6529,\n        "out": 6379\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n通过查看pulsar服务的状态和日志发现其并没有任何异常，手动去生产日志也是可以的，所以暂时排除了pulsar本身的问题。\n\n\n# 从堆栈中找到蛛丝马迹\n\n通过以下命令来查看logstash的线程堆栈信息\n\n# curl -XGET \'localhost:9600/_node/hot_threads?pretty\'\n\n"java.base@11.0.15/jdk.internal.misc.Unsafe.park(Native Method)", "java.base@11.0.15/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)", "java.base@11.0.15/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2081)", "org.apache.pulsar.client.impl.MemoryLimitController.reserveMemory(MemoryLimitController.java:88)", ...\n\n\n1\n2\n3\n\n\n通过上面的堆栈信息去google上搜索，找到了下面这个链接，发现是pulsar的官方bug，在开启压缩时，并且内存限制的越小，越容易触发该BUG，从而导致pulsar-client发生阻塞。\n\nhttps://lists.apache.org/thread/76jn7k01ldgkl54n0bpgw3sf2kxqq5q9\n\n\n# 复现\n\n这里用的是开源的pulsar插件：logstash-output-pulsar\n\n其并没有内存限制配置参数，通过修改源码将pulsar-client的memory_limit参数暴露出来，并将其设置成1，开启压缩，持续构造日志进来，会发现稳定快速复现该问题。\n\n\n# 修复\n\n查看logstash-output-pulsar项目下的build.gradle文件，其pulsar版本为2.10.2，而在https://github.com/apache/pulsar/pull/21790 提交可以看到在3.2.0版本修复的。\n\n修改项目中pulsar-client版本号，打包出来，再按照上面的复现步骤，发现不会再进行阻塞了。\n\n\n# 总结\n\n善于利用组件提供的各种工具得到其指标，分析原因，找到蛛丝马迹，再利用google去搜索。',normalizedContent:'# 背景\n\n在logstash中，input管道接收tcp和udp的日志，然后再通过output管道将日志输出到pulsar中，如下图所示：\n\n\n\n当前的问题是，在使用tcp和udp接入方式接入一段时间日志之后，日志突然无法接入了，在pulsar中的对应topic没有新的日志生产进来了。\n\n\n# 检查网络情况\n\n 1. 在容器中抓包，判断数据包是否进入到容器中\n\n因为服务都是容器化部署的，所以可以使用nsenter -t $pid -n来进入到容器的network namespace中，然后再使用tcpdump -i any port 514 -vvnn来抓取514端口的数据包。\n\n通过抓包是可以抓到数据包，并且看三次握手和数据包都是正常的，说明流量已经进入到容器中了。\n\n 2. 查看tcp和udp缓存队列\n\n使用netstat -anp查看tcp和upd缓存队列，发现recv-q是一直有堆积的，也就是说，服务端没有在从缓存队列中消费日志，服务端卡住了。\n\n# netstat -anp\nactive internet connections (servers and established)\nproto recv-q send-q local address           foreign address         state       pid/program name  \ntcp   286138      0 14.2.19.144:514         10.65.132.32:46778      established 538152/java   \nudp   152543      0 14.2.19.144:514         10.65.132.32:46774      established 538152/java  \n\n\n1\n2\n3\n4\n5\n\n\n\n# 检查logstash管道信息\n\n进入到容器中执行以下命令来获取logstash对应管道的信息\n\ncurl -xget \'localhost:9600/_node/stats/pipelines/syslog?pretty\'\n\n\n1\n\n\n可以看到input管道中tcp插件的out的数量一直保持不变，说明已经没有接收新的数据包了。\n\n{\n    "id": "d1a2689850bcefed823d25f0ae0ee7b863f3843474c6eafd3d3fe5aa7babcded",\n    "name": "tcp",\n    "events": {\n        "queue_push_duration_in_millis": 3728,\n        "out": 6680\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n再看output管道的pulsar插件信息，可以看到in比out多了150，这是因为pipeline.batch.size=50，并且pipeline.workers=3，所以一共有150条日志阻塞在队列中，pulsar-client法发送出去，阻塞了。\n\n{\n    "id": "4acf48fc134b333ecb24218723c8fd36d54dc3713cbe66bd199ce4ccb09f2cd1",\n    "name": "pulsar",\n    "events": {\n        "duration_in_millis": 9923,\n        "in": 6529,\n        "out": 6379\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n通过查看pulsar服务的状态和日志发现其并没有任何异常，手动去生产日志也是可以的，所以暂时排除了pulsar本身的问题。\n\n\n# 从堆栈中找到蛛丝马迹\n\n通过以下命令来查看logstash的线程堆栈信息\n\n# curl -xget \'localhost:9600/_node/hot_threads?pretty\'\n\n"java.base@11.0.15/jdk.internal.misc.unsafe.park(native method)", "java.base@11.0.15/java.util.concurrent.locks.locksupport.park(locksupport.java:194)", "java.base@11.0.15/java.util.concurrent.locks.abstractqueuedsynchronizer$conditionobject.await(abstractqueuedsynchronizer.java:2081)", "org.apache.pulsar.client.impl.memorylimitcontroller.reservememory(memorylimitcontroller.java:88)", ...\n\n\n1\n2\n3\n\n\n通过上面的堆栈信息去google上搜索，找到了下面这个链接，发现是pulsar的官方bug，在开启压缩时，并且内存限制的越小，越容易触发该bug，从而导致pulsar-client发生阻塞。\n\nhttps://lists.apache.org/thread/76jn7k01ldgkl54n0bpgw3sf2kxqq5q9\n\n\n# 复现\n\n这里用的是开源的pulsar插件：logstash-output-pulsar\n\n其并没有内存限制配置参数，通过修改源码将pulsar-client的memory_limit参数暴露出来，并将其设置成1，开启压缩，持续构造日志进来，会发现稳定快速复现该问题。\n\n\n# 修复\n\n查看logstash-output-pulsar项目下的build.gradle文件，其pulsar版本为2.10.2，而在https://github.com/apache/pulsar/pull/21790 提交可以看到在3.2.0版本修复的。\n\n修改项目中pulsar-client版本号，打包出来，再按照上面的复现步骤，发现不会再进行阻塞了。\n\n\n# 总结\n\n善于利用组件提供的各种工具得到其指标，分析原因，找到蛛丝马迹，再利用google去搜索。',charsets:{cjk:!0},lastUpdated:"2025/02/09, 23:47:02",lastUpdatedTimestamp:1739116022e3},{title:"python上下文管理器",frontmatter:{title:"python上下文管理器",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/a6b804/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"python的上下文管理的使用及实现的几种方式",feed:{enable:!0},tags:["python"],categories:["编程","python","基础"],comment:!0,meta:[{name:"twitter:title",content:"python上下文管理器"},{name:"twitter:description",content:"python的上下文管理的使用及实现的几种方式"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/04.python%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python上下文管理器"},{property:"og:description",content:"python的上下文管理的使用及实现的几种方式"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/04.python%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python上下文管理器"},{itemprop:"description",content:"python的上下文管理的使用及实现的几种方式"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/04.python%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8.html",relativePath:"04.编程/01.python/01.基础/04.python上下文管理器.md",key:"v-ed00c198",path:"/pages/a6b804/",headers:[{level:2,title:"什么是上下文管理器",slug:"什么是上下文管理器",normalizedTitle:"什么是上下文管理器",charIndex:2},{level:2,title:"经典open案例",slug:"经典open案例",normalizedTitle:"经典open案例",charIndex:89},{level:2,title:"自定义上下文管理器",slug:"自定义上下文管理器",normalizedTitle:"自定义上下文管理器",charIndex:314},{level:3,title:"类实现",slug:"类实现",normalizedTitle:"类实现",charIndex:328},{level:3,title:"方法实现",slug:"方法实现",normalizedTitle:"方法实现",charIndex:631}],headersStr:"什么是上下文管理器 经典open案例 自定义上下文管理器 类实现 方法实现",content:'# 什么是上下文管理器\n\npython中使用with来使用上下文管理器.\n\n在使用某个资源时，可以对该资源进行初始化和资源的清理两个操作，在这两个操作之间边成为上下文。\n\n\n# 经典open案例\n\n对文件操作时，需要打开文件及关闭文件。然后在这之间进行文件的操作。\n\nf = open("a.txt")\nf.write("hello world")\nf.close()\n\n\n1\n2\n3\n\n\n使用上下文管理器 打开文件后，得到文件描述符，在with代码块中对f进行操作，结束时，会自动的进行关闭操作.\n\nwith open("a.txt") as f:\n    f.write("hello world")\n\n\n1\n2\n\n\n\n# 自定义上下文管理器\n\n\n# 类实现\n\n进入上下文时，调用__enter__方法进行初始化，退出时，调用__exit__退出。\n\n\nclass A:\ndef __enter__(self):\n    print("进入")\n\ndef __exit__(self, exc_type, exc_val, exc_tb):\n    print("释放资源")\n\nwith A() as f:\n    print("hello")\n    print("world")\n   \noutput: \n进入\nhello\nworld\n释放资源\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# 方法实现\n\n使用contextlib.contextmanager 对方法实现上下文管理器. 使用生成器完成。\n\n\nimport contextlib\n\n@contextlib.contextmanager\ndef test(a):\n    print("open..")\n    yield a\n    print("close")\n    \nwith test(2) as f:\n    print(f)\n\noutput:\nopen..\n2\nclose\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n',normalizedContent:'# 什么是上下文管理器\n\npython中使用with来使用上下文管理器.\n\n在使用某个资源时，可以对该资源进行初始化和资源的清理两个操作，在这两个操作之间边成为上下文。\n\n\n# 经典open案例\n\n对文件操作时，需要打开文件及关闭文件。然后在这之间进行文件的操作。\n\nf = open("a.txt")\nf.write("hello world")\nf.close()\n\n\n1\n2\n3\n\n\n使用上下文管理器 打开文件后，得到文件描述符，在with代码块中对f进行操作，结束时，会自动的进行关闭操作.\n\nwith open("a.txt") as f:\n    f.write("hello world")\n\n\n1\n2\n\n\n\n# 自定义上下文管理器\n\n\n# 类实现\n\n进入上下文时，调用__enter__方法进行初始化，退出时，调用__exit__退出。\n\n\nclass a:\ndef __enter__(self):\n    print("进入")\n\ndef __exit__(self, exc_type, exc_val, exc_tb):\n    print("释放资源")\n\nwith a() as f:\n    print("hello")\n    print("world")\n   \noutput: \n进入\nhello\nworld\n释放资源\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# 方法实现\n\n使用contextlib.contextmanager 对方法实现上下文管理器. 使用生成器完成。\n\n\nimport contextlib\n\n@contextlib.contextmanager\ndef test(a):\n    print("open..")\n    yield a\n    print("close")\n    \nwith test(2) as f:\n    print(f)\n\noutput:\nopen..\n2\nclose\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"python垃圾回收机制",frontmatter:{title:"python垃圾回收机制",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/78c648/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"python的垃圾回收机制的几种方式：引用计数、标记清楚及分代回收，介绍他们的原理。",feed:{enable:!0},tags:["python"],categories:["编程","python","基础"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215650.png"},{name:"twitter:title",content:"python垃圾回收机制"},{name:"twitter:description",content:"python的垃圾回收机制的几种方式：引用计数、标记清楚及分代回收，介绍他们的原理。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215650.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/03.python%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python垃圾回收机制"},{property:"og:description",content:"python的垃圾回收机制的几种方式：引用计数、标记清楚及分代回收，介绍他们的原理。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215650.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/03.python%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python垃圾回收机制"},{itemprop:"description",content:"python的垃圾回收机制的几种方式：引用计数、标记清楚及分代回收，介绍他们的原理。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215650.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/03.python%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6.html",relativePath:"04.编程/01.python/01.基础/03.python垃圾回收机制.md",key:"v-06e111a1",path:"/pages/78c648/",headers:[{level:2,title:"引用计数",slug:"引用计数",normalizedTitle:"引用计数",charIndex:2},{level:2,title:"标记-清除",slug:"标记-清除",normalizedTitle:"标记-清除",charIndex:68},{level:2,title:"分代回收",slug:"分代回收",normalizedTitle:"分代回收",charIndex:428},{level:2,title:"垃圾回收触发情况",slug:"垃圾回收触发情况",normalizedTitle:"垃圾回收触发情况",charIndex:684}],headersStr:"引用计数 标记-清除 分代回收 垃圾回收触发情况",content:"# 引用计数\n\n每次对象被引用时，会被计数加1，当计数为0时，则回收该对象。\n\n注意： 循环引用的情况，引用计数不能解决.\n\n\n\n\n# 标记-清除\n\n对所有活跃的对象进行标记，对非活跃对象进行回收。可以有效的解决循环引用的问题\n\n原理 对象之间通过引用构建有向图，从root object(全局变量，寄存器等不可删除的对象)出发，沿着有向边遍历对象，可达的对象标记为活跃对象，不可达的对象就是要被清除的非活动对象。\n\n在下图中，从黑点开始出发，1对象可达，2、3间接可达，1、2、3是活跃对象，4,5不可达，所以是非活跃对象，进行回收。\n\n过程 找到root object集合, 在内存建立两条连表，一条链表维护root object集合，另一条链表哦维护剩下的对象，在标记的过程中，如果在不可达链表中存在被root链表中的独享，直接或间接引用独享，就将其从不可达链表移到root链表中。当完成标记后，不可达链表剩下的对象都是垃圾对象，进行回收。\n\n\n# 分代回收\n\n对象分在不同集合中，每个集合称为一个代, Python中分为3代，年轻代(第0代)、中年代(第1代)、老年代(第二代)，对应3各链表，每一代GC频率不同，第0代最高，第1代次之，第二代最低(越年轻的对象越容易死掉，而老的对象通常会存错更久)，新生的对象放入第0代，如果该对象在第0代的一次GC中存活，则移动到第1代，如果第一代对象在第1代GC中存错，则移动到第2代。\n\n什么情况触发GC， 可以设置阈值，也可以手动调用gc.collect()\n\n每次扫描全部对象，费时费力，提高GC的效率。\n\n\n# 垃圾回收触发情况\n\n调用gc.collect(),需要先导入gc模块。\n\n当gc模块的计数器达到阈值的时候。阈值可以设置",normalizedContent:"# 引用计数\n\n每次对象被引用时，会被计数加1，当计数为0时，则回收该对象。\n\n注意： 循环引用的情况，引用计数不能解决.\n\n\n\n\n# 标记-清除\n\n对所有活跃的对象进行标记，对非活跃对象进行回收。可以有效的解决循环引用的问题\n\n原理 对象之间通过引用构建有向图，从root object(全局变量，寄存器等不可删除的对象)出发，沿着有向边遍历对象，可达的对象标记为活跃对象，不可达的对象就是要被清除的非活动对象。\n\n在下图中，从黑点开始出发，1对象可达，2、3间接可达，1、2、3是活跃对象，4,5不可达，所以是非活跃对象，进行回收。\n\n过程 找到root object集合, 在内存建立两条连表，一条链表维护root object集合，另一条链表哦维护剩下的对象，在标记的过程中，如果在不可达链表中存在被root链表中的独享，直接或间接引用独享，就将其从不可达链表移到root链表中。当完成标记后，不可达链表剩下的对象都是垃圾对象，进行回收。\n\n\n# 分代回收\n\n对象分在不同集合中，每个集合称为一个代, python中分为3代，年轻代(第0代)、中年代(第1代)、老年代(第二代)，对应3各链表，每一代gc频率不同，第0代最高，第1代次之，第二代最低(越年轻的对象越容易死掉，而老的对象通常会存错更久)，新生的对象放入第0代，如果该对象在第0代的一次gc中存活，则移动到第1代，如果第一代对象在第1代gc中存错，则移动到第2代。\n\n什么情况触发gc， 可以设置阈值，也可以手动调用gc.collect()\n\n每次扫描全部对象，费时费力，提高gc的效率。\n\n\n# 垃圾回收触发情况\n\n调用gc.collect(),需要先导入gc模块。\n\n当gc模块的计数器达到阈值的时候。阈值可以设置",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"使用python实现单例模式的三种方式",frontmatter:{title:"使用python实现单例模式的三种方式",date:"2022-12-10T16:47:40.000Z",permalink:"/pages/33b8d0/",tags:["python"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文主要介绍使用python的三种实现单例模式的方式。",feed:{enable:!0},categories:["编程","python","基础"],comment:!0,meta:[{name:"twitter:title",content:"使用python实现单例模式的三种方式"},{name:"twitter:description",content:"本文主要介绍使用python的三种实现单例模式的方式。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/06.%E4%BD%BF%E7%94%A8python%E5%AE%9E%E7%8E%B0%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F.html"},{property:"og:type",content:"article"},{property:"og:title",content:"使用python实现单例模式的三种方式"},{property:"og:description",content:"本文主要介绍使用python的三种实现单例模式的方式。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/06.%E4%BD%BF%E7%94%A8python%E5%AE%9E%E7%8E%B0%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-12-10T16:47:40.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"使用python实现单例模式的三种方式"},{itemprop:"description",content:"本文主要介绍使用python的三种实现单例模式的方式。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/06.%E4%BD%BF%E7%94%A8python%E5%AE%9E%E7%8E%B0%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F.html",relativePath:"04.编程/01.python/01.基础/06.使用python实现单例模式的三种方式.md",key:"v-e35e3500",path:"/pages/33b8d0/",headers:[{level:2,title:"0 . 前言",slug:"_0-前言",normalizedTitle:"0 . 前言",charIndex:2},{level:2,title:"1. 在类中_new_方法中实现",slug:"_1-在类中-new-方法中实现",normalizedTitle:"1. 在类中_new_方法中实现",charIndex:null},{level:2,title:"2. 通过元类实现",slug:"_2-通过元类实现",normalizedTitle:"2. 通过元类实现",charIndex:627},{level:2,title:"3. 通过装饰器实现单例",slug:"_3-通过装饰器实现单例",normalizedTitle:"3. 通过装饰器实现单例",charIndex:2516}],headersStr:"0 . 前言 1. 在类中_new_方法中实现 2. 通过元类实现 3. 通过装饰器实现单例",content:'# 0 . 前言\n\n在整个进程中，有且只有一个对象存在，在任何地点使用都是同一个对象，可以解决多线程资源竞争问题，也常用于配置信息。\n\n本文主要介绍使用python的三种实现单例模式的方式。\n\n\n# 1. 在类中__new__方法中实现\n\n在需要实现单例的 class 中添加__new__方法，在创建该 class 对象时会调用该方法，使用类变量 _instance 来保存当前对象，每次创建之前都会判断是否有该对象，没有则创建，有则直接返回。\n\nfrom typing import Any\n\nclass A:\n    def __new__(cls, *args, **kwargs) -> Any:\n        if not hasattr(cls, "_instance"):\n            cls._instance = super().__new__(cls, *args, **kwargs)\n    return cls._instance\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们创建两个 class A 对象，然后分别打印他们的内存 ID，会发现两者 ID 是一致的，也就是是同一个对象。\n\na1 = A()  \na2 = A()  \nprint(id(a1))  \nprint(id(a2))\n\nOutput: \n2659742107728\n2659742107728\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2. 通过元类实现\n\n上面的方式需要在每一个单例类中都要添加一个__new__方法，有大量的重复代码。接下来我们介绍通过元类来实现单例。\n\n * 第一版\n\n首先创建 class Singleton 来继承 type，该类为我们自定义的元类。然后创建我们需要单例的 class A 和 B，它们都需要通过 metaclass=Singleton 来选择 Singleton 作为它们的元类。\n\n在元类中，创建 __call__ 方法，该方法会在 class A 和 B 创建对象时调用，在该方法中会调用 __new__ 和 __init__ 方法，创建完对象后，再将该对象放在类变量 _instance 中，和 1. 在__new__中实现单例 的方法一样。\n\nfrom typing import Any\n\nclass Singleton(type):\n    def __call__(self, *args: Any, **kwds: Any) -> Any:\n        if not hasattr(self, "_instance"):\n            self._instance = super(Singleton, self).__call__(*args, **kwds)\n\n        return self._instance\n\nclass A(metaclass=Singleton):\n    pass\n\nclass B(metaclass=Singleton):\n    pass\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n我们再通过测试，可以看到 class A 和 B 都实现了单例。\n\na1 = A()\na2 = A()\nprint(id(a1))\nprint(id(a2))\n\nb1 = B()\nb2 = B()\nprint(id(b1))\nprint(id(b2))\n\nOutput:\n>>> 2802632572784\n>>> 2802632572784\n>>> 2802632572400\n>>> 2802632572400\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n但这个单例设计只适用于单线程，在多线程中，如果两个线程都停留 hasattr 下面，可能还是会创建两个对象，达不到单例的效果。\n\n * 第二版\n\n通过加锁解决上面并发的问题。\n\nimport threading\n\nclass Singleton(type):\n    lock = threading.Lock()\n    \n    def __call__(self, *args: Any, **kwds: Any) -> Any:\n        with Singleton.lock:\n            if not hasattr(self, "_instance"):\n                self._instance = super(Singleton, self).__call__(*args, **kwds)\n\n        return self._instance\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n但是其实只有第一次创建对象时，需要通过锁同步获取单例对象，在已有对象时，不需要再用锁了，在这种情况下，每次获取对象都经过锁，会影响性能。\n\n * 最终版\n\n所以再加上一重判断，减少每次锁判断带来的性能消耗。\n\nimport threading\nclass Singleton(type):\n    lock = threading.Lock()\n    \n    def __call__(self, *args: Any, **kwds: Any) -> Any:\n        if not hasattr(self, "_instance"):\n            with Singleton.lock:\n                if not hasattr(self, "_instance"):\n                    self._instance = super(Singleton, self).__call__(*args, **kwds)\n\n        return self._instance\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 3. 通过装饰器实现单例\n\n该方法是通过实现一个装饰器，在需要实现类上添加该装饰器即可完成，使用简单。\n\n通过将所有的单例对象保存在装饰器的 _instance 字典中，以类为 key，对象为 value 进行存储。\n\ndef Singleton(cls):\n    _instance = {}\n    def _singleton(*args, **kargs):\n        if cls not in _instance:\n            _instance[cls] = cls(*args, **kargs)\n        return _instance[cls]\n    return _singleton\n@Singleton\nclass A:\n    pass\n  \n@Singleton\nclass B:\n    pass\n  \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n',normalizedContent:'# 0 . 前言\n\n在整个进程中，有且只有一个对象存在，在任何地点使用都是同一个对象，可以解决多线程资源竞争问题，也常用于配置信息。\n\n本文主要介绍使用python的三种实现单例模式的方式。\n\n\n# 1. 在类中__new__方法中实现\n\n在需要实现单例的 class 中添加__new__方法，在创建该 class 对象时会调用该方法，使用类变量 _instance 来保存当前对象，每次创建之前都会判断是否有该对象，没有则创建，有则直接返回。\n\nfrom typing import any\n\nclass a:\n    def __new__(cls, *args, **kwargs) -> any:\n        if not hasattr(cls, "_instance"):\n            cls._instance = super().__new__(cls, *args, **kwargs)\n    return cls._instance\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们创建两个 class a 对象，然后分别打印他们的内存 id，会发现两者 id 是一致的，也就是是同一个对象。\n\na1 = a()  \na2 = a()  \nprint(id(a1))  \nprint(id(a2))\n\noutput: \n2659742107728\n2659742107728\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2. 通过元类实现\n\n上面的方式需要在每一个单例类中都要添加一个__new__方法，有大量的重复代码。接下来我们介绍通过元类来实现单例。\n\n * 第一版\n\n首先创建 class singleton 来继承 type，该类为我们自定义的元类。然后创建我们需要单例的 class a 和 b，它们都需要通过 metaclass=singleton 来选择 singleton 作为它们的元类。\n\n在元类中，创建 __call__ 方法，该方法会在 class a 和 b 创建对象时调用，在该方法中会调用 __new__ 和 __init__ 方法，创建完对象后，再将该对象放在类变量 _instance 中，和 1. 在__new__中实现单例 的方法一样。\n\nfrom typing import any\n\nclass singleton(type):\n    def __call__(self, *args: any, **kwds: any) -> any:\n        if not hasattr(self, "_instance"):\n            self._instance = super(singleton, self).__call__(*args, **kwds)\n\n        return self._instance\n\nclass a(metaclass=singleton):\n    pass\n\nclass b(metaclass=singleton):\n    pass\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n我们再通过测试，可以看到 class a 和 b 都实现了单例。\n\na1 = a()\na2 = a()\nprint(id(a1))\nprint(id(a2))\n\nb1 = b()\nb2 = b()\nprint(id(b1))\nprint(id(b2))\n\noutput:\n>>> 2802632572784\n>>> 2802632572784\n>>> 2802632572400\n>>> 2802632572400\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n但这个单例设计只适用于单线程，在多线程中，如果两个线程都停留 hasattr 下面，可能还是会创建两个对象，达不到单例的效果。\n\n * 第二版\n\n通过加锁解决上面并发的问题。\n\nimport threading\n\nclass singleton(type):\n    lock = threading.lock()\n    \n    def __call__(self, *args: any, **kwds: any) -> any:\n        with singleton.lock:\n            if not hasattr(self, "_instance"):\n                self._instance = super(singleton, self).__call__(*args, **kwds)\n\n        return self._instance\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n但是其实只有第一次创建对象时，需要通过锁同步获取单例对象，在已有对象时，不需要再用锁了，在这种情况下，每次获取对象都经过锁，会影响性能。\n\n * 最终版\n\n所以再加上一重判断，减少每次锁判断带来的性能消耗。\n\nimport threading\nclass singleton(type):\n    lock = threading.lock()\n    \n    def __call__(self, *args: any, **kwds: any) -> any:\n        if not hasattr(self, "_instance"):\n            with singleton.lock:\n                if not hasattr(self, "_instance"):\n                    self._instance = super(singleton, self).__call__(*args, **kwds)\n\n        return self._instance\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 3. 通过装饰器实现单例\n\n该方法是通过实现一个装饰器，在需要实现类上添加该装饰器即可完成，使用简单。\n\n通过将所有的单例对象保存在装饰器的 _instance 字典中，以类为 key，对象为 value 进行存储。\n\ndef singleton(cls):\n    _instance = {}\n    def _singleton(*args, **kargs):\n        if cls not in _instance:\n            _instance[cls] = cls(*args, **kargs)\n        return _instance[cls]\n    return _singleton\n@singleton\nclass a:\n    pass\n  \n@singleton\nclass b:\n    pass\n  \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"python中import原理",frontmatter:{title:"python中import原理",date:"2023-02-07T09:34:33.000Z",permalink:"/pages/d8fd49/",categories:["编程","python","基础"],tags:["python"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文介绍python正在import module时做了什么，它又是如何加载module的。",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"python中import原理"},{name:"twitter:description",content:"本文介绍python正在import module时做了什么，它又是如何加载module的。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/07.python%E4%B8%ADimport%E5%8E%9F%E7%90%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python中import原理"},{property:"og:description",content:"本文介绍python正在import module时做了什么，它又是如何加载module的。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/07.python%E4%B8%ADimport%E5%8E%9F%E7%90%86.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-02-07T09:34:33.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python中import原理"},{itemprop:"description",content:"本文介绍python正在import module时做了什么，它又是如何加载module的。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/07.python%E4%B8%ADimport%E5%8E%9F%E7%90%86.html",relativePath:"04.编程/01.python/01.基础/07.python中import原理.md",key:"v-a7079bc2",path:"/pages/d8fd49/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 什么是 module？",slug:"_1-什么是-module",normalizedTitle:"1. 什么是 module？",charIndex:84},{level:2,title:"2. 什么是 Package?",slug:"_2-什么是-package",normalizedTitle:"2. 什么是 package?",charIndex:471},{level:2,title:"3. module 缓存",slug:"_3-module-缓存",normalizedTitle:"3. module 缓存",charIndex:1510},{level:2,title:"4. 搜索路径",slug:"_4-搜索路径",normalizedTitle:"4. 搜索路径",charIndex:4108},{level:2,title:"5. 总结",slug:"_5-总结",normalizedTitle:"5. 总结",charIndex:4366},{level:2,title:"6. 加入腾讯云开发者社区",slug:"_6-加入腾讯云开发者社区",normalizedTitle:"6. 加入腾讯云开发者社区",charIndex:4527}],headersStr:"0. 前言 1. 什么是 module？ 2. 什么是 Package? 3. module 缓存 4. 搜索路径 5. 总结 6. 加入腾讯云开发者社区",content:"# 0. 前言\n\n在 python 中引入 Module 是再常见不过了，那么当我们 import 时它做了什么事情呢？它是如何加载 Module 使用的呢？\n\n\n# 1. 什么是 module？\n\n一般，Module 是一个后缀为 .py 的文件，其 module 名称一般是文件名称去除 .py，我们可以通过 __name__ 来查看 module 名称。\n\ndemo.py 是需要被引入的 module，main.py 是入口程序，它们在同一级目录。\n\n# demo.py\nprint(__name__)\n\n# main.py\nimport demo\n\n>>> python main.py\ndemo\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n如果 module 为入口文件，则__name__为 __main__，这也是常见 if __name__ == __main__: 的写法由来。\n\n# demo.py\nprint(__name__)\n\n>>> python demo.py\n__main__\n\n\n1\n2\n3\n4\n5\n\n\n\n# 2. 什么是 Package?\n\n包含了 __init__ 文件的目录为 Package，该目录包含多个 py 文件，都属于 Module。我们在 import package 时，会初始化执行 package 的 __init__.py 文件，然后将其作为一个 Module 对象给放在当前的全局变量中。\n\n├───demo\n│   │   __init__.py\n|   main.py\n\n\n1\n2\n3\n\n\n# __init__.py\nprint(\"demo __init__\")\n\n# main.py\nimport demo\nprint(demo)\nprint(globals()[\"demo\"])\n\n>>> python main.py\noutput: \ndemo __init__.py\n<module 'demo' from 'D:\\\\code\\\\my_demo\\\\demo\\\\__init__.py'>\n<module 'demo' from 'D:\\\\code\\\\my_demo\\\\demo\\\\__init__.py'>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n可以看到 package 的名称 demo 是在 globals()中的，并且其是一个 module 对象，包含了该 __init__.py 文件所在的路径。\n\n如果想要导入 package 下的 module，可以通过 from package import module 的方式将其加载到当前的全局变量中。\n\n├───demo\n│   │   __init__.py\n|   |   a.py\n|   main.py\n\n\n1\n2\n3\n4\n\n\n# __init__.py\n\n# a.py\nclass Demo:\n\tpass\n\n# main.py\nfrom demo import a\nprint(a)\nprint(a.Demo)\nprint(globals()[\"a\"])\n\n>>> python main.py\n<module 'demo.a' from 'D:\\\\code\\\\my_demo\\\\demo\\\\a.py'>\n<class 'demo.a.Demo'>\n<module 'demo.a' from 'D:\\\\code\\\\my_demo\\\\demo\\\\a.py'>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n# 3. module 缓存\n\n * module 缓存初始化\n\n在 python 程序初始化时，会将大批的内置 module 提前加载到内存中，保存在 sys.modules 中，这是一个字典，是以 module 名称或者 package 名称为 key，module 对象为 value 存储。\n\n>>> import sys\n>>> sys.modules\n{... 'os': <module 'os' from '/usr/lib64/python3.6/os.py'> ...}\n>>> sys.modules[\"os\"].cpu_count()\n8\n>>> os.cpu_count()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'os' is not defined\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n * 将 module 添加到当前去全局变量中\n\n既然提前加载了，但是这里为什么找不到 os 呢？这是因为虽然 sys.modules 中已经存在了，但是并没有把 os 加入到当前的全局变量中。\n\n>>> globals()[\"os\"]\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nKeyError: 'os'\n\n\n1\n2\n3\n4\n\n\n所以当我们通过 import os 时，它会通过模块名称在 sys.modules 找到其 module 对象，然后再将其加入到当前的全局变量中，这样就可以使用它了。\n\n>>> import os\n>>> globals()[\"os\"]\n<module 'os' from '/usr/lib64/python3.6/os.py'>\n>>> os.cpu_count()\n8\n>>> id(sys.modules[\"os\"])\n140260375998856\n>>> id(os)\n140260375998856\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以看到从 sys.modules 中拿到的 os 对象的地址和当前导入的 os 的地址是一致的，无论 import 多少次相同的 module，都是从该全局 sys.modules 中获取，拿到的都是同一个对象，也是单例模式实现的一种。\n\n * 导入 module 中的属性\n\n如果我只是引入 module 中的一个属性变量呢？那 sys.modules 中还是会加载该 module，将其属性变量作为全局变量引入。\n\n>>> import sys\n>>> sys.modules[\"json\"]\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nKeyError: 'json'\n>>> from json import load\n>>> sys.modules[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * 模块不需要了，del 销毁\n\ndel 销毁的只是销毁当前全局变量中的变量，并不会影响 sys.modules 中的缓存。为什么不销毁 sys.modules 中的呢？是因为该销毁的 module 可能还会在其他的文件中引用。\n\n>>> import json\n>>> import sys\n>>> sys.modules[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n>>> globals()[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n>>> del json\n>>> sys.modules[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n>>> globals()[\"json\"]\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nKeyError: 'json'\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n * module 重新加载\n\n因为每次 import 都是从 sys.modules 的缓存中获取，那么如果 module 文件变动，则无法拿到最新的 module，这个时候需要通过手动调用 importlib.reload 来重新加载，从本地文件中重新加载 module 对象到 sys.modules 中。\n\n在当前目录下创建 demo.py 文件，内容为空\n\n# demo.py\n\n>>> import demo\n>>> demo.Demo\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: module 'demo' has no attribute 'Demo'\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n这个时候在 demo.py 中添加：\n\nclass Demo:\n    pass\n\n\n1\n2\n\n\nreload demo 后，可以看到加载到 Demo 了。\n\n>>> reload(demo)\n<module 'demo' from '/root/work/mydemo/demo.py'>\n>>> demo.Demo\n<class 'demo.Demo'>\n\n\n1\n2\n3\n4\n\n\n那如果 import 的 module 或者 package 没有在 sys.modules 中呢，这个时候就要去 sys.path 中去本地搜索了。\n\n\n# 4. 搜索路径\n\nsys.path 是一个列表，其中包含了要去搜索 module 的本地路径。当 sys.modules 中查找不到 module 时，将会从该路径中搜索到 module 文件并将其加载到 sys.modules 中来。\n\nsys.path 的路径的来源有：\n\n * 运行脚本所在的目录\n * PYTHONPATH 环境变量\n * python 安装时的默认设置\n\n当在搜索路径找到该 module 的本地路径后，会将其加载到 sys.modules 中，然后再将其添加到当前的全局变量中。\n\n\n# 5. 总结\n\nimport 的加载过程：\n\n 1. 先从 sys.modules 中查看是否有导入的模块，有，则获取该模块，并加入到当前的全局变量中。\n 2. 如果 sys.modules 中没有需要导入的模块，则按照 sys.path 中的目录路径进行搜索找到对应的模块文件再加载到 module 对象中返回。\n\n\n# 6. 加入腾讯云开发者社区\n\n我的博客即将同步至腾讯云开发者社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=3u3wcswfaeiok",normalizedContent:"# 0. 前言\n\n在 python 中引入 module 是再常见不过了，那么当我们 import 时它做了什么事情呢？它是如何加载 module 使用的呢？\n\n\n# 1. 什么是 module？\n\n一般，module 是一个后缀为 .py 的文件，其 module 名称一般是文件名称去除 .py，我们可以通过 __name__ 来查看 module 名称。\n\ndemo.py 是需要被引入的 module，main.py 是入口程序，它们在同一级目录。\n\n# demo.py\nprint(__name__)\n\n# main.py\nimport demo\n\n>>> python main.py\ndemo\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n如果 module 为入口文件，则__name__为 __main__，这也是常见 if __name__ == __main__: 的写法由来。\n\n# demo.py\nprint(__name__)\n\n>>> python demo.py\n__main__\n\n\n1\n2\n3\n4\n5\n\n\n\n# 2. 什么是 package?\n\n包含了 __init__ 文件的目录为 package，该目录包含多个 py 文件，都属于 module。我们在 import package 时，会初始化执行 package 的 __init__.py 文件，然后将其作为一个 module 对象给放在当前的全局变量中。\n\n├───demo\n│   │   __init__.py\n|   main.py\n\n\n1\n2\n3\n\n\n# __init__.py\nprint(\"demo __init__\")\n\n# main.py\nimport demo\nprint(demo)\nprint(globals()[\"demo\"])\n\n>>> python main.py\noutput: \ndemo __init__.py\n<module 'demo' from 'd:\\\\code\\\\my_demo\\\\demo\\\\__init__.py'>\n<module 'demo' from 'd:\\\\code\\\\my_demo\\\\demo\\\\__init__.py'>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n可以看到 package 的名称 demo 是在 globals()中的，并且其是一个 module 对象，包含了该 __init__.py 文件所在的路径。\n\n如果想要导入 package 下的 module，可以通过 from package import module 的方式将其加载到当前的全局变量中。\n\n├───demo\n│   │   __init__.py\n|   |   a.py\n|   main.py\n\n\n1\n2\n3\n4\n\n\n# __init__.py\n\n# a.py\nclass demo:\n\tpass\n\n# main.py\nfrom demo import a\nprint(a)\nprint(a.demo)\nprint(globals()[\"a\"])\n\n>>> python main.py\n<module 'demo.a' from 'd:\\\\code\\\\my_demo\\\\demo\\\\a.py'>\n<class 'demo.a.demo'>\n<module 'demo.a' from 'd:\\\\code\\\\my_demo\\\\demo\\\\a.py'>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n# 3. module 缓存\n\n * module 缓存初始化\n\n在 python 程序初始化时，会将大批的内置 module 提前加载到内存中，保存在 sys.modules 中，这是一个字典，是以 module 名称或者 package 名称为 key，module 对象为 value 存储。\n\n>>> import sys\n>>> sys.modules\n{... 'os': <module 'os' from '/usr/lib64/python3.6/os.py'> ...}\n>>> sys.modules[\"os\"].cpu_count()\n8\n>>> os.cpu_count()\ntraceback (most recent call last):\n  file \"<stdin>\", line 1, in <module>\nnameerror: name 'os' is not defined\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n * 将 module 添加到当前去全局变量中\n\n既然提前加载了，但是这里为什么找不到 os 呢？这是因为虽然 sys.modules 中已经存在了，但是并没有把 os 加入到当前的全局变量中。\n\n>>> globals()[\"os\"]\ntraceback (most recent call last):\n  file \"<stdin>\", line 1, in <module>\nkeyerror: 'os'\n\n\n1\n2\n3\n4\n\n\n所以当我们通过 import os 时，它会通过模块名称在 sys.modules 找到其 module 对象，然后再将其加入到当前的全局变量中，这样就可以使用它了。\n\n>>> import os\n>>> globals()[\"os\"]\n<module 'os' from '/usr/lib64/python3.6/os.py'>\n>>> os.cpu_count()\n8\n>>> id(sys.modules[\"os\"])\n140260375998856\n>>> id(os)\n140260375998856\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以看到从 sys.modules 中拿到的 os 对象的地址和当前导入的 os 的地址是一致的，无论 import 多少次相同的 module，都是从该全局 sys.modules 中获取，拿到的都是同一个对象，也是单例模式实现的一种。\n\n * 导入 module 中的属性\n\n如果我只是引入 module 中的一个属性变量呢？那 sys.modules 中还是会加载该 module，将其属性变量作为全局变量引入。\n\n>>> import sys\n>>> sys.modules[\"json\"]\ntraceback (most recent call last):\n  file \"<stdin>\", line 1, in <module>\nkeyerror: 'json'\n>>> from json import load\n>>> sys.modules[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * 模块不需要了，del 销毁\n\ndel 销毁的只是销毁当前全局变量中的变量，并不会影响 sys.modules 中的缓存。为什么不销毁 sys.modules 中的呢？是因为该销毁的 module 可能还会在其他的文件中引用。\n\n>>> import json\n>>> import sys\n>>> sys.modules[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n>>> globals()[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n>>> del json\n>>> sys.modules[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n>>> globals()[\"json\"]\ntraceback (most recent call last):\n  file \"<stdin>\", line 1, in <module>\nkeyerror: 'json'\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n * module 重新加载\n\n因为每次 import 都是从 sys.modules 的缓存中获取，那么如果 module 文件变动，则无法拿到最新的 module，这个时候需要通过手动调用 importlib.reload 来重新加载，从本地文件中重新加载 module 对象到 sys.modules 中。\n\n在当前目录下创建 demo.py 文件，内容为空\n\n# demo.py\n\n>>> import demo\n>>> demo.demo\ntraceback (most recent call last):\n  file \"<stdin>\", line 1, in <module>\nattributeerror: module 'demo' has no attribute 'demo'\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n这个时候在 demo.py 中添加：\n\nclass demo:\n    pass\n\n\n1\n2\n\n\nreload demo 后，可以看到加载到 demo 了。\n\n>>> reload(demo)\n<module 'demo' from '/root/work/mydemo/demo.py'>\n>>> demo.demo\n<class 'demo.demo'>\n\n\n1\n2\n3\n4\n\n\n那如果 import 的 module 或者 package 没有在 sys.modules 中呢，这个时候就要去 sys.path 中去本地搜索了。\n\n\n# 4. 搜索路径\n\nsys.path 是一个列表，其中包含了要去搜索 module 的本地路径。当 sys.modules 中查找不到 module 时，将会从该路径中搜索到 module 文件并将其加载到 sys.modules 中来。\n\nsys.path 的路径的来源有：\n\n * 运行脚本所在的目录\n * pythonpath 环境变量\n * python 安装时的默认设置\n\n当在搜索路径找到该 module 的本地路径后，会将其加载到 sys.modules 中，然后再将其添加到当前的全局变量中。\n\n\n# 5. 总结\n\nimport 的加载过程：\n\n 1. 先从 sys.modules 中查看是否有导入的模块，有，则获取该模块，并加入到当前的全局变量中。\n 2. 如果 sys.modules 中没有需要导入的模块，则按照 sys.path 中的目录路径进行搜索找到对应的模块文件再加载到 module 对象中返回。\n\n\n# 6. 加入腾讯云开发者社区\n\n我的博客即将同步至腾讯云开发者社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=3u3wcswfaeiok",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"python装饰器的使用方法",frontmatter:{title:"python装饰器的使用方法",date:"2022-10-23T17:18:08.000Z",permalink:"/pages/7434f1/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍python中的装饰器的几种常见的使用方法并理解它们的实现原理。",feed:{enable:!0},tags:["python"],categories:["编程","python","基础"],comment:!0,meta:[{name:"twitter:title",content:"python装饰器的使用方法"},{name:"twitter:description",content:"介绍python中的装饰器的几种常见的使用方法并理解它们的实现原理。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/05.python%E8%A3%85%E9%A5%B0%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python装饰器的使用方法"},{property:"og:description",content:"介绍python中的装饰器的几种常见的使用方法并理解它们的实现原理。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/05.python%E8%A3%85%E9%A5%B0%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-10-23T17:18:08.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python装饰器的使用方法"},{itemprop:"description",content:"介绍python中的装饰器的几种常见的使用方法并理解它们的实现原理。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/05.python%E8%A3%85%E9%A5%B0%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95.html",relativePath:"04.编程/01.python/01.基础/05.python装饰器的使用方法.md",key:"v-da2a3b40",path:"/pages/7434f1/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 使用",slug:"_1-使用",normalizedTitle:"1. 使用",charIndex:87},{level:3,title:"1.1 在函数上添加装饰器",slug:"_1-1-在函数上添加装饰器",normalizedTitle:"1.1 在函数上添加装饰器",charIndex:97},{level:3,title:"1.2 装饰器的运行过程",slug:"_1-2-装饰器的运行过程",normalizedTitle:"1.2 装饰器的运行过程",charIndex:547},{level:3,title:"1.3 保存原函数信息",slug:"_1-3-保存原函数信息",normalizedTitle:"1.3 保存原函数信息",charIndex:1077},{level:3,title:"1.4 调用原函数",slug:"_1-4-调用原函数",normalizedTitle:"1.4 调用原函数",charIndex:2311},{level:3,title:"1.5 带参数的装饰器",slug:"_1-5-带参数的装饰器",normalizedTitle:"1.5 带参数的装饰器",charIndex:2824},{level:3,title:"1.6 带可选参数的装饰器",slug:"_1-6-带可选参数的装饰器",normalizedTitle:"1.6 带可选参数的装饰器",charIndex:3581},{level:3,title:"1.7 在类上添加装饰器",slug:"_1-7-在类上添加装饰器",normalizedTitle:"1.7 在类上添加装饰器",charIndex:4553},{level:3,title:"1.8 类装饰器",slug:"_1-8-类装饰器",normalizedTitle:"1.8 类装饰器",charIndex:5209},{level:3,title:"1.9 暴露被装饰的元信息",slug:"_1-9-暴露被装饰的元信息",normalizedTitle:"1.9 暴露被装饰的元信息",charIndex:5869},{level:3,title:"1.10 带参数的类装饰器",slug:"_1-10-带参数的类装饰器",normalizedTitle:"1.10 带参数的类装饰器",charIndex:6595},{level:2,title:"2. 总结",slug:"_2-总结",normalizedTitle:"2. 总结",charIndex:7334},{level:2,title:"3. 参考资料",slug:"_3-参考资料",normalizedTitle:"3. 参考资料",charIndex:7395}],headersStr:"0. 前言 1. 使用 1.1 在函数上添加装饰器 1.2 装饰器的运行过程 1.3 保存原函数信息 1.4 调用原函数 1.5 带参数的装饰器 1.6 带可选参数的装饰器 1.7 在类上添加装饰器 1.8 类装饰器 1.9 暴露被装饰的元信息 1.10 带参数的类装饰器 2. 总结 3. 参考资料",content:'# 0. 前言\n\n装饰器在 python 中使用的频率非常高，它可以在不改动原有函数的基础上对其进行增强功能。\n\n下面主要是介绍装饰器的各种用法，并理解其运行过程。\n\n\n# 1. 使用\n\n\n# 1.1 在函数上添加装饰器\n\ndecro 是一个装饰器函数，其实现是将内部的函数 wrapper 作为返回值返回出去。\n\n在函数 test 上添加 @decro 进行使用，可以将本函数作为一个参数传入到 decro 函数中，然后，然后得到的是装饰器函数内部返回的函数 wrapper, 我们在调用 test 方法时，其实调用的是装饰器返回的 wrapper 函数，该函数中会调用被装饰的函数 test\n\ndef decro(func):  \n    def wrapper(*args, **kwargs):  \n        print("wrapper")  \n        return func()  \n  \n    return wrapper\n\n\n@decro  \ndef test():  \n    print("test")  \n\n\ntest()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n输出：\n\nwrapper\ntest\n\n\n1\n2\n\n\n\n# 1.2 装饰器的运行过程\n\n装饰器时在被装饰的函数定义之后立即运行的，当执行到@decro 装饰 test 函数时，会马上执行函数 decro，然后将 wrapper 给返回出去。\n\ndef decro(func):  \n    print("decro")  \n  \n    def wrapper(*args, **kwargs):  \n        print("wrapper")  \n        return func()  \n  \n    return wrapper  \n  \nprint("start")  \n  \n@decro  \ndef test():  \n    print("test")  \n  \nprint("end")\n\ntest()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n输出如下，可以看到先执行了 start，然后马上执行了装饰器 decro，然后再执行 end，当我们调用 test 函数时，执行了装饰器内部函数 wrapper，然后再调用被装饰的函数 test\n\nstart\ndecro\nend\nwrapper\ntest\n\n\n1\n2\n3\n4\n5\n\n\n\n# 1.3 保存原函数信息\n\n在使用装饰器时，调用的原方法已经被替换为装饰器返回的新方法了，所以方法的元信息已经被替换了, 通过 name、doc 得到的元数据已经被替换成了新方法的。\n\ndef decro(func):  \n    def wrapper(*args, **kwargs):  \n        """ wrapper doc """  \n        print("wrapper")  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@decro  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \nprint("test\'s __name__ = {}".format(test.__name__))  \nprint("test\'s __doc__ = {}".format(test.__doc__))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n输出如下，会发现函数 test 的函数信息 __name__ 和 __doc__ 变成 wrapper 的信息。\n\ntest\'s __name__ = wrapper\ntest\'s __doc__ =  wrapper doc\n\n\n1\n2\n\n\n但是我们不想要改变原方法的元信息，这个时候需要使用 functools.wraps 解决。\n\nfrom functools import wraps  \n  \ndef decro(func):  \n  \n    @wraps(func)  \n    def wrapper(*args, **kwargs):  \n        """ wrapper doc """  \n        print("wrapper")  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@decro  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \nprint("test\'s __name__ = {}".format(test.__name__))  \nprint("test\'s __doc__ = {}".format(test.__doc__))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n输出如下，会发现，test 函数信息没有被替换掉，保证了函数的原汁原味。\n\ntest\'s __name__ = test\ntest\'s __doc__ =  test doc \n\n\n1\n2\n\n\n\n# 1.4 调用原函数\n\n装饰器可以增强函数的功能，但是在某些场景我就想要使用原函数，而不想使用装饰之后的函数，可以通过调用__wrapped__来调用原函数。\n\nfrom functools import wraps  \n  \n\ndef decro(func):  \n    @wraps(func)  \n    def wrapper(*args, **kwargs):  \n        """ wrapper doc """  \n        print("wrapper")  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@decro  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \ntest.__wrapped__()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n输出如下，输出 text，而没有输出 wrapper，说明调用的是原函数。\n\ntest\n\n\n1\n\n\n\n# 1.5 带参数的装饰器\n\n还有这么一种场景，我们想要在装饰器中添加参数。\n\n想要通过参数决定日志级别，这里的 logged 接收 level 参数并将它作用在内部函数中，返回值是将 decro 函数返回，然后再将函数 test 作为参数从传入到 decro 函数中，再将 wrapper 返回，最终 test 还是替换成了 wrapper，在该方法中使用了传入的 ERROR 的日志级别。\n\nfrom functools import wraps  \nimport logging  \n  \n  \ndef logged(level):  \n    def decro(func):  \n        @wraps(func)  \n        def wrapper(*args, **kwargs):  \n            """ wrapper doc """  \n            logging.log(level, func.__name__)  \n            return func(*args, **kwargs)  \n  \n        return wrapper  \n  \n    return decro  \n  \n  \n@logged(level=logging.ERROR)  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \ntest()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n输出了 ERROR 日志级别的日志：\n\nERROR:root:test\ntest\n\n\n1\n2\n\n\n\n# 1.6 带可选参数的装饰器\n\n上面实现的装饰器是必须要带上参数的，但是有的时候，我们不需要带参数，那么该如何实现？\n\n装饰器的 func 默认值为 None，当传入 level 参数时，则返回偏函数 partial ，该函数会基于 logged 创建一个仅包含 level 的新的函数，这个新的函数作为新的装饰器来装饰 add 函数。\n\n当没有传入 level 参数时，就和普通的装饰器一样使用。\n\nfrom functools import wraps, partial  \nimport logging  \n  \n  \ndef logged(func=None, level=logging.INFO):  \n    if func is None:  \n        return partial(logged, level=level)  \n  \n    @wraps(func)  \n    def wrapper(*args, **kwargs):  \n        logging.log(level, func.__name__)  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@logged(level=logging.ERROR)  \ndef add(a, b):  \n    print("add")  \n    return a + b  \n  \n  \n@logged  \ndef add2(a, b):  \n    print("add2")  \n    return a + b  \n  \n  \nprint(add(1, 2))  \nprint("-" * 10)  \nprint(add2(1, 2))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n输出如下，add 函数的装饰器传入了日志级别为 ERROR 的参数，输出了 ERROR 的日志，而add2 没有。\n\nERROR:root:add\nadd\n3\n----------\nadd2\n3\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 1.7 在类上添加装饰器\n\n上面都是使用装饰器来增强函数的功能，但它还可以增强类的功能，对类进行装饰。\n\n下面的例子中，decro 将被装饰的类 Demo 传入进来，主要是将其类中 __getattribute__ 方法替换成了 new_getattribute 方法。\n\ndef decro(cls):  \n    orig_getattribute = cls.__getattribute__  \n  \n    def new_getattribute(self, name):  \n        print("get name = {}".format(name))  \n        return orig_getattribute(self, name)  \n  \n    cls.__getattribute__ = new_getattribute  \n    return cls  \n  \n  \n@decro  \nclass Demo:  \n  \n    def __init__(self, num):  \n        self.num = num  \n  \n  \nd = Demo(1)  \nprint(d.num)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n输出如下，获取 num 的值时，调用了装饰器替换的 new_getattribute 方法。\n\nget name = num\n1\n\n\n1\n2\n\n\n\n# 1.8 类装饰器\n\n之前都是使用函数方法来定义装饰器，但其实也可以通过类来定义装饰器。\n\n在类装饰器中定义__init__方法，被它装饰的函数会被传入到 func 参数中，这个时候该类装饰器已经被实例化了，也就是将该实例对象替换了被装饰的函数 say。\n\n当我们调用 say 函数时，其实调用的是类装饰器的对象，这个时候会调用__call__方法，该方法中可以对原函数进行增强，并进行调用原方法。\n\nclass logger(object):  \n    def __init__(self, func):  \n        self.func = func  \n  \n    def __call__(self, *args, **kwargs):  \n        print("the function {func}() is running...".format(func=self.func.__name__))  \n        return self.func(*args, **kwargs)  \n  \n  \n@logger  \ndef say(something):  \n    print("say {}!".format(something))  \n  \n  \nsay("hello")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n输出如下：\n\nthe function say() is running...\nsay hello!\n\n\n1\n2\n\n\n\n# 1.9 暴露被装饰的元信息\n\n这个时候会出现和函数装饰器一样的问题，那就是被装饰的函数的元信息已经被替换掉了，这个时候我们还是想保留原有的原信息。\n\n还是使用 wraps 函数来解决该问题。\n\nfrom functools import wraps  \n  \n  \nclass logger(object):  \n    """ logger doc """  \n  \n    def __init__(self, func):  \n        wraps(func)(self)  \n  \n    def __call__(self, *args, **kwargs):  \n        print("the function {func}() is running...".format(func=self.__wrapped__.__name__))  \n        return self.__wrapped__(*args, **kwargs)  \n  \n  \n@logger  \ndef say(something):  \n    """ say doc """  \n    print("say {}!".format(something))  \n  \n  \nsay("hello2")  \nprint(say.__doc__)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n输出的是 say 方法的 doc：\n\nthe function say() is running...\nsay hello2!\n say doc \n\n\n1\n2\n3\n\n\n\n# 1.10 带参数的类装饰器\n\n那么带参数的类装饰器该如何实现呢？\n\n在 __init__ 方法中接收装饰器传入的参数，保存起来，然后再通过 __call__ 函数将内部函数 wrapper 给返回出去，这个时候被装饰的函数已经被 wrapper 给替换了。\n\nclass logger(object):  \n  \n    def __init__(self, level="INFO"):  \n        self.level = level  \n  \n    def __call__(self, func):  \n        def wrapper(*args, **kwargs): \n\t        print("[{level}]: the function {func}() is running...".format(level=self.level, func=func.__name__)) \n            func(*args, **kwargs)  \n  \n        return wrapper  \n  \n  \n@logger(level="ERROR")  \ndef say(something):  \n    print("say {}!".format(something))  \n  \n  \nsay("hello2")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n输出如下，调用 say 函数也就是调用 wrapper 函数：\n\n[ERROR]: the function say() is running...\nsay hello2!\n\n\n1\n2\n\n\n\n# 2. 总结\n\n装饰器的用法很多，封装成库，给其他人使用也非常的方便，我们需要理解它的运行过程，才能更好的使用它。\n\n\n# 3. 参考资料\n\n * https://python3-cookbook.readthedocs.io/zh_CN/latest/c09/p01_put_wrapper_around_function.html',normalizedContent:'# 0. 前言\n\n装饰器在 python 中使用的频率非常高，它可以在不改动原有函数的基础上对其进行增强功能。\n\n下面主要是介绍装饰器的各种用法，并理解其运行过程。\n\n\n# 1. 使用\n\n\n# 1.1 在函数上添加装饰器\n\ndecro 是一个装饰器函数，其实现是将内部的函数 wrapper 作为返回值返回出去。\n\n在函数 test 上添加 @decro 进行使用，可以将本函数作为一个参数传入到 decro 函数中，然后，然后得到的是装饰器函数内部返回的函数 wrapper, 我们在调用 test 方法时，其实调用的是装饰器返回的 wrapper 函数，该函数中会调用被装饰的函数 test\n\ndef decro(func):  \n    def wrapper(*args, **kwargs):  \n        print("wrapper")  \n        return func()  \n  \n    return wrapper\n\n\n@decro  \ndef test():  \n    print("test")  \n\n\ntest()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n输出：\n\nwrapper\ntest\n\n\n1\n2\n\n\n\n# 1.2 装饰器的运行过程\n\n装饰器时在被装饰的函数定义之后立即运行的，当执行到@decro 装饰 test 函数时，会马上执行函数 decro，然后将 wrapper 给返回出去。\n\ndef decro(func):  \n    print("decro")  \n  \n    def wrapper(*args, **kwargs):  \n        print("wrapper")  \n        return func()  \n  \n    return wrapper  \n  \nprint("start")  \n  \n@decro  \ndef test():  \n    print("test")  \n  \nprint("end")\n\ntest()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n输出如下，可以看到先执行了 start，然后马上执行了装饰器 decro，然后再执行 end，当我们调用 test 函数时，执行了装饰器内部函数 wrapper，然后再调用被装饰的函数 test\n\nstart\ndecro\nend\nwrapper\ntest\n\n\n1\n2\n3\n4\n5\n\n\n\n# 1.3 保存原函数信息\n\n在使用装饰器时，调用的原方法已经被替换为装饰器返回的新方法了，所以方法的元信息已经被替换了, 通过 name、doc 得到的元数据已经被替换成了新方法的。\n\ndef decro(func):  \n    def wrapper(*args, **kwargs):  \n        """ wrapper doc """  \n        print("wrapper")  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@decro  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \nprint("test\'s __name__ = {}".format(test.__name__))  \nprint("test\'s __doc__ = {}".format(test.__doc__))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n输出如下，会发现函数 test 的函数信息 __name__ 和 __doc__ 变成 wrapper 的信息。\n\ntest\'s __name__ = wrapper\ntest\'s __doc__ =  wrapper doc\n\n\n1\n2\n\n\n但是我们不想要改变原方法的元信息，这个时候需要使用 functools.wraps 解决。\n\nfrom functools import wraps  \n  \ndef decro(func):  \n  \n    @wraps(func)  \n    def wrapper(*args, **kwargs):  \n        """ wrapper doc """  \n        print("wrapper")  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@decro  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \nprint("test\'s __name__ = {}".format(test.__name__))  \nprint("test\'s __doc__ = {}".format(test.__doc__))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n输出如下，会发现，test 函数信息没有被替换掉，保证了函数的原汁原味。\n\ntest\'s __name__ = test\ntest\'s __doc__ =  test doc \n\n\n1\n2\n\n\n\n# 1.4 调用原函数\n\n装饰器可以增强函数的功能，但是在某些场景我就想要使用原函数，而不想使用装饰之后的函数，可以通过调用__wrapped__来调用原函数。\n\nfrom functools import wraps  \n  \n\ndef decro(func):  \n    @wraps(func)  \n    def wrapper(*args, **kwargs):  \n        """ wrapper doc """  \n        print("wrapper")  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@decro  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \ntest.__wrapped__()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n输出如下，输出 text，而没有输出 wrapper，说明调用的是原函数。\n\ntest\n\n\n1\n\n\n\n# 1.5 带参数的装饰器\n\n还有这么一种场景，我们想要在装饰器中添加参数。\n\n想要通过参数决定日志级别，这里的 logged 接收 level 参数并将它作用在内部函数中，返回值是将 decro 函数返回，然后再将函数 test 作为参数从传入到 decro 函数中，再将 wrapper 返回，最终 test 还是替换成了 wrapper，在该方法中使用了传入的 error 的日志级别。\n\nfrom functools import wraps  \nimport logging  \n  \n  \ndef logged(level):  \n    def decro(func):  \n        @wraps(func)  \n        def wrapper(*args, **kwargs):  \n            """ wrapper doc """  \n            logging.log(level, func.__name__)  \n            return func(*args, **kwargs)  \n  \n        return wrapper  \n  \n    return decro  \n  \n  \n@logged(level=logging.error)  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \ntest()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n输出了 error 日志级别的日志：\n\nerror:root:test\ntest\n\n\n1\n2\n\n\n\n# 1.6 带可选参数的装饰器\n\n上面实现的装饰器是必须要带上参数的，但是有的时候，我们不需要带参数，那么该如何实现？\n\n装饰器的 func 默认值为 none，当传入 level 参数时，则返回偏函数 partial ，该函数会基于 logged 创建一个仅包含 level 的新的函数，这个新的函数作为新的装饰器来装饰 add 函数。\n\n当没有传入 level 参数时，就和普通的装饰器一样使用。\n\nfrom functools import wraps, partial  \nimport logging  \n  \n  \ndef logged(func=none, level=logging.info):  \n    if func is none:  \n        return partial(logged, level=level)  \n  \n    @wraps(func)  \n    def wrapper(*args, **kwargs):  \n        logging.log(level, func.__name__)  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@logged(level=logging.error)  \ndef add(a, b):  \n    print("add")  \n    return a + b  \n  \n  \n@logged  \ndef add2(a, b):  \n    print("add2")  \n    return a + b  \n  \n  \nprint(add(1, 2))  \nprint("-" * 10)  \nprint(add2(1, 2))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n输出如下，add 函数的装饰器传入了日志级别为 error 的参数，输出了 error 的日志，而add2 没有。\n\nerror:root:add\nadd\n3\n----------\nadd2\n3\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 1.7 在类上添加装饰器\n\n上面都是使用装饰器来增强函数的功能，但它还可以增强类的功能，对类进行装饰。\n\n下面的例子中，decro 将被装饰的类 demo 传入进来，主要是将其类中 __getattribute__ 方法替换成了 new_getattribute 方法。\n\ndef decro(cls):  \n    orig_getattribute = cls.__getattribute__  \n  \n    def new_getattribute(self, name):  \n        print("get name = {}".format(name))  \n        return orig_getattribute(self, name)  \n  \n    cls.__getattribute__ = new_getattribute  \n    return cls  \n  \n  \n@decro  \nclass demo:  \n  \n    def __init__(self, num):  \n        self.num = num  \n  \n  \nd = demo(1)  \nprint(d.num)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n输出如下，获取 num 的值时，调用了装饰器替换的 new_getattribute 方法。\n\nget name = num\n1\n\n\n1\n2\n\n\n\n# 1.8 类装饰器\n\n之前都是使用函数方法来定义装饰器，但其实也可以通过类来定义装饰器。\n\n在类装饰器中定义__init__方法，被它装饰的函数会被传入到 func 参数中，这个时候该类装饰器已经被实例化了，也就是将该实例对象替换了被装饰的函数 say。\n\n当我们调用 say 函数时，其实调用的是类装饰器的对象，这个时候会调用__call__方法，该方法中可以对原函数进行增强，并进行调用原方法。\n\nclass logger(object):  \n    def __init__(self, func):  \n        self.func = func  \n  \n    def __call__(self, *args, **kwargs):  \n        print("the function {func}() is running...".format(func=self.func.__name__))  \n        return self.func(*args, **kwargs)  \n  \n  \n@logger  \ndef say(something):  \n    print("say {}!".format(something))  \n  \n  \nsay("hello")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n输出如下：\n\nthe function say() is running...\nsay hello!\n\n\n1\n2\n\n\n\n# 1.9 暴露被装饰的元信息\n\n这个时候会出现和函数装饰器一样的问题，那就是被装饰的函数的元信息已经被替换掉了，这个时候我们还是想保留原有的原信息。\n\n还是使用 wraps 函数来解决该问题。\n\nfrom functools import wraps  \n  \n  \nclass logger(object):  \n    """ logger doc """  \n  \n    def __init__(self, func):  \n        wraps(func)(self)  \n  \n    def __call__(self, *args, **kwargs):  \n        print("the function {func}() is running...".format(func=self.__wrapped__.__name__))  \n        return self.__wrapped__(*args, **kwargs)  \n  \n  \n@logger  \ndef say(something):  \n    """ say doc """  \n    print("say {}!".format(something))  \n  \n  \nsay("hello2")  \nprint(say.__doc__)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n输出的是 say 方法的 doc：\n\nthe function say() is running...\nsay hello2!\n say doc \n\n\n1\n2\n3\n\n\n\n# 1.10 带参数的类装饰器\n\n那么带参数的类装饰器该如何实现呢？\n\n在 __init__ 方法中接收装饰器传入的参数，保存起来，然后再通过 __call__ 函数将内部函数 wrapper 给返回出去，这个时候被装饰的函数已经被 wrapper 给替换了。\n\nclass logger(object):  \n  \n    def __init__(self, level="info"):  \n        self.level = level  \n  \n    def __call__(self, func):  \n        def wrapper(*args, **kwargs): \n\t        print("[{level}]: the function {func}() is running...".format(level=self.level, func=func.__name__)) \n            func(*args, **kwargs)  \n  \n        return wrapper  \n  \n  \n@logger(level="error")  \ndef say(something):  \n    print("say {}!".format(something))  \n  \n  \nsay("hello2")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n输出如下，调用 say 函数也就是调用 wrapper 函数：\n\n[error]: the function say() is running...\nsay hello2!\n\n\n1\n2\n\n\n\n# 2. 总结\n\n装饰器的用法很多，封装成库，给其他人使用也非常的方便，我们需要理解它的运行过程，才能更好的使用它。\n\n\n# 3. 参考资料\n\n * https://python3-cookbook.readthedocs.io/zh_cn/latest/c09/p01_put_wrapper_around_function.html',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"使用ddt实现unittest的参数化测试",frontmatter:{title:"使用ddt实现unittest的参数化测试",date:"2022-10-12T14:48:10.000Z",permalink:"/pages/8d9ab9/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文介绍如何使用ddt库来完成unitest的参数化设置。",feed:{enable:!0},tags:["python"],categories:["编程","python","第三方库"],comment:!0,meta:[{name:"twitter:title",content:"使用ddt实现unittest的参数化测试"},{name:"twitter:description",content:"本文介绍如何使用ddt库来完成unitest的参数化设置。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/01.%E4%BD%BF%E7%94%A8ddt%E5%AE%9E%E7%8E%B0unittest%E7%9A%84%E5%8F%82%E6%95%B0%E5%8C%96%E6%B5%8B%E8%AF%95.html"},{property:"og:type",content:"article"},{property:"og:title",content:"使用ddt实现unittest的参数化测试"},{property:"og:description",content:"本文介绍如何使用ddt库来完成unitest的参数化设置。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/01.%E4%BD%BF%E7%94%A8ddt%E5%AE%9E%E7%8E%B0unittest%E7%9A%84%E5%8F%82%E6%95%B0%E5%8C%96%E6%B5%8B%E8%AF%95.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-10-12T14:48:10.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"使用ddt实现unittest的参数化测试"},{itemprop:"description",content:"本文介绍如何使用ddt库来完成unitest的参数化设置。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/01.%E4%BD%BF%E7%94%A8ddt%E5%AE%9E%E7%8E%B0unittest%E7%9A%84%E5%8F%82%E6%95%B0%E5%8C%96%E6%B5%8B%E8%AF%95.html",relativePath:"04.编程/01.python/02.第三方库/01.使用ddt实现unittest的参数化测试.md",key:"v-3644af7a",path:"/pages/8d9ab9/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 为什么需要参数化",slug:"_1-为什么需要参数化",normalizedTitle:"1. 为什么需要参数化",charIndex:67},{level:2,title:"2. 使用ddt实现参数化",slug:"_2-使用ddt实现参数化",normalizedTitle:"2. 使用ddt实现参数化",charIndex:677},{level:3,title:"2.1 基本使用",slug:"_2-1-基本使用",normalizedTitle:"2.1 基本使用",charIndex:733},{level:3,title:"2.2 多个值使用参数化",slug:"_2-2-多个值使用参数化",normalizedTitle:"2.2 多个值使用参数化",charIndex:1735},{level:3,title:"2.3 参数化扁平使用",slug:"_2-3-参数化扁平使用",normalizedTitle:"2.3 参数化扁平使用",charIndex:2586},{level:3,title:"2.4 命名参数",slug:"_2-4-命名参数",normalizedTitle:"2.4 命名参数",charIndex:3419},{level:3,title:"2.5 从json文件中读取参数进行单测",slug:"_2-5-从json文件中读取参数进行单测",normalizedTitle:"2.5 从json文件中读取参数进行单测",charIndex:4254},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:5266}],headersStr:"0. 前言 1. 为什么需要参数化 2. 使用ddt实现参数化 2.1 基本使用 2.2 多个值使用参数化 2.3 参数化扁平使用 2.4 命名参数 2.5 从json文件中读取参数进行单测 3. 总结",content:'# 0. 前言\n\n本文介绍如何使用ddt库来完成unitest的参数化设置。\n\nddt的github地址\n\nddt的官方文档\n\n\n# 1. 为什么需要参数化\n\n我们在写单测中，需要考虑到各种场景，通过输入各种场景的值执行目的的方法，来判断输出是否是我们所期待的值。\n\n如下代码代码所示，针对large_than_two方法进行了三种场景的校验写了三个单测，但其中逻辑代码是一致的，而只需要使用不同的参数值进行输入，导致有许多的重复代码进行复制粘贴。\n\nfrom unittest.case import TestCase\n\n\ndef large_than_two(value) -> bool:\n    return value > 2\n\n\nclass TestDemoCase(TestCase):\n\n    def test_larger_than_two_with_three(self):\n        self.assertTrue(large_than_two(3))\n\n    def test_larger_than_two_with_eight(self):\n        self.assertTrue(large_than_two(8))\n\n    def test_larger_than_two_with_five(self):\n        self.assertFalse(large_than_two(5))\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# 2. 使用ddt实现参数化\n\n首先需要通过pip来安装该库\n\npip install ddt\n\n\n1\n\n\n\n# 2.1 基本使用\n\n我们在TestCase上添加ddt装饰器，然后在单测方法上添加data装饰器，并添加了3种场景的输入参数，如下代码所示：\n\nfrom unittest.case import TestCase\n\nfrom ddt import ddt, data\n\n\ndef large_than_two(value) -> bool:\n    return value > 2\n\n\n@ddt\nclass TestDemoCase(TestCase):\n\n    @data(3, 8, 5)\n    def test_larger_than_two(self, value):\n        self.assertTrue(large_than_two(value))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n执行上面的单测，输入出如下：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::TestDemoCase::test_larger_than_two_with_three_1_3 PASSED   [ 33%]\ntest_demo.py::TestDemoCase::test_larger_than_two_with_three_2_8 PASSED   [ 66%]\ntest_demo.py::TestDemoCase::test_larger_than_two_with_three_3_5 PASSED   [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n会发现，虽然我们写了一个单测用例，但是却执行了3个用例，这是因为ddt会将data的3个参数分别注入到test_larger_than_two方法中value中并执行单测。\n\n在输出的单测信息中，会输出单测方法+第多少个单测+参数值来表示当前用例的执行。\n\n通过这种方式可以减少我们的重复代码。\n\n\n# 2.2 多个值使用参数化\n\n当我们需要在一个单测用例中注入多个值时，可以在data中传入多个元组进行参数化，但执行单例时，会将元组注入到value中，我们将其解开则能拿到多个值。代码如下图所示：\n\ndef greater(v1, v2) -> bool:\n    return v1 > v2\n\n\n@ddt\nclass TestDemoCase(TestCase):\n\n    @data(\n        (3, 2),\n        (4, 1),\n        (8, 6))\n    def test_greater(self, value):\n        v1, v2 = value\n        self.assertTrue(greater(v1, v2))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n执行之后输出如下所示：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::TestDemoCase::test_greater_1__3__2_ PASSED                 [ 33%]\ntest_demo.py::TestDemoCase::test_greater_2__4__1_ PASSED                 [ 66%]\ntest_demo.py::TestDemoCase::test_greater_3__8__6_ PASSED                 [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2.3 参数化扁平使用\n\n元组中的数据可以由ddt解开后注入到单测方法中的参数中。只需要在单测方法钱添加unpack装饰器即可。代码如下所示：\n\nfrom unittest.case import TestCase\n\nfrom ddt import ddt, data, unpack\n\n@ddt\nclass TestDemoCase(TestCase):\n\n    @unpack\n    @data(\n        (3, 2),\n        (4, 1),\n        (8, 6))\n    def test_greater(self, v1, v2):\n        self.assertTrue(greater(v1, v2))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n执行后结果如下：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::TestDemoCase::test_greater_1__3__2_ PASSED                 [ 33%]\ntest_demo.py::TestDemoCase::test_greater_2__4__1_ PASSED                 [ 66%]\ntest_demo.py::TestDemoCase::test_greater_3__8__6_ PASSED                 [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2.4 命名参数\n\n我们还可以给传入的参数进行命名而不是元组的形式，传入的参数名称与单测方法中参数的变量名对应，则不需要对应顺序传入，可读性更强了。代码如下：\n\n@ddt\nclass TestDemoCase(TestCase):\n\n    @unpack\n    @data(\n        {"first": 3, "second": 2},\n        {"first": 4, "second": 1},\n        {"first": 8, "second": 6}\n    )\n    def test_greater(self, second, first):\n        self.assertTrue(greater(first, second))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n执行后输出：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::TestDemoCase::test_greater_1 PASSED                        [ 33%]\ntest_demo.py::TestDemoCase::test_greater_2 PASSED                        [ 66%]\ntest_demo.py::TestDemoCase::test_greater_3 PASSED                        [100%]\n\n============================== 3 passed in 0.01s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2.5 从json文件中读取参数进行单测\n\n在某些业务中，输入的参数过于复杂，并且场景繁多，如果将参数数据全部放在单测代码中，则会显得繁重，而且代码不易读，ddt提供了从json文件中读取参数来作为单测的输入数据。\n\n创建data.json文件，其中包含了参数数据。\n\n[\n  {\n    "first": 3,\n    "second": 2\n  },\n  {\n    "first": 4,\n    "second": 1\n  },\n  {\n    "first": 8,\n    "second": 6\n  }\n]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后使用file_data作为单测方法的装饰器，并传入上面数据文件的路径。\n\nfrom ddt import ddt, file_data\n\n@ddt\nclass TestDemoCase(TestCase):\n\n    @file_data("data.json")\n    def test_greater(self, second, first):\n        self.assertTrue(greater(first, second))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n执行成功并输出：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::TestDemoCase::test_greater_1 PASSED                        [ 33%]\ntest_demo.py::TestDemoCase::test_greater_2 PASSED                        [ 66%]\ntest_demo.py::TestDemoCase::test_greater_3 PASSED                        [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 3. 总结\n\n本文是介绍ddt的基本并常用的用法，如果想要深入使用可以参考官方文档。\n\n其实ddt有个缺点是不能针对某一个单测方法进行单独的执行，必须要运行整个Unittest class才行，这样在调试的过程中非常不方便。\n\n如果你看到本文其实我比较推荐你使用pytest来替代unittest使用，pytest中也有参数化的使用，并且可以单独的去运行每一个单测。\n\n我是因为在做一个django项目，其中使用的是django test来写单测的，而django test是基于Unittest来实现的，所以只能使用ddt来实现参数化。',normalizedContent:'# 0. 前言\n\n本文介绍如何使用ddt库来完成unitest的参数化设置。\n\nddt的github地址\n\nddt的官方文档\n\n\n# 1. 为什么需要参数化\n\n我们在写单测中，需要考虑到各种场景，通过输入各种场景的值执行目的的方法，来判断输出是否是我们所期待的值。\n\n如下代码代码所示，针对large_than_two方法进行了三种场景的校验写了三个单测，但其中逻辑代码是一致的，而只需要使用不同的参数值进行输入，导致有许多的重复代码进行复制粘贴。\n\nfrom unittest.case import testcase\n\n\ndef large_than_two(value) -> bool:\n    return value > 2\n\n\nclass testdemocase(testcase):\n\n    def test_larger_than_two_with_three(self):\n        self.asserttrue(large_than_two(3))\n\n    def test_larger_than_two_with_eight(self):\n        self.asserttrue(large_than_two(8))\n\n    def test_larger_than_two_with_five(self):\n        self.assertfalse(large_than_two(5))\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# 2. 使用ddt实现参数化\n\n首先需要通过pip来安装该库\n\npip install ddt\n\n\n1\n\n\n\n# 2.1 基本使用\n\n我们在testcase上添加ddt装饰器，然后在单测方法上添加data装饰器，并添加了3种场景的输入参数，如下代码所示：\n\nfrom unittest.case import testcase\n\nfrom ddt import ddt, data\n\n\ndef large_than_two(value) -> bool:\n    return value > 2\n\n\n@ddt\nclass testdemocase(testcase):\n\n    @data(3, 8, 5)\n    def test_larger_than_two(self, value):\n        self.asserttrue(large_than_two(value))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n执行上面的单测，输入出如下：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::testdemocase::test_larger_than_two_with_three_1_3 passed   [ 33%]\ntest_demo.py::testdemocase::test_larger_than_two_with_three_2_8 passed   [ 66%]\ntest_demo.py::testdemocase::test_larger_than_two_with_three_3_5 passed   [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n会发现，虽然我们写了一个单测用例，但是却执行了3个用例，这是因为ddt会将data的3个参数分别注入到test_larger_than_two方法中value中并执行单测。\n\n在输出的单测信息中，会输出单测方法+第多少个单测+参数值来表示当前用例的执行。\n\n通过这种方式可以减少我们的重复代码。\n\n\n# 2.2 多个值使用参数化\n\n当我们需要在一个单测用例中注入多个值时，可以在data中传入多个元组进行参数化，但执行单例时，会将元组注入到value中，我们将其解开则能拿到多个值。代码如下图所示：\n\ndef greater(v1, v2) -> bool:\n    return v1 > v2\n\n\n@ddt\nclass testdemocase(testcase):\n\n    @data(\n        (3, 2),\n        (4, 1),\n        (8, 6))\n    def test_greater(self, value):\n        v1, v2 = value\n        self.asserttrue(greater(v1, v2))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n执行之后输出如下所示：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::testdemocase::test_greater_1__3__2_ passed                 [ 33%]\ntest_demo.py::testdemocase::test_greater_2__4__1_ passed                 [ 66%]\ntest_demo.py::testdemocase::test_greater_3__8__6_ passed                 [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2.3 参数化扁平使用\n\n元组中的数据可以由ddt解开后注入到单测方法中的参数中。只需要在单测方法钱添加unpack装饰器即可。代码如下所示：\n\nfrom unittest.case import testcase\n\nfrom ddt import ddt, data, unpack\n\n@ddt\nclass testdemocase(testcase):\n\n    @unpack\n    @data(\n        (3, 2),\n        (4, 1),\n        (8, 6))\n    def test_greater(self, v1, v2):\n        self.asserttrue(greater(v1, v2))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n执行后结果如下：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::testdemocase::test_greater_1__3__2_ passed                 [ 33%]\ntest_demo.py::testdemocase::test_greater_2__4__1_ passed                 [ 66%]\ntest_demo.py::testdemocase::test_greater_3__8__6_ passed                 [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2.4 命名参数\n\n我们还可以给传入的参数进行命名而不是元组的形式，传入的参数名称与单测方法中参数的变量名对应，则不需要对应顺序传入，可读性更强了。代码如下：\n\n@ddt\nclass testdemocase(testcase):\n\n    @unpack\n    @data(\n        {"first": 3, "second": 2},\n        {"first": 4, "second": 1},\n        {"first": 8, "second": 6}\n    )\n    def test_greater(self, second, first):\n        self.asserttrue(greater(first, second))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n执行后输出：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::testdemocase::test_greater_1 passed                        [ 33%]\ntest_demo.py::testdemocase::test_greater_2 passed                        [ 66%]\ntest_demo.py::testdemocase::test_greater_3 passed                        [100%]\n\n============================== 3 passed in 0.01s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2.5 从json文件中读取参数进行单测\n\n在某些业务中，输入的参数过于复杂，并且场景繁多，如果将参数数据全部放在单测代码中，则会显得繁重，而且代码不易读，ddt提供了从json文件中读取参数来作为单测的输入数据。\n\n创建data.json文件，其中包含了参数数据。\n\n[\n  {\n    "first": 3,\n    "second": 2\n  },\n  {\n    "first": 4,\n    "second": 1\n  },\n  {\n    "first": 8,\n    "second": 6\n  }\n]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后使用file_data作为单测方法的装饰器，并传入上面数据文件的路径。\n\nfrom ddt import ddt, file_data\n\n@ddt\nclass testdemocase(testcase):\n\n    @file_data("data.json")\n    def test_greater(self, second, first):\n        self.asserttrue(greater(first, second))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n执行成功并输出：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::testdemocase::test_greater_1 passed                        [ 33%]\ntest_demo.py::testdemocase::test_greater_2 passed                        [ 66%]\ntest_demo.py::testdemocase::test_greater_3 passed                        [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 3. 总结\n\n本文是介绍ddt的基本并常用的用法，如果想要深入使用可以参考官方文档。\n\n其实ddt有个缺点是不能针对某一个单测方法进行单独的执行，必须要运行整个unittest class才行，这样在调试的过程中非常不方便。\n\n如果你看到本文其实我比较推荐你使用pytest来替代unittest使用，pytest中也有参数化的使用，并且可以单独的去运行每一个单测。\n\n我是因为在做一个django项目，其中使用的是django test来写单测的，而django test是基于unittest来实现的，所以只能使用ddt来实现参数化。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django-apschedule定时任务异常停止",frontmatter:{title:"django-apschedule定时任务异常停止",date:"2023-10-30T16:53:28.000Z",permalink:"/pages/ec5110/",categories:["编程","python","第三方库"],tags:["python","django"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"在django项目中使用`django-apschedule`来实现定时任务，使用的是`BackgroundScheduler`调度类，该调度的实现是通过后台线程的方式执行定时任务。其中任务都是持久化到数据库中的。在项目的运行过程中，因为数据库的异常，导致定时任务线程异常终止，即使数据库后续恢复正常，但也不再继续执行。我多次尝试复现未果，在开启定时任务期间，手动将数据库连接断开，定时任务执行失败，然后再将数据库建立连接，定时任务竟然重新恢复了，这让我一时摸不着头脑。",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"django-apschedule定时任务异常停止"},{name:"twitter:description",content:"在django项目中使用`django-apschedule`来实现定时任务，使用的是`BackgroundScheduler`调度类，该调度的实现是通过后台线程的方式执行定时任务。其中任务都是持久化到数据库中的。在项目的运行过程中，因为数据库的异常，导致定时任务线程异常终止，即使数据库后续恢复正常，但也不再继续执行。我多次尝试复现未果，在开启定时任务期间，手动将数据库连接断开，定时任务执行失败，然后再将数据库建立连接，定时任务竟然重新恢复了，这让我一时摸不着头脑。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/03.django-apschedule%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8%E5%81%9C%E6%AD%A2.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django-apschedule定时任务异常停止"},{property:"og:description",content:"在django项目中使用`django-apschedule`来实现定时任务，使用的是`BackgroundScheduler`调度类，该调度的实现是通过后台线程的方式执行定时任务。其中任务都是持久化到数据库中的。在项目的运行过程中，因为数据库的异常，导致定时任务线程异常终止，即使数据库后续恢复正常，但也不再继续执行。我多次尝试复现未果，在开启定时任务期间，手动将数据库连接断开，定时任务执行失败，然后再将数据库建立连接，定时任务竟然重新恢复了，这让我一时摸不着头脑。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/03.django-apschedule%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8%E5%81%9C%E6%AD%A2.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-10-30T16:53:28.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django-apschedule定时任务异常停止"},{itemprop:"description",content:"在django项目中使用`django-apschedule`来实现定时任务，使用的是`BackgroundScheduler`调度类，该调度的实现是通过后台线程的方式执行定时任务。其中任务都是持久化到数据库中的。在项目的运行过程中，因为数据库的异常，导致定时任务线程异常终止，即使数据库后续恢复正常，但也不再继续执行。我多次尝试复现未果，在开启定时任务期间，手动将数据库连接断开，定时任务执行失败，然后再将数据库建立连接，定时任务竟然重新恢复了，这让我一时摸不着头脑。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/03.django-apschedule%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8%E5%81%9C%E6%AD%A2.html",relativePath:"04.编程/01.python/02.第三方库/03.django-apschedule定时任务异常停止.md",key:"v-6fc4dda8",path:"/pages/ec5110/",headers:[{level:2,title:"背景",slug:"背景",normalizedTitle:"背景",charIndex:2},{level:2,title:"源码分析原因",slug:"源码分析原因",normalizedTitle:"源码分析原因",charIndex:3211},{level:2,title:"搭建demo",slug:"搭建demo",normalizedTitle:"搭建demo",charIndex:5215},{level:2,title:"线程重启",slug:"线程重启",normalizedTitle:"线程重启",charIndex:7380},{level:2,title:"listener",slug:"listener",normalizedTitle:"listener",charIndex:7666},{level:2,title:"捕获线程中函数的异常",slug:"捕获线程中函数的异常",normalizedTitle:"捕获线程中函数的异常",charIndex:8659},{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:9435}],headersStr:"背景 源码分析原因 搭建demo 线程重启 listener 捕获线程中函数的异常 相关链接",content:'# 背景\n\n在django项目中使用django-apschedule来实现定时任务，使用的是BackgroundScheduler调度类，该调度的实现是通过后台线程的方式执行定时任务。其中任务都是持久化到数据库中的。\n\n在项目的运行过程中，因为数据库的异常，导致定时任务线程异常终止，即使数据库后续恢复正常，但也不再继续执行。我多次尝试复现未果，在开启定时任务期间，手动将数据库连接断开，定时任务执行失败，然后再将数据库建立连接，定时任务竟然重新恢复了，这让我一时摸不着头脑。\n\n具体的错误日志如下，通过分析，是update_job连接数据库异常，没有任何捕获机制，然后层层网上抛，最终导致线程停止，可以很肯定的是，绝对是因为数据库连接失败导致的定时任务失败，那为什么无法复现呢？\n\nTraceback (most recent call last):\n  File "/usr/local/python3/lib/python3.7/threading.py", line 926, in _bootstrap_inner\n    self.run()\n  File "/usr/local/python3/lib/python3.7/threading.py", line 870, in run\n    self._target(*self._args, **self._kwargs)\n  File "/usr/local/python3/lib/python3.7/site-packages/apscheduler/schedulers/blocking.py", line 32, in _main_loop\n    wait_seconds = self._process_jobs()\n  File "/usr/local/python3/lib/python3.7/site-packages/apscheduler/schedulers/base.py", line 1009, in _process_jobs\n    jobstore.update_job(job)\n  File "/usr/local/python3/lib/python3.7/site-packages/django_apscheduler/util.py", line 105, in func_wrapper\n    result = func(*args, **kwargs)\n  File "/usr/local/python3/lib/python3.7/site-packages/django_apscheduler/jobstores.py", line 249, in update_job\n    with transaction.atomic():\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/transaction.py", line 189, in __enter__\n    if not connection.get_autocommit():\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 389, in get_autocommit\n    self.ensure_connection()\n  File "/usr/local/python3/lib/python3.7/site-packages/django/utils/asyncio.py", line 33, in inner\n     return func(*args, **kwargs)\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 219, in ensure_connection\n    self.connect()\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/utils.py", line 90, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 219, in ensure_connection\n    self.connect()\n  File "/usr/local/python3/lib/python3.7/site-packages/django/utils/asyncio.py", line 33, in inner\n    return func(*args, **kwargs)\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 200, in connect\n    self.connection = self.get_new_connection(conn_params)\n  File "/usr/local/python3/lib/python3.7/site-packages/django/utils/asyncio.py", line 33, in inner\n    return func(*args, **kwargs)\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/postgresql/base.py", line 187, in get_new_connection\n    connection = Database.connect(**conn_params)\n  File "/usr/local/python3/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect\n    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\ndjango.db.utils.OperationalError: connection to server at "xxxx.postgresql.svc.cluster.local" (xx.xx.xx.xx), port xxxx failed: server closed the connection unexpectedly\nThis probably means the server terminated abnormally\nbefore or while processing the request.\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n\n# 源码分析原因\n\n可以先看下BackgroundScheduler的实现方式，在start方法中创建了个子线程。\n\nclass BackgroundScheduler(BlockingScheduler):\n\n    _thread = None\n\n    def start(self, *args, **kwargs):\n        if self._event is None or self._event.is_set():\n            self._event = Event()\n\n        BaseScheduler.start(self, *args, **kwargs)\n        self._thread = Thread(target=self._main_loop, name=\'APScheduler\')\n        self._thread.daemon = self._daemon\n        self._thread.start()\n\n    def shutdown(self, *args, **kwargs):\n        super(BackgroundScheduler, self).shutdown(*args, **kwargs)\n        self._thread.join()\n        del self._thread\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n其中_main_loop在BlockingScheduler中实现，是一个死循环，执行_process_jobs方法\n\nclass BlockingScheduler(BaseScheduler):\n    \n    ...\n\n    def _main_loop(self):\n        wait_seconds = TIMEOUT_MAX\n        while self.state != STATE_STOPPED:\n            self._event.wait(wait_seconds)\n            self._event.clear()\n            wait_seconds = self._process_jobs()\n    \n    ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n再看_process_jobs中的内容，在BaseScheduler实现的，主要流程如下，先找到所有要执行的job，然后进行遍历运行并更新Job的状态。之前的错误日志，也就是这里的update_job抛出异常，而这里并没有捕获异常，最终层层往上抛，update_job -> _process_jobs -> _main_loop，最终线程异常终止。\n\ndef _process_jobs(self):\n    for jobstore_alias, jobstore in six.iteritems(self._jobstores):\n        try:\n            due_jobs = jobstore.get_due_jobs(now)\n        except Exception as e:\n            ...\n            continue\n\n        ...\n                \n        for job in due_jobs:\n      \n            ...\n            \n            try:\n                executor.submit_job(job, run_times)\n            except BaseException:\n                ...\n\n            ...\n            jobstore.update_job(job)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n那为什么复现不了呢？这个是因为，关闭数据库连接时，程序不一定可以正好运行在update_job，可以看到前面的get_due_jobs进行了异常捕获，如果这里抛出数据库连接异常是可以捕获到的，然后跳过后面的操作，等待下一次定时任务的执行，如果还是失败，则再次等待，所以这里的异常不会抛到最上层导致线程停止。\n\n但如果某个时机，上面连接数据库都成功了，到update_job这里异常抛出，则会导致整个线程停止，定时任务不再执行。\n\n那如何解决该问题呢？\n\n\n# 搭建demo\n\n首先我们搭建一个demo出来，模拟复现该问题。\n\n 1. 创建django项目\n\n\ndjango-admin startproject apschedule_demo\n\npython manage.py startapp demo\n\npython manage.py makemigrations\n\npython manage.py migrate\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 2. 在settings.py中配置到好数据库信息\n\nDATABASES = {\n    "default": {\n        "ENGINE": "django.db.backends.postgresql",\n        "NAME": "apschedule_demo",\n        "HOST": "xxxx",\n        "PORT": 5432,\n        "USER": "xxx",\n        "PASSWORD": "xxx"\n    }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n 3. 根据django-apschedule官方提供的文档搭建demo\n\n在settings.py中添加该APP\n\nINSTALLED_APPS = (\n    # ...\n    "django_apscheduler",\n)\n\n\n1\n2\n3\n4\n\n\n创建目录demo/management/commands，并在其下面创建runapscheduler.py文件，代码内容如下：\n\nimport logging\n\nfrom django.conf import settings\n\nfrom apscheduler.schedulers.blocking import BlockingScheduler\nfrom apscheduler.triggers.cron import CronTrigger\nfrom django.core.management.base import BaseCommand\nfrom django_apscheduler.jobstores import DjangoJobStore\n\nlogger = logging.getLogger(__name__)\n\n\ndef my_job():\n  # Your job processing logic here...\n  print("job..")\n\n\nclass Command(BaseCommand):\n  help = "Runs APScheduler."\n\n  def handle(self, *args, **options):\n    scheduler = BlockingScheduler(timezone=settings.TIME_ZONE)\n    scheduler.add_jobstore(DjangoJobStore(), "default")\n\n    scheduler.add_job(\n      my_job,\n      trigger=CronTrigger(second="*/3"),  # Every 3 seconds\n      id="my_job",  # The `id` assigned to each job MUST be unique\n      max_instances=1,\n      replace_existing=True,\n    )\n    logger.info("Added job \'my_job\'.")\n\n    try:\n      logger.info("Starting scheduler...")\n      scheduler.start()\n\n    # 因为上面是非阻塞开启定时任务，所以这里需要阻塞，不让主线程结束。\n    while True:\n            time.sleep(10)\n    except KeyboardInterrupt:\n      logger.info("Stopping scheduler...")\n      scheduler.shutdown()\n      logger.info("Scheduler shut down successfully!")\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n\n\n可以通过python manage.py runapscheduler执行上面的命令运行定时任务，该脚本创建了一个每3秒执行一次的任务。\n\n 4. 复现\n\n我们将断点打在jobstore.update_job(job)上，然后使用debug模式进行调试，当程序运行到断点上时，将数据库关闭，然后程序继续运行，则会报错，并抛出异常，线程停止了运行。至此，我们复现了该问题。\n\n\n# 线程重启\n\n我一开始想，我可以判断该线程是否异常，如果异常则将线程重启就好了\n\n    while True:\n        if not scheduler._thread.is_alive():\n            scheduler._thread.start()\n\n        time.sleep(10)\n\n\n1\n2\n3\n4\n5\n\n\n但事与愿违，抛出了异常，异常信息如下：\n\nRuntimeError: threads can only be started once\n\n\n1\n\n\n通过查看官方文档可以知道，线程的start方法只能调用一次。\n\n\n# listener\n\napschedule中提供了监听器机制，也就是在定时任务的成功、失败等状态都可以通过提前注册的listener方法来进行回调。但通过分析源码，其并不能捕获到定时任务线程的异常。\n\n下面是简化了代码的listeners的原理流程：\n\n 1. 外部通过add_listener方法注册回调方法\n 2. 在定时任务线程主流程_process_jobs中发生的各个事件添加到events中\n 3. 遍历events事件，然后通过与注册的回调方法mask进行匹配，匹配上则调用回调方法\n\nclass BaseScheduler:\n    def __init__(...):\n        self._listeners = []\n\n    def add_listener(self, callback, mask=EVENT_ALL):\n        self._listeners.append((callback, mask))\n\n    def _process_jobs(self):\n\n        events = []\n        \n        ...\n\n        events.append(event)\n \n        ...\n\n\n        for event in events:\n            self._dispatch_event(event)\n\n\n    def _dispatch_event(self, event):\n        for cb, mask in listeners:\n            if event.code & mask:\n                try:\n                    cb(event)\n                except BaseException:\n                    self._logger.exception(\'Error notifying listener\')\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n如果线程本身挂了，回调方法是不可执行的。\n\n\n# 捕获线程中函数的异常\n\n如果update_job抛出异常导致线程停止，那我捕获它的异常，然后再continue，等待下次定时任务运行再重试不就好了，但是这就需要改动源码，能不能改源码就尽量不改。所以这边我采用了继承BackgroundScheduler类，然后再重写_process_jobs方法来解决。\n\n在重写的_process_jobs方法中，对父类的_process_jobs()进行异常的捕获，然后再不断的进行重试，这样即使update_job抛出异常了，也可以不断的进行尝试恢复，直至成功。\n\nclass DemoBackgroundScheduler(BackgroundScheduler):\n    def _process_jobs(self):\n        while True:\n            try:\n                return super()._process_jobs()\n            except BaseException:\n                time.sleep(5)\n\nclass Command(BaseCommand):\n    help = "Runs APScheduler."\n\n    def handle(self, *args, **options):\n        scheduler = DemoBackgroundScheduler(timezone=settings.TIME_ZONE)\n        ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后再次尝试复现该问题，可以发现在断开数据库后，它能够一直进行重试，线程没有停止，当数据库恢复运行后，job执行成功，不再抛出异常。\n\n\n# 相关链接\n\n * APScheduler官方文档',normalizedContent:'# 背景\n\n在django项目中使用django-apschedule来实现定时任务，使用的是backgroundscheduler调度类，该调度的实现是通过后台线程的方式执行定时任务。其中任务都是持久化到数据库中的。\n\n在项目的运行过程中，因为数据库的异常，导致定时任务线程异常终止，即使数据库后续恢复正常，但也不再继续执行。我多次尝试复现未果，在开启定时任务期间，手动将数据库连接断开，定时任务执行失败，然后再将数据库建立连接，定时任务竟然重新恢复了，这让我一时摸不着头脑。\n\n具体的错误日志如下，通过分析，是update_job连接数据库异常，没有任何捕获机制，然后层层网上抛，最终导致线程停止，可以很肯定的是，绝对是因为数据库连接失败导致的定时任务失败，那为什么无法复现呢？\n\ntraceback (most recent call last):\n  file "/usr/local/python3/lib/python3.7/threading.py", line 926, in _bootstrap_inner\n    self.run()\n  file "/usr/local/python3/lib/python3.7/threading.py", line 870, in run\n    self._target(*self._args, **self._kwargs)\n  file "/usr/local/python3/lib/python3.7/site-packages/apscheduler/schedulers/blocking.py", line 32, in _main_loop\n    wait_seconds = self._process_jobs()\n  file "/usr/local/python3/lib/python3.7/site-packages/apscheduler/schedulers/base.py", line 1009, in _process_jobs\n    jobstore.update_job(job)\n  file "/usr/local/python3/lib/python3.7/site-packages/django_apscheduler/util.py", line 105, in func_wrapper\n    result = func(*args, **kwargs)\n  file "/usr/local/python3/lib/python3.7/site-packages/django_apscheduler/jobstores.py", line 249, in update_job\n    with transaction.atomic():\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/transaction.py", line 189, in __enter__\n    if not connection.get_autocommit():\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 389, in get_autocommit\n    self.ensure_connection()\n  file "/usr/local/python3/lib/python3.7/site-packages/django/utils/asyncio.py", line 33, in inner\n     return func(*args, **kwargs)\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 219, in ensure_connection\n    self.connect()\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/utils.py", line 90, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 219, in ensure_connection\n    self.connect()\n  file "/usr/local/python3/lib/python3.7/site-packages/django/utils/asyncio.py", line 33, in inner\n    return func(*args, **kwargs)\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 200, in connect\n    self.connection = self.get_new_connection(conn_params)\n  file "/usr/local/python3/lib/python3.7/site-packages/django/utils/asyncio.py", line 33, in inner\n    return func(*args, **kwargs)\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/postgresql/base.py", line 187, in get_new_connection\n    connection = database.connect(**conn_params)\n  file "/usr/local/python3/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect\n    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\ndjango.db.utils.operationalerror: connection to server at "xxxx.postgresql.svc.cluster.local" (xx.xx.xx.xx), port xxxx failed: server closed the connection unexpectedly\nthis probably means the server terminated abnormally\nbefore or while processing the request.\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n\n# 源码分析原因\n\n可以先看下backgroundscheduler的实现方式，在start方法中创建了个子线程。\n\nclass backgroundscheduler(blockingscheduler):\n\n    _thread = none\n\n    def start(self, *args, **kwargs):\n        if self._event is none or self._event.is_set():\n            self._event = event()\n\n        basescheduler.start(self, *args, **kwargs)\n        self._thread = thread(target=self._main_loop, name=\'apscheduler\')\n        self._thread.daemon = self._daemon\n        self._thread.start()\n\n    def shutdown(self, *args, **kwargs):\n        super(backgroundscheduler, self).shutdown(*args, **kwargs)\n        self._thread.join()\n        del self._thread\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n其中_main_loop在blockingscheduler中实现，是一个死循环，执行_process_jobs方法\n\nclass blockingscheduler(basescheduler):\n    \n    ...\n\n    def _main_loop(self):\n        wait_seconds = timeout_max\n        while self.state != state_stopped:\n            self._event.wait(wait_seconds)\n            self._event.clear()\n            wait_seconds = self._process_jobs()\n    \n    ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n再看_process_jobs中的内容，在basescheduler实现的，主要流程如下，先找到所有要执行的job，然后进行遍历运行并更新job的状态。之前的错误日志，也就是这里的update_job抛出异常，而这里并没有捕获异常，最终层层往上抛，update_job -> _process_jobs -> _main_loop，最终线程异常终止。\n\ndef _process_jobs(self):\n    for jobstore_alias, jobstore in six.iteritems(self._jobstores):\n        try:\n            due_jobs = jobstore.get_due_jobs(now)\n        except exception as e:\n            ...\n            continue\n\n        ...\n                \n        for job in due_jobs:\n      \n            ...\n            \n            try:\n                executor.submit_job(job, run_times)\n            except baseexception:\n                ...\n\n            ...\n            jobstore.update_job(job)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n那为什么复现不了呢？这个是因为，关闭数据库连接时，程序不一定可以正好运行在update_job，可以看到前面的get_due_jobs进行了异常捕获，如果这里抛出数据库连接异常是可以捕获到的，然后跳过后面的操作，等待下一次定时任务的执行，如果还是失败，则再次等待，所以这里的异常不会抛到最上层导致线程停止。\n\n但如果某个时机，上面连接数据库都成功了，到update_job这里异常抛出，则会导致整个线程停止，定时任务不再执行。\n\n那如何解决该问题呢？\n\n\n# 搭建demo\n\n首先我们搭建一个demo出来，模拟复现该问题。\n\n 1. 创建django项目\n\n\ndjango-admin startproject apschedule_demo\n\npython manage.py startapp demo\n\npython manage.py makemigrations\n\npython manage.py migrate\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 2. 在settings.py中配置到好数据库信息\n\ndatabases = {\n    "default": {\n        "engine": "django.db.backends.postgresql",\n        "name": "apschedule_demo",\n        "host": "xxxx",\n        "port": 5432,\n        "user": "xxx",\n        "password": "xxx"\n    }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n 3. 根据django-apschedule官方提供的文档搭建demo\n\n在settings.py中添加该app\n\ninstalled_apps = (\n    # ...\n    "django_apscheduler",\n)\n\n\n1\n2\n3\n4\n\n\n创建目录demo/management/commands，并在其下面创建runapscheduler.py文件，代码内容如下：\n\nimport logging\n\nfrom django.conf import settings\n\nfrom apscheduler.schedulers.blocking import blockingscheduler\nfrom apscheduler.triggers.cron import crontrigger\nfrom django.core.management.base import basecommand\nfrom django_apscheduler.jobstores import djangojobstore\n\nlogger = logging.getlogger(__name__)\n\n\ndef my_job():\n  # your job processing logic here...\n  print("job..")\n\n\nclass command(basecommand):\n  help = "runs apscheduler."\n\n  def handle(self, *args, **options):\n    scheduler = blockingscheduler(timezone=settings.time_zone)\n    scheduler.add_jobstore(djangojobstore(), "default")\n\n    scheduler.add_job(\n      my_job,\n      trigger=crontrigger(second="*/3"),  # every 3 seconds\n      id="my_job",  # the `id` assigned to each job must be unique\n      max_instances=1,\n      replace_existing=true,\n    )\n    logger.info("added job \'my_job\'.")\n\n    try:\n      logger.info("starting scheduler...")\n      scheduler.start()\n\n    # 因为上面是非阻塞开启定时任务，所以这里需要阻塞，不让主线程结束。\n    while true:\n            time.sleep(10)\n    except keyboardinterrupt:\n      logger.info("stopping scheduler...")\n      scheduler.shutdown()\n      logger.info("scheduler shut down successfully!")\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n\n\n可以通过python manage.py runapscheduler执行上面的命令运行定时任务，该脚本创建了一个每3秒执行一次的任务。\n\n 4. 复现\n\n我们将断点打在jobstore.update_job(job)上，然后使用debug模式进行调试，当程序运行到断点上时，将数据库关闭，然后程序继续运行，则会报错，并抛出异常，线程停止了运行。至此，我们复现了该问题。\n\n\n# 线程重启\n\n我一开始想，我可以判断该线程是否异常，如果异常则将线程重启就好了\n\n    while true:\n        if not scheduler._thread.is_alive():\n            scheduler._thread.start()\n\n        time.sleep(10)\n\n\n1\n2\n3\n4\n5\n\n\n但事与愿违，抛出了异常，异常信息如下：\n\nruntimeerror: threads can only be started once\n\n\n1\n\n\n通过查看官方文档可以知道，线程的start方法只能调用一次。\n\n\n# listener\n\napschedule中提供了监听器机制，也就是在定时任务的成功、失败等状态都可以通过提前注册的listener方法来进行回调。但通过分析源码，其并不能捕获到定时任务线程的异常。\n\n下面是简化了代码的listeners的原理流程：\n\n 1. 外部通过add_listener方法注册回调方法\n 2. 在定时任务线程主流程_process_jobs中发生的各个事件添加到events中\n 3. 遍历events事件，然后通过与注册的回调方法mask进行匹配，匹配上则调用回调方法\n\nclass basescheduler:\n    def __init__(...):\n        self._listeners = []\n\n    def add_listener(self, callback, mask=event_all):\n        self._listeners.append((callback, mask))\n\n    def _process_jobs(self):\n\n        events = []\n        \n        ...\n\n        events.append(event)\n \n        ...\n\n\n        for event in events:\n            self._dispatch_event(event)\n\n\n    def _dispatch_event(self, event):\n        for cb, mask in listeners:\n            if event.code & mask:\n                try:\n                    cb(event)\n                except baseexception:\n                    self._logger.exception(\'error notifying listener\')\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n如果线程本身挂了，回调方法是不可执行的。\n\n\n# 捕获线程中函数的异常\n\n如果update_job抛出异常导致线程停止，那我捕获它的异常，然后再continue，等待下次定时任务运行再重试不就好了，但是这就需要改动源码，能不能改源码就尽量不改。所以这边我采用了继承backgroundscheduler类，然后再重写_process_jobs方法来解决。\n\n在重写的_process_jobs方法中，对父类的_process_jobs()进行异常的捕获，然后再不断的进行重试，这样即使update_job抛出异常了，也可以不断的进行尝试恢复，直至成功。\n\nclass demobackgroundscheduler(backgroundscheduler):\n    def _process_jobs(self):\n        while true:\n            try:\n                return super()._process_jobs()\n            except baseexception:\n                time.sleep(5)\n\nclass command(basecommand):\n    help = "runs apscheduler."\n\n    def handle(self, *args, **options):\n        scheduler = demobackgroundscheduler(timezone=settings.time_zone)\n        ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后再次尝试复现该问题，可以发现在断开数据库后，它能够一直进行重试，线程没有停止，当数据库恢复运行后，job执行成功，不再抛出异常。\n\n\n# 相关链接\n\n * apscheduler官方文档',charsets:{cjk:!0},lastUpdated:"2023/11/17, 16:03:58",lastUpdatedTimestamp:1700208238e3},{title:"ddt源码分析",frontmatter:{title:"ddt源码分析",date:"2022-10-23T20:04:51.000Z",permalink:"/pages/069c65/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"ddt 是 python 的第三方库，主要是解决使用 unittest 来写单测时可以支持参数化的配置，本文介绍源码解析该库，理解它的实现过程。",feed:{enable:!0},tags:["python"],categories:["编程","python","第三方库"],comment:!0,meta:[{name:"twitter:title",content:"ddt源码分析"},{name:"twitter:description",content:"ddt 是 python 的第三方库，主要是解决使用 unittest 来写单测时可以支持参数化的配置，本文介绍源码解析该库，理解它的实现过程。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/02.ddt%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:type",content:"article"},{property:"og:title",content:"ddt源码分析"},{property:"og:description",content:"ddt 是 python 的第三方库，主要是解决使用 unittest 来写单测时可以支持参数化的配置，本文介绍源码解析该库，理解它的实现过程。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/02.ddt%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-10-23T20:04:51.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"ddt源码分析"},{itemprop:"description",content:"ddt 是 python 的第三方库，主要是解决使用 unittest 来写单测时可以支持参数化的配置，本文介绍源码解析该库，理解它的实现过程。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/02.ddt%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html",relativePath:"04.编程/01.python/02.第三方库/02.ddt源码分析.md",key:"v-dea92c98",path:"/pages/069c65/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 源码分析",slug:"_1-源码分析",normalizedTitle:"1. 源码分析",charIndex:177},{level:3,title:"1.1 example",slug:"_1-1-example",normalizedTitle:"1.1 example",charIndex:189},{level:3,title:"1.2 源码分析流程",slug:"_1-2-源码分析流程",normalizedTitle:"1.2 源码分析流程",charIndex:2004},{level:2,title:"2. 总结",slug:"_2-总结",normalizedTitle:"2. 总结",charIndex:5859}],headersStr:"0. 前言 1. 源码分析 1.1 example 1.2 源码分析流程 2. 总结",content:'# 0. 前言\n\nddt 是 python 的第三方库，主要是解决使用 unittest 来写单测时可以支持参数化的配置，这个库的使用方法可以参考我之前写的使用ddt实现unittest的参数化测试。本文主要是讲自己在学习 ddt 库时所获。\n\nddt 库的使用方法是用装饰器来实现的，可以参考这边文章python装饰器的使用方法来学习装饰器.\n\n\n# 1. 源码分析\n\n\n# 1.1 example\n\n先看一个最简单的使用例子，我们创建 larger_than_two 函数，并使用 unittest 对其编写单测。\n\n这里使用了 @ddt 来装饰 DemoTestCase，并使用 @data 填写多个测试的参数，这样执行就完成了参数化的单测了。\n\nimport unittest  \nfrom ddt import ddt, data  \n  \n  \ndef larger_than_two(value):  \n    return value > 2  \n  \n  \n@ddt  \nclass DemoTestCase(unittest.TestCase):  \n  \n    @data(1, 2, 3)  \n    def test_larger_than_two(self, value):  \n        self.assertTrue(larger_than_two(value))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n我们执行上面的单测会发现，虽然我们代码只写了一个用例，但是执行却是 3 个用例，成功了 1 个，失败了 2 个，并且输出了失败的用例的名称，test_larger_than_two_1_1 和 test_larger_than_two_2_2，名称的规则是：单测的名称_索引_参数。\n\nFF.\n======================================================================\nFAIL: test_larger_than_two_1_1 (__main__.DemoTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File "c:\\crazyboy\\code\\ddt\\ddt.py", line 220, in wrapper\n    return func(self, *args, **kwargs)\n  File "C:\\CrazyBoy\\workspace\\demo\\demo.py", line 24, in test_larger_than_two\n    self.assertTrue(larger_than_two(value))\nAssertionError: False is not true\n\n======================================================================\nFAIL: test_larger_than_two_2_2 (__main__.DemoTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File "c:\\crazyboy\\code\\ddt\\ddt.py", line 220, in wrapper\n    return func(self, *args, **kwargs)\n  File "C:\\CrazyBoy\\workspace\\demo\\demo.py", line 24, in test_larger_than_two\n    self.assertTrue(larger_than_two(value))\nAssertionError: False is not true\n\n----------------------------------------------------------------------\nRan 3 tests in 0.004s\n\nFAILED (failures=2)\n\nProcess finished with exit code 1\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n这是如何实现的呢？\n\n\n# 1.2 源码分析流程\n\n我们首先来看看 @data 装饰器里面做了什么？\n\ndef data(*values):  \n    return idata(values)\n\n\n1\n2\n\n\ndata 调用了函数 idata，我们再来看看 idata 的实现，通过 setattr 方法，给被装饰的单测用例添加两个属性\n\n * DATA_ATTR 是用来保存 data 的参数化的参数。\n * INDEX_LEN 用来保存参数化的长度。\n\nDATA_ATTR = \'%values\'\nINDEX_LEN = \'%index_len\'\n\ndef idata(iterable, index_len=None):  \n    if index_len is None:  \n        iterable = tuple(iterable)  \n        index_len = len(str(len(iterable)))  \n  \n    def wrapper(func):  \n        setattr(func, DATA_ATTR, iterable)  \n        setattr(func, INDEX_LEN, index_len)  \n        return func  \n  \n    return wrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后我们再来看装饰器@ddt 中，传入的 cls 是被装饰的单测类，通过该类，找到上面使用@data 装饰器中添加的属性 DATA_ATTR 和对应的单测方法，其中的每条数据都是一个用例，通过遍历该属性中的参数值调用函数 mk_test_name 去构造每一条参数的用例名称。\n\n然后再调用 add_test 函数去生成对应的单测用例。\n\ndef ddt(arg=None, **kwargs):\n\tfmt_test_name = kwargs.get("testNameFormat", TestNameFormat.DEFAULT)  \n\t  \n\tdef wrapper(cls):  \n\t    for name, func in list(cls.__dict__.items()):  \n\t        if hasattr(func, DATA_ATTR):  \n\t            index_len = getattr(func, INDEX_LEN)  \n\t            for i, v in enumerate(getattr(func, DATA_ATTR)):  \n\t                test_name = mk_test_name(  \n\t                    name,  \n\t                    getattr(v, "__name__", v),  \n\t                    i,  \n\t                    index_len,  \n\t                    fmt_test_name  \n\t                )  \n\t                test_data_docstring = _get_test_data_docstring(func, v)  \n\t                if hasattr(func, UNPACK_ATTR):  \n\t                    if isinstance(v, tuple) or isinstance(v, list):  \n\t                        add_test(  \n\t                            cls,  \n\t                            test_name,  \n\t                            test_data_docstring,  \n\t                            func,  \n\t                            *v  \n\t                        )  \n\t                    else:  \n\t                        # unpack dictionary  \n\t                        add_test(  \n\t                            cls,  \n\t                            test_name,  \n\t                            test_data_docstring,  \n\t                            func,  \n\t                            **v  \n\t                        )  \n\t                else:  \n\t                    add_test(cls, test_name, test_data_docstring, func, v)  \n\t            delattr(cls, name)  \n\t        elif hasattr(func, FILE_ATTR):  \n\t            file_attr = getattr(func, FILE_ATTR)  \n\t            process_file_data(cls, name, func, file_attr)  \n\t            delattr(cls, name)  \n\t    return cls  \n\t  \n\t# ``arg`` is the unittest\'s test class when decorating with ``@ddt`` while  \n\t# it is ``None`` when decorating a test class with ``@ddt(k=v)``.  \n\treturn wrapper(arg) if inspect.isclass(arg) else wrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n\n\n我们看看 add_test 做了什么？很简单，就是给单测的 TestCase 添加属性，以单测用例名称为名，feed_data 的返回值为值。\n\nfeed_data 中，根据单个参数值和被@data 装饰的函数组成一个新的单测用例，并返回出去。\n\ndef add_test(cls, test_name, test_docstring, func, *args, **kwargs):  \n\tsetattr(cls, test_name, feed_data(func, test_name, test_docstring, *args, **kwargs))\n\ndef feed_data(func, new_name, test_data_docstring, *args, **kwargs):      \n    @wraps(func)  \n    def wrapper(self):  \n        return func(self, *args, **kwargs)  \n    wrapper.__name__ = new_name  \n    wrapper.__wrapped__ = func  \n    # set docstring if exists  \n    if test_data_docstring is not None:  \n        wrapper.__doc__ = test_data_docstring  \n    else:  \n        # Try to call format on the docstring  \n        if func.__doc__:  \n            try:  \n                wrapper.__doc__ = func.__doc__.format(*args, **kwargs)  \n            except (IndexError, KeyError):  \n\t\t\t\tpass  \n    return wrapper\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n也就是说，参数化的每个值都会生成一个用例方法并注册到被@ddt 装饰的 TestCase 类中。\n\n\n# 2. 总结\n\n主要流程是：通过 @data 装饰器将参数化注册到该单测用例方法的 DATA_ATTR 属性中，然后@ddt 装饰器遍历当前 TestCase 的所有包含 DATA_ATTR 属性的用例方法，再遍历其 DATA_ATTR 的参数值，把每条参数值都生成一条用例方法，并注册到 TestCase 中。这样执行该 TestCase 时，虽然只编码了一条单测，但是却有多条用例被执行。\n\n整个过程都是对类和单测方法的元数据属性进行各种操作来实现的。',normalizedContent:'# 0. 前言\n\nddt 是 python 的第三方库，主要是解决使用 unittest 来写单测时可以支持参数化的配置，这个库的使用方法可以参考我之前写的使用ddt实现unittest的参数化测试。本文主要是讲自己在学习 ddt 库时所获。\n\nddt 库的使用方法是用装饰器来实现的，可以参考这边文章python装饰器的使用方法来学习装饰器.\n\n\n# 1. 源码分析\n\n\n# 1.1 example\n\n先看一个最简单的使用例子，我们创建 larger_than_two 函数，并使用 unittest 对其编写单测。\n\n这里使用了 @ddt 来装饰 demotestcase，并使用 @data 填写多个测试的参数，这样执行就完成了参数化的单测了。\n\nimport unittest  \nfrom ddt import ddt, data  \n  \n  \ndef larger_than_two(value):  \n    return value > 2  \n  \n  \n@ddt  \nclass demotestcase(unittest.testcase):  \n  \n    @data(1, 2, 3)  \n    def test_larger_than_two(self, value):  \n        self.asserttrue(larger_than_two(value))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n我们执行上面的单测会发现，虽然我们代码只写了一个用例，但是执行却是 3 个用例，成功了 1 个，失败了 2 个，并且输出了失败的用例的名称，test_larger_than_two_1_1 和 test_larger_than_two_2_2，名称的规则是：单测的名称_索引_参数。\n\nff.\n======================================================================\nfail: test_larger_than_two_1_1 (__main__.demotestcase)\n----------------------------------------------------------------------\ntraceback (most recent call last):\n  file "c:\\crazyboy\\code\\ddt\\ddt.py", line 220, in wrapper\n    return func(self, *args, **kwargs)\n  file "c:\\crazyboy\\workspace\\demo\\demo.py", line 24, in test_larger_than_two\n    self.asserttrue(larger_than_two(value))\nassertionerror: false is not true\n\n======================================================================\nfail: test_larger_than_two_2_2 (__main__.demotestcase)\n----------------------------------------------------------------------\ntraceback (most recent call last):\n  file "c:\\crazyboy\\code\\ddt\\ddt.py", line 220, in wrapper\n    return func(self, *args, **kwargs)\n  file "c:\\crazyboy\\workspace\\demo\\demo.py", line 24, in test_larger_than_two\n    self.asserttrue(larger_than_two(value))\nassertionerror: false is not true\n\n----------------------------------------------------------------------\nran 3 tests in 0.004s\n\nfailed (failures=2)\n\nprocess finished with exit code 1\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n这是如何实现的呢？\n\n\n# 1.2 源码分析流程\n\n我们首先来看看 @data 装饰器里面做了什么？\n\ndef data(*values):  \n    return idata(values)\n\n\n1\n2\n\n\ndata 调用了函数 idata，我们再来看看 idata 的实现，通过 setattr 方法，给被装饰的单测用例添加两个属性\n\n * data_attr 是用来保存 data 的参数化的参数。\n * index_len 用来保存参数化的长度。\n\ndata_attr = \'%values\'\nindex_len = \'%index_len\'\n\ndef idata(iterable, index_len=none):  \n    if index_len is none:  \n        iterable = tuple(iterable)  \n        index_len = len(str(len(iterable)))  \n  \n    def wrapper(func):  \n        setattr(func, data_attr, iterable)  \n        setattr(func, index_len, index_len)  \n        return func  \n  \n    return wrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后我们再来看装饰器@ddt 中，传入的 cls 是被装饰的单测类，通过该类，找到上面使用@data 装饰器中添加的属性 data_attr 和对应的单测方法，其中的每条数据都是一个用例，通过遍历该属性中的参数值调用函数 mk_test_name 去构造每一条参数的用例名称。\n\n然后再调用 add_test 函数去生成对应的单测用例。\n\ndef ddt(arg=none, **kwargs):\n\tfmt_test_name = kwargs.get("testnameformat", testnameformat.default)  \n\t  \n\tdef wrapper(cls):  \n\t    for name, func in list(cls.__dict__.items()):  \n\t        if hasattr(func, data_attr):  \n\t            index_len = getattr(func, index_len)  \n\t            for i, v in enumerate(getattr(func, data_attr)):  \n\t                test_name = mk_test_name(  \n\t                    name,  \n\t                    getattr(v, "__name__", v),  \n\t                    i,  \n\t                    index_len,  \n\t                    fmt_test_name  \n\t                )  \n\t                test_data_docstring = _get_test_data_docstring(func, v)  \n\t                if hasattr(func, unpack_attr):  \n\t                    if isinstance(v, tuple) or isinstance(v, list):  \n\t                        add_test(  \n\t                            cls,  \n\t                            test_name,  \n\t                            test_data_docstring,  \n\t                            func,  \n\t                            *v  \n\t                        )  \n\t                    else:  \n\t                        # unpack dictionary  \n\t                        add_test(  \n\t                            cls,  \n\t                            test_name,  \n\t                            test_data_docstring,  \n\t                            func,  \n\t                            **v  \n\t                        )  \n\t                else:  \n\t                    add_test(cls, test_name, test_data_docstring, func, v)  \n\t            delattr(cls, name)  \n\t        elif hasattr(func, file_attr):  \n\t            file_attr = getattr(func, file_attr)  \n\t            process_file_data(cls, name, func, file_attr)  \n\t            delattr(cls, name)  \n\t    return cls  \n\t  \n\t# ``arg`` is the unittest\'s test class when decorating with ``@ddt`` while  \n\t# it is ``none`` when decorating a test class with ``@ddt(k=v)``.  \n\treturn wrapper(arg) if inspect.isclass(arg) else wrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n\n\n我们看看 add_test 做了什么？很简单，就是给单测的 testcase 添加属性，以单测用例名称为名，feed_data 的返回值为值。\n\nfeed_data 中，根据单个参数值和被@data 装饰的函数组成一个新的单测用例，并返回出去。\n\ndef add_test(cls, test_name, test_docstring, func, *args, **kwargs):  \n\tsetattr(cls, test_name, feed_data(func, test_name, test_docstring, *args, **kwargs))\n\ndef feed_data(func, new_name, test_data_docstring, *args, **kwargs):      \n    @wraps(func)  \n    def wrapper(self):  \n        return func(self, *args, **kwargs)  \n    wrapper.__name__ = new_name  \n    wrapper.__wrapped__ = func  \n    # set docstring if exists  \n    if test_data_docstring is not none:  \n        wrapper.__doc__ = test_data_docstring  \n    else:  \n        # try to call format on the docstring  \n        if func.__doc__:  \n            try:  \n                wrapper.__doc__ = func.__doc__.format(*args, **kwargs)  \n            except (indexerror, keyerror):  \n\t\t\t\tpass  \n    return wrapper\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n也就是说，参数化的每个值都会生成一个用例方法并注册到被@ddt 装饰的 testcase 类中。\n\n\n# 2. 总结\n\n主要流程是：通过 @data 装饰器将参数化注册到该单测用例方法的 data_attr 属性中，然后@ddt 装饰器遍历当前 testcase 的所有包含 data_attr 属性的用例方法，再遍历其 data_attr 的参数值，把每条参数值都生成一条用例方法，并注册到 testcase 中。这样执行该 testcase 时，虽然只编码了一条单测，但是却有多条用例被执行。\n\n整个过程都是对类和单测方法的元数据属性进行各种操作来实现的。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django rest_framework使用jwt",frontmatter:{tags:["python","django"],title:"django rest_framework使用jwt",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/25eafd/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文介绍在 django rest_framework 使用jwt认证.",feed:{enable:!0},categories:["编程","python","django"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604218012751.jpg#alt="},{name:"twitter:title",content:"django rest_framework使用jwt"},{name:"twitter:description",content:"本文介绍在 django rest_framework 使用jwt认证."},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604218012751.jpg#alt="},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/02.django%20rest_framework%E4%BD%BF%E7%94%A8jwt.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django rest_framework使用jwt"},{property:"og:description",content:"本文介绍在 django rest_framework 使用jwt认证."},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604218012751.jpg#alt="},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/02.django%20rest_framework%E4%BD%BF%E7%94%A8jwt.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django rest_framework使用jwt"},{itemprop:"description",content:"本文介绍在 django rest_framework 使用jwt认证."},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604218012751.jpg#alt="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/02.django%20rest_framework%E4%BD%BF%E7%94%A8jwt.html",relativePath:"04.编程/01.python/06.django/02.django rest_framework使用jwt.md",key:"v-a6f8fe8c",path:"/pages/25eafd/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:113},{level:2,title:"jwt 认证流程",slug:"jwt-认证流程",normalizedTitle:"jwt 认证流程",charIndex:126},{level:2,title:"使用",slug:"使用",normalizedTitle:"使用",charIndex:34}],headersStr:"简介 相关链接 jwt 认证流程 使用",content:"# 简介\n\n本文介绍在 django rest_framework 使用jwt认证.\n\njwt 不是 rest_framework自带的认证方式，需要通过第三方库djangorestframework-jwt结合使用\n\n\n# 相关链接\n\n官网\n\n\n# jwt 认证流程\n\n\n\n\n# 使用\n\n 0. 安装djangorestframework-jwt\n\n> pip install djangorestframework-jwt\n\n 1. 添加获取token的路由\n\nfrom rest_framework_jwt.views import obtain_jwt_token\n\nurlpatterns = [\n    re_path(r'^api-token-auth/', obtain_jwt_token),\n]\n\n\n1\n2\n3\n4\n5\n\n 2. 全局添加认证。将jwt authentication类注入到框架中\n\n访问任何的路由都会使用JSONWebTokenAuthentication.authenticate进行认证.\n\nsettings.py\n\nREST_FRAMEWORK = {\n    'DEFAULT_AUTHENTICATION_CLASSES': [\n        'rest_framework_jwt.authentication.JSONWebTokenAuthentication',\n    ]\n\n\n1\n2\n3\n4\n\n 3. 局部添加认证，在APIView中添加认证类.\n\n每次访问该视图时，都会调用JSONWebTokenAuthentication.authenticate 进行认证.\n\nclass TestView(APIView):\n    authentication_classes = (JSONWebTokenAuthentication,)\n\n    def get(self, *args, **kwargs):\n        return HttpResponse(self.request.user)\n\n\n1\n2\n3\n4\n5\n\n 4. 设置\n\nsettings.py\n\n\nJWT_AUTH = {\n    'JWT_EXPIRATION_DELTA': datetime.timedelta(minutes=30),   # 过期时间\n    'JWT_RESPONSE_PAYLOAD_HANDLER': 'user.utils.jwt_response_payload_handler'    # 默认返回的仅有`token`字段，可以由自己修改返回的数据，可以包含user.id和user.username   \n}\n\n\n1\n2\n3\n4\n5\n",normalizedContent:"# 简介\n\n本文介绍在 django rest_framework 使用jwt认证.\n\njwt 不是 rest_framework自带的认证方式，需要通过第三方库djangorestframework-jwt结合使用\n\n\n# 相关链接\n\n官网\n\n\n# jwt 认证流程\n\n\n\n\n# 使用\n\n 0. 安装djangorestframework-jwt\n\n> pip install djangorestframework-jwt\n\n 1. 添加获取token的路由\n\nfrom rest_framework_jwt.views import obtain_jwt_token\n\nurlpatterns = [\n    re_path(r'^api-token-auth/', obtain_jwt_token),\n]\n\n\n1\n2\n3\n4\n5\n\n 2. 全局添加认证。将jwt authentication类注入到框架中\n\n访问任何的路由都会使用jsonwebtokenauthentication.authenticate进行认证.\n\nsettings.py\n\nrest_framework = {\n    'default_authentication_classes': [\n        'rest_framework_jwt.authentication.jsonwebtokenauthentication',\n    ]\n\n\n1\n2\n3\n4\n\n 3. 局部添加认证，在apiview中添加认证类.\n\n每次访问该视图时，都会调用jsonwebtokenauthentication.authenticate 进行认证.\n\nclass testview(apiview):\n    authentication_classes = (jsonwebtokenauthentication,)\n\n    def get(self, *args, **kwargs):\n        return httpresponse(self.request.user)\n\n\n1\n2\n3\n4\n5\n\n 4. 设置\n\nsettings.py\n\n\njwt_auth = {\n    'jwt_expiration_delta': datetime.timedelta(minutes=30),   # 过期时间\n    'jwt_response_payload_handler': 'user.utils.jwt_response_payload_handler'    # 默认返回的仅有`token`字段，可以由自己修改返回的数据，可以包含user.id和user.username   \n}\n\n\n1\n2\n3\n4\n5\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django rest_framework Authentication",frontmatter:{tags:["python","django"],title:"django rest_framework Authentication",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/626675/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文介绍的是 django rest_framework的认证方式.",feed:{enable:!0},categories:["编程","python","django"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217645776.png#alt="},{name:"twitter:title",content:"django rest_framework Authentication"},{name:"twitter:description",content:"本文介绍的是 django rest_framework的认证方式."},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217645776.png#alt="},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/03.django%20rest_framework%20Authentication.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django rest_framework Authentication"},{property:"og:description",content:"本文介绍的是 django rest_framework的认证方式."},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217645776.png#alt="},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/03.django%20rest_framework%20Authentication.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django rest_framework Authentication"},{itemprop:"description",content:"本文介绍的是 django rest_framework的认证方式."},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217645776.png#alt="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/03.django%20rest_framework%20Authentication.html",relativePath:"04.编程/01.python/06.django/03.django rest_framework Authentication.md",key:"v-cf78fd3a",path:"/pages/626675/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"源码解析",slug:"源码解析",normalizedTitle:"源码解析",charIndex:132},{level:2,title:"认证方式",slug:"认证方式",normalizedTitle:"认证方式",charIndex:35},{level:3,title:"Token",slug:"token",normalizedTitle:"token",charIndex:42},{level:4,title:"使用",slug:"使用",normalizedTitle:"使用",charIndex:124},{level:4,title:"缺陷",slug:"缺陷",normalizedTitle:"缺陷",charIndex:1493},{level:3,title:"session",slug:"session",normalizedTitle:"session",charIndex:1683}],headersStr:"简介 源码解析 认证方式 Token 使用 缺陷 session",content:"# 简介\n\n本文介绍的是 django rest_framework的认证方式.\n\nToken、Session、RemoteUser、jwt等认证方式。前三种是框架自带的，而jwt需要安装第三方库djangorestframework-jwt，然后使用。\n\n\n# 源码解析\n\n以下是认证源码认证流程.\n\n 1. 通过路由匹配后首先进入到ApiView.as_view中.\n\n 2. ApiView继承Django的View，然后调用View.as_view\n\n 3. 在View中调用dispatch方法，因为ApiView实现dispatch方法，所以调用的是ApiView.dispatch而不是View.dispatch.\n\n 4. 在ApiView.dispatch中将django.request再次封装成框架的rest_framework.request\n\n 5. 封装的过程中将配置的Authentication类注入到request中.\n\n 6. 封装完request后，调用ApiView.perform_authentication开始认证\n\n 7. 认证的过程是通过request.user，然后再调用request._authentication进行循环遍历所有注入的Authentiation类中authenticate方法进行认证，认证成功则返回user和auth两个结果.\n\n\n\n\n# 认证方式\n\n可以自定义认证类，只需要继承BaseAuthentication类，然后实现authenticate方法即可，然后将该类注入到request即可.\n\n或者使用框架自带的认证类也可。\n\n\n# Token\n\n是框架自带的认证方式之一.\n\n# 使用\n\n 1. 配置authtoken app settings\n\nINSTALLED_APPS = [\n    ...\n    'rest_framework.authtoken']\n\n\n1\n2\n3\n\n\n然后使用python manage.py migrate，会创建authtoken表，该表连接auth_user.表，每个用户都有对应一个token，用户每次访问带有该token，系统就能通过token得到当前user.\n\n 2. 局部添加认证方式.\n\n在TestView添加TokenAuthentication认证, 路由到TestView时，会调用该类中的authenticate方法，通过token获取到user.\n\nview.py\n\n\nfrom rest_framework.authentication import TokenAuthentication\n\nclass TestView(APIView):\n    authentication_classes = (TokenAuthentication,)\n\n    def get(self, *args, **kwargs):\n        return HttpResponse(self.request.user)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 3. 全局添加认证方式\n\n任何路由请求需要通过Token认证.\n\nsettings.py\n\nREST_FRAMEWORK = {\n    'DEFAULT_AUTHENTICATION_CLASSES': [\n        'rest_framework.authentication.TokenAuthentication',\n    ]\n}\n\n\n1\n2\n3\n4\n5\n\n\n# 缺陷\n\n * Token验证是放在一张表中，即authtoken_token中，key没有失效时间，永久有效，一旦泄露，后果不可想象，安全性极差。\n * 不利于分布式部署或多个系统使用一套验证，authtoken_token是放在某台服务器上的，如果分布式部署，将失效，或多个系统用一套验证，将必须复制该表到相应服务器上，麻烦费力。\n\n鉴于以上缺陷，使用jwt更加优秀.\n\n\n# session\n\ndrf中session认证，是通过django SessionMiddleware和AuthenticationMiddleware中将user存储到request中，然后获取到的.\n\n",normalizedContent:"# 简介\n\n本文介绍的是 django rest_framework的认证方式.\n\ntoken、session、remoteuser、jwt等认证方式。前三种是框架自带的，而jwt需要安装第三方库djangorestframework-jwt，然后使用。\n\n\n# 源码解析\n\n以下是认证源码认证流程.\n\n 1. 通过路由匹配后首先进入到apiview.as_view中.\n\n 2. apiview继承django的view，然后调用view.as_view\n\n 3. 在view中调用dispatch方法，因为apiview实现dispatch方法，所以调用的是apiview.dispatch而不是view.dispatch.\n\n 4. 在apiview.dispatch中将django.request再次封装成框架的rest_framework.request\n\n 5. 封装的过程中将配置的authentication类注入到request中.\n\n 6. 封装完request后，调用apiview.perform_authentication开始认证\n\n 7. 认证的过程是通过request.user，然后再调用request._authentication进行循环遍历所有注入的authentiation类中authenticate方法进行认证，认证成功则返回user和auth两个结果.\n\n\n\n\n# 认证方式\n\n可以自定义认证类，只需要继承baseauthentication类，然后实现authenticate方法即可，然后将该类注入到request即可.\n\n或者使用框架自带的认证类也可。\n\n\n# token\n\n是框架自带的认证方式之一.\n\n# 使用\n\n 1. 配置authtoken app settings\n\ninstalled_apps = [\n    ...\n    'rest_framework.authtoken']\n\n\n1\n2\n3\n\n\n然后使用python manage.py migrate，会创建authtoken表，该表连接auth_user.表，每个用户都有对应一个token，用户每次访问带有该token，系统就能通过token得到当前user.\n\n 2. 局部添加认证方式.\n\n在testview添加tokenauthentication认证, 路由到testview时，会调用该类中的authenticate方法，通过token获取到user.\n\nview.py\n\n\nfrom rest_framework.authentication import tokenauthentication\n\nclass testview(apiview):\n    authentication_classes = (tokenauthentication,)\n\n    def get(self, *args, **kwargs):\n        return httpresponse(self.request.user)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 3. 全局添加认证方式\n\n任何路由请求需要通过token认证.\n\nsettings.py\n\nrest_framework = {\n    'default_authentication_classes': [\n        'rest_framework.authentication.tokenauthentication',\n    ]\n}\n\n\n1\n2\n3\n4\n5\n\n\n# 缺陷\n\n * token验证是放在一张表中，即authtoken_token中，key没有失效时间，永久有效，一旦泄露，后果不可想象，安全性极差。\n * 不利于分布式部署或多个系统使用一套验证，authtoken_token是放在某台服务器上的，如果分布式部署，将失效，或多个系统用一套验证，将必须复制该表到相应服务器上，麻烦费力。\n\n鉴于以上缺陷，使用jwt更加优秀.\n\n\n# session\n\ndrf中session认证，是通过django sessionmiddleware和authenticationmiddleware中将user存储到request中，然后获取到的.\n\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django rest_framework异常处理",frontmatter:{tags:["python","django"],title:"django rest_framework异常处理",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/070fec/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"当程序中出现异常时，我们想要返回的是包含异常信息的json数据。返回正常的信息和异常信息的格式一致化。",feed:{enable:!0},categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django rest_framework异常处理"},{name:"twitter:description",content:"当程序中出现异常时，我们想要返回的是包含异常信息的json数据。返回正常的信息和异常信息的格式一致化。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/04.django%20rest_framework%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django rest_framework异常处理"},{property:"og:description",content:"当程序中出现异常时，我们想要返回的是包含异常信息的json数据。返回正常的信息和异常信息的格式一致化。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/04.django%20rest_framework%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django rest_framework异常处理"},{itemprop:"description",content:"当程序中出现异常时，我们想要返回的是包含异常信息的json数据。返回正常的信息和异常信息的格式一致化。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/04.django%20rest_framework%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86.html",relativePath:"04.编程/01.python/06.django/04.django rest_framework异常处理.md",key:"v-3599af91",path:"/pages/070fec/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"操作",slug:"操作",normalizedTitle:"操作",charIndex:62}],headersStr:"简介 操作",content:'# 简介\n\n当程序中出现异常时，我们想要返回的是包含异常信息的json数据。返回正常的信息和异常信息的格式一致化。\n\n\n# 操作\n\n 1. 自定义json返回的格式\n\nlibs/response.py\n\nfrom rest_framework.response import Response\n\n\nclass JsonResponse(Response):\n    def __init__(self, data=None, code=None, msg=None, status=None,\n                 template_name=None, headers=None,\n                 exception=False, content_type=None):\n        rsp_data = {"code": code, "message": msg, "data": data}\n        super(JsonResponse, self).__init__(data=rsp_data, status=status, template_name=template_name,\n                                                 headers=headers,\n                                                 exception=exception, content_type=content_type)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n 2. 自定义全局的异常处理方法 libs/exceptions.py\n\n\nfrom rest_framework import status\nfrom rest_framework.views import exception_handler\nfrom libs.response import JsonResponse\n\n\nclass DataException(Exception):\n\n    def __init__(self, message="", code=0, status=status.HTTP_400_BAD_REQUEST, data=None):\n        self.code = code\n        self.status = status\n        self.detail = message\n        self.data = data if data else {}\n\n        def __str__(self):\n            return self.message\n\n\ndef custom_exception_handler(exc, context):\n    data = exc.data if hasattr(exc, "data") else {}\n    return JsonResponse(msg=exc.detail, status=exc.status_code, data=data, code=exc.status_code)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n 3. 将该异常方法注册到rest_framework框架中 settings.py\n\nREST_FRAMEWORK = {\n    \'EXCEPTION_HANDLER\': \'libs.exceptions.custom_exception_handler\',\n}\n\n\n1\n2\n3\n',normalizedContent:'# 简介\n\n当程序中出现异常时，我们想要返回的是包含异常信息的json数据。返回正常的信息和异常信息的格式一致化。\n\n\n# 操作\n\n 1. 自定义json返回的格式\n\nlibs/response.py\n\nfrom rest_framework.response import response\n\n\nclass jsonresponse(response):\n    def __init__(self, data=none, code=none, msg=none, status=none,\n                 template_name=none, headers=none,\n                 exception=false, content_type=none):\n        rsp_data = {"code": code, "message": msg, "data": data}\n        super(jsonresponse, self).__init__(data=rsp_data, status=status, template_name=template_name,\n                                                 headers=headers,\n                                                 exception=exception, content_type=content_type)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n 2. 自定义全局的异常处理方法 libs/exceptions.py\n\n\nfrom rest_framework import status\nfrom rest_framework.views import exception_handler\nfrom libs.response import jsonresponse\n\n\nclass dataexception(exception):\n\n    def __init__(self, message="", code=0, status=status.http_400_bad_request, data=none):\n        self.code = code\n        self.status = status\n        self.detail = message\n        self.data = data if data else {}\n\n        def __str__(self):\n            return self.message\n\n\ndef custom_exception_handler(exc, context):\n    data = exc.data if hasattr(exc, "data") else {}\n    return jsonresponse(msg=exc.detail, status=exc.status_code, data=data, code=exc.status_code)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n 3. 将该异常方法注册到rest_framework框架中 settings.py\n\nrest_framework = {\n    \'exception_handler\': \'libs.exceptions.custom_exception_handler\',\n}\n\n\n1\n2\n3\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django celery 结合使用",frontmatter:{title:"django celery 结合使用",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/853501/",tags:["python","django"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文主要介绍django和celery结合使用的案例。",feed:{enable:!0},categories:["编程","python","django"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217044049.png#alt=#crop=0&crop=0&crop=1&crop=1&id=kAMz1&originHeight=475&originWidth=564&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{name:"twitter:title",content:"django celery 结合使用"},{name:"twitter:description",content:"本文主要介绍django和celery结合使用的案例。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217044049.png#alt=#crop=0&crop=0&crop=1&crop=1&id=kAMz1&originHeight=475&originWidth=564&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/01.django%20celery%20%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django celery 结合使用"},{property:"og:description",content:"本文主要介绍django和celery结合使用的案例。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217044049.png#alt=#crop=0&crop=0&crop=1&crop=1&id=kAMz1&originHeight=475&originWidth=564&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/01.django%20celery%20%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django celery 结合使用"},{itemprop:"description",content:"本文主要介绍django和celery结合使用的案例。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217044049.png#alt=#crop=0&crop=0&crop=1&crop=1&id=kAMz1&originHeight=475&originWidth=564&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/01.django%20celery%20%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8.html",relativePath:"04.编程/01.python/06.django/01.django celery 结合使用.md",key:"v-3e233877",path:"/pages/853501/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"流程",slug:"流程",normalizedTitle:"流程",charIndex:143},{level:2,title:"消息分发与任务调度的实现机制",slug:"消息分发与任务调度的实现机制",normalizedTitle:"消息分发与任务调度的实现机制",charIndex:233},{level:2,title:"celery-beat",slug:"celery-beat",normalizedTitle:"celery-beat",charIndex:254},{level:2,title:"案例1",slug:"案例1",normalizedTitle:"案例1",charIndex:399},{level:3,title:"配置celery",slug:"配置celery",normalizedTitle:"配置celery",charIndex:425},{level:3,title:"在view中异步执行task",slug:"在view中异步执行task",normalizedTitle:"在view中异步执行task",charIndex:1933},{level:2,title:"案例2",slug:"案例2",normalizedTitle:"案例2",charIndex:2660},{level:3,title:"定时任务简介",slug:"定时任务简介",normalizedTitle:"定时任务简介",charIndex:2678},{level:3,title:"配置",slug:"配置",normalizedTitle:"配置",charIndex:425},{level:3,title:"定时任务",slug:"定时任务",normalizedTitle:"定时任务",charIndex:66},{level:2,title:"案例三-路由",slug:"案例三-路由",normalizedTitle:"案例三-路由",charIndex:3083},{level:3,title:"管理worker 进程",slug:"管理worker-进程",normalizedTitle:"管理worker 进程",charIndex:3819},{level:3,title:"基本操作",slug:"基本操作",normalizedTitle:"基本操作",charIndex:3861},{level:3,title:"命令",slug:"命令",normalizedTitle:"命令",charIndex:3970},{level:3,title:"配合celery使用",slug:"配合celery使用",normalizedTitle:"配合celery使用",charIndex:4105},{level:3,title:"问题",slug:"问题",normalizedTitle:"问题",charIndex:5604},{level:2,title:"使用flower监控celery",slug:"使用flower监控celery",normalizedTitle:"使用flower监控celery",charIndex:5786},{level:3,title:"持久化",slug:"持久化",normalizedTitle:"持久化",charIndex:5930},{level:3,title:"时区问题",slug:"时区问题",normalizedTitle:"时区问题",charIndex:6018}],headersStr:"简介 流程 消息分发与任务调度的实现机制 celery-beat 案例1 配置celery 在view中异步执行task 案例2 定时任务简介 配置 定时任务 案例三-路由 管理worker 进程 基本操作 命令 配合celery使用 问题 使用flower监控celery 持久化 时区问题",content:"# 简介\n\n本文主要介绍django和celery结合使用的案例。\n\ncelery 是一个异步任务的调度工具，可以完成一些异步任务和定时任务。\n\n本文使用djcelery来完成django和celery的结合使用。\n\n该案例在github中django_celery_demo\n\n\n# 流程\n\n任务发布者(Producer)将任务丢到消息队列(Broker)中，任务消费者(worker)从消息代理中获取任务执行，然后将保存存储结果(backend)。\n\n\n\n\n# 消息分发与任务调度的实现机制\n\n\n\n\n# celery-beat\n\ncelery 有个定时功能，通过定时去将task丢到broker中，然后worker去执行任务。但是有个确定是，该定时任务必须硬编写到代码中，不可在程序运行中动态增加任务。使用djcelery可以将定时任务写入到数据库中，然后通过操作数据库操作定时任务。\n\n\n# 案例1\n\n访问接口，异步调用程序中task\n\n\n# 配置celery\n\n安装**djcelery**\n\n> pip install django_celery\n\n在settings中设置celery配置\n\n代码: django_celery_demo/settings.py\n\nimport djcelery\ndjcelery.setup_loader() # 加载djcelery\n\n\n# 允许的格式\nCELERY_ACCEPT_CONTENT = ['pickle', 'json', 'yaml']\n\nBROKER_URL = 'redis://localhost:6379/1' # redis作为中间件\nBROKER_TRANSPORT = 'redis'\n\nCELERYBEAT_SCHEDULER = 'djcelery.schedulers.DatabaseScheduler' # 定时任务使用数据库来操作\nCELERY_RESULT_BACKEND = 'djcelery.backends.database:DatabaseBackend'  # 结果存储到数据库中\n\n# worker 并发数\nCELERY_CONCURRENCY = 2\n\n# 指定导入task任务\nCELERY_IMPORTS = {\n'tasks.tasks'\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\ncelery app 配置\n\n代码: django_celery_demo/celery.py\n\nimport os\n\nimport django\nfrom celery import Celery, shared_task\nfrom celery.schedules import crontab\nfrom celery.signals import task_success\nfrom django.conf import settings\nfrom django.utils import timezone\n\nos.environ.setdefault('DJANGO_SETTINGS_MODULE', 'django_celery_demo.settings')\ndjango.setup()\n\napp = Celery('django_celery_demo')\napp.config_from_object('django.conf:settings') # celery app 加载 settings中的配置\n\napp.now = timezone.now # 设置时间时区和django一样\n\n# 加载每个django app下的tasks.py中的task任务\napp.autodiscover_tasks(lambda: settings.INSTALLED_APPS)\n\n# 这个一个task\n@app.task(bind=True)\ndef debug_task(self):\n    print('Request: {0!r}'.format(self.request))\n    \n# 异步执行这个task\ndebug_task.delay()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n创建djcelery中的表\n\n会自动创建djcelery中的表。里面有保存定时记录、结果记录等等表。\n\n> python manage.py migrate\n\n\n# 在view中异步执行task\n\n在app中创建**add**task\n\n代码: demo/tasks.py\n\nfrom celery import shared_task\n\n@shared_task(name=\"add\")\ndef add(a, b):\n    return int(a) + int(b)\n\n\n1\n2\n3\n4\n5\n\n\n创建view去异步执行该task\n\n代码: demo/views.py\n\nfrom django.http import HttpResponse\nfrom demo.tasks import add as add_task\n\ndef add(request):\n    a = request.GET[\"a\"]\n    b = request.GET[\"b\"]\n    add_task.delay(a, b)\n    \n    return HttpResponse(\"success\")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nurl中配置view\n\nfrom demo.views import add\n\nurlpatterns = [\n    path('add', add),\n]\n\n\n1\n2\n3\n4\n5\n\n\n运行celery worker\n\n> celery -A django_celery_demo worker -l info\n\n运行项目\n\n> python manage.py runserver 0:8888\n\n访问接口\n\nhttp://127.0.0.1:8888/add?a=1&b=2\n\n结果: 返回success，在worker中可以看到add任务被调用，并且结果是3\n\n\n\n\n# 案例2\n\n定时调用异步任务\n\n\n# 定时任务简介\n\n有两种定时任务方式，这里使用的是常见的crontab，与linux一毛一样，方便很多。\n\n\n# 配置\n\n配置和案例1中一样。\n\n\n# 定时任务\n\n硬编码中创建定时任务\n\n每分钟调用一次add task\n\n代码: django_celery_demo/celery.py\n\n# 这个是硬编码的定时任务\napp.conf.beat_schedule = {\n    'aa': {\n        'task': 'add',\n        'schedule': crontab(minute=\"*/1\"),\n        'args': (2, 4)\n    },\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n开启celery beat\n\n> celery beat -A django_celery_demo -l info\n\n这个服务会将数据库中的定时任务丢到broker 中\n\n\n# 案例三-路由\n\n将不同的任务放到不同的队列中，放到不同的worker中。\n\n图: 消息分发与任务调度的实现机制\n\ndefault = Exchange('default', type=\"direct\")\nfrequent = Exchange('frequent', type=\"direct\")\n\nCELERY_QUEUES = {\n    Queue('default', default, routing_key=\"default\"),\n    Queue('frequent', frequent, routing_key=\"frequent\")\n}\n\napp.conf.task_default_queue = 'default'\n\ntask_routes = {\n    'apps.periodic.tasks.oozie_workflow_task': {'queue': 'default'},\n    'apps.periodic.tasks.oozie_workflow_status': {'queue': 'custom'}\n}\n\napp.conf.beat_schedule = {\n\n    # 每分钟检查oozie运行中的任务状态\n    'oozie_workflow_status': {\n        'task': 'oozie_workflow_status',\n        'schedule': crontab(),\n        'args': (2, 1)\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 管理worker 进程\n\n使用supervisor来管理worker进程。\n\n\n# 基本操作\n\n安装\n\n> pip install supervisor\n\n生成默认配置文件\n\n> echo_supervisord_conf > /etc/supervisor/supervisord.conf\n\n\n# 命令\n\nsupervisorctl\n\n命令          描述\nstatus      \nreread      读取配置文件\nupdate      加载最新的进程\nstop 进程名    \nstart 进程名   \nreload      重新加载配置\n\n\n# 配合celery使用\n\n在supervisord.conf中添加下面的配置。\n\n[include]\n; files = relative/directory/*.ini\nfiles = /home/jim/conf/supervisor/supervisord.conf.d/*.conf\n\n\n1\n2\n3\n\n\n创建配置文件/home/jim/conf/supervisor/supervisord.conf.d/celeryd_worker.conf，添加下面配置\n\n[program:celeryworker]\ncommand=celery -A datahub_poster worker -l info\ndirectory=/home/hadoop/jim/projs/datahub_poster\nstdout_logfile=/yun/jim/log/supervisor/celeryworker.log\n;stderr_logfile=/yun/jim/log/supervisor/celeryworker_err.log\nredirect_stderr=true\nautorestart=true\nautostart=true\nnumprocs=1\nstartsecs=10\nstopwaitsecs = 600\npriority=15\n\n[program:celerybeat]\ncommand=celery -A datahub_poster beat -l info\ndirectory=/home/hadoop/jim/projs/datahub_poster\nstdout_logfile=/yun/jim/log/supervisor/celerybeat.log\n;stderr_logfile=/yun/jim/log/supervisor/celerybeat_err.log\nredirect_stderr=true\nautorestart=true\nautostart=true\nnumprocs=1\nstartsecs=10\nstopwaitsecs = 600\npriority=15\n\n[program:celery_flower]\ncommand=celery -A datahub_poster flower --port=5555\ndirectory=/home/hadoop/jim/projs/datahub_poster\nstdout_logfile=/yun/jim/log/supervisor/celery_flower.log\n;stderr_logfile=/yun/jim/log/supervisor/celery_flower_err.log\nredirect_stderr=true\nautorestart=true\nautostart=true\nnumprocs=1\nstartsecs=10\nstopwaitsecs = 600\npriority=15\n\n[inet_http_server]\nport=127.0.0.1:9001\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n\n\n使用配置文件启动supervisor\n\n> supervisord -c /etc/supervisor/supervisord.conf\n\n\n# 问题\n\n 1. 在supervisorctl status时，出现http://localhost:9001 refused connection错误。\n\n解决办法：\n\n在配置文件supervisord.conf中添加\n\n[inet_http_server]\nport=127.0.0.1:9001\n\n\n1\n2\n\n\n然后再update或reload以下。\n\n\n# 使用flower监控celery\n\n可以通过flower监控celery中的worker、task等等。\n\n安装flower\n\n> pip install flower\n\n运行\n\n> celery flower --broker=redis://localhost:6379/0\n\n\n# 持久化\n\n问题: 每次重启flower之后发现，以前的task运行记录清空。\n\n解决: 启动flower时添加 --persistent=True，可以持久化task\n\n\n# 时区问题\n\nflower会读取celery的时区配置，在项目中配置下面参数即可。\n\nTIME_ZONE = 'Asia/Shanghai'\nCELERY_TIMEZONE = TIME_ZONE\n\n\n1\n2\n",normalizedContent:"# 简介\n\n本文主要介绍django和celery结合使用的案例。\n\ncelery 是一个异步任务的调度工具，可以完成一些异步任务和定时任务。\n\n本文使用djcelery来完成django和celery的结合使用。\n\n该案例在github中django_celery_demo\n\n\n# 流程\n\n任务发布者(producer)将任务丢到消息队列(broker)中，任务消费者(worker)从消息代理中获取任务执行，然后将保存存储结果(backend)。\n\n\n\n\n# 消息分发与任务调度的实现机制\n\n\n\n\n# celery-beat\n\ncelery 有个定时功能，通过定时去将task丢到broker中，然后worker去执行任务。但是有个确定是，该定时任务必须硬编写到代码中，不可在程序运行中动态增加任务。使用djcelery可以将定时任务写入到数据库中，然后通过操作数据库操作定时任务。\n\n\n# 案例1\n\n访问接口，异步调用程序中task\n\n\n# 配置celery\n\n安装**djcelery**\n\n> pip install django_celery\n\n在settings中设置celery配置\n\n代码: django_celery_demo/settings.py\n\nimport djcelery\ndjcelery.setup_loader() # 加载djcelery\n\n\n# 允许的格式\ncelery_accept_content = ['pickle', 'json', 'yaml']\n\nbroker_url = 'redis://localhost:6379/1' # redis作为中间件\nbroker_transport = 'redis'\n\ncelerybeat_scheduler = 'djcelery.schedulers.databasescheduler' # 定时任务使用数据库来操作\ncelery_result_backend = 'djcelery.backends.database:databasebackend'  # 结果存储到数据库中\n\n# worker 并发数\ncelery_concurrency = 2\n\n# 指定导入task任务\ncelery_imports = {\n'tasks.tasks'\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\ncelery app 配置\n\n代码: django_celery_demo/celery.py\n\nimport os\n\nimport django\nfrom celery import celery, shared_task\nfrom celery.schedules import crontab\nfrom celery.signals import task_success\nfrom django.conf import settings\nfrom django.utils import timezone\n\nos.environ.setdefault('django_settings_module', 'django_celery_demo.settings')\ndjango.setup()\n\napp = celery('django_celery_demo')\napp.config_from_object('django.conf:settings') # celery app 加载 settings中的配置\n\napp.now = timezone.now # 设置时间时区和django一样\n\n# 加载每个django app下的tasks.py中的task任务\napp.autodiscover_tasks(lambda: settings.installed_apps)\n\n# 这个一个task\n@app.task(bind=true)\ndef debug_task(self):\n    print('request: {0!r}'.format(self.request))\n    \n# 异步执行这个task\ndebug_task.delay()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n创建djcelery中的表\n\n会自动创建djcelery中的表。里面有保存定时记录、结果记录等等表。\n\n> python manage.py migrate\n\n\n# 在view中异步执行task\n\n在app中创建**add**task\n\n代码: demo/tasks.py\n\nfrom celery import shared_task\n\n@shared_task(name=\"add\")\ndef add(a, b):\n    return int(a) + int(b)\n\n\n1\n2\n3\n4\n5\n\n\n创建view去异步执行该task\n\n代码: demo/views.py\n\nfrom django.http import httpresponse\nfrom demo.tasks import add as add_task\n\ndef add(request):\n    a = request.get[\"a\"]\n    b = request.get[\"b\"]\n    add_task.delay(a, b)\n    \n    return httpresponse(\"success\")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nurl中配置view\n\nfrom demo.views import add\n\nurlpatterns = [\n    path('add', add),\n]\n\n\n1\n2\n3\n4\n5\n\n\n运行celery worker\n\n> celery -a django_celery_demo worker -l info\n\n运行项目\n\n> python manage.py runserver 0:8888\n\n访问接口\n\nhttp://127.0.0.1:8888/add?a=1&b=2\n\n结果: 返回success，在worker中可以看到add任务被调用，并且结果是3\n\n\n\n\n# 案例2\n\n定时调用异步任务\n\n\n# 定时任务简介\n\n有两种定时任务方式，这里使用的是常见的crontab，与linux一毛一样，方便很多。\n\n\n# 配置\n\n配置和案例1中一样。\n\n\n# 定时任务\n\n硬编码中创建定时任务\n\n每分钟调用一次add task\n\n代码: django_celery_demo/celery.py\n\n# 这个是硬编码的定时任务\napp.conf.beat_schedule = {\n    'aa': {\n        'task': 'add',\n        'schedule': crontab(minute=\"*/1\"),\n        'args': (2, 4)\n    },\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n开启celery beat\n\n> celery beat -a django_celery_demo -l info\n\n这个服务会将数据库中的定时任务丢到broker 中\n\n\n# 案例三-路由\n\n将不同的任务放到不同的队列中，放到不同的worker中。\n\n图: 消息分发与任务调度的实现机制\n\ndefault = exchange('default', type=\"direct\")\nfrequent = exchange('frequent', type=\"direct\")\n\ncelery_queues = {\n    queue('default', default, routing_key=\"default\"),\n    queue('frequent', frequent, routing_key=\"frequent\")\n}\n\napp.conf.task_default_queue = 'default'\n\ntask_routes = {\n    'apps.periodic.tasks.oozie_workflow_task': {'queue': 'default'},\n    'apps.periodic.tasks.oozie_workflow_status': {'queue': 'custom'}\n}\n\napp.conf.beat_schedule = {\n\n    # 每分钟检查oozie运行中的任务状态\n    'oozie_workflow_status': {\n        'task': 'oozie_workflow_status',\n        'schedule': crontab(),\n        'args': (2, 1)\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 管理worker 进程\n\n使用supervisor来管理worker进程。\n\n\n# 基本操作\n\n安装\n\n> pip install supervisor\n\n生成默认配置文件\n\n> echo_supervisord_conf > /etc/supervisor/supervisord.conf\n\n\n# 命令\n\nsupervisorctl\n\n命令          描述\nstatus      \nreread      读取配置文件\nupdate      加载最新的进程\nstop 进程名    \nstart 进程名   \nreload      重新加载配置\n\n\n# 配合celery使用\n\n在supervisord.conf中添加下面的配置。\n\n[include]\n; files = relative/directory/*.ini\nfiles = /home/jim/conf/supervisor/supervisord.conf.d/*.conf\n\n\n1\n2\n3\n\n\n创建配置文件/home/jim/conf/supervisor/supervisord.conf.d/celeryd_worker.conf，添加下面配置\n\n[program:celeryworker]\ncommand=celery -a datahub_poster worker -l info\ndirectory=/home/hadoop/jim/projs/datahub_poster\nstdout_logfile=/yun/jim/log/supervisor/celeryworker.log\n;stderr_logfile=/yun/jim/log/supervisor/celeryworker_err.log\nredirect_stderr=true\nautorestart=true\nautostart=true\nnumprocs=1\nstartsecs=10\nstopwaitsecs = 600\npriority=15\n\n[program:celerybeat]\ncommand=celery -a datahub_poster beat -l info\ndirectory=/home/hadoop/jim/projs/datahub_poster\nstdout_logfile=/yun/jim/log/supervisor/celerybeat.log\n;stderr_logfile=/yun/jim/log/supervisor/celerybeat_err.log\nredirect_stderr=true\nautorestart=true\nautostart=true\nnumprocs=1\nstartsecs=10\nstopwaitsecs = 600\npriority=15\n\n[program:celery_flower]\ncommand=celery -a datahub_poster flower --port=5555\ndirectory=/home/hadoop/jim/projs/datahub_poster\nstdout_logfile=/yun/jim/log/supervisor/celery_flower.log\n;stderr_logfile=/yun/jim/log/supervisor/celery_flower_err.log\nredirect_stderr=true\nautorestart=true\nautostart=true\nnumprocs=1\nstartsecs=10\nstopwaitsecs = 600\npriority=15\n\n[inet_http_server]\nport=127.0.0.1:9001\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n\n\n使用配置文件启动supervisor\n\n> supervisord -c /etc/supervisor/supervisord.conf\n\n\n# 问题\n\n 1. 在supervisorctl status时，出现http://localhost:9001 refused connection错误。\n\n解决办法：\n\n在配置文件supervisord.conf中添加\n\n[inet_http_server]\nport=127.0.0.1:9001\n\n\n1\n2\n\n\n然后再update或reload以下。\n\n\n# 使用flower监控celery\n\n可以通过flower监控celery中的worker、task等等。\n\n安装flower\n\n> pip install flower\n\n运行\n\n> celery flower --broker=redis://localhost:6379/0\n\n\n# 持久化\n\n问题: 每次重启flower之后发现，以前的task运行记录清空。\n\n解决: 启动flower时添加 --persistent=true，可以持久化task\n\n\n# 时区问题\n\nflower会读取celery的时区配置，在项目中配置下面参数即可。\n\ntime_zone = 'asia/shanghai'\ncelery_timezone = time_zone\n\n\n1\n2\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django压缩文件下载",frontmatter:{title:"django压缩文件下载",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/f2738b/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍在django中，如何将数据生成zip文件提供给用户进行下载",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django压缩文件下载"},{name:"twitter:description",content:"介绍在django中，如何将数据生成zip文件提供给用户进行下载"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/06.django%E5%8E%8B%E7%BC%A9%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django压缩文件下载"},{property:"og:description",content:"介绍在django中，如何将数据生成zip文件提供给用户进行下载"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/06.django%E5%8E%8B%E7%BC%A9%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django压缩文件下载"},{itemprop:"description",content:"介绍在django中，如何将数据生成zip文件提供给用户进行下载"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/06.django%E5%8E%8B%E7%BC%A9%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD.html",relativePath:"04.编程/01.python/06.django/06.django压缩文件下载.md",key:"v-628321a6",path:"/pages/f2738b/",headersStr:null,content:'# 简介\n\n需求: 需要在请求时，将数据生成zip文件提供给用户下载。\n\n不想要在生成后再提供给用户下载\n\n解决: 使用BytesIO在内存中写入数据，而不是落地到本地中。\n\n\n# 栗子\n\n\nfrom io import BytesIO\nimport zipfile\nfrom django.http import FileResponse\n\ndef view():\n\n    download_io = BytesIO()\n\n    with zipfile.ZipFile(pb_zip_io, "w", zipfile.ZIP_DEFLATED) as zip_fp:\n        zip_fp.open("a.txt", "w") as f:\n            f.write("hello world")\n\n\n    # 注意，需要要将指针指向内存的开始位置\n    download_io.seek(0)\n\n    return FileResponse(download_io, as_attachment=True, filename="a.zip")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n',normalizedContent:'# 简介\n\n需求: 需要在请求时，将数据生成zip文件提供给用户下载。\n\n不想要在生成后再提供给用户下载\n\n解决: 使用bytesio在内存中写入数据，而不是落地到本地中。\n\n\n# 栗子\n\n\nfrom io import bytesio\nimport zipfile\nfrom django.http import fileresponse\n\ndef view():\n\n    download_io = bytesio()\n\n    with zipfile.zipfile(pb_zip_io, "w", zipfile.zip_deflated) as zip_fp:\n        zip_fp.open("a.txt", "w") as f:\n            f.write("hello world")\n\n\n    # 注意，需要要将指针指向内存的开始位置\n    download_io.seek(0)\n\n    return fileresponse(download_io, as_attachment=true, filename="a.zip")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django rest_framework使用pytest单元测试",frontmatter:{title:"django rest_framework使用pytest单元测试",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/c28126/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍在django的rest_framework中如何使用pytest进行单元测试而不是自带的测试框架。",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django rest_framework使用pytest单元测试"},{name:"twitter:description",content:"介绍在django的rest_framework中如何使用pytest进行单元测试而不是自带的测试框架。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/07.django%20rest_framework%E4%BD%BF%E7%94%A8pytest%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django rest_framework使用pytest单元测试"},{property:"og:description",content:"介绍在django的rest_framework中如何使用pytest进行单元测试而不是自带的测试框架。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/07.django%20rest_framework%E4%BD%BF%E7%94%A8pytest%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django rest_framework使用pytest单元测试"},{itemprop:"description",content:"介绍在django的rest_framework中如何使用pytest进行单元测试而不是自带的测试框架。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/07.django%20rest_framework%E4%BD%BF%E7%94%A8pytest%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95.html",relativePath:"04.编程/01.python/06.django/07.django rest_framework使用pytest单元测试.md",key:"v-77d8c9f4",path:"/pages/c28126/",headers:[{level:2,title:"djang自带测试",slug:"djang自带测试",normalizedTitle:"djang自带测试",charIndex:2},{level:2,title:"rest framework",slug:"rest-framework",normalizedTitle:"rest framework",charIndex:665}],headersStr:"djang自带测试 rest framework",content:'# djang自带测试\n\n> django本身自带了测试框架库，是基于unittest的。\n\n执行 python manager.py test 会对路径所有test*.py 进行测试\n\nfrom django.test import TestCase\nfrom event_track.models.app import Appclass \n\nAppTestCase(TestCase):    \n    def setUp(self):        \n        App.objects.create(name="app1", package_name="package1")        \n        App.objects.create(name="app2", package_name="package2")    \n    def test_app(self):        \n        app1 = App.objects.get(name="app1")        \n        self.assertEqual(app1.package_name, "package1")        \n        app1 = App.objects.get(name="app2")        \n        self.assertEqual(app1.package_name, "package3")\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# rest framework\n\n> 下面是一个简单的测试案例。使用pytest对rest framework进行测试\n\n1. 添加一个配置文件 具体看pytest-django官网\n\n[pytest]\nDJANGO_SETTINGS_MODULE=event_track_root.settings\npython_files = tests.py test_*.py *_tests.py\n\n\n1\n2\n3\n\n\n2. 创建一个model app.py\n\nfrom django.db import models\nclass App(models.Model):    \n    name = models.CharField(max_length=24)    \n    package_name = models.CharField(max_length=50, unique=True)\n\n\n1\n2\n3\n4\n\n\n> 对app的model类进行增删改查的测试 model测试必须添加@pytest.mark.django_db才可以启用数据库。 使用APITestCase对接口进行测试\n\n3. 编写测试用例 test_app.py\n\n\n@pytest.mark.django_db\n@pytest.fixture(scope="module")\ndef init_app_data():\n    App.objects.create(name="app1", package_name="package1")\n    App.objects.create(name="app2", package_name="package2")\n    App.objects.create(name="app3", package_name="package3")\n    App.objects.create(name="app4", package_name="package4")\n\nclass AppTests(APITestCase):\n\n    def test_create_app(self):\n        url = reverse(\'event_track:App-list\')\n        data_list = [{"name": "app1", "package_name": "package1"},\n                     {"name": "app2", "package_name": "package2"},\n                     {"name": "app3", "package_name": "package3"},\n                     {"name": "app4", "package_name": "package4"}\n                     ]\n\n        for data in data_list:\n            response = self.client.post(url, data)\n            self.assertEqual(response.status_code, status.HTTP_201_CREATED)\n\n        self.assertEqual(App.objects.count(), 4)\n        self.assertEqual(App.objects.get(name="app1").package_name, "package1")\n\n    @pytest.mark.usefixtures(\'init_app_data\')\n    def test_delete_app(self):\n        app = App.objects.get(package_name="package3")\n        url = reverse(\'event_track:App-detail\', [app.id])\n        response = self.client.delete(url)\n\n        self.assertEqual(App.objects.count(), 3)\n        with pytest.raises(App.DoesNotExist):\n            App.objects.get(package_name="package3")\n        self.assertEqual(response.status_code, 204)\n\n    @pytest.mark.usefixtures(\'init_app_data\')\n    def test_update_app(self):\n        app = App.objects.get(name="app4")\n        url = reverse(\'event_track:App-detail\', [app.id])\n\n        app.package_name = "package_update"\n        response = self.client.put(url, AppSerializer(app).data)\n\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.data[\'package_name\'], \'package_update\')\n        self.assertEqual(App.objects.get(name="app4").package_name, \'package_update\')\n\n    @pytest.mark.usefixtures(\'init_app_data\')\n    def test_list_app(self):\n        url = reverse(\'event_track:App-list\')\n        response = self.client.get(url, {\'limit\': 2, \'offset\': 2})\n\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(len(response.data[\'results\']), 2)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n',normalizedContent:'# djang自带测试\n\n> django本身自带了测试框架库，是基于unittest的。\n\n执行 python manager.py test 会对路径所有test*.py 进行测试\n\nfrom django.test import testcase\nfrom event_track.models.app import appclass \n\napptestcase(testcase):    \n    def setup(self):        \n        app.objects.create(name="app1", package_name="package1")        \n        app.objects.create(name="app2", package_name="package2")    \n    def test_app(self):        \n        app1 = app.objects.get(name="app1")        \n        self.assertequal(app1.package_name, "package1")        \n        app1 = app.objects.get(name="app2")        \n        self.assertequal(app1.package_name, "package3")\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# rest framework\n\n> 下面是一个简单的测试案例。使用pytest对rest framework进行测试\n\n1. 添加一个配置文件 具体看pytest-django官网\n\n[pytest]\ndjango_settings_module=event_track_root.settings\npython_files = tests.py test_*.py *_tests.py\n\n\n1\n2\n3\n\n\n2. 创建一个model app.py\n\nfrom django.db import models\nclass app(models.model):    \n    name = models.charfield(max_length=24)    \n    package_name = models.charfield(max_length=50, unique=true)\n\n\n1\n2\n3\n4\n\n\n> 对app的model类进行增删改查的测试 model测试必须添加@pytest.mark.django_db才可以启用数据库。 使用apitestcase对接口进行测试\n\n3. 编写测试用例 test_app.py\n\n\n@pytest.mark.django_db\n@pytest.fixture(scope="module")\ndef init_app_data():\n    app.objects.create(name="app1", package_name="package1")\n    app.objects.create(name="app2", package_name="package2")\n    app.objects.create(name="app3", package_name="package3")\n    app.objects.create(name="app4", package_name="package4")\n\nclass apptests(apitestcase):\n\n    def test_create_app(self):\n        url = reverse(\'event_track:app-list\')\n        data_list = [{"name": "app1", "package_name": "package1"},\n                     {"name": "app2", "package_name": "package2"},\n                     {"name": "app3", "package_name": "package3"},\n                     {"name": "app4", "package_name": "package4"}\n                     ]\n\n        for data in data_list:\n            response = self.client.post(url, data)\n            self.assertequal(response.status_code, status.http_201_created)\n\n        self.assertequal(app.objects.count(), 4)\n        self.assertequal(app.objects.get(name="app1").package_name, "package1")\n\n    @pytest.mark.usefixtures(\'init_app_data\')\n    def test_delete_app(self):\n        app = app.objects.get(package_name="package3")\n        url = reverse(\'event_track:app-detail\', [app.id])\n        response = self.client.delete(url)\n\n        self.assertequal(app.objects.count(), 3)\n        with pytest.raises(app.doesnotexist):\n            app.objects.get(package_name="package3")\n        self.assertequal(response.status_code, 204)\n\n    @pytest.mark.usefixtures(\'init_app_data\')\n    def test_update_app(self):\n        app = app.objects.get(name="app4")\n        url = reverse(\'event_track:app-detail\', [app.id])\n\n        app.package_name = "package_update"\n        response = self.client.put(url, appserializer(app).data)\n\n        self.assertequal(response.status_code, 200)\n        self.assertequal(response.data[\'package_name\'], \'package_update\')\n        self.assertequal(app.objects.get(name="app4").package_name, \'package_update\')\n\n    @pytest.mark.usefixtures(\'init_app_data\')\n    def test_list_app(self):\n        url = reverse(\'event_track:app-list\')\n        response = self.client.get(url, {\'limit\': 2, \'offset\': 2})\n\n        self.assertequal(response.status_code, 200)\n        self.assertequal(len(response.data[\'results\']), 2)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django rest_framework 自定义文档",frontmatter:{title:"django rest_framework 自定义文档",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/c3af6a/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"django rest_framework 自动生成文档的功能，能够很好的给前端提供帮助，在文档中可以看到api的参数和其提供的功能信息，并且还能够在上面直接测试api接口。",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django rest_framework 自定义文档"},{name:"twitter:description",content:"django rest_framework 自动生成文档的功能，能够很好的给前端提供帮助，在文档中可以看到api的参数和其提供的功能信息，并且还能够在上面直接测试api接口。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/05.django%20rest_framework%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E6%A1%A3.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django rest_framework 自定义文档"},{property:"og:description",content:"django rest_framework 自动生成文档的功能，能够很好的给前端提供帮助，在文档中可以看到api的参数和其提供的功能信息，并且还能够在上面直接测试api接口。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/05.django%20rest_framework%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E6%A1%A3.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django rest_framework 自定义文档"},{itemprop:"description",content:"django rest_framework 自动生成文档的功能，能够很好的给前端提供帮助，在文档中可以看到api的参数和其提供的功能信息，并且还能够在上面直接测试api接口。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/05.django%20rest_framework%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E6%A1%A3.html",relativePath:"04.编程/01.python/06.django/05.django rest_framework 自定义文档.md",key:"v-226be104",path:"/pages/c3af6a/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"配置",slug:"配置",normalizedTitle:"配置",charIndex:102},{level:2,title:"自定义文档",slug:"自定义文档",normalizedTitle:"自定义文档",charIndex:293},{level:2,title:"schema",slug:"schema",normalizedTitle:"schema",charIndex:335},{level:3,title:"方法一",slug:"方法一",normalizedTitle:"方法一",charIndex:371},{level:3,title:"方法二",slug:"方法二",normalizedTitle:"方法二",charIndex:3082},{level:2,title:"location",slug:"location",normalizedTitle:"location",charIndex:3219}],headersStr:"简介 配置 自定义文档 schema 方法一 方法二 location",content:'# 简介\n\ndjango rest_framework 自动生成文档的功能，能够很好的给前端提供帮助，在文档中可以看到api的参数和其提供的功能信息，并且还能够在上面直接测试api接口。\n\n官网\n\n\n# 配置\n\nurls.py\n\nfrom rest_framework.documentation import include_docs_urls\n\nurlpatterns = [\n    ...\n    url(r\'^docs/\', include_docs_urls(title=\'My API title\'))]\n\n\n1\n2\n3\n4\n5\n\n\n即可使用该url对文档的访问\n\n\n# 自定义文档\n\n虽然可以自动生成文档，但是不是很完善，所以需要自定义写文档。\n\n\n# schema\n\n通过改写AutoSchema来完成自定义文档。\n\n\n# 方法一\n\nget_link是AutoSchema中的函数. 重写get_link函数，对文档中的每个字段的说明进行改写。\n\n集成AutoSchema，在__init__初始化params_desc_dict参数，该参数包含文档中字段对应的注释，然后在get_link对该参数进行解析，并替换字段注释.\n\nclass BaseSchema(AutoSchema):\n    """\n    自动生成的文档会有缺失，或者是因为可读性比较差。所以需要对文档中的字段进行自定义注解。\n    该类是通用的对文档中的get、post、put、delete、patch进行注释。\n    是在已有字段的基础上修改注释.\n    \n    `get`是对get中的字段进行注解说明。\n    `other`是`post`、`put`、`delete`、`patch`\n    \n    例子:\n        {\n            "get": {\n                "字段名": "对该字段进行注释"\n            },\n            "post": {\n                "字段名": "对该字段进行注释"\n            }\n        }\n\n    """\n    def __init__(self, manual_fields=None, params_desc_dict=None):\n        self.params_desc_dict = {\n            "get": {\n                "page": "当前页码",\n                "page_size": "每一页显示的行数. 默认传 10条"\n            },\n            "other": {\n\n            }\n        }\n\n        if params_desc_dict:\n            if \'get\' in params_desc_dict:\n                self.params_desc_dict[\'get\'].update(params_desc_dict[\'get\'])\n\n            if \'other\' in params_desc_dict:\n                self.params_desc_dict[\'other\'].update(params_desc_dict[\'other\'])\n\n        super(BaseSchema, self).__init__(manual_fields)\n\n    def get_link(self, path, method, base_url):\n        link = super(BaseSchema, self).get_link(path, method, base_url)\n\n        fields = []\n\n        params_method = \'get\' if method.lower() == \'get\' else \'other\'\n\n        for field in link.fields:\n            if field.name in self.params_desc_dict[params_method].keys():\n                field = field._replace(\n                    schema=coreschema.String(description=self.params_desc_dict[params_method][field.name]))\n\n            fields.append(field)\n\n        return coreapi.Link(\n            url=link.url,\n            action=link.action,\n            encoding=link.encoding,\n            fields=fields,\n            description=link.description\n        )\n\nperiodictaskSchema = BaseSchema(params_desc_dict={\n    \'other\': {\n        "crontab": "定时crontab. json。 包含的字段有: minute, hour, day_of_week, day_of_month, month_of_year",\n        "name": "该定时任务名称",\n        "task": "模板任务名",\n        "args": "传递给任务模板参数. 数组",\n        "kwargs": "传递给任务模板参数. json字符串",\n        "queue": "将任务放在哪个队列中.",\n        "enabled": "是否开启该任务. True or False. 默认为True",\n        "description": "定时任务说明"\n    }\n})\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n\n\n在view中绑定自定义的schema\n\nclass PeriodictasksViewSet(viewsets.ModelViewSet):\n    queryset = PeriodicTask.objects.all()\n    serializer_class = PeriodictaskSerializer\n    schema = periodictaskSchema\n\n\n1\n2\n3\n4\n\n\n\n# 方法二\n\n如果只是普通的APIView的话，直接在AutoSchema中添加字段即可。\n\ndatabaseInfoSchema = AutoSchema(manual_fields=[\n    coreapi.Field(name="db", required=True, location="query",\n                  schema=coreschema.String(description="数据库host, normal或者sub")),\n    coreapi.Field(name="database", location="query", schema=coreschema.String(description="数据库")),\n    coreapi.Field(name="table", required=True, location="query", schema=coreschema.String(description="数据库表"))\n])\n\n\n1\n2\n3\n4\n5\n6\n\n\n绑定自定义schema\n\nclass DataBaseInfo(APIView):\n    schema = databaseInfoSchema\n\n    def get(self, request):\n        pass\n\n\n1\n2\n3\n4\n5\n\n\n\n# location\n\nLOCATION   描述\nquery      查询. list\nform       表单提交. post\npath       在url中的，/oozieJob/{id}/. read',normalizedContent:'# 简介\n\ndjango rest_framework 自动生成文档的功能，能够很好的给前端提供帮助，在文档中可以看到api的参数和其提供的功能信息，并且还能够在上面直接测试api接口。\n\n官网\n\n\n# 配置\n\nurls.py\n\nfrom rest_framework.documentation import include_docs_urls\n\nurlpatterns = [\n    ...\n    url(r\'^docs/\', include_docs_urls(title=\'my api title\'))]\n\n\n1\n2\n3\n4\n5\n\n\n即可使用该url对文档的访问\n\n\n# 自定义文档\n\n虽然可以自动生成文档，但是不是很完善，所以需要自定义写文档。\n\n\n# schema\n\n通过改写autoschema来完成自定义文档。\n\n\n# 方法一\n\nget_link是autoschema中的函数. 重写get_link函数，对文档中的每个字段的说明进行改写。\n\n集成autoschema，在__init__初始化params_desc_dict参数，该参数包含文档中字段对应的注释，然后在get_link对该参数进行解析，并替换字段注释.\n\nclass baseschema(autoschema):\n    """\n    自动生成的文档会有缺失，或者是因为可读性比较差。所以需要对文档中的字段进行自定义注解。\n    该类是通用的对文档中的get、post、put、delete、patch进行注释。\n    是在已有字段的基础上修改注释.\n    \n    `get`是对get中的字段进行注解说明。\n    `other`是`post`、`put`、`delete`、`patch`\n    \n    例子:\n        {\n            "get": {\n                "字段名": "对该字段进行注释"\n            },\n            "post": {\n                "字段名": "对该字段进行注释"\n            }\n        }\n\n    """\n    def __init__(self, manual_fields=none, params_desc_dict=none):\n        self.params_desc_dict = {\n            "get": {\n                "page": "当前页码",\n                "page_size": "每一页显示的行数. 默认传 10条"\n            },\n            "other": {\n\n            }\n        }\n\n        if params_desc_dict:\n            if \'get\' in params_desc_dict:\n                self.params_desc_dict[\'get\'].update(params_desc_dict[\'get\'])\n\n            if \'other\' in params_desc_dict:\n                self.params_desc_dict[\'other\'].update(params_desc_dict[\'other\'])\n\n        super(baseschema, self).__init__(manual_fields)\n\n    def get_link(self, path, method, base_url):\n        link = super(baseschema, self).get_link(path, method, base_url)\n\n        fields = []\n\n        params_method = \'get\' if method.lower() == \'get\' else \'other\'\n\n        for field in link.fields:\n            if field.name in self.params_desc_dict[params_method].keys():\n                field = field._replace(\n                    schema=coreschema.string(description=self.params_desc_dict[params_method][field.name]))\n\n            fields.append(field)\n\n        return coreapi.link(\n            url=link.url,\n            action=link.action,\n            encoding=link.encoding,\n            fields=fields,\n            description=link.description\n        )\n\nperiodictaskschema = baseschema(params_desc_dict={\n    \'other\': {\n        "crontab": "定时crontab. json。 包含的字段有: minute, hour, day_of_week, day_of_month, month_of_year",\n        "name": "该定时任务名称",\n        "task": "模板任务名",\n        "args": "传递给任务模板参数. 数组",\n        "kwargs": "传递给任务模板参数. json字符串",\n        "queue": "将任务放在哪个队列中.",\n        "enabled": "是否开启该任务. true or false. 默认为true",\n        "description": "定时任务说明"\n    }\n})\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n\n\n在view中绑定自定义的schema\n\nclass periodictasksviewset(viewsets.modelviewset):\n    queryset = periodictask.objects.all()\n    serializer_class = periodictaskserializer\n    schema = periodictaskschema\n\n\n1\n2\n3\n4\n\n\n\n# 方法二\n\n如果只是普通的apiview的话，直接在autoschema中添加字段即可。\n\ndatabaseinfoschema = autoschema(manual_fields=[\n    coreapi.field(name="db", required=true, location="query",\n                  schema=coreschema.string(description="数据库host, normal或者sub")),\n    coreapi.field(name="database", location="query", schema=coreschema.string(description="数据库")),\n    coreapi.field(name="table", required=true, location="query", schema=coreschema.string(description="数据库表"))\n])\n\n\n1\n2\n3\n4\n5\n6\n\n\n绑定自定义schema\n\nclass databaseinfo(apiview):\n    schema = databaseinfoschema\n\n    def get(self, request):\n        pass\n\n\n1\n2\n3\n4\n5\n\n\n\n# location\n\nlocation   描述\nquery      查询. list\nform       表单提交. post\npath       在url中的，/ooziejob/{id}/. read',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django restframework choice 自定义输出数据",frontmatter:{title:"django restframework choice 自定义输出数据",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/b90015/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍如何在django restframework中使用choice来自定义输出数据。",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django restframework choice 自定义输出数据"},{name:"twitter:description",content:"介绍如何在django restframework中使用choice来自定义输出数据。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/08.django%20restframework%20choice%20%E8%87%AA%E5%AE%9A%E4%B9%89%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django restframework choice 自定义输出数据"},{property:"og:description",content:"介绍如何在django restframework中使用choice来自定义输出数据。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/08.django%20restframework%20choice%20%E8%87%AA%E5%AE%9A%E4%B9%89%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django restframework choice 自定义输出数据"},{itemprop:"description",content:"介绍如何在django restframework中使用choice来自定义输出数据。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/08.django%20restframework%20choice%20%E8%87%AA%E5%AE%9A%E4%B9%89%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE.html",relativePath:"04.编程/01.python/06.django/08.django restframework choice 自定义输出数据.md",key:"v-22b0df18",path:"/pages/b90015/",headers:[{level:2,title:"问题",slug:"问题",normalizedTitle:"问题",charIndex:2},{level:2,title:"解决方案",slug:"解决方案",normalizedTitle:"解决方案",charIndex:502}],headersStr:"问题 解决方案",content:"# 问题\n\n我有一个这样的需求，返回的数据json中返回的是id，但是我想要得到该id对应的name。\n\nid对应的name\n\nPlatformType = (   \n    (0, '通用'),   \n    (1, '前装'),   \n    (2, '后装'),   \n    (3, '海外前装'),   \n    (4, '海外后装'),   \n    (5, '小系统')\n)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nclass TrackSerializer(serializers.ModelSerializer):\n    \n    platform = serializers.ChoiceField(choices=PlatformType)\n    \n    class Meta:    \n        model = Track    \n        fields = \"__all__\"\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n返回的结果是:\n\n{\n    platform: 1\n}\n\n\n1\n2\n3\n\n\n但是我想要的是1对应的前装，这个时候需要自定义返回的数据。\n\n\n# 解决方案\n\n 1. 自定义字段类型，重写ChoiceField字段类，并重写to_representation方法，在序列化platform字段时，会调用to_representation方法转换成我们想要的格式。\n\nclass PlatFormField(serializers.ChoiceField):    \n    def to_representation(self, value: Any):        \n        return self.choices[value]\n\nclass TrackSerializer(serializers.ModelSerializer):\n    \n    platform = PlatFormField(choices=PlatformType)\n    \n    class Meta:    \n        model = Track    \n        fields = \"__all__\"\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n 2. 重写显示的字段。\n\n将platform字段重新进行改写，获取其显示的名字。\n\nclass TrackSerializer(serializers.ModelSerializer):\n    platform = serializers.SerializerMethodField()\n    class Meta:\n        model = Track\n        fields = \"__all__\"\n\ndef get_platform(self, obj):\n    return obj.get_platform_display()\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n",normalizedContent:"# 问题\n\n我有一个这样的需求，返回的数据json中返回的是id，但是我想要得到该id对应的name。\n\nid对应的name\n\nplatformtype = (   \n    (0, '通用'),   \n    (1, '前装'),   \n    (2, '后装'),   \n    (3, '海外前装'),   \n    (4, '海外后装'),   \n    (5, '小系统')\n)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nclass trackserializer(serializers.modelserializer):\n    \n    platform = serializers.choicefield(choices=platformtype)\n    \n    class meta:    \n        model = track    \n        fields = \"__all__\"\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n返回的结果是:\n\n{\n    platform: 1\n}\n\n\n1\n2\n3\n\n\n但是我想要的是1对应的前装，这个时候需要自定义返回的数据。\n\n\n# 解决方案\n\n 1. 自定义字段类型，重写choicefield字段类，并重写to_representation方法，在序列化platform字段时，会调用to_representation方法转换成我们想要的格式。\n\nclass platformfield(serializers.choicefield):    \n    def to_representation(self, value: any):        \n        return self.choices[value]\n\nclass trackserializer(serializers.modelserializer):\n    \n    platform = platformfield(choices=platformtype)\n    \n    class meta:    \n        model = track    \n        fields = \"__all__\"\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n 2. 重写显示的字段。\n\n将platform字段重新进行改写，获取其显示的名字。\n\nclass trackserializer(serializers.modelserializer):\n    platform = serializers.serializermethodfield()\n    class meta:\n        model = track\n        fields = \"__all__\"\n\ndef get_platform(self, obj):\n    return obj.get_platform_display()\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django Filtering 使用",frontmatter:{title:"django Filtering 使用",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/cfdb5f/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍django-filter是如何使用的。",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217188654.png#alt="},{name:"twitter:title",content:"django Filtering 使用"},{name:"twitter:description",content:"介绍django-filter是如何使用的。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217188654.png#alt="},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/09.django%20Filtering%20%E4%BD%BF%E7%94%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django Filtering 使用"},{property:"og:description",content:"介绍django-filter是如何使用的。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217188654.png#alt="},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/09.django%20Filtering%20%E4%BD%BF%E7%94%A8.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django Filtering 使用"},{itemprop:"description",content:"介绍django-filter是如何使用的。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217188654.png#alt="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/09.django%20Filtering%20%E4%BD%BF%E7%94%A8.html",relativePath:"04.编程/01.python/06.django/09.django Filtering 使用.md",key:"v-fab79492",path:"/pages/cfdb5f/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"准备工作",slug:"准备工作",normalizedTitle:"准备工作",charIndex:157},{level:2,title:"DjangoFilterBackend",slug:"djangofilterbackend",normalizedTitle:"djangofilterbackend",charIndex:97},{level:2,title:"使用默认的过滤",slug:"使用默认的过滤",normalizedTitle:"使用默认的过滤",charIndex:334},{level:2,title:"自定义过滤",slug:"自定义过滤",normalizedTitle:"自定义过滤",charIndex:801},{level:2,title:"SearchFilter",slug:"searchfilter",normalizedTitle:"searchfilter",charIndex:121},{level:2,title:"OrderingFilter",slug:"orderingfilter",normalizedTitle:"orderingfilter",charIndex:138},{level:2,title:"自定义过滤条件",slug:"自定义过滤条件",normalizedTitle:"自定义过滤条件",charIndex:2994}],headersStr:"简介 准备工作 DjangoFilterBackend 使用默认的过滤 自定义过滤 SearchFilter OrderingFilter 自定义过滤条件",content:"# 简介\n\ndjango-filter是单独的一个库，不属于djangorestframework中的，属于外部库引用进来使用。下面就来介绍下filter\n\n有三种filter方式:\n\n 1. DjangoFilterBackend\n 2. SearchFilter\n 3. OrderingFilter\n\n\n# 准备工作\n\n首先需要安装django-filter\n\n> pip install django-filter\n\n然后需要将django_filters 添加到 INSTALLED_APPS中\n\nINSTALLED_APPS = [\n    'django_filters',\n]\n\n\n1\n2\n3\n\n\n\n# DjangoFilterBackend\n\n\n# 使用默认的过滤\n\n在View中添加filter_backends属性,设置过滤方式DjangoFilterBackend，并且设置过滤的属性。\n\n\nfrom django_filters.rest_framework import DjangoFilterBackend\n\nclass GoodsListViewSet(ModelViewSet):    \n    queryset = Goods.objects.all()    \n    serializer_class = GoodsSerializer    \n    pagination_class = MyPagination    \n    filter_backends = (DjangoFilterBackend,)    \n    filterset_fields = ('name', 'shop_price')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在调试界面中会出现过滤器选项, 可以在其中过滤name和shop_price两个属性的值\n\n\n# 自定义过滤\n\n创建filters.py，在里面定义自己的过滤器。 可以通过最小的价格、最大的价格，和模糊查询名字去过滤想要的数据。\n\nfrom django_filters import FilterSet, NumberFilter, CharFilter\nfrom .models import Goods\n\nclass GoodsFilter(FilterSet):   \n    \"\"\"    商品的过滤类    \"\"\"    \n    price_min = NumberFilter(field_name='shop_price', help_text=\"最低价格\", lookup_expr='gte')    \n    price_max = NumberFilter(field_name='shop_price', lookup_expr='lte')    \n    name = CharFilter(field_name='name', lookup_expr=\"icontains\")    \n    class Meta:        \n        model = Goods        \n        fields = ['price_min', 'price_max', 'name']\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n将该过滤器添加到view中 view.py\n\nclass GoodsListViewSet(ModelViewSet):    \n    queryset = Goods.objects.all()    \n    serializer_class = GoodsSerializer   \n    pagination_class = MyPagination    \n    filter_backends = (DjangoFilterBackend,)    \n    filter_class = GoodsFilter\n\n\n1\n2\n3\n4\n5\n6\n\n\n最后可以通过 http://127.0.0.1:8000/goods/?price_min=150&price_max=160&name=水果 去过滤得到想要的数据。\n\n\n# SearchFilter\n\n这个Filter是基于Django的搜索。现在我们将SearchFilter集成到过滤里面来。在filter_backends中添加SearchFiler，然后再在search_fields中添加需要搜索的字段即可，在搜索的字段前面字符变量来提高搜索效率。\n\n * '^' Starts-with search.\n * '=' Exact matches.\n * '@' Full-text search. (Currently only supported Django's MySQL backend.)\n * '$' Regex search.\n\nview.py\n\nfrom rest_framework.filters import SearchFilter\n\nclass GoodsListViewSet(ModelViewSet):    \n    queryset = Goods.objects.all()    \n    serializer_class = GoodsSerializer    \n    pagination_class = MyPagination    \n    filter_backends = (DjangoFilterBackend, SearchFilter)    \n    filter_class = GoodsFilter    \n    search_fields = (\"=name\", 'goods_brief', 'goods_desc')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# OrderingFilter\n\n可以对数据进行排序筛选数据。我们将其加入进去\n\nview.py\n\nfrom rest_framework.filters import SearchFilter, OrderingFilter\n\n\n\nclass GoodsListViewSet(ModelViewSet):    \n    queryset = Goods.objects.all()    \n    serializer_class = GoodsSerializer    \n    pagination_class = MyPagination    \n    filter_backends = (DjangoFilterBackend, SearchFilter, OrderingFilter) \n    filter_class = GoodsFilter    \n    search_fields = (\"=name\", 'goods_brief', 'goods_desc')\n    ordering_fields = (\"sold_num\", \"add_time\")\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 自定义过滤条件\n\n修改filters.py文件，编写过滤方法top_category_filter绑定到top_category字段中，即可通过该属性名进行相应的筛选。\n\nclass GoodsFilter(FilterSet):    \n    \"\"\"    商品的过滤类    \"\"\"    \n    pricemin = NumberFilter(field_name='shop_price', help_text=\"最低价格\", lookup_expr='gte')    \n    pricemax = NumberFilter(field_name='shop_price', lookup_expr='lte')    \n    name = CharFilter(field_name='name', lookup_expr=\"icontains\")   \n    top_category = NumberFilter(method='top_category_filter')    \n    \n    def top_category_filter(self, queryset, name, value):        \n        return queryset.filter(Q(category_id=value) | Q(category__parent_category_id=value) | (category__parent_category__parent_category_id=value))\n    \n    class Meta:        \n        model = Goods\n        fields = ['pricemin', 'pricemax', 'name']\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n",normalizedContent:"# 简介\n\ndjango-filter是单独的一个库，不属于djangorestframework中的，属于外部库引用进来使用。下面就来介绍下filter\n\n有三种filter方式:\n\n 1. djangofilterbackend\n 2. searchfilter\n 3. orderingfilter\n\n\n# 准备工作\n\n首先需要安装django-filter\n\n> pip install django-filter\n\n然后需要将django_filters 添加到 installed_apps中\n\ninstalled_apps = [\n    'django_filters',\n]\n\n\n1\n2\n3\n\n\n\n# djangofilterbackend\n\n\n# 使用默认的过滤\n\n在view中添加filter_backends属性,设置过滤方式djangofilterbackend，并且设置过滤的属性。\n\n\nfrom django_filters.rest_framework import djangofilterbackend\n\nclass goodslistviewset(modelviewset):    \n    queryset = goods.objects.all()    \n    serializer_class = goodsserializer    \n    pagination_class = mypagination    \n    filter_backends = (djangofilterbackend,)    \n    filterset_fields = ('name', 'shop_price')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在调试界面中会出现过滤器选项, 可以在其中过滤name和shop_price两个属性的值\n\n\n# 自定义过滤\n\n创建filters.py，在里面定义自己的过滤器。 可以通过最小的价格、最大的价格，和模糊查询名字去过滤想要的数据。\n\nfrom django_filters import filterset, numberfilter, charfilter\nfrom .models import goods\n\nclass goodsfilter(filterset):   \n    \"\"\"    商品的过滤类    \"\"\"    \n    price_min = numberfilter(field_name='shop_price', help_text=\"最低价格\", lookup_expr='gte')    \n    price_max = numberfilter(field_name='shop_price', lookup_expr='lte')    \n    name = charfilter(field_name='name', lookup_expr=\"icontains\")    \n    class meta:        \n        model = goods        \n        fields = ['price_min', 'price_max', 'name']\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n将该过滤器添加到view中 view.py\n\nclass goodslistviewset(modelviewset):    \n    queryset = goods.objects.all()    \n    serializer_class = goodsserializer   \n    pagination_class = mypagination    \n    filter_backends = (djangofilterbackend,)    \n    filter_class = goodsfilter\n\n\n1\n2\n3\n4\n5\n6\n\n\n最后可以通过 http://127.0.0.1:8000/goods/?price_min=150&price_max=160&name=水果 去过滤得到想要的数据。\n\n\n# searchfilter\n\n这个filter是基于django的搜索。现在我们将searchfilter集成到过滤里面来。在filter_backends中添加searchfiler，然后再在search_fields中添加需要搜索的字段即可，在搜索的字段前面字符变量来提高搜索效率。\n\n * '^' starts-with search.\n * '=' exact matches.\n * '@' full-text search. (currently only supported django's mysql backend.)\n * '$' regex search.\n\nview.py\n\nfrom rest_framework.filters import searchfilter\n\nclass goodslistviewset(modelviewset):    \n    queryset = goods.objects.all()    \n    serializer_class = goodsserializer    \n    pagination_class = mypagination    \n    filter_backends = (djangofilterbackend, searchfilter)    \n    filter_class = goodsfilter    \n    search_fields = (\"=name\", 'goods_brief', 'goods_desc')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# orderingfilter\n\n可以对数据进行排序筛选数据。我们将其加入进去\n\nview.py\n\nfrom rest_framework.filters import searchfilter, orderingfilter\n\n\n\nclass goodslistviewset(modelviewset):    \n    queryset = goods.objects.all()    \n    serializer_class = goodsserializer    \n    pagination_class = mypagination    \n    filter_backends = (djangofilterbackend, searchfilter, orderingfilter) \n    filter_class = goodsfilter    \n    search_fields = (\"=name\", 'goods_brief', 'goods_desc')\n    ordering_fields = (\"sold_num\", \"add_time\")\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 自定义过滤条件\n\n修改filters.py文件，编写过滤方法top_category_filter绑定到top_category字段中，即可通过该属性名进行相应的筛选。\n\nclass goodsfilter(filterset):    \n    \"\"\"    商品的过滤类    \"\"\"    \n    pricemin = numberfilter(field_name='shop_price', help_text=\"最低价格\", lookup_expr='gte')    \n    pricemax = numberfilter(field_name='shop_price', lookup_expr='lte')    \n    name = charfilter(field_name='name', lookup_expr=\"icontains\")   \n    top_category = numberfilter(method='top_category_filter')    \n    \n    def top_category_filter(self, queryset, name, value):        \n        return queryset.filter(q(category_id=value) | q(category__parent_category_id=value) | (category__parent_category__parent_category_id=value))\n    \n    class meta:        \n        model = goods\n        fields = ['pricemin', 'pricemax', 'name']\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django viewset 和 Router 配合使用时报的错",frontmatter:{title:"django viewset 和 Router 配合使用时报的错",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/e75ceb/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"解决django viewset和router配合使用时报的错误",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django viewset 和 Router 配合使用时报的错"},{name:"twitter:description",content:"解决django viewset和router配合使用时报的错误"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/10.django%20viewset%20%E5%92%8C%20Router%20%E9%85%8D%E5%90%88%E4%BD%BF%E7%94%A8%E6%97%B6%E6%8A%A5%E7%9A%84%E9%94%99.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django viewset 和 Router 配合使用时报的错"},{property:"og:description",content:"解决django viewset和router配合使用时报的错误"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/10.django%20viewset%20%E5%92%8C%20Router%20%E9%85%8D%E5%90%88%E4%BD%BF%E7%94%A8%E6%97%B6%E6%8A%A5%E7%9A%84%E9%94%99.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django viewset 和 Router 配合使用时报的错"},{itemprop:"description",content:"解决django viewset和router配合使用时报的错误"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/10.django%20viewset%20%E5%92%8C%20Router%20%E9%85%8D%E5%90%88%E4%BD%BF%E7%94%A8%E6%97%B6%E6%8A%A5%E7%9A%84%E9%94%99.html",relativePath:"04.编程/01.python/06.django/10.django viewset 和 Router 配合使用时报的错.md",key:"v-fab7554a",path:"/pages/e75ceb/",headersStr:null,content:"报错内容:\n\n> 'basename' argument not specified, and could not automatically determine the name from the viewset, as it does not have a '.queryset' attribute.\n\nbasename是Router.register()中的一个属性。\n\n如果没有设置basename将会自动的基于viewset中的queryset属性。如果不使用queryset属性，自定义get_quertset方法，那么需要设置basename参数。\n\n示例代码如下. 这里使用了自定义的get_quertset方法，所以router.register()中必须加上basename，不然会出现以上错误 view.py\n\nclass GoodsListViewSet(ModelViewSet):    \n    # queryset = Goods.objects.all()    \n    serializer_class = GoodsSerializer    \n    pagination_class = MyPagination    \n    \n    def get_queryset(self):        \n        queryset = Goods.objects.all()        \n        price_min = self.request.query_params.get(\"price_min\", 0)        \n        if price_min:            \n            queryset = queryset.filter(shop_price__gt=int(price_min))        \n    \n    return queryset\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nurl.py\n\nfrom rest_framework.routers import DefaultRouter\nrouter = DefaultRouter()\nrouter.register(r'goods', GoodsListViewSet, base_name=\"goods\")\n\n\n1\n2\n3\n",normalizedContent:"报错内容:\n\n> 'basename' argument not specified, and could not automatically determine the name from the viewset, as it does not have a '.queryset' attribute.\n\nbasename是router.register()中的一个属性。\n\n如果没有设置basename将会自动的基于viewset中的queryset属性。如果不使用queryset属性，自定义get_quertset方法，那么需要设置basename参数。\n\n示例代码如下. 这里使用了自定义的get_quertset方法，所以router.register()中必须加上basename，不然会出现以上错误 view.py\n\nclass goodslistviewset(modelviewset):    \n    # queryset = goods.objects.all()    \n    serializer_class = goodsserializer    \n    pagination_class = mypagination    \n    \n    def get_queryset(self):        \n        queryset = goods.objects.all()        \n        price_min = self.request.query_params.get(\"price_min\", 0)        \n        if price_min:            \n            queryset = queryset.filter(shop_price__gt=int(price_min))        \n    \n    return queryset\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nurl.py\n\nfrom rest_framework.routers import defaultrouter\nrouter = defaultrouter()\nrouter.register(r'goods', goodslistviewset, base_name=\"goods\")\n\n\n1\n2\n3\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django model的序列化",frontmatter:{title:"django model的序列化",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/acdd50/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"django model如何实现序列化。",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217291865.png#alt="},{name:"twitter:title",content:"django model的序列化"},{name:"twitter:description",content:"django model如何实现序列化。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217291865.png#alt="},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/11.django%20model%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django model的序列化"},{property:"og:description",content:"django model如何实现序列化。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217291865.png#alt="},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/11.django%20model%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django model的序列化"},{itemprop:"description",content:"django model如何实现序列化。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604217291865.png#alt="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/11.django%20model%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96.html",relativePath:"04.编程/01.python/06.django/11.django model的序列化.md",key:"v-15cbdfc3",path:"/pages/acdd50/",headersStr:null,content:'网络传输数据现在流行的是json数据格式，所以非常需要将数据库查询的到对象数据序列化成json格式，然后返回给前端进行数据展示。\n\n下面讨论在django中如何更方便的将model 序列化。\n\n一个goods的modle如下。\n\n class Goods(models.Model):\n    name = models.CharField(max_length=100, verbose_name="商品名")\n    market_price = models.FloatField(default=0, verbose_name="市场价格")\n    goods_front_image = models.ImageField(upload_to="goods/images/", null=True, blank=True, verbose_name="封面图")    \n    .....\n\n\n\n1\n2\n3\n4\n5\n6\n\n\n序列化一. 最原始的model序列化，比较繁琐..太不智能了.\n\ngoodList = Goods.objects.all()[:10]\nfor good in goodList:\n    json_dict = {}\n    json_dict["name"] = good.name                    \n    json_dict["market_price"] = good.market_price\n    json_dict["add_time"] = good.add_time\n    json_list.append(json_dict)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n序列化二.\n\nfrom django.forms.models import model_to_dict\n\ngoodsList = Goods.objects.all()[:10]\nfor goods in goodsList:    json_list.append(model_to_dict(good))\n\n\n1\n2\n3\n4\n\n\n通过使用model_to_dict 更方便的去序列化goods对象。唯一不足的是无法序列化ImageField字段。\n\n\n\n序列化三.\n\ngoodsList = Goods.objects.all()[:10]\ngoods_json = serialize(\'json\', goodList)\n\n\n1\n2\n\n\n直接将整个goods list 进行序列化，更加方便的使用。但是虽然能够将ImageField序列化，但是得到的图片路径是从数据库中拿到的，并不是图片真实的路径，前端拿到后需要做处理才能使用。\n\n\n\n最后，还有没有更方便的序列化方式呢，当然有，去了解下djangorestframework吧，后期我也会有写关于该框架的博客。',normalizedContent:'网络传输数据现在流行的是json数据格式，所以非常需要将数据库查询的到对象数据序列化成json格式，然后返回给前端进行数据展示。\n\n下面讨论在django中如何更方便的将model 序列化。\n\n一个goods的modle如下。\n\n class goods(models.model):\n    name = models.charfield(max_length=100, verbose_name="商品名")\n    market_price = models.floatfield(default=0, verbose_name="市场价格")\n    goods_front_image = models.imagefield(upload_to="goods/images/", null=true, blank=true, verbose_name="封面图")    \n    .....\n\n\n\n1\n2\n3\n4\n5\n6\n\n\n序列化一. 最原始的model序列化，比较繁琐..太不智能了.\n\ngoodlist = goods.objects.all()[:10]\nfor good in goodlist:\n    json_dict = {}\n    json_dict["name"] = good.name                    \n    json_dict["market_price"] = good.market_price\n    json_dict["add_time"] = good.add_time\n    json_list.append(json_dict)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n序列化二.\n\nfrom django.forms.models import model_to_dict\n\ngoodslist = goods.objects.all()[:10]\nfor goods in goodslist:    json_list.append(model_to_dict(good))\n\n\n1\n2\n3\n4\n\n\n通过使用model_to_dict 更方便的去序列化goods对象。唯一不足的是无法序列化imagefield字段。\n\n\n\n序列化三.\n\ngoodslist = goods.objects.all()[:10]\ngoods_json = serialize(\'json\', goodlist)\n\n\n1\n2\n\n\n直接将整个goods list 进行序列化，更加方便的使用。但是虽然能够将imagefield序列化，但是得到的图片路径是从数据库中拿到的，并不是图片真实的路径，前端拿到后需要做处理才能使用。\n\n\n\n最后，还有没有更方便的序列化方式呢，当然有，去了解下djangorestframework吧，后期我也会有写关于该框架的博客。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django中使用AbStractUser",frontmatter:{title:"django中使用AbStractUser",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/382755/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍在django中如何使用AbStractUser",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django中使用AbStractUser"},{name:"twitter:description",content:"介绍在django中如何使用AbStractUser"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/12.django%E4%B8%AD%E4%BD%BF%E7%94%A8AbStractUser.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django中使用AbStractUser"},{property:"og:description",content:"介绍在django中如何使用AbStractUser"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/12.django%E4%B8%AD%E4%BD%BF%E7%94%A8AbStractUser.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django中使用AbStractUser"},{itemprop:"description",content:"介绍在django中如何使用AbStractUser"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/12.django%E4%B8%AD%E4%BD%BF%E7%94%A8AbStractUser.html",relativePath:"04.编程/01.python/06.django/12.django中使用AbStractUser.md",key:"v-74cd7d9e",path:"/pages/382755/",headersStr:null,content:"> Django内置的User对象，已经包含了一些主要的属性，如username、password、email等，但实际情况可能还需要昵称、头像等其他属性，仅仅使用内置的User属性是不够的。\n> \n> 通过使用AbstractUser可以对User进行扩展使用，添加用户自定义的属性。\n\nUser模型源码如下。\n\nclass User(AbstractUser):\n    class Meta(AbstractUser.Meta):\n        swappable = 'AUTH_USER_MODEL'\n\n\n1\n2\n3\n\n\n由此可见，User对AbstractUser仅仅是继承，没有进行任何的扩展。所以我们继承AbstractUser可以获得User的所有特性。\n\n * model中使用\n\n继承AbstractUser\n\nfrom django.contrib.auth.models import AbstractUser\n\nclass MyUser(AbstractUser):\n    pass\n\n\n1\n2\n3\n4\n\n * 全局settings.py中设置\n\n覆盖默认的user model\n\nAUTH_USER_MODEL = 'app.MyUser'\n\n\n1\n\n * 在admin.py中注册MyUser\n\nfrom django.contrib import admin\nfrom .models import UserProfile\nadmin.site.register(UserProfile,UserAdmin)  \n#用UserAdmin去注册UserProfile\n\n\n1\n2\n3\n4\n",normalizedContent:"> django内置的user对象，已经包含了一些主要的属性，如username、password、email等，但实际情况可能还需要昵称、头像等其他属性，仅仅使用内置的user属性是不够的。\n> \n> 通过使用abstractuser可以对user进行扩展使用，添加用户自定义的属性。\n\nuser模型源码如下。\n\nclass user(abstractuser):\n    class meta(abstractuser.meta):\n        swappable = 'auth_user_model'\n\n\n1\n2\n3\n\n\n由此可见，user对abstractuser仅仅是继承，没有进行任何的扩展。所以我们继承abstractuser可以获得user的所有特性。\n\n * model中使用\n\n继承abstractuser\n\nfrom django.contrib.auth.models import abstractuser\n\nclass myuser(abstractuser):\n    pass\n\n\n1\n2\n3\n4\n\n * 全局settings.py中设置\n\n覆盖默认的user model\n\nauth_user_model = 'app.myuser'\n\n\n1\n\n * 在admin.py中注册myuser\n\nfrom django.contrib import admin\nfrom .models import userprofile\nadmin.site.register(userprofile,useradmin)  \n#用useradmin去注册userprofile\n\n\n1\n2\n3\n4\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users",frontmatter:{title:"django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/060c51/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"使用pycharm professional 开发django时出现以下异常。",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604218742346.png#alt="},{name:"twitter:title",content:"django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users"},{name:"twitter:description",content:"使用pycharm professional 开发django时出现以下异常。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604218742346.png#alt="},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/13.django.core.exceptions.ImproperlyConfigured%20Application%20labels%20aren't%20unique,%20duplicates%20users.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users"},{property:"og:description",content:"使用pycharm professional 开发django时出现以下异常。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604218742346.png#alt="},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/13.django.core.exceptions.ImproperlyConfigured%20Application%20labels%20aren't%20unique,%20duplicates%20users.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users"},{itemprop:"description",content:"使用pycharm professional 开发django时出现以下异常。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1604218742346.png#alt="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/13.django.core.exceptions.ImproperlyConfigured%20Application%20labels%20aren't%20unique,%20duplicates%20users.html",relativePath:"04.编程/01.python/06.django/13.django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users.md",key:"v-37cf929d",path:"/pages/060c51/",headersStr:null,content:"使用pycharm professional 开发django时出现以下异常。\n\n> django.core.exceptions.ImproperlyConfigured: Application labels aren't unique, duplicates: users\n\n查找资料后发现，因为users应用重复了，所以报错。\n\n> 在使用pycharm professional 创建django项目时，已经创建了users 应用，并自动添加到项目中。\n\n\n\n> 后面再在INSTALLED_APPS中添加users则会重复添加users应用。\n\n",normalizedContent:"使用pycharm professional 开发django时出现以下异常。\n\n> django.core.exceptions.improperlyconfigured: application labels aren't unique, duplicates: users\n\n查找资料后发现，因为users应用重复了，所以报错。\n\n> 在使用pycharm professional 创建django项目时，已经创建了users 应用，并自动添加到项目中。\n\n\n\n> 后面再在installed_apps中添加users则会重复添加users应用。\n\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django 中 media配置",frontmatter:{title:"django 中 media配置",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/de01e2/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"media文件夹一般用于上传媒体文件到服务中存放的地方。介绍在django中如何使用media的配置",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django 中 media配置"},{name:"twitter:description",content:"media文件夹一般用于上传媒体文件到服务中存放的地方。介绍在django中如何使用media的配置"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/14.django%20%E4%B8%AD%20media%E9%85%8D%E7%BD%AE.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django 中 media配置"},{property:"og:description",content:"media文件夹一般用于上传媒体文件到服务中存放的地方。介绍在django中如何使用media的配置"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/14.django%20%E4%B8%AD%20media%E9%85%8D%E7%BD%AE.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django 中 media配置"},{itemprop:"description",content:"media文件夹一般用于上传媒体文件到服务中存放的地方。介绍在django中如何使用media的配置"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/14.django%20%E4%B8%AD%20media%E9%85%8D%E7%BD%AE.html",relativePath:"04.编程/01.python/06.django/14.django 中 media配置.md",key:"v-40dce165",path:"/pages/de01e2/",headersStr:null,content:'media文件夹一般用于上传媒体文件到服务中存放的地方。\n\n配置\n\n 1. 在项目中创建media文件夹\n\n 2. models 配置\n\nclass UserModel(models.Model):\n    \n    # 文件会上传到 /media/users目录下\n    image = models.ImageField(max_length=200, upload_to="users/")\n\n\n1\n2\n3\n4\n\n 3. settings 配置\n\nMEDIA_URL = "/media/"\nMEDIA_ROOT = os.path.join(BASE_DIR, "media")\n\n\n1\n2\n\n 4. urls.py 配置\n\nfrom django.urls import re_path\nfrom settings import MEDIA_ROOT\n\nurlpatterns = [    \n    re_path(r\'^media/(?P<path>.*)$\', serve, {"document_root": MEDIA_ROOT})\n]\n\n\n1\n2\n3\n4\n5\n6\n\n 5. 测试\n\n> 通过localhost:8000/media/user/a.jpg 可以访问图片',normalizedContent:'media文件夹一般用于上传媒体文件到服务中存放的地方。\n\n配置\n\n 1. 在项目中创建media文件夹\n\n 2. models 配置\n\nclass usermodel(models.model):\n    \n    # 文件会上传到 /media/users目录下\n    image = models.imagefield(max_length=200, upload_to="users/")\n\n\n1\n2\n3\n4\n\n 3. settings 配置\n\nmedia_url = "/media/"\nmedia_root = os.path.join(base_dir, "media")\n\n\n1\n2\n\n 4. urls.py 配置\n\nfrom django.urls import re_path\nfrom settings import media_root\n\nurlpatterns = [    \n    re_path(r\'^media/(?p<path>.*)$\', serve, {"document_root": media_root})\n]\n\n\n1\n2\n3\n4\n5\n6\n\n 5. 测试\n\n> 通过localhost:8000/media/user/a.jpg 可以访问图片',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django 外键引用自身和on_delete参数",frontmatter:{title:"django 外键引用自身和on_delete参数",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/b422bd/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"django中使用外键引用自身的方法及on_delete参数的配置",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django 外键引用自身和on_delete参数"},{name:"twitter:description",content:"django中使用外键引用自身的方法及on_delete参数的配置"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/15.django%20%E5%A4%96%E9%94%AE%E5%BC%95%E7%94%A8%E8%87%AA%E8%BA%AB%E5%92%8Con_delete%E5%8F%82%E6%95%B0.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django 外键引用自身和on_delete参数"},{property:"og:description",content:"django中使用外键引用自身的方法及on_delete参数的配置"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/15.django%20%E5%A4%96%E9%94%AE%E5%BC%95%E7%94%A8%E8%87%AA%E8%BA%AB%E5%92%8Con_delete%E5%8F%82%E6%95%B0.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django 外键引用自身和on_delete参数"},{itemprop:"description",content:"django中使用外键引用自身的方法及on_delete参数的配置"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/15.django%20%E5%A4%96%E9%94%AE%E5%BC%95%E7%94%A8%E8%87%AA%E8%BA%AB%E5%92%8Con_delete%E5%8F%82%E6%95%B0.html",relativePath:"04.编程/01.python/06.django/15.django 外键引用自身和on_delete参数.md",key:"v-722217eb",path:"/pages/b422bd/",headersStr:null,content:"案例. 该模型使用外键引用自己本身。\n\nfrom django.db import models\n\nclass Category(models.Model):\n    name = models.TextField()\n    parent_cat = models.ForeignKey('self',on_delete=models.CASCADE)\n\n\n1\n2\n3\n4\n5\n\n\non_delete参数如下:\n\n 1. CASCADE：级联操作。如果外键对应的那条数据被删除了，那么这条数据也会被删除。\n\n 2. PROTECT：受保护。即只要这条数据引用了外键的那条数据，那么就不能删除外键的那条数据。如果我们强行删除，Django就会报错。\n\n 3. SET_NULL：设置为空。如果外键的那条数据被删除了，那么在本条数据上就将这个字段设置为空。如果设置这个选项，前提是要指定这个字段可以为空。\n\n 4. SET_DEFAULT：设置默认值。如果外键的那条数据被删除了，那么本条数据上就将这个字段设置为默认值。如果设置这个选项，== 前提是要指定这个字段一个默认值 ==。\n\n 5. SET()：如果外键的那条数据被删除了。那么将会获取SET函数中的值来作为这个外键的值。SET函数可以接收一个可以调用的对象（比如函数或者方法），如果是可以调用的对象，那么会将这个对象调用后的结果作为值返回回去。== 可以不用指定默认值 ==\n\n 6. DO_NOTHING：不采取任何行为。一切全看数据库级别的约束。\n\n注意:以上的配置都是django级别的，在数据库中的级别依旧是RESTRICT\n\n数据库层面的约束有:\n\n 1. RESTRICT：默认的选项，如果想要删除父表的记录时，而在子表中有关联该父表的记录，则不允许删除父表中的记录；\n\n 2. NOACTION：同 RESTRICT效果一样，也是首先先检查外键;\n\n 3. CASCADE：父表delete、update的时候，子表会delete、update掉关联记录；\n\n 4. SET NULL:父表delete、update的时候，子表会将关联记录的外键字段所在列设为null，所以注意在设计子表时外键不能设为not null；\n\n为什么在django中可以是用不同的约束去操作数据库呢。\n\n> 比如 django 中 on_delete=CASCADE, 但是数据库的外键约束是RESTRICT. 在进行删除A表数据时，发现被外键约束着，使数据不能被删除，则django会先去删除约束的B表数据，然后再来删除A表数据。",normalizedContent:"案例. 该模型使用外键引用自己本身。\n\nfrom django.db import models\n\nclass category(models.model):\n    name = models.textfield()\n    parent_cat = models.foreignkey('self',on_delete=models.cascade)\n\n\n1\n2\n3\n4\n5\n\n\non_delete参数如下:\n\n 1. cascade：级联操作。如果外键对应的那条数据被删除了，那么这条数据也会被删除。\n\n 2. protect：受保护。即只要这条数据引用了外键的那条数据，那么就不能删除外键的那条数据。如果我们强行删除，django就会报错。\n\n 3. set_null：设置为空。如果外键的那条数据被删除了，那么在本条数据上就将这个字段设置为空。如果设置这个选项，前提是要指定这个字段可以为空。\n\n 4. set_default：设置默认值。如果外键的那条数据被删除了，那么本条数据上就将这个字段设置为默认值。如果设置这个选项，== 前提是要指定这个字段一个默认值 ==。\n\n 5. set()：如果外键的那条数据被删除了。那么将会获取set函数中的值来作为这个外键的值。set函数可以接收一个可以调用的对象（比如函数或者方法），如果是可以调用的对象，那么会将这个对象调用后的结果作为值返回回去。== 可以不用指定默认值 ==\n\n 6. do_nothing：不采取任何行为。一切全看数据库级别的约束。\n\n注意:以上的配置都是django级别的，在数据库中的级别依旧是restrict\n\n数据库层面的约束有:\n\n 1. restrict：默认的选项，如果想要删除父表的记录时，而在子表中有关联该父表的记录，则不允许删除父表中的记录；\n\n 2. noaction：同 restrict效果一样，也是首先先检查外键;\n\n 3. cascade：父表delete、update的时候，子表会delete、update掉关联记录；\n\n 4. set null:父表delete、update的时候，子表会将关联记录的外键字段所在列设为null，所以注意在设计子表时外键不能设为not null；\n\n为什么在django中可以是用不同的约束去操作数据库呢。\n\n> 比如 django 中 on_delete=cascade, 但是数据库的外键约束是restrict. 在进行删除a表数据时，发现被外键约束着，使数据不能被删除，则django会先去删除约束的b表数据，然后再来删除a表数据。",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django 警告 while time zone support is active",frontmatter:{title:"django 警告 while time zone support is active",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/f0d816/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"django中的时区问题",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django 警告 while time zone support is active"},{name:"twitter:description",content:"django中的时区问题"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/16.django%20%E8%AD%A6%E5%91%8A%20while%20time%20zone%20support%20is%20active.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django 警告 while time zone support is active"},{property:"og:description",content:"django中的时区问题"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/16.django%20%E8%AD%A6%E5%91%8A%20while%20time%20zone%20support%20is%20active.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django 警告 while time zone support is active"},{itemprop:"description",content:"django中的时区问题"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/16.django%20%E8%AD%A6%E5%91%8A%20while%20time%20zone%20support%20is%20active.html",relativePath:"04.编程/01.python/06.django/16.django 警告 while time zone support is active.md",key:"v-224b6ec4",path:"/pages/f0d816/",headersStr:null,content:"告警错误如下。\n\n> DateTimeField Customer.updated received a naive datetime (2016-06-19 07:18:21.118000) while time zone support is active\n\n在 settings.py 中设置的 USE_TZ=True，所以需要使用 active datetime, 但是却得到了 naive datetime.\n\n> naive datetime 是通过 datetime 输出不带时区的时间. active time 是使用django.utils.timezone.now() 输出的是带时区utc时间。\n\n解决办法\n\n 1. 使用带时区的时间, django中使用 django.utils.timezone.now() , settings.py 中 USE_TZ=True\n\n 2. 使用不带时区的时间, django中使用 datetime.now(), settings.py 中 USE_TZ=False",normalizedContent:"告警错误如下。\n\n> datetimefield customer.updated received a naive datetime (2016-06-19 07:18:21.118000) while time zone support is active\n\n在 settings.py 中设置的 use_tz=true，所以需要使用 active datetime, 但是却得到了 naive datetime.\n\n> naive datetime 是通过 datetime 输出不带时区的时间. active time 是使用django.utils.timezone.now() 输出的是带时区utc时间。\n\n解决办法\n\n 1. 使用带时区的时间, django中使用 django.utils.timezone.now() , settings.py 中 use_tz=true\n\n 2. 使用不带时区的时间, django中使用 datetime.now(), settings.py 中 use_tz=false",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"Flask使用flask_socketio实现websocket",frontmatter:{author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},title:"Flask使用flask_socketio实现websocket",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/b71dc2/",description:"在flask中使用flask_socketio来实现websocket的功能。",feed:{enable:!0},tags:["python","flask"],categories:["编程","python","flask"],comment:!0,meta:[{name:"twitter:title",content:"Flask使用flask_socketio实现websocket"},{name:"twitter:description",content:"在flask中使用flask_socketio来实现websocket的功能。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/07.flask/01.Flask%E4%BD%BF%E7%94%A8flask_socketio%E5%AE%9E%E7%8E%B0websocket.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Flask使用flask_socketio实现websocket"},{property:"og:description",content:"在flask中使用flask_socketio来实现websocket的功能。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/07.flask/01.Flask%E4%BD%BF%E7%94%A8flask_socketio%E5%AE%9E%E7%8E%B0websocket.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"flask"},{itemprop:"name",content:"Flask使用flask_socketio实现websocket"},{itemprop:"description",content:"在flask中使用flask_socketio来实现websocket的功能。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/07.flask/01.Flask%E4%BD%BF%E7%94%A8flask_socketio%E5%AE%9E%E7%8E%B0websocket.html",relativePath:"04.编程/01.python/07.flask/01.Flask使用flask_socketio实现websocket.md",key:"v-73bfa208",path:"/pages/b71dc2/",headers:[{level:2,title:"前端实现",slug:"前端实现",normalizedTitle:"前端实现",charIndex:105},{level:2,title:"后端实现",slug:"后端实现",normalizedTitle:"后端实现",charIndex:1556},{level:3,title:"安装",slug:"安装",normalizedTitle:"安装",charIndex:1615},{level:3,title:"send 和 emit区别",slug:"send-和-emit区别",normalizedTitle:"send 和 emit区别",charIndex:1652},{level:3,title:"简单使用",slug:"简单使用",normalizedTitle:"简单使用",charIndex:1711},{level:3,title:"基于类的使用",slug:"基于类的使用",normalizedTitle:"基于类的使用",charIndex:2613}],excerpt:'<h1 id="flask使用flask-socketio实现websocket"><a class="header-anchor" href="#flask使用flask-socketio实现websocket">#</a> Flask使用flask_socketio实现websocket</h1>\n<p>下面是案例，是我自己用来测试使用的，可以直接运行的。详细的使用请看<a href="https://flask-socketio.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">官网<OutboundLink/></a></p>\n<p>websocket主要应用于客户端和服务端双向通信的。</p>\n',headersStr:"前端实现 后端实现 安装 send 和 emit区别 简单使用 基于类的使用",content:"# Flask使用flask_socketio实现websocket\n\n下面是案例，是我自己用来测试使用的，可以直接运行的。详细的使用请看官网\n\nwebsocket主要应用于客户端和服务端双向通信的。\n\n\n# 前端实现\n\n使用socket.io.min.js是node.js的一个websocket库，首先创建socket. emit是向后端发送消息, message是该条消息的名称，后面是发送消息的数据。on是注册接受消息的事件,获取后端传过来的数据. namespace是指一类的消息。当连接成功时，会触发connect事件，连接关闭时，触发disconnect事件。\n\n\n<html>\n    <head>\n        <script type=\"text/javascript\"\n        src=\"https://code.jquery.com/jquery-3.4.0.min.js\"><\/script>\n        <script type=\"text/javascript\"\n        src=\"//cdnjs.cloudflare.com/ajax/libs/socket.io/1.3.6/socket.io.min.js\"><\/script>\n        \n        <script type=\"text/javascript\" charset=\"utf-8\">\n            $(document).ready(function () {\n                namespace = \"/wechat\"\n                var socket = io.connect('http://' + document.domain + ':' + location.port + namespace);\n                \n                socket.emit(\"message\", { \"data\": \"zhangsan\" })\n                \n                socket.on('connect', function (data) {\n                    socket.emit('message', { 'data': 'I\\'m connected!' });\n                });\n                \n                socket.on('disconnect', function(data){\n                    socket.emit('message', { 'data': 'I\\'m disconnected!' });\n                });\n                    \n                socket.on('response', function (data) {\n                    console.log(data.age)\n                });\n            });\n        <\/script>\n    </head>\n    \n    <body>\n        <h1>德玛西亚</h1>\n    </body>\n</html>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n\n\n\n# 后端实现\n\n> Flask-SocketIO使Flask应用程序可以访问客户端和服务器之间的低延迟双向通信。\n\n\n# 安装\n\n> pip install flask-socketio\n\n\n# send 和 emit区别\n\nsend发送的是无命名的数据，而emit是发送有命名的数据，个人建议是emit\n\n\n# 简单使用\n\non是注册接收前端消息的方法，message是指接收的信息的名称，和前端对应。namespace是指一类的消息，和前端对应。emit是指向前端发送消息，对应的消息的名称、数据和namespace。\n\n默认的两个事件，connect和disconnect，当websocket连接成功和失败时，自动触发这两个事件。\n\n\nfrom flask import Flask, render_template\nfrom flask_socketio import SocketIO\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'secret!'\nsocketio = SocketIO(app)\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@socketio.on('message', namespace=\"/wechat\")\ndef handle_message(message):\n    print('received message: ' + message['data'])\n    socketio.emit(\"response\", {'age': 18}, namespace=\"/wechat\")\n\n@socketio.on('connect', namespace=\"/wechat\")\ndef connect():\n    print(\"connect..\")\n\n@socketio.on('disconnect', namespace=\"/wechat\")\ndef connect():\n    print(\"disconnect...\")\n\nif __name__ == '__main__':\n    socketio.run(app, port=8080)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n\n# 基于类的使用\n\n上面都是基于方法使用，个人感觉如果操作较多的情况，比较凌乱，使用类去管理会整齐和方便很多。\n\n服务器收到的任何事件都会被分配到一个名为带有on_前缀的事件名称的方法。\n\n这个案例和上面基于方法是一样的，但是更加方便管理了，每个class管理一个namespace。\n\n\nclass MyCustomNamespace(Namespace):\n\n    def on_connect(self):\n        print(\"连接..\")\n        \n    def on_disconnect(self):\n        print(\"关闭连接\")\n        \n    def on_message(self, data):\n        print('received message: ' + data['data'])\n        self.emit(\"response\", {'age': 18})\n    \nsocketio.on_namespace(MyCustomNamespace(\"/wechat\"))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n",normalizedContent:"# flask使用flask_socketio实现websocket\n\n下面是案例，是我自己用来测试使用的，可以直接运行的。详细的使用请看官网\n\nwebsocket主要应用于客户端和服务端双向通信的。\n\n\n# 前端实现\n\n使用socket.io.min.js是node.js的一个websocket库，首先创建socket. emit是向后端发送消息, message是该条消息的名称，后面是发送消息的数据。on是注册接受消息的事件,获取后端传过来的数据. namespace是指一类的消息。当连接成功时，会触发connect事件，连接关闭时，触发disconnect事件。\n\n\n<html>\n    <head>\n        <script type=\"text/javascript\"\n        src=\"https://code.jquery.com/jquery-3.4.0.min.js\"><\/script>\n        <script type=\"text/javascript\"\n        src=\"//cdnjs.cloudflare.com/ajax/libs/socket.io/1.3.6/socket.io.min.js\"><\/script>\n        \n        <script type=\"text/javascript\" charset=\"utf-8\">\n            $(document).ready(function () {\n                namespace = \"/wechat\"\n                var socket = io.connect('http://' + document.domain + ':' + location.port + namespace);\n                \n                socket.emit(\"message\", { \"data\": \"zhangsan\" })\n                \n                socket.on('connect', function (data) {\n                    socket.emit('message', { 'data': 'i\\'m connected!' });\n                });\n                \n                socket.on('disconnect', function(data){\n                    socket.emit('message', { 'data': 'i\\'m disconnected!' });\n                });\n                    \n                socket.on('response', function (data) {\n                    console.log(data.age)\n                });\n            });\n        <\/script>\n    </head>\n    \n    <body>\n        <h1>德玛西亚</h1>\n    </body>\n</html>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n\n\n\n# 后端实现\n\n> flask-socketio使flask应用程序可以访问客户端和服务器之间的低延迟双向通信。\n\n\n# 安装\n\n> pip install flask-socketio\n\n\n# send 和 emit区别\n\nsend发送的是无命名的数据，而emit是发送有命名的数据，个人建议是emit\n\n\n# 简单使用\n\non是注册接收前端消息的方法，message是指接收的信息的名称，和前端对应。namespace是指一类的消息，和前端对应。emit是指向前端发送消息，对应的消息的名称、数据和namespace。\n\n默认的两个事件，connect和disconnect，当websocket连接成功和失败时，自动触发这两个事件。\n\n\nfrom flask import flask, render_template\nfrom flask_socketio import socketio\n\napp = flask(__name__)\napp.config['secret_key'] = 'secret!'\nsocketio = socketio(app)\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@socketio.on('message', namespace=\"/wechat\")\ndef handle_message(message):\n    print('received message: ' + message['data'])\n    socketio.emit(\"response\", {'age': 18}, namespace=\"/wechat\")\n\n@socketio.on('connect', namespace=\"/wechat\")\ndef connect():\n    print(\"connect..\")\n\n@socketio.on('disconnect', namespace=\"/wechat\")\ndef connect():\n    print(\"disconnect...\")\n\nif __name__ == '__main__':\n    socketio.run(app, port=8080)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n\n# 基于类的使用\n\n上面都是基于方法使用，个人感觉如果操作较多的情况，比较凌乱，使用类去管理会整齐和方便很多。\n\n服务器收到的任何事件都会被分配到一个名为带有on_前缀的事件名称的方法。\n\n这个案例和上面基于方法是一样的，但是更加方便管理了，每个class管理一个namespace。\n\n\nclass mycustomnamespace(namespace):\n\n    def on_connect(self):\n        print(\"连接..\")\n        \n    def on_disconnect(self):\n        print(\"关闭连接\")\n        \n    def on_message(self, data):\n        print('received message: ' + data['data'])\n        self.emit(\"response\", {'age': 18})\n    \nsocketio.on_namespace(mycustomnamespace(\"/wechat\"))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django-prometheus使用及源码分析",frontmatter:{title:"django-prometheus使用及源码分析",date:"2024-09-17T15:18:44.000Z",permalink:"/pages/4b0adb/",categories:["编程","python","django"],tags:["python","django"],author:{name:"zhengwenfeng",link:"https://www.zhengwenfeng.com"},description:"而本文主要是介绍使用[django-prometheus](https://github.com/korfuri/django-prometheus)来对django服务添加对prometheus指标的支持，它已经内置了部分的指标采集，包括请求、数据库和缓存等方面的指标。除了使用方法外，也会对其源码进行分析，看它是如何实现的。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1726558982722image-20240917134902-uu4hpp3.png"},{name:"twitter:title",content:"django-prometheus使用及源码分析"},{name:"twitter:description",content:"而本文主要是介绍使用[django-prometheus](https://github.com/korfuri/django-prometheus)来对django服务添加对prometheus指标的支持，它已经内置了部分的指标采集，包括请求、数据库和缓存等方面的指标。除了使用方法外，也会对其源码进行分析，看它是如何实现的。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1726558982722image-20240917134902-uu4hpp3.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/18.django-prometheus%E4%BD%BF%E7%94%A8%E5%8F%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django-prometheus使用及源码分析"},{property:"og:description",content:"而本文主要是介绍使用[django-prometheus](https://github.com/korfuri/django-prometheus)来对django服务添加对prometheus指标的支持，它已经内置了部分的指标采集，包括请求、数据库和缓存等方面的指标。除了使用方法外，也会对其源码进行分析，看它是如何实现的。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1726558982722image-20240917134902-uu4hpp3.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/18.django-prometheus%E4%BD%BF%E7%94%A8%E5%8F%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2024-09-17T15:18:44.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django-prometheus使用及源码分析"},{itemprop:"description",content:"而本文主要是介绍使用[django-prometheus](https://github.com/korfuri/django-prometheus)来对django服务添加对prometheus指标的支持，它已经内置了部分的指标采集，包括请求、数据库和缓存等方面的指标。除了使用方法外，也会对其源码进行分析，看它是如何实现的。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/1726558982722image-20240917134902-uu4hpp3.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/18.django-prometheus%E4%BD%BF%E7%94%A8%E5%8F%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html",relativePath:"04.编程/01.python/06.django/18.django-prometheus使用及源码分析.md",key:"v-9c48962a",path:"/pages/4b0adb/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"获取prometheus指标",slug:"获取prometheus指标",normalizedTitle:"获取prometheus指标",charIndex:328},{level:3,title:"新增接口获取指标",slug:"新增接口获取指标",normalizedTitle:"新增接口获取指标",charIndex:347},{level:3,title:"在专用线程中获取指标",slug:"在专用线程中获取指标",normalizedTitle:"在专用线程中获取指标",charIndex:1520},{level:2,title:"请求指标",slug:"请求指标",normalizedTitle:"请求指标",charIndex:2690},{level:2,title:"postgres指标",slug:"postgres指标",normalizedTitle:"postgres指标",charIndex:7636},{level:3,title:"对insert、update、delete操作计数",slug:"对insert、update、delete操作计数",normalizedTitle:"对insert、update、delete操作计数",charIndex:7731},{level:3,title:"执行耗时",slug:"执行耗时",normalizedTitle:"执行耗时",charIndex:9516},{level:2,title:"redis指标",slug:"redis指标",normalizedTitle:"redis指标",charIndex:13572},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:15321}],headersStr:"简介 获取prometheus指标 新增接口获取指标 在专用线程中获取指标 请求指标 postgres指标 对insert、update、delete操作计数 执行耗时 redis指标 总结",content:'# 简介\n\n在django服务运行过程中，希望可以对其获取promethues指标进行监控，这样可以实时知道其运行状态，当它运行异常时可以及时进行告警，并且帮助我们可以对其针对性进行优化。比如请求量过大是否要进行限流或者扩容，再或者发现接口过慢，可能是数据库访问太慢，出现了慢sql，需要及时进行优化等等。\n\n而本文主要是介绍使用django-prometheus来对django服务添加对prometheus指标的支持，它已经内置了部分的指标采集，包括请求、数据库和缓存等方面的指标。除了使用方法外，也会对其源码进行分析，看它是如何实现的。\n\n本文中使用的例子已经上传到github中，可以在django_demo上查看，搭配本文章学习。\n\n‍\n\n\n# 获取prometheus指标\n\n\n# 新增接口获取指标\n\n在url.py中新增下面的路由\n\npath(\'\', include(\'django_prometheus.urls\')),\n\n\n1\n\n\n然后运行服务，调用/metrics接口，即可获取到默认的prometheus指标信息。\n\n...\npython_gc_objects_collected_total{generation="0"} 667.0\npython_gc_objects_collected_total{generation="1"} 405.0\npython_gc_objects_collected_total{generation="2"} 19.0\n...\n\n\n1\n2\n3\n4\n5\n\n\n我们可以看下引用的 django_prometheus.urls源码，它包含了一个metrics的路由，调用的是 exports.ExportToDjangoView方法\n\nurlpatterns = [path("metrics", exports.ExportToDjangoView, name="prometheus-django-metrics")]\n\n\n1\n\n\n再看看下 ExportToDjangoView方法，这里有一个分支，如果配置了环境变量PROMETHEUS_MULTIPROC_DIR或者 prometheus_multiproc_dir则会走多进程收集指标逻辑，否则单进程会则从全局变量REGISTRY 中获取所有的指标，最后返回响应。\n\ndef ExportToDjangoView(request):\n    if "PROMETHEUS_MULTIPROC_DIR" in os.environ or "prometheus_multiproc_dir" in os.environ:\n        registry = prometheus_client.CollectorRegistry()\n        multiprocess.MultiProcessCollector(registry)\n    else:\n        registry = prometheus_client.REGISTRY\n    metrics_page = prometheus_client.generate_latest(registry)\n    return HttpResponse(metrics_page, content_type=prometheus_client.CONTENT_TYPE_LATEST)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n> 这里注意多进程与单进程收集指标的方式是不一样的，多进程是从各个进程的文件读取，而单进程是从全局变量中读取。\n\n‍\n\n\n# 在专用线程中获取指标\n\n上面的方法是在django服务中获取指标，但如果业务bug可能会导致监控受到影响，出现无法获取到指标的情况，这样就无法提供定位问题的帮助。\n\n所以提供了一种方式在单独的线程中来获取指标，达到解耦的目的，保证即使业务异常也不会影响指标的获取。\n\n这种方式默认是关闭的，需要在setting.py中添加以下变量启用：\n\nPROMETHEUS_METRICS_EXPORT_PORT = 8001\nPROMETHEUS_METRICS_EXPORT_ADDRESS = \'0.0.0.0\'  # all addresses\n\n\n1\n2\n\n\n然后需要在 INSTALLED_APPS 中添加 django_prometheus ，这时因为该线程是在 DjangoPrometheusConfig.ready -> SetupPrometheusExportsFromConfig -> SetupPrometheusEndpointOnPort 中被调用的，需要引用该app才会被执行。\n\nINSTALLED_APPS = [\n    ...\n    \'django_prometheus\',\n    \'demo\',\n]\n\n\n1\n2\n3\n4\n5\n\n\n再来看 SetupPrometheusEndpointOnPort 方法可以看到是调用 prometheus_client.start_http_server 方法来开启线程，并暴露指定的 PROMETHEUS_METRICS_EXPORT_PORT 端口和允许访问的 PROMETHEUS_METRICS_EXPORT_ADDRESS 地址。\n\ndef SetupPrometheusEndpointOnPort(port, addr=""):\n    assert os.environ.get("RUN_MAIN") != "true", (\n        "The thread-based exporter can\'t be safely used when django\'s "\n        "autoreloader is active. Use the URL exporter, or start django "\n        "with --noreload. See documentation/exports.md."\n    )\n    prometheus_client.start_http_server(port, addr=addr)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n> 注意这里有一个断言，该种方式不支持热加载启动。\n\n最后运行服务，通过访问上面的配置的8001端口即可获取该服务的默认promethues指标了。\n\n\n# 请求指标\n\n通过上面的步骤，已经知道了如何配置获取指标信息，现在需要知道如何获取请求质量的指标信息。\n\n而 django_prometheus 已经给我们默认提供了请求相关的指标信息，部分如下：\n\n指标                                                           说明                     阶段\ndjango_http_requests_latency_including_middlewares_seconds   包含middleware的请求时间直方图   在开始的middleware process_request\ndjango_http_requests_before_middlewares_total                请求数                    在开始的middleware process_request\ndjango_http_responses_before_middlewares_total               响应数                    在开始的middleware process_response\ndjango_http_requests_latency_seconds_by_view_method          view层请求时间的直方图          在最后的middlewar process_request\ndjango_http_requests_total_by_method                         view层带有请求方法的请求数        在最后的middlewar process_request\ndjango_http_requests_total_by_view_transport_method          view层的请求数              在最后的middlewar process_view\nresponses_by_status_view_method                              view层的响应数              在最后的middlewar process_response\n\n使用方法\n\n在 settings.py 中的 MIDDLEWARE 中添加两个中间件，配置如下：\n\nMIDDLEWARE = [\n    \'django_prometheus.middleware.PrometheusBeforeMiddleware\',\n  ...\n    \'django_prometheus.middleware.PrometheusAfterMiddleware\',\n]\n\n\n1\n2\n3\n4\n5\n\n\n> 注意这里的顺序很重要，一定要是放在MIDDLEWARE的第一个和最后一个。\n\n在 view.py 中新增一个接口 myview\n\ndef my_view(request):\n    return HttpResponse("hello")\n\n\n1\n2\n\n\n在 urls.py 中新增一条路由\n\npath(\'myview/\', my_view)\n\n\n1\n\n\n最后你请求接口一次该接口，再获取指标，你可以得到部分请求指标的变化。\n\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.01",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.025",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.05",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.075",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.1",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.25",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.5",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.75",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="1.0",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="2.5",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="5.0",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="7.5",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="10.0",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="25.0",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="50.0",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="75.0",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="+Inf",method="GET",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_count{method="GET",view="demo.views.my_view"} 1.0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n实现原理\n\n请求进入 view 层之前会先按照顺序经过 middleware，然后再到view进行执行，最后响应的时候再按照逆序经过 middleware，如下图所示：\n\n\n\n而 middleware 中会有一系列的钩子函数可以对请求做一些预处理工作，比如认证等，而我们的请求指标就是在 middleware 层中实现的。\n\n先看 PrometheusBeforeMiddleware，实现了 process_request 和 process_response 方法，这两个方法就是在 request 进来时和 response 返回时分别会调用的方法。\n\nclass PrometheusBeforeMiddleware(MiddlewareMixin):\n    metrics_cls = Metrics\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.metrics = self.metrics_cls.get_instance()\n\n    def process_request(self, request):\n        self.metrics.requests_total.inc()\n        request.prometheus_before_middleware_event = Time()\n\n    def process_response(self, request, response):\n        self.metrics.responses_total.inc()\n        if hasattr(request, "prometheus_before_middleware_event"):\n            self.metrics.requests_latency_before.observe(TimeSince(request.prometheus_before_middleware_event))\n        else:\n            self.metrics.requests_unknown_latency_before.inc()\n        return response\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n如下图所示：\n\n\n\n在 process_request 中对 requests_total 进行递增，在 process_response 中对 responses_total 也进行递增，这两个就是进入服务的请求总数和响应总数的指标。\n\n再看 process_request 中记录了当前的时间 prometheus_before_middleware_event，然后在 process_response 中将当前时间与上一个时间进行相减，也就得到了从请求进来到响应的整个时间，赋值给了 requests_latency_before 指标中。\n\n而除了配置 PrometheusBeforeMiddleware 外，还配置了 PrometheusAfterMiddleware，但基本原理都是一样的，都是通过中间件在不同阶段的钩子方法来进行指标的统计，只是统计的指标不一样而已。\n\n‍\n\n\n# postgres指标\n\n接下来就是讲关于数据库的指标，该库支持mysql、sqlite和postgres等数据库的支持，但这里主要是对postgres介绍，其他的使用方法也是类似。\n\n\n# 对insert、update、delete操作计数\n\n使用方法\n\n在 models.py 中创建 class User，并继承 ExportModelOperationsMixin，这是一个常见的python设计模式，可以给已有的类额外的添加功能。\n\nfrom django_prometheus.models import ExportModelOperationsMixin\n\nclass User(ExportModelOperationsMixin(\'User\'), models.Model):\n    class Meta:\n        db_table = \'t_user\'\n\n    id = models.AutoField(primary_key=True)\n    name = models.CharField()\n    age = models.IntegerField()\n    sex = models.CharField()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n然后建表\n\npython manager.py makemigrations\npython manager.py migrate\n\n\n1\n2\n\n\n在view.py新增接口my_view2\n\ndef my_view2(request):\n    User(name="zhangsan", age=12, sex="male").save()\n    return HttpResponse("hello")\n\n\n\n1\n2\n3\n4\n\n\n在url.py新增路由\n\npath(\'myview2/\', my_view2)\n\n\n1\n\n\n然后运行服务，先调用/myview2接口，再获取指标就可以看到对User的新增计数\n\ndjango_model_inserts_total{model="User"} 1.0\n\n\n1\n\n\n实现原理\n\n我们看看 ExportModelOperationsMixin 类，可以看到里面创建了一个 class Mixin 它重写了 _do_insert、 _do_update 、 delete 三个方法，而这三个方法是 models.Model 的方法，是在对 model 进行插入、更新和删除时执行的三个方法，而这里重写是在执行这些操作前，使用指标变量进行递增，这样就记录了次数。\n\ndef ExportModelOperationsMixin(model_name):\n    model_inserts.labels(model_name)\n    model_updates.labels(model_name)\n    model_deletes.labels(model_name)\n\n    class Mixin:\n        def _do_insert(self, *args, **kwargs):\n            model_inserts.labels(model_name).inc()\n            return super()._do_insert(*args, **kwargs)\n\n        def _do_update(self, *args, **kwargs):\n            model_updates.labels(model_name).inc()\n            return super()._do_update(*args, **kwargs)\n\n        def delete(self, *args, **kwargs):\n            model_deletes.labels(model_name).inc()\n            return super().delete(*args, **kwargs)\n\n    Mixin.__qualname__ = f"ExportModelOperationsMixin(\'{model_name}\')"\n    return Mixin\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n\n# 执行耗时\n\n除了执行次数外，我们还想知道数据库执行的耗时。\n\n使用方法\n\n在 settings.py 中，将 DATABSE 中的 engine 换成 django_prometheus.db.backends.postgresql\n\nDATABASES = {\n    \'default\': {\n        \'ENGINE\': \'django_prometheus.db.backends.postgresql\',\n    ...\n    }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n然后就可以再次调用接口 myview2 对 User 进行操作，再获取指标可以看到对 postgres 的耗时的一个直方图指标。\n\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.01",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.025",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.05",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.075",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.1",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.25",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.5",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.75",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="1.0",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="2.5",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="5.0",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="7.5",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="10.0",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="25.0",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="50.0",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="75.0",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="+Inf",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_count{alias="default",vendor="postgresql"} 3.0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n实现原理\n\n我们看向 django_prometheus/db/backends/postgresql/base.py 文件，可以看到 DatabaseWrapper 类，而该类重写了 get_new_connection 方法，它目的是在创建数据库连接时，将内置使用的cursor替换成自己定义的 ExportingCursorWrapper\n\nclass DatabaseWrapper(DatabaseWrapperMixin, base.DatabaseWrapper):\n    def get_new_connection(self, *args, **kwargs):\n        conn = super().get_new_connection(*args, **kwargs)\n        conn.cursor_factory = ExportingCursorWrapper(\n            conn.cursor_factory or get_postgres_cursor_class(), self.alias, self.vendor\n        )\n        return conn\n\n    def create_cursor(self, name=None):\n        # cursor_factory is a kwarg to connect() so restore create_cursor()\'s\n        # default behavior\n        return base.DatabaseWrapper.create_cursor(self, name=name)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n再看向 class ExportingCursorWrapper，里面定义了 class CursorWrapper，重写了 execute 和 executemany 两个方法，是在执行sql时会调用的方法，而在调用父类执行sql前后进行统计计数和耗时。\n\ndef ExportingCursorWrapper(cursor_class, alias, vendor):\n    labels = {"alias": alias, "vendor": vendor}\n\n    class CursorWrapper(cursor_class):\n        def execute(self, *args, **kwargs):\n            execute_total.labels(alias, vendor).inc()\n            with query_duration_seconds.labels(**labels).time(), ExceptionCounterByType(\n                errors_total, extra_labels=labels\n            ):\n                return super().execute(*args, **kwargs)\n\n        def executemany(self, query, param_list, *args, **kwargs):\n            execute_total.labels(alias, vendor).inc(len(param_list))\n            execute_many_total.labels(alias, vendor).inc(len(param_list))\n            with query_duration_seconds.labels(**labels).time(), ExceptionCounterByType(\n                errors_total, extra_labels=labels\n            ):\n                return super().executemany(query, param_list, *args, **kwargs)\n\n    return CursorWrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n指标列表\n\n指标                                 说明\ndjango_db_query_duration_seconds   数据库所有的操作耗时，包含了增删改查\ndjango_db_new_connections_total    数据库创建的连接数\nexecute_total                      数据库执行总数\n\n‍\n\n\n# redis指标\n\n使用方法\n\n在 settings.py 中配置redis\n\nCACHES = {\n    \'default\': {\n        \'BACKEND\': \'django_prometheus.cache.backends.redis.RedisCache\',\n        \'LOCATION\': \'redis://127.0.0.1:6379\'\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n在 view.py 中新增 my_view3 接口，对redis进行操作\n\ndef my_view3(request):\n    cache.set("name", "zhangsan")\n    return HttpResponse(cache.get("name"))\n\n\n1\n2\n3\n\n\n在url.py中新增对应路由\n\npath(\'myview3/\', my_view3)\n\n\n1\n\n\n调用接口 /myview3 接口，然后获取指标，就可以看到redis相关的指标参数\n\ndjango_cache_get_total{backend="redis"} 1.0\ndjango_cache_get_created{backend="redis"} 1.7265568108417125e+09\ndjango_cache_get_hits_total{backend="redis"} 1.0\ndjango_cache_get_hits_created{backend="redis"} 1.726556810842234e+09\n\n\n1\n2\n3\n4\n\n\n实现原理\n\n我们看到 django_prometheus/cache/backends/redis.py 中的class RedisCache，该类继承了已有的缓存类 cache.RedisCache，重写了方法get，在调用父类操作方法的前后添加指标。\n\nclass RedisCache(cache.RedisCache):\n    @cache.omit_exception\n    def get(self, key, default=None, version=None, client=None):\n        try:\n            django_cache_get_total.labels(backend="redis").inc()\n            cached = self.client.get(key, default=None, version=version, client=client)\n        except exceptions.ConnectionInterrupted as e:\n            django_cache_get_fail_total.labels(backend="redis").inc()\n            if self._ignore_exceptions:\n                if self._log_ignored_exceptions:\n                    cache.logger.error(str(e))\n                return default\n            raise\n        else:\n            if cached is not None:\n                django_cache_hits_total.labels(backend="redis").inc()\n                return cached\n            else:\n                django_cache_misses_total.labels(backend="redis").inc()\n                return default\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n‍\n\n\n# 总结\n\ndjango-prometheus 是在充分的理解了django本身的机制上，通过已提供的钩子，或者重写部分的方法，替换掉内置的组件的方式，来达到自己的目的，这种方法值得参考与学习。\n\n‍',normalizedContent:'# 简介\n\n在django服务运行过程中，希望可以对其获取promethues指标进行监控，这样可以实时知道其运行状态，当它运行异常时可以及时进行告警，并且帮助我们可以对其针对性进行优化。比如请求量过大是否要进行限流或者扩容，再或者发现接口过慢，可能是数据库访问太慢，出现了慢sql，需要及时进行优化等等。\n\n而本文主要是介绍使用django-prometheus来对django服务添加对prometheus指标的支持，它已经内置了部分的指标采集，包括请求、数据库和缓存等方面的指标。除了使用方法外，也会对其源码进行分析，看它是如何实现的。\n\n本文中使用的例子已经上传到github中，可以在django_demo上查看，搭配本文章学习。\n\n‍\n\n\n# 获取prometheus指标\n\n\n# 新增接口获取指标\n\n在url.py中新增下面的路由\n\npath(\'\', include(\'django_prometheus.urls\')),\n\n\n1\n\n\n然后运行服务，调用/metrics接口，即可获取到默认的prometheus指标信息。\n\n...\npython_gc_objects_collected_total{generation="0"} 667.0\npython_gc_objects_collected_total{generation="1"} 405.0\npython_gc_objects_collected_total{generation="2"} 19.0\n...\n\n\n1\n2\n3\n4\n5\n\n\n我们可以看下引用的 django_prometheus.urls源码，它包含了一个metrics的路由，调用的是 exports.exporttodjangoview方法\n\nurlpatterns = [path("metrics", exports.exporttodjangoview, name="prometheus-django-metrics")]\n\n\n1\n\n\n再看看下 exporttodjangoview方法，这里有一个分支，如果配置了环境变量prometheus_multiproc_dir或者 prometheus_multiproc_dir则会走多进程收集指标逻辑，否则单进程会则从全局变量registry 中获取所有的指标，最后返回响应。\n\ndef exporttodjangoview(request):\n    if "prometheus_multiproc_dir" in os.environ or "prometheus_multiproc_dir" in os.environ:\n        registry = prometheus_client.collectorregistry()\n        multiprocess.multiprocesscollector(registry)\n    else:\n        registry = prometheus_client.registry\n    metrics_page = prometheus_client.generate_latest(registry)\n    return httpresponse(metrics_page, content_type=prometheus_client.content_type_latest)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n> 这里注意多进程与单进程收集指标的方式是不一样的，多进程是从各个进程的文件读取，而单进程是从全局变量中读取。\n\n‍\n\n\n# 在专用线程中获取指标\n\n上面的方法是在django服务中获取指标，但如果业务bug可能会导致监控受到影响，出现无法获取到指标的情况，这样就无法提供定位问题的帮助。\n\n所以提供了一种方式在单独的线程中来获取指标，达到解耦的目的，保证即使业务异常也不会影响指标的获取。\n\n这种方式默认是关闭的，需要在setting.py中添加以下变量启用：\n\nprometheus_metrics_export_port = 8001\nprometheus_metrics_export_address = \'0.0.0.0\'  # all addresses\n\n\n1\n2\n\n\n然后需要在 installed_apps 中添加 django_prometheus ，这时因为该线程是在 djangoprometheusconfig.ready -> setupprometheusexportsfromconfig -> setupprometheusendpointonport 中被调用的，需要引用该app才会被执行。\n\ninstalled_apps = [\n    ...\n    \'django_prometheus\',\n    \'demo\',\n]\n\n\n1\n2\n3\n4\n5\n\n\n再来看 setupprometheusendpointonport 方法可以看到是调用 prometheus_client.start_http_server 方法来开启线程，并暴露指定的 prometheus_metrics_export_port 端口和允许访问的 prometheus_metrics_export_address 地址。\n\ndef setupprometheusendpointonport(port, addr=""):\n    assert os.environ.get("run_main") != "true", (\n        "the thread-based exporter can\'t be safely used when django\'s "\n        "autoreloader is active. use the url exporter, or start django "\n        "with --noreload. see documentation/exports.md."\n    )\n    prometheus_client.start_http_server(port, addr=addr)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n> 注意这里有一个断言，该种方式不支持热加载启动。\n\n最后运行服务，通过访问上面的配置的8001端口即可获取该服务的默认promethues指标了。\n\n\n# 请求指标\n\n通过上面的步骤，已经知道了如何配置获取指标信息，现在需要知道如何获取请求质量的指标信息。\n\n而 django_prometheus 已经给我们默认提供了请求相关的指标信息，部分如下：\n\n指标                                                           说明                     阶段\ndjango_http_requests_latency_including_middlewares_seconds   包含middleware的请求时间直方图   在开始的middleware process_request\ndjango_http_requests_before_middlewares_total                请求数                    在开始的middleware process_request\ndjango_http_responses_before_middlewares_total               响应数                    在开始的middleware process_response\ndjango_http_requests_latency_seconds_by_view_method          view层请求时间的直方图          在最后的middlewar process_request\ndjango_http_requests_total_by_method                         view层带有请求方法的请求数        在最后的middlewar process_request\ndjango_http_requests_total_by_view_transport_method          view层的请求数              在最后的middlewar process_view\nresponses_by_status_view_method                              view层的响应数              在最后的middlewar process_response\n\n使用方法\n\n在 settings.py 中的 middleware 中添加两个中间件，配置如下：\n\nmiddleware = [\n    \'django_prometheus.middleware.prometheusbeforemiddleware\',\n  ...\n    \'django_prometheus.middleware.prometheusaftermiddleware\',\n]\n\n\n1\n2\n3\n4\n5\n\n\n> 注意这里的顺序很重要，一定要是放在middleware的第一个和最后一个。\n\n在 view.py 中新增一个接口 myview\n\ndef my_view(request):\n    return httpresponse("hello")\n\n\n1\n2\n\n\n在 urls.py 中新增一条路由\n\npath(\'myview/\', my_view)\n\n\n1\n\n\n最后你请求接口一次该接口，再获取指标，你可以得到部分请求指标的变化。\n\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.01",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.025",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.05",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.075",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.1",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.25",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.5",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="0.75",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="1.0",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="2.5",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="5.0",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="7.5",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="10.0",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="25.0",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="50.0",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="75.0",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_bucket{le="+inf",method="get",view="demo.views.my_view"} 1.0\ndjango_http_requests_latency_seconds_by_view_method_count{method="get",view="demo.views.my_view"} 1.0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n实现原理\n\n请求进入 view 层之前会先按照顺序经过 middleware，然后再到view进行执行，最后响应的时候再按照逆序经过 middleware，如下图所示：\n\n\n\n而 middleware 中会有一系列的钩子函数可以对请求做一些预处理工作，比如认证等，而我们的请求指标就是在 middleware 层中实现的。\n\n先看 prometheusbeforemiddleware，实现了 process_request 和 process_response 方法，这两个方法就是在 request 进来时和 response 返回时分别会调用的方法。\n\nclass prometheusbeforemiddleware(middlewaremixin):\n    metrics_cls = metrics\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.metrics = self.metrics_cls.get_instance()\n\n    def process_request(self, request):\n        self.metrics.requests_total.inc()\n        request.prometheus_before_middleware_event = time()\n\n    def process_response(self, request, response):\n        self.metrics.responses_total.inc()\n        if hasattr(request, "prometheus_before_middleware_event"):\n            self.metrics.requests_latency_before.observe(timesince(request.prometheus_before_middleware_event))\n        else:\n            self.metrics.requests_unknown_latency_before.inc()\n        return response\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n如下图所示：\n\n\n\n在 process_request 中对 requests_total 进行递增，在 process_response 中对 responses_total 也进行递增，这两个就是进入服务的请求总数和响应总数的指标。\n\n再看 process_request 中记录了当前的时间 prometheus_before_middleware_event，然后在 process_response 中将当前时间与上一个时间进行相减，也就得到了从请求进来到响应的整个时间，赋值给了 requests_latency_before 指标中。\n\n而除了配置 prometheusbeforemiddleware 外，还配置了 prometheusaftermiddleware，但基本原理都是一样的，都是通过中间件在不同阶段的钩子方法来进行指标的统计，只是统计的指标不一样而已。\n\n‍\n\n\n# postgres指标\n\n接下来就是讲关于数据库的指标，该库支持mysql、sqlite和postgres等数据库的支持，但这里主要是对postgres介绍，其他的使用方法也是类似。\n\n\n# 对insert、update、delete操作计数\n\n使用方法\n\n在 models.py 中创建 class user，并继承 exportmodeloperationsmixin，这是一个常见的python设计模式，可以给已有的类额外的添加功能。\n\nfrom django_prometheus.models import exportmodeloperationsmixin\n\nclass user(exportmodeloperationsmixin(\'user\'), models.model):\n    class meta:\n        db_table = \'t_user\'\n\n    id = models.autofield(primary_key=true)\n    name = models.charfield()\n    age = models.integerfield()\n    sex = models.charfield()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n然后建表\n\npython manager.py makemigrations\npython manager.py migrate\n\n\n1\n2\n\n\n在view.py新增接口my_view2\n\ndef my_view2(request):\n    user(name="zhangsan", age=12, sex="male").save()\n    return httpresponse("hello")\n\n\n\n1\n2\n3\n4\n\n\n在url.py新增路由\n\npath(\'myview2/\', my_view2)\n\n\n1\n\n\n然后运行服务，先调用/myview2接口，再获取指标就可以看到对user的新增计数\n\ndjango_model_inserts_total{model="user"} 1.0\n\n\n1\n\n\n实现原理\n\n我们看看 exportmodeloperationsmixin 类，可以看到里面创建了一个 class mixin 它重写了 _do_insert、 _do_update 、 delete 三个方法，而这三个方法是 models.model 的方法，是在对 model 进行插入、更新和删除时执行的三个方法，而这里重写是在执行这些操作前，使用指标变量进行递增，这样就记录了次数。\n\ndef exportmodeloperationsmixin(model_name):\n    model_inserts.labels(model_name)\n    model_updates.labels(model_name)\n    model_deletes.labels(model_name)\n\n    class mixin:\n        def _do_insert(self, *args, **kwargs):\n            model_inserts.labels(model_name).inc()\n            return super()._do_insert(*args, **kwargs)\n\n        def _do_update(self, *args, **kwargs):\n            model_updates.labels(model_name).inc()\n            return super()._do_update(*args, **kwargs)\n\n        def delete(self, *args, **kwargs):\n            model_deletes.labels(model_name).inc()\n            return super().delete(*args, **kwargs)\n\n    mixin.__qualname__ = f"exportmodeloperationsmixin(\'{model_name}\')"\n    return mixin\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n\n# 执行耗时\n\n除了执行次数外，我们还想知道数据库执行的耗时。\n\n使用方法\n\n在 settings.py 中，将 databse 中的 engine 换成 django_prometheus.db.backends.postgresql\n\ndatabases = {\n    \'default\': {\n        \'engine\': \'django_prometheus.db.backends.postgresql\',\n    ...\n    }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n然后就可以再次调用接口 myview2 对 user 进行操作，再获取指标可以看到对 postgres 的耗时的一个直方图指标。\n\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.01",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.025",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.05",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.075",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.1",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.25",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.5",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="0.75",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="1.0",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="2.5",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="5.0",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="7.5",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="10.0",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="25.0",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="50.0",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="75.0",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_bucket{alias="default",le="+inf",vendor="postgresql"} 3.0\ndjango_db_query_duration_seconds_count{alias="default",vendor="postgresql"} 3.0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n实现原理\n\n我们看向 django_prometheus/db/backends/postgresql/base.py 文件，可以看到 databasewrapper 类，而该类重写了 get_new_connection 方法，它目的是在创建数据库连接时，将内置使用的cursor替换成自己定义的 exportingcursorwrapper\n\nclass databasewrapper(databasewrappermixin, base.databasewrapper):\n    def get_new_connection(self, *args, **kwargs):\n        conn = super().get_new_connection(*args, **kwargs)\n        conn.cursor_factory = exportingcursorwrapper(\n            conn.cursor_factory or get_postgres_cursor_class(), self.alias, self.vendor\n        )\n        return conn\n\n    def create_cursor(self, name=none):\n        # cursor_factory is a kwarg to connect() so restore create_cursor()\'s\n        # default behavior\n        return base.databasewrapper.create_cursor(self, name=name)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n再看向 class exportingcursorwrapper，里面定义了 class cursorwrapper，重写了 execute 和 executemany 两个方法，是在执行sql时会调用的方法，而在调用父类执行sql前后进行统计计数和耗时。\n\ndef exportingcursorwrapper(cursor_class, alias, vendor):\n    labels = {"alias": alias, "vendor": vendor}\n\n    class cursorwrapper(cursor_class):\n        def execute(self, *args, **kwargs):\n            execute_total.labels(alias, vendor).inc()\n            with query_duration_seconds.labels(**labels).time(), exceptioncounterbytype(\n                errors_total, extra_labels=labels\n            ):\n                return super().execute(*args, **kwargs)\n\n        def executemany(self, query, param_list, *args, **kwargs):\n            execute_total.labels(alias, vendor).inc(len(param_list))\n            execute_many_total.labels(alias, vendor).inc(len(param_list))\n            with query_duration_seconds.labels(**labels).time(), exceptioncounterbytype(\n                errors_total, extra_labels=labels\n            ):\n                return super().executemany(query, param_list, *args, **kwargs)\n\n    return cursorwrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n指标列表\n\n指标                                 说明\ndjango_db_query_duration_seconds   数据库所有的操作耗时，包含了增删改查\ndjango_db_new_connections_total    数据库创建的连接数\nexecute_total                      数据库执行总数\n\n‍\n\n\n# redis指标\n\n使用方法\n\n在 settings.py 中配置redis\n\ncaches = {\n    \'default\': {\n        \'backend\': \'django_prometheus.cache.backends.redis.rediscache\',\n        \'location\': \'redis://127.0.0.1:6379\'\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n在 view.py 中新增 my_view3 接口，对redis进行操作\n\ndef my_view3(request):\n    cache.set("name", "zhangsan")\n    return httpresponse(cache.get("name"))\n\n\n1\n2\n3\n\n\n在url.py中新增对应路由\n\npath(\'myview3/\', my_view3)\n\n\n1\n\n\n调用接口 /myview3 接口，然后获取指标，就可以看到redis相关的指标参数\n\ndjango_cache_get_total{backend="redis"} 1.0\ndjango_cache_get_created{backend="redis"} 1.7265568108417125e+09\ndjango_cache_get_hits_total{backend="redis"} 1.0\ndjango_cache_get_hits_created{backend="redis"} 1.726556810842234e+09\n\n\n1\n2\n3\n4\n\n\n实现原理\n\n我们看到 django_prometheus/cache/backends/redis.py 中的class rediscache，该类继承了已有的缓存类 cache.rediscache，重写了方法get，在调用父类操作方法的前后添加指标。\n\nclass rediscache(cache.rediscache):\n    @cache.omit_exception\n    def get(self, key, default=none, version=none, client=none):\n        try:\n            django_cache_get_total.labels(backend="redis").inc()\n            cached = self.client.get(key, default=none, version=version, client=client)\n        except exceptions.connectioninterrupted as e:\n            django_cache_get_fail_total.labels(backend="redis").inc()\n            if self._ignore_exceptions:\n                if self._log_ignored_exceptions:\n                    cache.logger.error(str(e))\n                return default\n            raise\n        else:\n            if cached is not none:\n                django_cache_hits_total.labels(backend="redis").inc()\n                return cached\n            else:\n                django_cache_misses_total.labels(backend="redis").inc()\n                return default\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n‍\n\n\n# 总结\n\ndjango-prometheus 是在充分的理解了django本身的机制上，通过已提供的钩子，或者重写部分的方法，替换掉内置的组件的方式，来达到自己的目的，这种方法值得参考与学习。\n\n‍',charsets:{cjk:!0},lastUpdated:"2025/02/09, 23:47:02",lastUpdatedTimestamp:1739116022e3},{title:"django rest_framework 分页",frontmatter:{title:"django rest_framework 分页",date:"2023-03-20T11:32:52.000Z",permalink:"/pages/cb262f/",categories:["编程","python","django"],tags:[null],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文主要介绍在drf框架中如何对查询的数据进行分页，在drf框架中有提供该基础功能的使用案例和文档，详情参考drf-pagination-官网文档",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"django rest_framework 分页"},{name:"twitter:description",content:"本文主要介绍在drf框架中如何对查询的数据进行分页，在drf框架中有提供该基础功能的使用案例和文档，详情参考drf-pagination-官网文档"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/17.django%20rest_framework%20%E5%88%86%E9%A1%B5.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django rest_framework 分页"},{property:"og:description",content:"本文主要介绍在drf框架中如何对查询的数据进行分页，在drf框架中有提供该基础功能的使用案例和文档，详情参考drf-pagination-官网文档"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/06.django/17.django%20rest_framework%20%E5%88%86%E9%A1%B5.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-03-20T11:32:52.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"django rest_framework 分页"},{itemprop:"description",content:"本文主要介绍在drf框架中如何对查询的数据进行分页，在drf框架中有提供该基础功能的使用案例和文档，详情参考drf-pagination-官网文档"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/17.django%20rest_framework%20%E5%88%86%E9%A1%B5.html",relativePath:"04.编程/01.python/06.django/17.django rest_framework 分页.md",key:"v-ff2c286e",path:"/pages/cb262f/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"内置分页方式",slug:"内置分页方式",normalizedTitle:"内置分页方式",charIndex:84},{level:2,title:"自定义分页",slug:"自定义分页",normalizedTitle:"自定义分页",charIndex:375},{level:2,title:"自定义分页响应数据",slug:"自定义分页响应数据",normalizedTitle:"自定义分页响应数据",charIndex:906},{level:2,title:"配置",slug:"配置",normalizedTitle:"配置",charIndex:1513},{level:3,title:"全局",slug:"全局",normalizedTitle:"全局",charIndex:1520},{level:3,title:"局部",slug:"局部",normalizedTitle:"局部",charIndex:1862}],headersStr:"简介 内置分页方式 自定义分页 自定义分页响应数据 配置 全局 局部",content:"# 简介\n\n本文主要介绍在drf框架中如何对查询的数据进行分页，在drf框架中有提供该基础功能的使用案例和文档，详情参考drf-pagination-官网文档\n\n\n# 内置分页方式\n\ndrf框架中默认提供几种分页方式，并封装成了模块提供给开发者调用，主要是以下几种：\n\n * PageNumberPagination，主要是提供page 和page_size 进行分页。\n   * page，当前页数\n   * page_size，每页展示的数量\n * LimitOffsetPagination，提供limit 和offset 进行分页\n   * limit，当前分页展示的数量\n   * offset，当前数据是从第几行开始。\n * CursorPagination，对结果集中提供前进与后退的链接来进行操作，不允许随意跳动到任意位置。\n\n\n# 自定义分页\n\n框架本身提供了分类的模块，但在实际工作中并不适用，所以我们可以通过继承的方式对内置的分页模块中的部分属性进行覆盖，以符合自身业务。\n\nclass LargeResultsSetPagination(PageNumberPagination):\n    page_size = 1000\n    page_size_query_param = 'page_size'\n    max_page_size = 10000\n\nclass StandardResultsSetPagination(PageNumberPagination):\n    page_size = 100   \n    page_size_query_param = 'page_size'\n    max_page_size = 1000\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n参数：\n\n * page_size：请求接口未指明时，默认使用该值来查询数据量\n * max_page_size：这个是限制一页最大能展示的数量。\n * page_size_query_param：前端请求分页数量的字段\n\n上面是部分常用的字段，如果有特殊业务可以看源码再进行修改。\n\n\n# 自定义分页响应数据\n\n在内置的分页类PageNumberPagination 中响应的数据格式如下：\n\n{\n    \"count\": 总数,\n    \"next\": 下一页的链接,\n    \"previous\": 上一页的链接,\n    \"results\": 分页后的数据\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n但实我们在业务中可能并不需要next 和previous ，只需要保留count 和results 两个字段，这个时候我们可以通过重写get_paginated_response 方法需要对响应的数据进行裁剪。\n\nclass LargeResultsSetPagination(PageNumberPagination):\n    page_size = 1000\n    page_size_query_param = 'page_size'\n    max_page_size = 10000\n\n    def get_paginated_response(self, data):\n        return Response(OrderedDict([\n            ('count', self.page.paginator.count),\n            ('results', data)\n        ]))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 配置\n\n\n# 全局\n\n在settings.py 中可以设置全局的分页模式，在REST_FRAMEWORK 中设置DEFAULT_PAGINATION_CLASS ，该key是指定分页模式使用哪个分页类，而这里使用的是drf框架中内置的分页类LimitOffsetPagination，并设置参数PAGE_SIZE指定每页默认展示的数量。\n\nREST_FRAMEWORK = {\n    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.LimitOffsetPagination',\n    'PAGE_SIZE': 100\n}\n\n\n1\n2\n3\n4\n\n\n该项配置会对全局生效，也就是每一个view的List查询都会走该分页模式。\n\n\n# 局部\n\n在某些业务场景是不需要分页的，或者不同的接口需要使用的分页模式不同，那么上面的全局配置方法就不适用的了，这个时候就需要使用局部配置的方式。\n\n首先不进行全局模式，在需要分页的View中添加pagination_class 并设置对应的分页模式类，这里使用的是自定义的分页类，该配置只会在本View中生效。\n\nclass BillingRecordsView(generics.ListAPIView):\n    queryset = Billing.objects.all()\n    serializer_class = BillingRecordsSerializer\n    pagination_class = LargeResultsSetPagination\n\n\n1\n2\n3\n4\n",normalizedContent:"# 简介\n\n本文主要介绍在drf框架中如何对查询的数据进行分页，在drf框架中有提供该基础功能的使用案例和文档，详情参考drf-pagination-官网文档\n\n\n# 内置分页方式\n\ndrf框架中默认提供几种分页方式，并封装成了模块提供给开发者调用，主要是以下几种：\n\n * pagenumberpagination，主要是提供page 和page_size 进行分页。\n   * page，当前页数\n   * page_size，每页展示的数量\n * limitoffsetpagination，提供limit 和offset 进行分页\n   * limit，当前分页展示的数量\n   * offset，当前数据是从第几行开始。\n * cursorpagination，对结果集中提供前进与后退的链接来进行操作，不允许随意跳动到任意位置。\n\n\n# 自定义分页\n\n框架本身提供了分类的模块，但在实际工作中并不适用，所以我们可以通过继承的方式对内置的分页模块中的部分属性进行覆盖，以符合自身业务。\n\nclass largeresultssetpagination(pagenumberpagination):\n    page_size = 1000\n    page_size_query_param = 'page_size'\n    max_page_size = 10000\n\nclass standardresultssetpagination(pagenumberpagination):\n    page_size = 100   \n    page_size_query_param = 'page_size'\n    max_page_size = 1000\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n参数：\n\n * page_size：请求接口未指明时，默认使用该值来查询数据量\n * max_page_size：这个是限制一页最大能展示的数量。\n * page_size_query_param：前端请求分页数量的字段\n\n上面是部分常用的字段，如果有特殊业务可以看源码再进行修改。\n\n\n# 自定义分页响应数据\n\n在内置的分页类pagenumberpagination 中响应的数据格式如下：\n\n{\n    \"count\": 总数,\n    \"next\": 下一页的链接,\n    \"previous\": 上一页的链接,\n    \"results\": 分页后的数据\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n但实我们在业务中可能并不需要next 和previous ，只需要保留count 和results 两个字段，这个时候我们可以通过重写get_paginated_response 方法需要对响应的数据进行裁剪。\n\nclass largeresultssetpagination(pagenumberpagination):\n    page_size = 1000\n    page_size_query_param = 'page_size'\n    max_page_size = 10000\n\n    def get_paginated_response(self, data):\n        return response(ordereddict([\n            ('count', self.page.paginator.count),\n            ('results', data)\n        ]))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 配置\n\n\n# 全局\n\n在settings.py 中可以设置全局的分页模式，在rest_framework 中设置default_pagination_class ，该key是指定分页模式使用哪个分页类，而这里使用的是drf框架中内置的分页类limitoffsetpagination，并设置参数page_size指定每页默认展示的数量。\n\nrest_framework = {\n    'default_pagination_class': 'rest_framework.pagination.limitoffsetpagination',\n    'page_size': 100\n}\n\n\n1\n2\n3\n4\n\n\n该项配置会对全局生效，也就是每一个view的list查询都会走该分页模式。\n\n\n# 局部\n\n在某些业务场景是不需要分页的，或者不同的接口需要使用的分页模式不同，那么上面的全局配置方法就不适用的了，这个时候就需要使用局部配置的方式。\n\n首先不进行全局模式，在需要分页的view中添加pagination_class 并设置对应的分页模式类，这里使用的是自定义的分页类，该配置只会在本view中生效。\n\nclass billingrecordsview(generics.listapiview):\n    queryset = billing.objects.all()\n    serializer_class = billingrecordsserializer\n    pagination_class = largeresultssetpagination\n\n\n1\n2\n3\n4\n",charsets:{cjk:!0},lastUpdated:"2025/02/09, 23:47:02",lastUpdatedTimestamp:1739116022e3},{title:"flask结合mongo",frontmatter:{tags:["python","flask"],title:"flask结合mongo",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/c59edf/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"在flask中集成第三方库flask-mongoengine来通过ORM操作mongo数据库",feed:{enable:!0},categories:["编程","python","flask"],comment:!0,meta:[{name:"twitter:title",content:"flask结合mongo"},{name:"twitter:description",content:"在flask中集成第三方库flask-mongoengine来通过ORM操作mongo数据库"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/07.flask/02.flask%E7%BB%93%E5%90%88mongo.html"},{property:"og:type",content:"article"},{property:"og:title",content:"flask结合mongo"},{property:"og:description",content:"在flask中集成第三方库flask-mongoengine来通过ORM操作mongo数据库"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/07.flask/02.flask%E7%BB%93%E5%90%88mongo.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"flask"},{itemprop:"name",content:"flask结合mongo"},{itemprop:"description",content:"在flask中集成第三方库flask-mongoengine来通过ORM操作mongo数据库"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/07.flask/02.flask%E7%BB%93%E5%90%88mongo.html",relativePath:"04.编程/01.python/07.flask/02.flask结合mongo.md",key:"v-364f49b5",path:"/pages/c59edf/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:83},{level:2,title:"使用",slug:"使用",normalizedTitle:"使用",charIndex:26},{level:2,title:"解決问题",slug:"解決问题",normalizedTitle:"解決问题",charIndex:857}],headersStr:"简介 相关链接 使用 解決问题",content:'# 简介\n\n本文是flask中对mongo的操作. 使用Flask-MongoEngine集成了mongo的操作，使用的是类似于django中的orm操作。\n\n\n# 相关链接\n\nFlask-MongoEngine文档\n\nMongoEngine文档\n\n\n# 使用\n\nmongo的配置. flask将这个配置加载进来即可.\n\nMONGODB_SETTINGS = {\n    "db": "lifeAssistant",\n    "host": "192.168.0.206",\n    "port": 27017\n}\n\n\n1\n2\n3\n4\n5\n\n\n创建mongo引擎.\n\nfrom flask_mongoengine import MongoEngine\nmongodb = MongoEngine()\n\n\n1\n2\n\n\n创建Document，类似于django的model.\n\nfrom lifeAssistant.extension import mongodb\n\nclass Article(mongodb.Document):\n    category = mongodb.StringField()\n    category2 = mongodb.StringField()\n    title = mongodb.StringField()\n    content = mongodb.StringField()\n    publisher = mongodb.StringField()\n    publisher_time = mongodb.StringField()\n    create_time = mongodb.StringField()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n使用Document进行操作. 其他操作请看官方文档\n\n\n# 通过id获取数据.  \ninstance = Article.objects.get_or_404(id=id)\n\n\n1\n2\n3\n\n\n\n# 解決问题\n\nmongo数据转json\n\n问题: mongo转json时，会输出ObjectId这对象，而不是直接的id值，这个时候需要转换.\n\n\n# 这个是将mongo Document对象转换成json的编码器\nclass MongoEncoder(JSONEncoder):\n    def default(self, o):\n\n        # 转换日期\n        if isinstance(o, (datetime, date)):\n            pass\n\n        # 转换Document\n        if isinstance(o, BaseDocument):\n            return o.to_mongo()\n\n        # 转换id\n        if isinstance(o, ObjectId):\n            return str(o)\n\n        return JSONEncoder.default(self, o)\n\n\n\n# 在蓝图上添加mongo解码器.  jsonify会自动将Document对象转成json\nbp = Blueprint("article", __name__, url_prefix="/article")\nbp.json_encoder = MongoEncoder\n\n\n@bp.route("/<id>/", methods=("GET",))\ndef article(id: str):\n    instance = Article.objects.get_or_404(id=id)\n\n    return jsonify({\n        "code": 0,\n        "msg": "success",\n        "data": instance\n    })\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n',normalizedContent:'# 简介\n\n本文是flask中对mongo的操作. 使用flask-mongoengine集成了mongo的操作，使用的是类似于django中的orm操作。\n\n\n# 相关链接\n\nflask-mongoengine文档\n\nmongoengine文档\n\n\n# 使用\n\nmongo的配置. flask将这个配置加载进来即可.\n\nmongodb_settings = {\n    "db": "lifeassistant",\n    "host": "192.168.0.206",\n    "port": 27017\n}\n\n\n1\n2\n3\n4\n5\n\n\n创建mongo引擎.\n\nfrom flask_mongoengine import mongoengine\nmongodb = mongoengine()\n\n\n1\n2\n\n\n创建document，类似于django的model.\n\nfrom lifeassistant.extension import mongodb\n\nclass article(mongodb.document):\n    category = mongodb.stringfield()\n    category2 = mongodb.stringfield()\n    title = mongodb.stringfield()\n    content = mongodb.stringfield()\n    publisher = mongodb.stringfield()\n    publisher_time = mongodb.stringfield()\n    create_time = mongodb.stringfield()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n使用document进行操作. 其他操作请看官方文档\n\n\n# 通过id获取数据.  \ninstance = article.objects.get_or_404(id=id)\n\n\n1\n2\n3\n\n\n\n# 解決问题\n\nmongo数据转json\n\n问题: mongo转json时，会输出objectid这对象，而不是直接的id值，这个时候需要转换.\n\n\n# 这个是将mongo document对象转换成json的编码器\nclass mongoencoder(jsonencoder):\n    def default(self, o):\n\n        # 转换日期\n        if isinstance(o, (datetime, date)):\n            pass\n\n        # 转换document\n        if isinstance(o, basedocument):\n            return o.to_mongo()\n\n        # 转换id\n        if isinstance(o, objectid):\n            return str(o)\n\n        return jsonencoder.default(self, o)\n\n\n\n# 在蓝图上添加mongo解码器.  jsonify会自动将document对象转成json\nbp = blueprint("article", __name__, url_prefix="/article")\nbp.json_encoder = mongoencoder\n\n\n@bp.route("/<id>/", methods=("get",))\ndef article(id: str):\n    instance = article.objects.get_or_404(id=id)\n\n    return jsonify({\n        "code": 0,\n        "msg": "success",\n        "data": instance\n    })\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"tornado 文件上传",frontmatter:{title:"tornado 文件上传",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/4c38f5/",tags:["python","tornado"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"tornado实现的文件上传功能",feed:{enable:!0},categories:["编程","python","tornado"],comment:!0,meta:[{name:"twitter:title",content:"tornado 文件上传"},{name:"twitter:description",content:"tornado实现的文件上传功能"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/01.tornado%20%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tornado 文件上传"},{property:"og:description",content:"tornado实现的文件上传功能"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/01.tornado%20%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"tornado"},{itemprop:"name",content:"tornado 文件上传"},{itemprop:"description",content:"tornado实现的文件上传功能"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/01.tornado%20%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0.html",relativePath:"04.编程/01.python/08.tornado/01.tornado 文件上传.md",key:"v-2f2878f8",path:"/pages/4c38f5/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"栗子",slug:"栗子",normalizedTitle:"栗子",charIndex:71}],headersStr:"简介 栗子",content:'# 简介\n\n文章介绍的是使用tornado完成文件的上传功能\n\n该项目的github地址: tornado_learning.git\n\n\n# 栗子\n\n设置文件上传的路径\n\n代码: tornado_learning/settings.py\n\nBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsettings = {\n    "MEDIA_ROOT": os.path.join(BASE_DIR, "media"),\n}\n\n\n1\n2\n3\n4\n\n\n保存上传文件\n\n获取前端传送过来的front_image文件，然后再使用aiofiles完成上传文件的二进制异步写入。\n\n代码: /apps/hello/uploadHandler.py\n\n\nfrom tornado_learning.handler import BaseHandler\nimport os\nimport uuid\nimport aiofiles\n\nclass UploadHandler(BaseHandler):\n\n    async def post(self):\n        ret_data = {}\n\n        files_meta = self.request.files.get("front_image", None)\n        if not files_meta:\n            self.set_status(400)\n            ret_data["front_image"] = "请上传图片"\n        else:\n            for meta in files_meta:\n                filename = meta["filename"]\n                new_filename = "{uuid}_{filename}".format(uuid=uuid.uuid1(), filename=filename)\n                file_path = os.path.join(self.settings["MEDIA_ROOT"], new_filename)\n\n                async with aiofiles.open(file_path, "wb") as f:\n                    await f.write(meta["body"])\n\n                ret_data[\'file_path\'] = file_path\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n',normalizedContent:'# 简介\n\n文章介绍的是使用tornado完成文件的上传功能\n\n该项目的github地址: tornado_learning.git\n\n\n# 栗子\n\n设置文件上传的路径\n\n代码: tornado_learning/settings.py\n\nbase_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsettings = {\n    "media_root": os.path.join(base_dir, "media"),\n}\n\n\n1\n2\n3\n4\n\n\n保存上传文件\n\n获取前端传送过来的front_image文件，然后再使用aiofiles完成上传文件的二进制异步写入。\n\n代码: /apps/hello/uploadhandler.py\n\n\nfrom tornado_learning.handler import basehandler\nimport os\nimport uuid\nimport aiofiles\n\nclass uploadhandler(basehandler):\n\n    async def post(self):\n        ret_data = {}\n\n        files_meta = self.request.files.get("front_image", none)\n        if not files_meta:\n            self.set_status(400)\n            ret_data["front_image"] = "请上传图片"\n        else:\n            for meta in files_meta:\n                filename = meta["filename"]\n                new_filename = "{uuid}_{filename}".format(uuid=uuid.uuid1(), filename=filename)\n                file_path = os.path.join(self.settings["media_root"], new_filename)\n\n                async with aiofiles.open(file_path, "wb") as f:\n                    await f.write(meta["body"])\n\n                ret_data[\'file_path\'] = file_path\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"tornado 使用jwt完成用户异步认证",frontmatter:{tags:["python","tornado"],title:"tornado 使用jwt完成用户异步认证",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/c24905/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"tornado使用jwt实现用户的异步认证",feed:{enable:!0},categories:["编程","python","tornado"],comment:!0,meta:[{name:"twitter:title",content:"tornado 使用jwt完成用户异步认证"},{name:"twitter:description",content:"tornado使用jwt实现用户的异步认证"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/02.tornado%20%E4%BD%BF%E7%94%A8jwt%E5%AE%8C%E6%88%90%E7%94%A8%E6%88%B7%E5%BC%82%E6%AD%A5%E8%AE%A4%E8%AF%81.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tornado 使用jwt完成用户异步认证"},{property:"og:description",content:"tornado使用jwt实现用户的异步认证"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/02.tornado%20%E4%BD%BF%E7%94%A8jwt%E5%AE%8C%E6%88%90%E7%94%A8%E6%88%B7%E5%BC%82%E6%AD%A5%E8%AE%A4%E8%AF%81.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"tornado"},{itemprop:"name",content:"tornado 使用jwt完成用户异步认证"},{itemprop:"description",content:"tornado使用jwt实现用户的异步认证"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/02.tornado%20%E4%BD%BF%E7%94%A8jwt%E5%AE%8C%E6%88%90%E7%94%A8%E6%88%B7%E5%BC%82%E6%AD%A5%E8%AE%A4%E8%AF%81.html",relativePath:"04.编程/01.python/08.tornado/02.tornado 使用jwt完成用户异步认证.md",key:"v-33efde74",path:"/pages/c24905/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"栗子",slug:"栗子",normalizedTitle:"栗子",charIndex:156}],headersStr:"简介 栗子",content:'# 简介\n\n在使用特定功能时，需要验证用户是否登录。使用jwt将用户不敏感的信息保存在客户端上，然后访问时，将加密的信息发送给服务端验证。\n\n和session的不同之处在于，session需要在两端都存储，而jwt仅在客户端存储。\n\n该项目的github地址: tornado_learning.git\n\n\n# 栗子\n\n创建异步验证的装饰器\n\n从header中获取tsessionid的jwt token信息，然后从token获取用户id，从数据库中查找用户信息，再验证token是否过期。\n\n代码: utils/authenticated_async.py\n\ndef authenticated_async(method):\n    async def wrapper(self, *args, **kwargs):\n\n        # ret_data = {}\n\n        tsessionid = self.request.headers.get("tsessionid", None)\n        if tsessionid:\n\n            try:\n                payload = jwt.decode(tsessionid, self.settings["secret_key"], leeway=self.settings["jwt_expire"],\n                                     options={"verify_exp": True})\n\n                user_id = payload["id"]\n                try:\n                    user = await self.application.objects.get(User, id=user_id)\n                    self._current_user = user\n                    await method(self, *args, **kwargs)\n                except User.DoesNotExist as e:\n                    self.set_status(401)\n            except jwt.ExpiredSignatureError as e:\n                self.set_status(401)\n\n    return wrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n在请求上添加用户认证\n\n每次在请求该接口时，都需要对进行用户认证，认证通过才能访问该接口。\n\n代码: apps/school/handle.py\n\n\nfrom utils.authenticated_async import authenticated_async\n\nclass StudentHandler(BaseHandler):\n\n    @authenticated_async\n    async def get(self):\n        id = self.get_argument("id", None)\n        if not id:\n            return self.write("please provide the \'id\'")\n\n        student = await self.application.objects.get(Student, id=id)\n\n        try:\n            self.write({\n                "id": student.id,\n                "name": student.name\n            })\n        except Student.DoesNotExist:\n            raise tornado.webHttpError(404, "Object not found")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n',normalizedContent:'# 简介\n\n在使用特定功能时，需要验证用户是否登录。使用jwt将用户不敏感的信息保存在客户端上，然后访问时，将加密的信息发送给服务端验证。\n\n和session的不同之处在于，session需要在两端都存储，而jwt仅在客户端存储。\n\n该项目的github地址: tornado_learning.git\n\n\n# 栗子\n\n创建异步验证的装饰器\n\n从header中获取tsessionid的jwt token信息，然后从token获取用户id，从数据库中查找用户信息，再验证token是否过期。\n\n代码: utils/authenticated_async.py\n\ndef authenticated_async(method):\n    async def wrapper(self, *args, **kwargs):\n\n        # ret_data = {}\n\n        tsessionid = self.request.headers.get("tsessionid", none)\n        if tsessionid:\n\n            try:\n                payload = jwt.decode(tsessionid, self.settings["secret_key"], leeway=self.settings["jwt_expire"],\n                                     options={"verify_exp": true})\n\n                user_id = payload["id"]\n                try:\n                    user = await self.application.objects.get(user, id=user_id)\n                    self._current_user = user\n                    await method(self, *args, **kwargs)\n                except user.doesnotexist as e:\n                    self.set_status(401)\n            except jwt.expiredsignatureerror as e:\n                self.set_status(401)\n\n    return wrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n在请求上添加用户认证\n\n每次在请求该接口时，都需要对进行用户认证，认证通过才能访问该接口。\n\n代码: apps/school/handle.py\n\n\nfrom utils.authenticated_async import authenticated_async\n\nclass studenthandler(basehandler):\n\n    @authenticated_async\n    async def get(self):\n        id = self.get_argument("id", none)\n        if not id:\n            return self.write("please provide the \'id\'")\n\n        student = await self.application.objects.get(student, id=id)\n\n        try:\n            self.write({\n                "id": student.id,\n                "name": student.name\n            })\n        except student.doesnotexist:\n            raise tornado.webhttperror(404, "object not found")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"tornado 用户密码 bcrypt加密",frontmatter:{tags:["python","tornado"],title:"tornado 用户密码 bcrypt加密",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/22f35b/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"使用bcrypt来实现对用户密码进行加密",feed:{enable:!0},categories:["编程","python","tornado"],comment:!0,meta:[{name:"twitter:title",content:"tornado 用户密码 bcrypt加密"},{name:"twitter:description",content:"使用bcrypt来实现对用户密码进行加密"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/03.tornado%20%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%20bcrypt%E5%8A%A0%E5%AF%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tornado 用户密码 bcrypt加密"},{property:"og:description",content:"使用bcrypt来实现对用户密码进行加密"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/03.tornado%20%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%20bcrypt%E5%8A%A0%E5%AF%86.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"tornado"},{itemprop:"name",content:"tornado 用户密码 bcrypt加密"},{itemprop:"description",content:"使用bcrypt来实现对用户密码进行加密"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/03.tornado%20%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%20bcrypt%E5%8A%A0%E5%AF%86.html",relativePath:"04.编程/01.python/08.tornado/03.tornado 用户密码 bcrypt加密.md",key:"v-5000cd97",path:"/pages/22f35b/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"python 如何使用bcrypt 栗子",slug:"python-如何使用bcrypt-栗子",normalizedTitle:"python 如何使用bcrypt 栗子",charIndex:175},{level:2,title:"tornado 使用 bcrypt 加密密码栗子。",slug:"tornado-使用-bcrypt-加密密码栗子。",normalizedTitle:"tornado 使用 bcrypt 加密密码栗子。",charIndex:437},{level:3,title:"创建user model",slug:"创建user-model",normalizedTitle:"创建user model",charIndex:467},{level:3,title:"注册的handler",slug:"注册的handler",normalizedTitle:"注册的handler",charIndex:2218}],headersStr:"简介 python 如何使用bcrypt 栗子 tornado 使用 bcrypt 加密密码栗子。 创建user model 注册的handler",content:'# 简介\n\nbcrypt 可以通过加盐的方式对密码进行加密，更加的安全可靠。\n\n该项目的github地址: tornado_learning.git\n\n优点\n\nmd5加密，每个对应的明文密码，对应的是一样的加密的密文，比较容易的进行解密。而bcrypt每一次的明文密码得到的是不同的加密的密文，因为密文是通过随机的盐结合加密，所以更加安全。\n\n\n# python 如何使用bcrypt 栗子\n\nfrom bcrypt import hashpw, gensalt\n\n# 这个是随机生成的盐\nsalt = gensalt(12)\n\n# 这个是通过盐去加密\npasswd = hashpw("123456".encode(\'utf8\'), salt)\n\n# 将输入的明文密码与密文密码进行加密，是否等于密文密码。\nhashpw(input_passwd.encode(\'utf8\'), passwd) == passwd\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# tornado 使用 bcrypt 加密密码栗子。\n\n\n# 创建user model\n\n在user model中的密码字段使用自定义的PasswordField.\n\n代码/apps/user/models.py\n\nclass PasswordHash(bytes):\n    def check_password(self, password):\n        """\n        比较传入的密码和数据库中的密码是否匹配\n        :param password:\n        :return:\n        """\n        password = password.encode(\'utf-8\')\n        return hashpw(password, self) == self\n\nclass PasswordField(BlobField):\n    def __init__(self, iterations=12, *args, **kwargs):\n        if None in (hashpw, gensalt):\n            raise ValueError(\'Missing library required for PasswordField: bcrypt\')\n        self.bcrypt_iterations = iterations\n        self.raw_password = None\n        super(PasswordField, self).__init__(*args, **kwargs)\n\n    def db_value(self, value):\n        """\n        将python的值转换成存入数据库的值\n        存入数据库的值，是通过bcrypt加密后的密文。\n        :param value:\n        :return:\n        """\n        if isinstance(value, PasswordHash):\n            return bytes(value)\n\n        if isinstance(value, str):\n            value = value.encode(\'utf-8\')\n        salt = gensalt(self.bcrypt_iterations)\n        return value if value is None else hashpw(value, salt)\n\n    def python_value(self, value):\n        """\n        将数据库中的值转换成python中的值\n        这个值是一个PasswordHash对象。该对象提供比较密码的方法。\n        :param value:\n        :return:\n        """\n        if isinstance(value, str):\n            value = value.encode(\'utf-8\')\n\n        return PasswordHash(value)\n\nclass User(BaseModel):\n    username = CharField(max_length=16, verbose_name="用户名", index=True, unique=True)\n    password = PasswordField(verbose_name="密码")\n    address = CharField(max_length=200, null=True, verbose_name="地址")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n\n\n\n# 注册的handler\n\n注册的接口\n\n代码: /apps/user/handler.py\n\nclass RegisterHandler(BaseHandler):\n\n    async def post(self):\n\n        ret_data = {}\n\n        registerForm = RegisterForm(self.request.arguments)\n        if registerForm.validate():\n            username = registerForm.username.data\n\n            try:\n                exist_user = await self.application.objects.get(User, username=username)\n                ret_data["username"] = "用户名已经存在"\n            except User.DoesNotExist as e:\n                user = await self.application.objects.create(User, **registerForm.data)\n                ret_data["id"] = user.id\n        else:\n            self.set_status(400)\n            for field in registerForm.erros:\n                ret_data[field] = registerForm[field][0]\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n',normalizedContent:'# 简介\n\nbcrypt 可以通过加盐的方式对密码进行加密，更加的安全可靠。\n\n该项目的github地址: tornado_learning.git\n\n优点\n\nmd5加密，每个对应的明文密码，对应的是一样的加密的密文，比较容易的进行解密。而bcrypt每一次的明文密码得到的是不同的加密的密文，因为密文是通过随机的盐结合加密，所以更加安全。\n\n\n# python 如何使用bcrypt 栗子\n\nfrom bcrypt import hashpw, gensalt\n\n# 这个是随机生成的盐\nsalt = gensalt(12)\n\n# 这个是通过盐去加密\npasswd = hashpw("123456".encode(\'utf8\'), salt)\n\n# 将输入的明文密码与密文密码进行加密，是否等于密文密码。\nhashpw(input_passwd.encode(\'utf8\'), passwd) == passwd\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# tornado 使用 bcrypt 加密密码栗子。\n\n\n# 创建user model\n\n在user model中的密码字段使用自定义的passwordfield.\n\n代码/apps/user/models.py\n\nclass passwordhash(bytes):\n    def check_password(self, password):\n        """\n        比较传入的密码和数据库中的密码是否匹配\n        :param password:\n        :return:\n        """\n        password = password.encode(\'utf-8\')\n        return hashpw(password, self) == self\n\nclass passwordfield(blobfield):\n    def __init__(self, iterations=12, *args, **kwargs):\n        if none in (hashpw, gensalt):\n            raise valueerror(\'missing library required for passwordfield: bcrypt\')\n        self.bcrypt_iterations = iterations\n        self.raw_password = none\n        super(passwordfield, self).__init__(*args, **kwargs)\n\n    def db_value(self, value):\n        """\n        将python的值转换成存入数据库的值\n        存入数据库的值，是通过bcrypt加密后的密文。\n        :param value:\n        :return:\n        """\n        if isinstance(value, passwordhash):\n            return bytes(value)\n\n        if isinstance(value, str):\n            value = value.encode(\'utf-8\')\n        salt = gensalt(self.bcrypt_iterations)\n        return value if value is none else hashpw(value, salt)\n\n    def python_value(self, value):\n        """\n        将数据库中的值转换成python中的值\n        这个值是一个passwordhash对象。该对象提供比较密码的方法。\n        :param value:\n        :return:\n        """\n        if isinstance(value, str):\n            value = value.encode(\'utf-8\')\n\n        return passwordhash(value)\n\nclass user(basemodel):\n    username = charfield(max_length=16, verbose_name="用户名", index=true, unique=true)\n    password = passwordfield(verbose_name="密码")\n    address = charfield(max_length=200, null=true, verbose_name="地址")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n\n\n\n# 注册的handler\n\n注册的接口\n\n代码: /apps/user/handler.py\n\nclass registerhandler(basehandler):\n\n    async def post(self):\n\n        ret_data = {}\n\n        registerform = registerform(self.request.arguments)\n        if registerform.validate():\n            username = registerform.username.data\n\n            try:\n                exist_user = await self.application.objects.get(user, username=username)\n                ret_data["username"] = "用户名已经存在"\n            except user.doesnotexist as e:\n                user = await self.application.objects.create(user, **registerform.data)\n                ret_data["id"] = user.id\n        else:\n            self.set_status(400)\n            for field in registerform.erros:\n                ret_data[field] = registerform[field][0]\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"tornado 结合wtforms使用表单操作",frontmatter:{tags:["python","tornado"],title:"tornado 结合wtforms使用表单操作",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/7ac01f/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"tornado使用wtforms来对表单进行验证与操作。",feed:{enable:!0},categories:["编程","python","tornado"],comment:!0,meta:[{name:"twitter:title",content:"tornado 结合wtforms使用表单操作"},{name:"twitter:description",content:"tornado使用wtforms来对表单进行验证与操作。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/04.tornado%20%E7%BB%93%E5%90%88wtforms%E4%BD%BF%E7%94%A8%E8%A1%A8%E5%8D%95%E6%93%8D%E4%BD%9C.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tornado 结合wtforms使用表单操作"},{property:"og:description",content:"tornado使用wtforms来对表单进行验证与操作。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/04.tornado%20%E7%BB%93%E5%90%88wtforms%E4%BD%BF%E7%94%A8%E8%A1%A8%E5%8D%95%E6%93%8D%E4%BD%9C.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"tornado"},{itemprop:"name",content:"tornado 结合wtforms使用表单操作"},{itemprop:"description",content:"tornado使用wtforms来对表单进行验证与操作。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/04.tornado%20%E7%BB%93%E5%90%88wtforms%E4%BD%BF%E7%94%A8%E8%A1%A8%E5%8D%95%E6%93%8D%E4%BD%9C.html",relativePath:"04.编程/01.python/08.tornado/04.tornado 结合wtforms使用表单操作.md",key:"v-fad5dda8",path:"/pages/7ac01f/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"例子",slug:"例子",normalizedTitle:"例子",charIndex:110},{level:2,title:"html表单",slug:"html表单",normalizedTitle:"html表单",charIndex:1458},{level:2,title:"wtforms 读取json",slug:"wtforms-读取json",normalizedTitle:"wtforms 读取json",charIndex:2568}],headersStr:"简介 例子 html表单 wtforms 读取json",content:'# 简介\n\n在获取请求时，需要将请求的参数进行验证。\n使用wtforms和tornado的结合，可以获取到请求的参数，并且对参数进行验证。\n\n该项目的github地址: tornado_learning.git\n\n\n# 例子\n\n创建student的form\n\n代码: apps/shchool/forms.py\n\n\nfrom wtforms_tornado import Form\nfrom wtforms import StringField, IntegerField, TextAreaField\nfrom wtforms.validators import DataRequired, Length\n\nclass StudentForm(Form):\n    """\n    可以作为student的 post 和 put 的表单使用。\n    """\n\n    id = IntegerField("id", null=True)\n    name = StringField("姓名", validators=[DataRequired("请输入姓名")])\n    age = IntegerField("年龄", validators=[DataRequired("请输入年龄")])\n    desc = TextAreaField("个人简介", validators=[DataRequired("请输入个人简介")])\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后通过form接收参数，对参数进行验证，验证通过则操作model，对数据库进行保存操作\n\n通过遍历student_from.errors得到校验失败的字段，然后再返回到前端提示。\n\n代码: apps/school/handler.py\n\n\nimport tornado\n\nfrom apps.school.forms import StudentForm\nfrom apps.school.models import Student\nfrom tornado_learning.handler import BaseHandler\n\nclass StudentHandler(BaseHandler):\n\n        async def post(self):\n\n        ret_data = {}\n\n        student_form = StudentForm(self.request.arguments)\n        if student_form.validate():\n            await self.application.objects.create(Student, **student_form.data)\n\n            ret_data["ret"] = "success"\n        else:\n            for field in student_form.errors:\n                ret_data[field] = ret_data.errors[field][0]\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# html表单\n\n还可以通过wtforms创建对应的model模板表单。\n\n个人不是很推荐使用，因为前后端耦合性太强。\n\n获取表单\n\n代码: apps/school/forms.py\n\nclass StudentFormHandler(BaseHandler):\n\n    def get(self):\n        studentForm = StudentForm()\n        return self.render("student.html", studentForm=studentForm)\n\n\n1\n2\n3\n4\n5\n\n\n表单的html模板\n将该文件放在templates路径下\n\n代码: templates/student.html\n\n<form action="/student" , method="post">\n    {% autoescape None %}\n    {% for field in studentForm %}\n        <span>{{ field.label.text }} :</span>\n        {{ field(placeholder="请输入"+field.label.text) }}\n\n        {% if field.errors %}\n            {% for error_msg in field.errors %}\n                <div class="error-msg">{{ error_msg }}</div>\n                {% end %}\n                {% else %}\n                <div class="error-msg"></div>\n            {% end %}\n    {% end %}\n\n    <label>\n        <span>&nbsp;</span>\n        <input type="submit" class="button" value="提交"/>\n    </label>\n</form>\n</body>\n</html>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n需要在设置项中设置模板路径\n代码:tornado_learning/settings.py\n\nsettings = {\n    "template_path": "templates"\n}\n\n\n1\n2\n3\n\n\n\n# wtforms 读取json\n\n使用wtforms_json可以使表单直接对json参数的读取。\n\n初始化wtforms_json\n\n首选需要对wtforms_json初始化。\n代码: server.py\n\nimport wtforms_json\nwtforms_json.init()\n\n\n1\n2\n\n\n在handler中获取json参数，然后读入到form中\n\n代码: apps/school/handler.py\n\nclass TeacherHandler(BaseHandler):\n   \n    async def post(self):\n\n        ret_data = {}\n\n        param = self.request.body.decode("utf8")\n        param = json.loads(param)\n\n        teacherForm = TeacherForm.from_json(param)\n        print(teacherForm.data)\n        if teacherForm.validate():\n            teacher = await self.application.objects.create(Teacher, **teacherForm.data)\n\n            ret_data["ret"] = "success"\n        else:\n            for field in teacherForm.errors:\n                ret_data[field] = teacherForm.errors[field][0]\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n',normalizedContent:'# 简介\n\n在获取请求时，需要将请求的参数进行验证。\n使用wtforms和tornado的结合，可以获取到请求的参数，并且对参数进行验证。\n\n该项目的github地址: tornado_learning.git\n\n\n# 例子\n\n创建student的form\n\n代码: apps/shchool/forms.py\n\n\nfrom wtforms_tornado import form\nfrom wtforms import stringfield, integerfield, textareafield\nfrom wtforms.validators import datarequired, length\n\nclass studentform(form):\n    """\n    可以作为student的 post 和 put 的表单使用。\n    """\n\n    id = integerfield("id", null=true)\n    name = stringfield("姓名", validators=[datarequired("请输入姓名")])\n    age = integerfield("年龄", validators=[datarequired("请输入年龄")])\n    desc = textareafield("个人简介", validators=[datarequired("请输入个人简介")])\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后通过form接收参数，对参数进行验证，验证通过则操作model，对数据库进行保存操作\n\n通过遍历student_from.errors得到校验失败的字段，然后再返回到前端提示。\n\n代码: apps/school/handler.py\n\n\nimport tornado\n\nfrom apps.school.forms import studentform\nfrom apps.school.models import student\nfrom tornado_learning.handler import basehandler\n\nclass studenthandler(basehandler):\n\n        async def post(self):\n\n        ret_data = {}\n\n        student_form = studentform(self.request.arguments)\n        if student_form.validate():\n            await self.application.objects.create(student, **student_form.data)\n\n            ret_data["ret"] = "success"\n        else:\n            for field in student_form.errors:\n                ret_data[field] = ret_data.errors[field][0]\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# html表单\n\n还可以通过wtforms创建对应的model模板表单。\n\n个人不是很推荐使用，因为前后端耦合性太强。\n\n获取表单\n\n代码: apps/school/forms.py\n\nclass studentformhandler(basehandler):\n\n    def get(self):\n        studentform = studentform()\n        return self.render("student.html", studentform=studentform)\n\n\n1\n2\n3\n4\n5\n\n\n表单的html模板\n将该文件放在templates路径下\n\n代码: templates/student.html\n\n<form action="/student" , method="post">\n    {% autoescape none %}\n    {% for field in studentform %}\n        <span>{{ field.label.text }} :</span>\n        {{ field(placeholder="请输入"+field.label.text) }}\n\n        {% if field.errors %}\n            {% for error_msg in field.errors %}\n                <div class="error-msg">{{ error_msg }}</div>\n                {% end %}\n                {% else %}\n                <div class="error-msg"></div>\n            {% end %}\n    {% end %}\n\n    <label>\n        <span>&nbsp;</span>\n        <input type="submit" class="button" value="提交"/>\n    </label>\n</form>\n</body>\n</html>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n需要在设置项中设置模板路径\n代码:tornado_learning/settings.py\n\nsettings = {\n    "template_path": "templates"\n}\n\n\n1\n2\n3\n\n\n\n# wtforms 读取json\n\n使用wtforms_json可以使表单直接对json参数的读取。\n\n初始化wtforms_json\n\n首选需要对wtforms_json初始化。\n代码: server.py\n\nimport wtforms_json\nwtforms_json.init()\n\n\n1\n2\n\n\n在handler中获取json参数，然后读入到form中\n\n代码: apps/school/handler.py\n\nclass teacherhandler(basehandler):\n   \n    async def post(self):\n\n        ret_data = {}\n\n        param = self.request.body.decode("utf8")\n        param = json.loads(param)\n\n        teacherform = teacherform.from_json(param)\n        print(teacherform.data)\n        if teacherform.validate():\n            teacher = await self.application.objects.create(teacher, **teacherform.data)\n\n            ret_data["ret"] = "success"\n        else:\n            for field in teacherform.errors:\n                ret_data[field] = teacherform.errors[field][0]\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"tornado finish和write区别",frontmatter:{tags:["python","tornado"],title:"tornado finish和write区别",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/d18657/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍tornado中finish和write的区别",feed:{enable:!0},categories:["编程","python","tornado"],comment:!0,meta:[{name:"twitter:title",content:"tornado finish和write区别"},{name:"twitter:description",content:"介绍tornado中finish和write的区别"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/05.tornado%20finish%E5%92%8Cwrite%E5%8C%BA%E5%88%AB.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tornado finish和write区别"},{property:"og:description",content:"介绍tornado中finish和write的区别"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/05.tornado%20finish%E5%92%8Cwrite%E5%8C%BA%E5%88%AB.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"tornado"},{itemprop:"name",content:"tornado finish和write区别"},{itemprop:"description",content:"介绍tornado中finish和write的区别"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/05.tornado%20finish%E5%92%8Cwrite%E5%8C%BA%E5%88%AB.html",relativePath:"04.编程/01.python/08.tornado/05.tornado finish和write区别.md",key:"v-7f082a66",path:"/pages/d18657/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"例子",slug:"例子",normalizedTitle:"例子",charIndex:82},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:556}],headersStr:"简介 例子 总结",content:'# 简介\n\nfinish和write都可以将后端的数据传输到前端。他们有啥差别嘞。\n\n该项目的github地址: tornado_learning.git\n\n\n# 例子\n\n代码apps/hello/write_finish_handler.py\n\nfrom tornado_learning.handler import BaseHandler\nimport time\n\nclass Write_Finish_Handler(BaseHandler):\n\n    def get(self):\n        self.write("hello")\n        time.sleep(4)\n        self.finish("world")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在等待4秒后，同时输出： hello world\n\nclass Finish_Write_Handler(BaseHandler):\n\n    def get(self):\n        self.finish("hello")\n        self.write("world")\n\n\n1\n2\n3\n4\n5\n\n\n输出: hello\n并且报错: Cannot write() after finish()\n\n\n# 总结\n\nself.finish()代表回应到前端的终结。并且可以在finsh后做一些与回应给前端无关的操作，缩短响应时间。\nself.write()并不会马上将数据返回前端，必须在self.finsh()或者return后才会响应，类似以缓存吧。',normalizedContent:'# 简介\n\nfinish和write都可以将后端的数据传输到前端。他们有啥差别嘞。\n\n该项目的github地址: tornado_learning.git\n\n\n# 例子\n\n代码apps/hello/write_finish_handler.py\n\nfrom tornado_learning.handler import basehandler\nimport time\n\nclass write_finish_handler(basehandler):\n\n    def get(self):\n        self.write("hello")\n        time.sleep(4)\n        self.finish("world")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在等待4秒后，同时输出： hello world\n\nclass finish_write_handler(basehandler):\n\n    def get(self):\n        self.finish("hello")\n        self.write("world")\n\n\n1\n2\n3\n4\n5\n\n\n输出: hello\n并且报错: cannot write() after finish()\n\n\n# 总结\n\nself.finish()代表回应到前端的终结。并且可以在finsh后做一些与回应给前端无关的操作，缩短响应时间。\nself.write()并不会马上将数据返回前端，必须在self.finsh()或者return后才会响应，类似以缓存吧。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"python简单使用grpc",frontmatter:{title:"python简单使用grpc",date:"2022-09-06T19:45:31.000Z",permalink:"/pages/f9d78c/",tags:["python"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"简单介绍Python如何使用grpc",feed:{enable:!0},categories:["编程","python","其他"],comment:!0,meta:[{name:"twitter:title",content:"python简单使用grpc"},{name:"twitter:description",content:"简单介绍Python如何使用grpc"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/01.python%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8grpc.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python简单使用grpc"},{property:"og:description",content:"简单介绍Python如何使用grpc"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/01.python%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8grpc.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-09-06T19:45:31.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python简单使用grpc"},{itemprop:"description",content:"简单介绍Python如何使用grpc"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/01.python%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8grpc.html",relativePath:"04.编程/01.python/09.其他/01.python简单使用grpc.md",key:"v-4371bf05",path:"/pages/f9d78c/",headers:[{level:2,title:"0. 相关链接",slug:"_0-相关链接",normalizedTitle:"0. 相关链接",charIndex:2},{level:2,title:"1. 创建protobuf文件",slug:"_1-创建protobuf文件",normalizedTitle:"1. 创建protobuf文件",charIndex:117},{level:2,title:"2. 编译proto文件",slug:"_2-编译proto文件",normalizedTitle:"2. 编译proto文件",charIndex:827},{level:2,title:"3. 简单测试protobuf数据结构的序列化与反序列化",slug:"_3-简单测试protobuf数据结构的序列化与反序列化",normalizedTitle:"3. 简单测试protobuf数据结构的序列化与反序列化",charIndex:1419},{level:2,title:"4. 创建grpc服务端",slug:"_4-创建grpc服务端",normalizedTitle:"4. 创建grpc服务端",charIndex:1900},{level:2,title:"5. 创建grpc客户端",slug:"_5-创建grpc客户端",normalizedTitle:"5. 创建grpc客户端",charIndex:2902}],headersStr:"0. 相关链接 1. 创建protobuf文件 2. 编译proto文件 3. 简单测试protobuf数据结构的序列化与反序列化 4. 创建grpc服务端 5. 创建grpc客户端",content:"# 0. 相关链接\n\n源码案例：https://github.com/tenqaz/python-examples\n\n官方文档：https://grpc.io/docs/languages/python/quickstart\n\n\n# 1. 创建protobuf文件\n\n在目录proto目录下创建user.proto文件，创建User的rpc服务定义，该服务中包含AddUser和GetUser两个调用，并使用下面创建的对应的结构体作为请求体和响应体。 注意：需要添加package proto，否则下面编译生成的python文件引用路径则不正确。\n\nsyntax = \"proto3\";\n\n// 包名\npackage proto;\n\n// 定义User rpc服务\nservice User {\n  // 定义rpc服务的方法\n  rpc AddUser (UserRequest) returns (UserResponse);\n  rpc GetUser (GetUserRequest) returns (GetUserResponse);\n}\n\n// 请求的结构体\nmessage UserRequest {\n  string name = 1;\n  uint32 age = 2;\n}\n\n// 响应的结构体\nmessage UserResponse {\n  string msg = 1;\n  int32 code = 2;\n}\n\nmessage GetUserRequest {\n  string name = 1;\n}\n\nmessage GetUserResponse {\n  string name = 1;\n  string age = 2;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 2. 编译proto文件\n\n首选需要安装grpc的库和工具\n\npython -m pip install grpcio #安装grpc\npython -m pip install grpcio-tools #安装grpc tools\n\n\n1\n2\n\n\n然后，运行命令对proto文件进行编译，会根据上面的proto文件生成对应的python文件，你会发现在proto目录下创建了user_pb2.py和user_pb2_grpc.py两个文件\n\npython -m grpc_tools.protoc --python_out=. --grpc_python_out=. -I. ./proto/user.proto\n\n\n1\n\n * --python_out=.，protobuf相关代码文件生成在这里\n * --grpc_python_out=.，grpc相关代码生成在这里\n * -I. ./proto/user.proto，proto文件路径\n\n编译后：\n\n * user_pb2.py，用来和 protobuf 数据进行交互，这个就是根据proto文件定义好的数据结构类型生成的python化的数据结构文件\n * user_pb2_grpc.py: 用来和 grpc 进行交互，这个就是定义了rpc方法的类，包含了类的请求参数和响应等等，可用python直接实例化调用\n\n\n# 3. 简单测试protobuf数据结构的序列化与反序列化\n\n我们创建proto_test.py文件，创建User对象，填充值，并将该对象序列化成字符串输出\n\nfrom proto import user_pb2\n\n# 创建Student对象，将该对象序列化成字符串\ns = user_pb2.UserRequest()\ns.name = \"zhangsan\"\ns.age = 12\nreq_str = s.SerializeToString()\nprint(req_str)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n输出：\n\nb'\\n\\x08zhangsan\\x10\\x0c'\n\n\n1\n\n\n然后我们再创建User对象将将上面的输出的序列化字符串反序列化进来。\n\n# 将上面的输出的序列化字符串反序列化成对象\ns2 = user_pb2.UserRequest()\ns2.ParseFromString(req_str)\nprint(s2.name)\nprint(s2.age)\n\n\n1\n2\n3\n4\n5\n\n\n输出：\n\nzhangsan\n12\n\n\n1\n2\n\n\n\n# 4. 创建grpc服务端\n\n下面是使用之前创建的protobuf和grpc文件来构建grpc服务端代码。\n\nimport logging\nfrom concurrent import futures\n\nimport grpc\n\nfrom proto import user_pb2, user_pb2_grpc\n\n\nclass UserService(user_pb2_grpc.UserServicer):\n\n    # 实现proto文件中rpc的调用\n    def AddUser(self, request: user_pb2.UserRequest, context):\n        return user_pb2.UserResponse(msg='add user(name={},age={}) success'.format(request.name, request.age), code=0)\n\n    def GetUser(self, request: user_pb2.GetUserRequest, context):\n        return user_pb2.GetUserResponse(name=request.name, age=\"1888\")\n\n\ndef serve():\n    # 使用线程池来完成grpc的请求\n    server = grpc.server(futures.ThreadPoolExecutor(max_workers=5))\n    user_pb2_grpc.add_UserServicer_to_server(UserService(), server)\n    server.add_insecure_port('[::]:50051')  # 绑定端口\n    server.start()\n    server.wait_for_termination()\n\n\nif __name__ == '__main__':\n    logging.basicConfig()\n    serve()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n运行该服务端，会阻塞等待客户端的请求。\n\n\n# 5. 创建grpc客户端\n\nimport logging\n\nimport grpc\n\nfrom proto import user_pb2, user_pb2_grpc\n\n\ndef run():\n    # 连接rpc服务\n    with grpc.insecure_channel('localhost:50051') as channel:\n        stub = user_pb2_grpc.UserStub(channel)\n\n        # 调用rpc服务的AddUser方法\n        response: user_pb2.UserResponse = stub.AddUser(user_pb2.UserRequest(name=\"zhangsan\", age=18))\n        print(\"add user, response is 'msg={}, code={}'\".format(response.msg, response.code))\n\n        # 调用rpc服务的GetUser方法\n        response: user_pb2.GetUserResponse = stub.GetUser(user_pb2.GetUserRequest(name=\"lisi\"))\n        print(\"get user[name={}, age={}]\".format(response.name, response.age))\n\n\nif __name__ == '__main__':\n    logging.basicConfig()\n    run()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n运行客户端，调用rpc服务，输出：\n\nadd user, response is 'msg=add user(name=zhangsan,age=18) success, code=0'\nget user[name=lisi, age=1888]\n\n\n1\n2\n",normalizedContent:"# 0. 相关链接\n\n源码案例：https://github.com/tenqaz/python-examples\n\n官方文档：https://grpc.io/docs/languages/python/quickstart\n\n\n# 1. 创建protobuf文件\n\n在目录proto目录下创建user.proto文件，创建user的rpc服务定义，该服务中包含adduser和getuser两个调用，并使用下面创建的对应的结构体作为请求体和响应体。 注意：需要添加package proto，否则下面编译生成的python文件引用路径则不正确。\n\nsyntax = \"proto3\";\n\n// 包名\npackage proto;\n\n// 定义user rpc服务\nservice user {\n  // 定义rpc服务的方法\n  rpc adduser (userrequest) returns (userresponse);\n  rpc getuser (getuserrequest) returns (getuserresponse);\n}\n\n// 请求的结构体\nmessage userrequest {\n  string name = 1;\n  uint32 age = 2;\n}\n\n// 响应的结构体\nmessage userresponse {\n  string msg = 1;\n  int32 code = 2;\n}\n\nmessage getuserrequest {\n  string name = 1;\n}\n\nmessage getuserresponse {\n  string name = 1;\n  string age = 2;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 2. 编译proto文件\n\n首选需要安装grpc的库和工具\n\npython -m pip install grpcio #安装grpc\npython -m pip install grpcio-tools #安装grpc tools\n\n\n1\n2\n\n\n然后，运行命令对proto文件进行编译，会根据上面的proto文件生成对应的python文件，你会发现在proto目录下创建了user_pb2.py和user_pb2_grpc.py两个文件\n\npython -m grpc_tools.protoc --python_out=. --grpc_python_out=. -i. ./proto/user.proto\n\n\n1\n\n * --python_out=.，protobuf相关代码文件生成在这里\n * --grpc_python_out=.，grpc相关代码生成在这里\n * -i. ./proto/user.proto，proto文件路径\n\n编译后：\n\n * user_pb2.py，用来和 protobuf 数据进行交互，这个就是根据proto文件定义好的数据结构类型生成的python化的数据结构文件\n * user_pb2_grpc.py: 用来和 grpc 进行交互，这个就是定义了rpc方法的类，包含了类的请求参数和响应等等，可用python直接实例化调用\n\n\n# 3. 简单测试protobuf数据结构的序列化与反序列化\n\n我们创建proto_test.py文件，创建user对象，填充值，并将该对象序列化成字符串输出\n\nfrom proto import user_pb2\n\n# 创建student对象，将该对象序列化成字符串\ns = user_pb2.userrequest()\ns.name = \"zhangsan\"\ns.age = 12\nreq_str = s.serializetostring()\nprint(req_str)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n输出：\n\nb'\\n\\x08zhangsan\\x10\\x0c'\n\n\n1\n\n\n然后我们再创建user对象将将上面的输出的序列化字符串反序列化进来。\n\n# 将上面的输出的序列化字符串反序列化成对象\ns2 = user_pb2.userrequest()\ns2.parsefromstring(req_str)\nprint(s2.name)\nprint(s2.age)\n\n\n1\n2\n3\n4\n5\n\n\n输出：\n\nzhangsan\n12\n\n\n1\n2\n\n\n\n# 4. 创建grpc服务端\n\n下面是使用之前创建的protobuf和grpc文件来构建grpc服务端代码。\n\nimport logging\nfrom concurrent import futures\n\nimport grpc\n\nfrom proto import user_pb2, user_pb2_grpc\n\n\nclass userservice(user_pb2_grpc.userservicer):\n\n    # 实现proto文件中rpc的调用\n    def adduser(self, request: user_pb2.userrequest, context):\n        return user_pb2.userresponse(msg='add user(name={},age={}) success'.format(request.name, request.age), code=0)\n\n    def getuser(self, request: user_pb2.getuserrequest, context):\n        return user_pb2.getuserresponse(name=request.name, age=\"1888\")\n\n\ndef serve():\n    # 使用线程池来完成grpc的请求\n    server = grpc.server(futures.threadpoolexecutor(max_workers=5))\n    user_pb2_grpc.add_userservicer_to_server(userservice(), server)\n    server.add_insecure_port('[::]:50051')  # 绑定端口\n    server.start()\n    server.wait_for_termination()\n\n\nif __name__ == '__main__':\n    logging.basicconfig()\n    serve()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n运行该服务端，会阻塞等待客户端的请求。\n\n\n# 5. 创建grpc客户端\n\nimport logging\n\nimport grpc\n\nfrom proto import user_pb2, user_pb2_grpc\n\n\ndef run():\n    # 连接rpc服务\n    with grpc.insecure_channel('localhost:50051') as channel:\n        stub = user_pb2_grpc.userstub(channel)\n\n        # 调用rpc服务的adduser方法\n        response: user_pb2.userresponse = stub.adduser(user_pb2.userrequest(name=\"zhangsan\", age=18))\n        print(\"add user, response is 'msg={}, code={}'\".format(response.msg, response.code))\n\n        # 调用rpc服务的getuser方法\n        response: user_pb2.getuserresponse = stub.getuser(user_pb2.getuserrequest(name=\"lisi\"))\n        print(\"get user[name={}, age={}]\".format(response.name, response.age))\n\n\nif __name__ == '__main__':\n    logging.basicconfig()\n    run()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n运行客户端，调用rpc服务，输出：\n\nadd user, response is 'msg=add user(name=zhangsan,age=18) success, code=0'\nget user[name=lisi, age=1888]\n\n\n1\n2\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"tornado 使用peewee-async 完成异步orm数据库操作",frontmatter:{tags:["python","tornado"],title:"tornado 使用peewee-async 完成异步orm数据库操作",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/113ab1/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"tornado中使用peewee-async来完成异步orm数据库操作",feed:{enable:!0},categories:["编程","python","tornado"],comment:!0,meta:[{name:"twitter:title",content:"tornado 使用peewee-async 完成异步orm数据库操作"},{name:"twitter:description",content:"tornado中使用peewee-async来完成异步orm数据库操作"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/06.tornado%20%E4%BD%BF%E7%94%A8peewee-async%20%E5%AE%8C%E6%88%90%E5%BC%82%E6%AD%A5orm%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tornado 使用peewee-async 完成异步orm数据库操作"},{property:"og:description",content:"tornado中使用peewee-async来完成异步orm数据库操作"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/06.tornado%20%E4%BD%BF%E7%94%A8peewee-async%20%E5%AE%8C%E6%88%90%E5%BC%82%E6%AD%A5orm%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"tornado"},{itemprop:"name",content:"tornado 使用peewee-async 完成异步orm数据库操作"},{itemprop:"description",content:"tornado中使用peewee-async来完成异步orm数据库操作"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/06.tornado%20%E4%BD%BF%E7%94%A8peewee-async%20%E5%AE%8C%E6%88%90%E5%BC%82%E6%AD%A5orm%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C.html",relativePath:"04.编程/01.python/08.tornado/06.tornado 使用peewee-async 完成异步orm数据库操作.md",key:"v-13f4cf5a",path:"/pages/113ab1/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"配置",slug:"配置",normalizedTitle:"配置",charIndex:169},{level:2,title:"创建model",slug:"创建model",normalizedTitle:"创建model",charIndex:1026},{level:2,title:"增删改查",slug:"增删改查",normalizedTitle:"增删改查",charIndex:2523},{level:2,title:"连表查询",slug:"连表查询",normalizedTitle:"连表查询",charIndex:4290}],headersStr:"简介 配置 创建model 增删改查 连表查询",content:'# 简介\n\ntornado是一个异步web框架，其中不能使用阻塞的操作，不然会导致整个程序的阻塞。数据库操作时不可避免的需要使用，这里采用的是peewee-async去解决。\n\npeewee-async 是一个为 peewee orm框架提供异步接口的库。\n\n该项目的github地址: tornado_learning.git\n\n\n# 配置\n\n在settings.py文件中创建连接数据库\n代码: server.py\n\nimport peewee_async\n\ndatabase = peewee_async.MySQLDatabase("tornado_learning", "127.0.0.1", port=3306, user="root", password="root1234")\n\n\n1\n2\n3\n\n\n在server.py中引用数据库连接，并加入到app中\n\nfrom peewee_async import Manager\nfrom tornado import web, ioloop\n\nfrom tornado_learning.settings import database\nfrom tornado_learning.settings import settings\nfrom tornado_learning.urls import urlpattern\n\n\ndef make_app():    \n    app = web.Application(urlpattern, debug=True, **settings)    \n    \n    # 就在这里添加数据库连接\n    objects = Manager(database)    \n    \n    # 禁止使用同步操作\n    database.set_allow_sync(False)    \n    app.objects = objects    \n    return app\n\nif __name__ == \'__main__\':   \n    app = make_app()   \n    app.listen(8888)    \n    ioloop.IOLoop.current().start()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# 创建model\n\n创建通用的BaseModel类\ncreate_time是每个model都需要的字段，将两个字段提取到BaseModel中。\nid字段在peewee中会为每个model自动创建。\n为每一个model指定database\n在配置目录tornado_learning中创建model.py\n\n代码: tornado_learning/models\n\nfrom datetime import datetime\n\nfrom peewee import Model, DateTimeField\n\nfrom tornado_learning.settings import database\n\nclass BaseModel(Model):   \n    create_time = DateTimeField(default=datetime.now, verbose_name="创建时间")    \n    class Meta:        \n        database = database\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n创建model类\n\n> 这里的student和teacher的关系是1对多。\n\n创建student的模型类。\n代码: apps/school/models.py\n\nfrom peewee import CharField, IntegerField, TextField\nfrom tornado_learning.models import BaseModel\n\nclass Student(BaseModel):    \n    name = CharField(max_length=100, null=False, verbose_name="学生名")    \n    age = IntegerField(null=False, verbose_name="年龄")    \n    desc = TextField(verbose_name="个人简介")\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n创建teacher的模型类\n\nclass Teacher(BaseModel):    \n    student = ForeignKeyField(rel_model=Student, related_name="teachers")    \n    name = CharField(max_length=100, null=False, verbose_name="老师名")   \n    age = IntegerField(null=False, verbose_name="年龄")   \n    subject = CharField(max_length=100, null=False, verbose_name="学科")\n\n\n1\n2\n3\n4\n5\n\n\n使用工具类创建表\n在tools/init_db.py中初始化表。\n运行该文件即可在数据库中创建表\n\nfrom tornado_learning.settings import database\nfrom apps.school.models import Student\n\ndef init_db():    \n    database.create_tables([Student, student])\n\nif __name__ == \'__main__\':    \n    init_db()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 增删改查\n\n下面是增删改查的例子。\n\n> form表单的使用可以参考我的文章<<tornado 结合wtforms使用表单操作\n\n代码: apps/school/handler.py\n\n\nimport tornado\n\nfrom apps.school.forms import StudentForm\nfrom apps.school.models import Student\nfrom tornado_learning.handler import BaseHandler\n\nclass StudentHandler(BaseHandler):\n\n    async def get(self):\n        id = self.get_argument("id", None)\n        if not id:\n            return self.write("please provide the \'id\'")\n\n        student = await self.application.objects.get(Student, id=id)\n\n        try:\n            self.write({\n                "id": student.id,\n                "name": student.name\n            })\n        except Student.DoesNotExist:\n            raise tornado.webHttpError(404, "Object not found")\n\n    async def post(self):\n\n        student_form = StudentForm(self.request.arguments)\n        if student_form.validate():\n            await self.application.objects.create(Student, **student_form.data)\n\n            self.write("创建成功")\n        else:\n            self.write("校验失败")\n\n    async def delete(self):\n        id = self.get_argument("id", None)\n        if not id:\n            return self.write("please provide the \'id\'")\n\n        student = await self.application.objects.get(Student, id=id)\n        await self.application.objects.delete(student)\n\n        self.write("删除成功")\n\n    async def put(self):\n        studentForm = StudentForm(self.request.arguments)\n\n        student = Student(**studentForm.data)\n\n        if studentForm.validate():\n            await self.application.objects.update(student)\n            self.write("更新成功")\n        else:\n            print(studentForm.errors)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n\n\n\n# 连表查询\n\n在teacher model中添加extend方法，拼凑连表查询的方法，方便使用。\n代码: apps/school/model.py\n\nclass Teacher(BaseModel):\n    student = ForeignKeyField(rel_model=Student, related_name="teachers")\n    name = CharField(max_length=100, null=False, verbose_name="老师名")\n    age = IntegerField(null=False, verbose_name="年龄")\n    subject = CharField(max_length=100, null=False, verbose_name="学科")\n\n    @classmethod\n    def extend(cls):\n        return cls.select(cls, Student.name, Student.age).join(Student)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n使用peewee拼凑出查询，然后通过异步执行得到结果\n代码: apps/school/handler.py\n\nclass TeacherHandler(BaseHandler):\n\n    async def get(self):\n        ret_data = {"data": []}\n\n        teacher_query = Teacher.extend()\n        teacher_query = teacher_query.filter(Teacher.age > 20)\n        teachers = await self.application.objects.execute(teacher_query)\n\n        for teacher in teachers:\n            item_dict = {\n                "teacher_name": teacher.name,\n                "teacher_age": teacher.age,\n                "student_name": teacher.student.name,\n                "student_age": teacher.student.age\n            }\n            ret_data[\'data\'].append(item_dict)\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n',normalizedContent:'# 简介\n\ntornado是一个异步web框架，其中不能使用阻塞的操作，不然会导致整个程序的阻塞。数据库操作时不可避免的需要使用，这里采用的是peewee-async去解决。\n\npeewee-async 是一个为 peewee orm框架提供异步接口的库。\n\n该项目的github地址: tornado_learning.git\n\n\n# 配置\n\n在settings.py文件中创建连接数据库\n代码: server.py\n\nimport peewee_async\n\ndatabase = peewee_async.mysqldatabase("tornado_learning", "127.0.0.1", port=3306, user="root", password="root1234")\n\n\n1\n2\n3\n\n\n在server.py中引用数据库连接，并加入到app中\n\nfrom peewee_async import manager\nfrom tornado import web, ioloop\n\nfrom tornado_learning.settings import database\nfrom tornado_learning.settings import settings\nfrom tornado_learning.urls import urlpattern\n\n\ndef make_app():    \n    app = web.application(urlpattern, debug=true, **settings)    \n    \n    # 就在这里添加数据库连接\n    objects = manager(database)    \n    \n    # 禁止使用同步操作\n    database.set_allow_sync(false)    \n    app.objects = objects    \n    return app\n\nif __name__ == \'__main__\':   \n    app = make_app()   \n    app.listen(8888)    \n    ioloop.ioloop.current().start()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# 创建model\n\n创建通用的basemodel类\ncreate_time是每个model都需要的字段，将两个字段提取到basemodel中。\nid字段在peewee中会为每个model自动创建。\n为每一个model指定database\n在配置目录tornado_learning中创建model.py\n\n代码: tornado_learning/models\n\nfrom datetime import datetime\n\nfrom peewee import model, datetimefield\n\nfrom tornado_learning.settings import database\n\nclass basemodel(model):   \n    create_time = datetimefield(default=datetime.now, verbose_name="创建时间")    \n    class meta:        \n        database = database\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n创建model类\n\n> 这里的student和teacher的关系是1对多。\n\n创建student的模型类。\n代码: apps/school/models.py\n\nfrom peewee import charfield, integerfield, textfield\nfrom tornado_learning.models import basemodel\n\nclass student(basemodel):    \n    name = charfield(max_length=100, null=false, verbose_name="学生名")    \n    age = integerfield(null=false, verbose_name="年龄")    \n    desc = textfield(verbose_name="个人简介")\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n创建teacher的模型类\n\nclass teacher(basemodel):    \n    student = foreignkeyfield(rel_model=student, related_name="teachers")    \n    name = charfield(max_length=100, null=false, verbose_name="老师名")   \n    age = integerfield(null=false, verbose_name="年龄")   \n    subject = charfield(max_length=100, null=false, verbose_name="学科")\n\n\n1\n2\n3\n4\n5\n\n\n使用工具类创建表\n在tools/init_db.py中初始化表。\n运行该文件即可在数据库中创建表\n\nfrom tornado_learning.settings import database\nfrom apps.school.models import student\n\ndef init_db():    \n    database.create_tables([student, student])\n\nif __name__ == \'__main__\':    \n    init_db()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 增删改查\n\n下面是增删改查的例子。\n\n> form表单的使用可以参考我的文章<<tornado 结合wtforms使用表单操作\n\n代码: apps/school/handler.py\n\n\nimport tornado\n\nfrom apps.school.forms import studentform\nfrom apps.school.models import student\nfrom tornado_learning.handler import basehandler\n\nclass studenthandler(basehandler):\n\n    async def get(self):\n        id = self.get_argument("id", none)\n        if not id:\n            return self.write("please provide the \'id\'")\n\n        student = await self.application.objects.get(student, id=id)\n\n        try:\n            self.write({\n                "id": student.id,\n                "name": student.name\n            })\n        except student.doesnotexist:\n            raise tornado.webhttperror(404, "object not found")\n\n    async def post(self):\n\n        student_form = studentform(self.request.arguments)\n        if student_form.validate():\n            await self.application.objects.create(student, **student_form.data)\n\n            self.write("创建成功")\n        else:\n            self.write("校验失败")\n\n    async def delete(self):\n        id = self.get_argument("id", none)\n        if not id:\n            return self.write("please provide the \'id\'")\n\n        student = await self.application.objects.get(student, id=id)\n        await self.application.objects.delete(student)\n\n        self.write("删除成功")\n\n    async def put(self):\n        studentform = studentform(self.request.arguments)\n\n        student = student(**studentform.data)\n\n        if studentform.validate():\n            await self.application.objects.update(student)\n            self.write("更新成功")\n        else:\n            print(studentform.errors)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n\n\n\n# 连表查询\n\n在teacher model中添加extend方法，拼凑连表查询的方法，方便使用。\n代码: apps/school/model.py\n\nclass teacher(basemodel):\n    student = foreignkeyfield(rel_model=student, related_name="teachers")\n    name = charfield(max_length=100, null=false, verbose_name="老师名")\n    age = integerfield(null=false, verbose_name="年龄")\n    subject = charfield(max_length=100, null=false, verbose_name="学科")\n\n    @classmethod\n    def extend(cls):\n        return cls.select(cls, student.name, student.age).join(student)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n使用peewee拼凑出查询，然后通过异步执行得到结果\n代码: apps/school/handler.py\n\nclass teacherhandler(basehandler):\n\n    async def get(self):\n        ret_data = {"data": []}\n\n        teacher_query = teacher.extend()\n        teacher_query = teacher_query.filter(teacher.age > 20)\n        teachers = await self.application.objects.execute(teacher_query)\n\n        for teacher in teachers:\n            item_dict = {\n                "teacher_name": teacher.name,\n                "teacher_age": teacher.age,\n                "student_name": teacher.student.name,\n                "student_age": teacher.student.age\n            }\n            ret_data[\'data\'].append(item_dict)\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"pyspark streaming简介 和 消费 kafka示例",frontmatter:{tags:["python"],title:"pyspark streaming简介 和 消费 kafka示例",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/72664a/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"简单介绍pyspark streaming以及消费kafka的示例",feed:{enable:!0},categories:["编程","python","其他"],comment:!0,meta:[{name:"image",content:"https://img-blog.csdnimg.cn/20190416164155495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIyOTE4MjQz,size_16,color_FFFFFF,t_70"},{name:"twitter:title",content:"pyspark streaming简介 和 消费 kafka示例"},{name:"twitter:description",content:"简单介绍pyspark streaming以及消费kafka的示例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://img-blog.csdnimg.cn/20190416164155495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIyOTE4MjQz,size_16,color_FFFFFF,t_70"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/02.pyspark%20streaming%E7%AE%80%E4%BB%8B%20%E5%92%8C%20%E6%B6%88%E8%B4%B9%20kafka%E7%A4%BA%E4%BE%8B.html"},{property:"og:type",content:"article"},{property:"og:title",content:"pyspark streaming简介 和 消费 kafka示例"},{property:"og:description",content:"简单介绍pyspark streaming以及消费kafka的示例"},{property:"og:image",content:"https://img-blog.csdnimg.cn/20190416164155495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIyOTE4MjQz,size_16,color_FFFFFF,t_70"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/02.pyspark%20streaming%E7%AE%80%E4%BB%8B%20%E5%92%8C%20%E6%B6%88%E8%B4%B9%20kafka%E7%A4%BA%E4%BE%8B.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"pyspark streaming简介 和 消费 kafka示例"},{itemprop:"description",content:"简单介绍pyspark streaming以及消费kafka的示例"},{itemprop:"image",content:"https://img-blog.csdnimg.cn/20190416164155495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIyOTE4MjQz,size_16,color_FFFFFF,t_70"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/02.pyspark%20streaming%E7%AE%80%E4%BB%8B%20%E5%92%8C%20%E6%B6%88%E8%B4%B9%20kafka%E7%A4%BA%E4%BE%8B.html",relativePath:"04.编程/01.python/09.其他/02.pyspark streaming简介 和 消费 kafka示例.md",key:"v-ba59602c",path:"/pages/72664a/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"基础数据源",slug:"基础数据源",normalizedTitle:"基础数据源",charIndex:314},{level:2,title:"高级数据源",slug:"高级数据源",normalizedTitle:"高级数据源",charIndex:1431},{level:3,title:"Spark Streaming 和 kafka 整合",slug:"spark-streaming-和-kafka-整合",normalizedTitle:"spark streaming 和 kafka 整合",charIndex:1441}],headersStr:"简介 基础数据源 高级数据源 Spark Streaming 和 kafka 整合",content:'# 简介\n\n> 并不是真正的实时处理框架，只是按照时间进行微批处理进行，时间可以设置的尽可能的小。\n\n> 将不同的额数据源的数据经过SparkStreaming 处理之后将结果输出到外部文件系统\n\n * 特点\n\n> 低延时 能从错误中搞笑的恢复: fault-tolerant 能够运行在成百上千的节点 能够将批处理、机器学习、图计算等自框架和Spark Streaming 综合起来使用\n\n * 粗粒度\n\n> Spark Streaming接收到实时数据流，把数据按照指定的时间段切成一片片小的数据块，然后把小的数据块传给Spark Engine处理。\n\n * 细粒度\n\n * 数据源 kafka提供了两种数据源。\n\n 1. 基础数据源，可以直接通过streamingContext API实现。如文件系统和socket连接\n 2. 高级的数据源，如Kafka, Flume, Kinesis等等. 可以通过额外的类库去实现。\n\n\n# 基础数据源\n\n 1. 使用官方的案例\n\n/spark/examples/src/main/python/streaming\n\nnc -lk 6789\n\n 2. 处理socket数据\n\n示例代码如下: 读取socket中的数据进行流处理\n\nfrom pyspark import SparkContext\nfrom pyspark.streaming import StreamingContext\n\n# local 必须设为2\nsc = SparkContext("local[2]", "NetworkWordCount")\nssc = StreamingContext(sc, 1)\n\nlines = ssc.socketTextStream("localhost", 9999)\n\nwords = lines.flatMap(lambda line: line.split(" "))\n\npairs = words.map(lambda word: (word, 1))\nwordCounts = pairs.reduceByKey(lambda x, y: x + y)\n\nwordCounts.pprint()\n\nssc.start()\nssc.awaitTermination()\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n测试\n\n> nc -lk 9999\n\n 3. 处理文件系统数据\n\n> 文件系统(fileStream(that is, HDFSM S3, NFS))暂不支持python，python仅支持文本文件(textFileStream)\n\n示例如下，但未成功，找不到该文件。\n\n\nlines = ssc.textFileStream("hdfs://txz-data0:9820/user/jim/workflow/crash/python/crash_2_hdfs.py")\n\n\n\n1\n2\n3\n\n\n * streaming context\n\n * DStreams\n\n> 持续化的数据流 对DStream操作算子， 比如map/flatMap,其实底层会被翻译为对DStream中的每个RDD都做相同的操作，因为一个DStream是由不同批次的RDD所\n\n * Input DStreams and Receivers\n\n\n# 高级数据源\n\n\n# Spark Streaming 和 kafka 整合\n\n两种模式\n\n * receiver 模式\n\nfrom pyspark.streaming.kafka import KafkaUtils\nfrom pyspark import SparkContext\nfrom pyspark.streaming import StreamingContext\n\nsc = SparkContext("local[2]", "NetworkWordCount")\nsc.setLogLevel("OFF")\nssc = StreamingContext(sc, 1)\n\n# 创建Kafka streaming\nline = KafkaUtils.createStream(ssc, "192.168.0.208:2181", \'test\', {"jim_test": 1})\n\n# 分词\nwords = line.flatMap(lambda line: line.split(" "))\npairs = words.map(lambda word: (word, 1))\nwordCounts = pairs.reduceByKey(lambda x, y: x + y)\nwordCounts.pprint()\n\nssc.start()\nssc.awaitTermination()\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n * no receiver\n\n根据上面的代码替换掉createStream即可。\n\nline = KafkaUtils.createDirectStream(ssc, ["jim_test"], {"metadata.broker.list": "192.168.0.208:9092"})\n\n\n1\n\n\n运行:\n\n> spark-submit --jars spark-streaming-kafka-0-8-assembly_2.11-2.4.0.jar test_spark_stream.py\n\n需要下载相应的jar包.下载地址如下，搜索。 https://search.maven.org\n\njar版本会在运行程序时报错提醒。',normalizedContent:'# 简介\n\n> 并不是真正的实时处理框架，只是按照时间进行微批处理进行，时间可以设置的尽可能的小。\n\n> 将不同的额数据源的数据经过sparkstreaming 处理之后将结果输出到外部文件系统\n\n * 特点\n\n> 低延时 能从错误中搞笑的恢复: fault-tolerant 能够运行在成百上千的节点 能够将批处理、机器学习、图计算等自框架和spark streaming 综合起来使用\n\n * 粗粒度\n\n> spark streaming接收到实时数据流，把数据按照指定的时间段切成一片片小的数据块，然后把小的数据块传给spark engine处理。\n\n * 细粒度\n\n * 数据源 kafka提供了两种数据源。\n\n 1. 基础数据源，可以直接通过streamingcontext api实现。如文件系统和socket连接\n 2. 高级的数据源，如kafka, flume, kinesis等等. 可以通过额外的类库去实现。\n\n\n# 基础数据源\n\n 1. 使用官方的案例\n\n/spark/examples/src/main/python/streaming\n\nnc -lk 6789\n\n 2. 处理socket数据\n\n示例代码如下: 读取socket中的数据进行流处理\n\nfrom pyspark import sparkcontext\nfrom pyspark.streaming import streamingcontext\n\n# local 必须设为2\nsc = sparkcontext("local[2]", "networkwordcount")\nssc = streamingcontext(sc, 1)\n\nlines = ssc.sockettextstream("localhost", 9999)\n\nwords = lines.flatmap(lambda line: line.split(" "))\n\npairs = words.map(lambda word: (word, 1))\nwordcounts = pairs.reducebykey(lambda x, y: x + y)\n\nwordcounts.pprint()\n\nssc.start()\nssc.awaittermination()\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n测试\n\n> nc -lk 9999\n\n 3. 处理文件系统数据\n\n> 文件系统(filestream(that is, hdfsm s3, nfs))暂不支持python，python仅支持文本文件(textfilestream)\n\n示例如下，但未成功，找不到该文件。\n\n\nlines = ssc.textfilestream("hdfs://txz-data0:9820/user/jim/workflow/crash/python/crash_2_hdfs.py")\n\n\n\n1\n2\n3\n\n\n * streaming context\n\n * dstreams\n\n> 持续化的数据流 对dstream操作算子， 比如map/flatmap,其实底层会被翻译为对dstream中的每个rdd都做相同的操作，因为一个dstream是由不同批次的rdd所\n\n * input dstreams and receivers\n\n\n# 高级数据源\n\n\n# spark streaming 和 kafka 整合\n\n两种模式\n\n * receiver 模式\n\nfrom pyspark.streaming.kafka import kafkautils\nfrom pyspark import sparkcontext\nfrom pyspark.streaming import streamingcontext\n\nsc = sparkcontext("local[2]", "networkwordcount")\nsc.setloglevel("off")\nssc = streamingcontext(sc, 1)\n\n# 创建kafka streaming\nline = kafkautils.createstream(ssc, "192.168.0.208:2181", \'test\', {"jim_test": 1})\n\n# 分词\nwords = line.flatmap(lambda line: line.split(" "))\npairs = words.map(lambda word: (word, 1))\nwordcounts = pairs.reducebykey(lambda x, y: x + y)\nwordcounts.pprint()\n\nssc.start()\nssc.awaittermination()\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n * no receiver\n\n根据上面的代码替换掉createstream即可。\n\nline = kafkautils.createdirectstream(ssc, ["jim_test"], {"metadata.broker.list": "192.168.0.208:9092"})\n\n\n1\n\n\n运行:\n\n> spark-submit --jars spark-streaming-kafka-0-8-assembly_2.11-2.4.0.jar test_spark_stream.py\n\n需要下载相应的jar包.下载地址如下，搜索。 https://search.maven.org\n\njar版本会在运行程序时报错提醒。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"基于pre-commit的Python代码规范落地实践",frontmatter:{title:"基于pre-commit的Python代码规范落地实践",date:"2025-05-12T12:46:45.000Z",permalink:"/pages/7f6078/",categories:["编程","python","其他"],tags:["编码工具"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"pre-commit 是一个开源工具，用于管理和执行 Git 钩子，确保代码库的一致性和质量。通过在提交代码前自动运行代码风格检查（Linting）和格式修正（Formatting），它有助于保持项目代码的统一标准。本文将通过一个 Python 项目的实例，展示如何配置 pre-commit 工作流。本文旨在介绍使用 pre-commit 对 Python 项目进行代码检查的方法，以提前发现并解决代码中的问题，提高代码的整体质量。",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"基于pre-commit的Python代码规范落地实践"},{name:"twitter:description",content:"pre-commit 是一个开源工具，用于管理和执行 Git 钩子，确保代码库的一致性和质量。通过在提交代码前自动运行代码风格检查（Linting）和格式修正（Formatting），它有助于保持项目代码的统一标准。本文将通过一个 Python 项目的实例，展示如何配置 pre-commit 工作流。本文旨在介绍使用 pre-commit 对 Python 项目进行代码检查的方法，以提前发现并解决代码中的问题，提高代码的整体质量。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/03.%E5%9F%BA%E4%BA%8Epre-commit%E7%9A%84Python%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E8%90%BD%E5%9C%B0%E5%AE%9E%E8%B7%B5.html"},{property:"og:type",content:"article"},{property:"og:title",content:"基于pre-commit的Python代码规范落地实践"},{property:"og:description",content:"pre-commit 是一个开源工具，用于管理和执行 Git 钩子，确保代码库的一致性和质量。通过在提交代码前自动运行代码风格检查（Linting）和格式修正（Formatting），它有助于保持项目代码的统一标准。本文将通过一个 Python 项目的实例，展示如何配置 pre-commit 工作流。本文旨在介绍使用 pre-commit 对 Python 项目进行代码检查的方法，以提前发现并解决代码中的问题，提高代码的整体质量。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/03.%E5%9F%BA%E4%BA%8Epre-commit%E7%9A%84Python%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E8%90%BD%E5%9C%B0%E5%AE%9E%E8%B7%B5.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-05-12T12:46:45.000Z"},{property:"article:tag",content:"编码工具"},{itemprop:"name",content:"基于pre-commit的Python代码规范落地实践"},{itemprop:"description",content:"pre-commit 是一个开源工具，用于管理和执行 Git 钩子，确保代码库的一致性和质量。通过在提交代码前自动运行代码风格检查（Linting）和格式修正（Formatting），它有助于保持项目代码的统一标准。本文将通过一个 Python 项目的实例，展示如何配置 pre-commit 工作流。本文旨在介绍使用 pre-commit 对 Python 项目进行代码检查的方法，以提前发现并解决代码中的问题，提高代码的整体质量。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/03.%E5%9F%BA%E4%BA%8Epre-commit%E7%9A%84Python%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E8%90%BD%E5%9C%B0%E5%AE%9E%E8%B7%B5.html",relativePath:"04.编程/01.python/09.其他/03.基于pre-commit的Python代码规范落地实践.md",key:"v-4edff9fd",path:"/pages/7f6078/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"使用",slug:"使用",normalizedTitle:"使用",charIndex:165},{level:2,title:"最佳实践",slug:"最佳实践",normalizedTitle:"最佳实践",charIndex:2956},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:3082}],headersStr:"简介 使用 最佳实践 总结",content:'# 简介\n\npre-commit 是一个开源工具，用于管理和执行 Git 钩子，确保代码库的一致性和质量。通过在提交代码前自动运行代码风格检查（Linting）和格式修正（Formatting），它有助于保持项目代码的统一标准。本文将通过一个 Python 项目的实例，展示如何配置 pre-commit 工作流。\n\n本文旨在介绍使用 pre-commit 对 Python 项目进行代码检查的方法，以提前发现并解决代码中的问题，提高代码的整体质量。文中提及的所有代码示例可以在 pre-commit-demo 找到。\n\n\n# 使用\n\n 1. 安装\n\n首先，安装 pre-commit：\n\npip install pre-commit\n\n\n1\n\n\n安装成功后，您可以通过以下命令验证安装是否成功：\n\n$ pre-commit --version \npre-commit 4.2.0\n\n\n1\n2\n\n\n接下来，设置 Git 钩子脚本：\n\n$ pre-commit install\npre-commit installed at .git/hooks/pre-commit\n\n\n1\n2\n\n 1. 创建配置文件 在项目的根目录下创建 .pre-commit-config.yaml 文件，并推荐使用最新稳定版：\n\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v2.3.0\n    hooks:\n      - id: check-yaml\n      - id: check-json\n      - id: check-toml\n      - id: end-of-file-fixer\n      - id: trailing-whitespace\n  - repo: https://github.com/psf/black\n    rev: 22.10.0\n    hooks:\n      - id: black\n  - repo: https://github.com/PyCQA/isort\n    rev: 5.13.2\n    hooks:\n      - id: isort\n  - repo: https://github.com/PyCQA/flake8\n    rev: 7.2.0\n    hooks:\n      - id: flake8\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n配置文件说明:\n\n * repos: 包含要使用的仓库列表。\n * repo: 每个仓库的 URL。\n * rev: 版本号，建议使用最新稳定版。\n * hooks: 需要执行的钩子列表。\n * id: 各个钩子的标识符。\n\n每个钩子 ID 的具体作用可参考相应仓库的官方文档。\n\n 3. 执行与应用\n\n在执行 commit 命令时，会自动调用配置文件中定义的钩子脚本，检查代码是否符合规范。例如：\n\n$ pre-commit_demo % git add *\n$ pre-commit_demo % git commit -m "add main.py"\nCheck Yaml...........................................(no files to check)Skipped\nCheck JSON...........................................(no files to check)Skipped\nCheck Toml...........................................(no files to check)Skipped\nFix End of Files.........................................................Passed\nTrim Trailing Whitespace.................................................Passed\nblack....................................................................Passed\nisort....................................................................Passed\nflake8...................................................................Passed\n[main 27890fe] add main.py\n 1 file changed, 1 insertion(+)\n create mode 100644 main.py\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n默认情况下，仅检查新添加或修改的文件。若需手动检查所有文件，可以使用如下命令：\n\n$ pre-commit run --all-files\nCheck Yaml...............................................................Passed\nCheck JSON...........................................(no files to check)Skipped\nCheck Toml...............................................................Passed\nFix End of Files.........................................................Passed\nTrim Trailing Whitespace.................................................Passed\nblack....................................................................Passed\nisort....................................................................Passed\nflake8...................................................................Passed\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n如需临时跳过校验，可在 commit 命令中加上 --no-verify 参数：\n\n$ git commit -m "add main.py" --no-verify\n\n\n1\n\n\n\n# 最佳实践\n\n 1. 将.pre-commit-config.yaml纳入版本控制，确保团队配置一致\n 2. 定期运行pre-commit autoupdate保持工具最新版本\n 3. 优先修复而不是--no-verify，让规范成为肌肉记忆.\n\n\n# 总结\n\n通过本文的实践，我们已经为Python项目搭建了自动化代码质检流水线。pre-commit 就像一位尽职的代码审查员，帮我们做到：\n\n * 规范守护者：自动执行代码格式化（Black/isort）和静态检查（flake8）\n * 效率加速器：拦截问题在提交前，避免CI/CD环节反复返工\n * 团队协作者：统一项目代码风格，降低多人协作成本',normalizedContent:'# 简介\n\npre-commit 是一个开源工具，用于管理和执行 git 钩子，确保代码库的一致性和质量。通过在提交代码前自动运行代码风格检查（linting）和格式修正（formatting），它有助于保持项目代码的统一标准。本文将通过一个 python 项目的实例，展示如何配置 pre-commit 工作流。\n\n本文旨在介绍使用 pre-commit 对 python 项目进行代码检查的方法，以提前发现并解决代码中的问题，提高代码的整体质量。文中提及的所有代码示例可以在 pre-commit-demo 找到。\n\n\n# 使用\n\n 1. 安装\n\n首先，安装 pre-commit：\n\npip install pre-commit\n\n\n1\n\n\n安装成功后，您可以通过以下命令验证安装是否成功：\n\n$ pre-commit --version \npre-commit 4.2.0\n\n\n1\n2\n\n\n接下来，设置 git 钩子脚本：\n\n$ pre-commit install\npre-commit installed at .git/hooks/pre-commit\n\n\n1\n2\n\n 1. 创建配置文件 在项目的根目录下创建 .pre-commit-config.yaml 文件，并推荐使用最新稳定版：\n\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v2.3.0\n    hooks:\n      - id: check-yaml\n      - id: check-json\n      - id: check-toml\n      - id: end-of-file-fixer\n      - id: trailing-whitespace\n  - repo: https://github.com/psf/black\n    rev: 22.10.0\n    hooks:\n      - id: black\n  - repo: https://github.com/pycqa/isort\n    rev: 5.13.2\n    hooks:\n      - id: isort\n  - repo: https://github.com/pycqa/flake8\n    rev: 7.2.0\n    hooks:\n      - id: flake8\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n配置文件说明:\n\n * repos: 包含要使用的仓库列表。\n * repo: 每个仓库的 url。\n * rev: 版本号，建议使用最新稳定版。\n * hooks: 需要执行的钩子列表。\n * id: 各个钩子的标识符。\n\n每个钩子 id 的具体作用可参考相应仓库的官方文档。\n\n 3. 执行与应用\n\n在执行 commit 命令时，会自动调用配置文件中定义的钩子脚本，检查代码是否符合规范。例如：\n\n$ pre-commit_demo % git add *\n$ pre-commit_demo % git commit -m "add main.py"\ncheck yaml...........................................(no files to check)skipped\ncheck json...........................................(no files to check)skipped\ncheck toml...........................................(no files to check)skipped\nfix end of files.........................................................passed\ntrim trailing whitespace.................................................passed\nblack....................................................................passed\nisort....................................................................passed\nflake8...................................................................passed\n[main 27890fe] add main.py\n 1 file changed, 1 insertion(+)\n create mode 100644 main.py\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n默认情况下，仅检查新添加或修改的文件。若需手动检查所有文件，可以使用如下命令：\n\n$ pre-commit run --all-files\ncheck yaml...............................................................passed\ncheck json...........................................(no files to check)skipped\ncheck toml...............................................................passed\nfix end of files.........................................................passed\ntrim trailing whitespace.................................................passed\nblack....................................................................passed\nisort....................................................................passed\nflake8...................................................................passed\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n如需临时跳过校验，可在 commit 命令中加上 --no-verify 参数：\n\n$ git commit -m "add main.py" --no-verify\n\n\n1\n\n\n\n# 最佳实践\n\n 1. 将.pre-commit-config.yaml纳入版本控制，确保团队配置一致\n 2. 定期运行pre-commit autoupdate保持工具最新版本\n 3. 优先修复而不是--no-verify，让规范成为肌肉记忆.\n\n\n# 总结\n\n通过本文的实践，我们已经为python项目搭建了自动化代码质检流水线。pre-commit 就像一位尽职的代码审查员，帮我们做到：\n\n * 规范守护者：自动执行代码格式化（black/isort）和静态检查（flake8）\n * 效率加速器：拦截问题在提交前，避免ci/cd环节反复返工\n * 团队协作者：统一项目代码风格，降低多人协作成本',charsets:{cjk:!0},lastUpdated:"2025/05/13, 17:42:32",lastUpdatedTimestamp:1747129352e3},{title:"gin中validator模块的源码分析",frontmatter:{tags:["go语言","gin"],title:"gin中validator模块的源码分析",date:"2022-09-11T16:23:04.000Z",permalink:"/pages/c41003/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"在gin中使用的是validator模块来对表单进行校验的，本文主要是对该模块的源码分析与学习",feed:{enable:!0},categories:["编程","go语言"],comment:!0,meta:[{name:"twitter:title",content:"gin中validator模块的源码分析"},{name:"twitter:description",content:"在gin中使用的是validator模块来对表单进行校验的，本文主要是对该模块的源码分析与学习"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/02.%20gin%E4%B8%ADvalidator%E6%A8%A1%E5%9D%97%E7%9A%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:type",content:"article"},{property:"og:title",content:"gin中validator模块的源码分析"},{property:"og:description",content:"在gin中使用的是validator模块来对表单进行校验的，本文主要是对该模块的源码分析与学习"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/02.%20gin%E4%B8%ADvalidator%E6%A8%A1%E5%9D%97%E7%9A%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-09-11T16:23:04.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"gin"},{itemprop:"name",content:"gin中validator模块的源码分析"},{itemprop:"description",content:"在gin中使用的是validator模块来对表单进行校验的，本文主要是对该模块的源码分析与学习"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/02.%20gin%E4%B8%ADvalidator%E6%A8%A1%E5%9D%97%E7%9A%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html",relativePath:"04.编程/02.go语言/02. gin中validator模块的源码分析.md",key:"v-69c6394c",path:"/pages/c41003/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"懒加载validate对象",slug:"懒加载validate对象",normalizedTitle:"懒加载validate对象",charIndex:62},{level:2,title:"多种请求参数的校验",slug:"多种请求参数的校验",normalizedTitle:"多种请求参数的校验",charIndex:1555},{level:2,title:"钩子方法",slug:"钩子方法",normalizedTitle:"钩子方法",charIndex:3621},{level:2,title:"对象池的应用",slug:"对象池的应用",normalizedTitle:"对象池的应用",charIndex:4816},{level:2,title:"根据标签校验过程",slug:"根据标签校验过程",normalizedTitle:"根据标签校验过程",charIndex:6027},{level:2,title:"错误提示信息翻译",slug:"错误提示信息翻译",normalizedTitle:"错误提示信息翻译",charIndex:9749}],headersStr:"简介 懒加载validate对象 多种请求参数的校验 钩子方法 对象池的应用 根据标签校验过程 错误提示信息翻译",content:'# 简介\n\n在gin中使用的是validator模块来对表单进行校验的。\n\nvalidator模块github地址\n\n\n# 懒加载validate对象\n\n众所周知，在api层需要使用gin.Context中的ShouldBindJSON方法来对request中的json字段进行校验，例子如下:\n\nfunc login(c *gin.Context) {\n\n\tvar user User\n\tif err := c.ShouldBindJSON(&user); err != nil {\n\n\t\terrs, ok := err.(validator.ValidationErrors)\n\t\tif !ok {\n\t\t\t// 非校验错误，其他错误直接返回\n\t\t\tc.JSON(http.StatusOK, gin.H{"msg": err.Error()})\n\t\t\treturn\n\t\t}\n\n\t\tc.JSON(http.StatusOK, gin.H{"msg": errs.Translate(global.Trans)})\n\t\treturn\n\t}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n在c.ShourdBindJSON中，一直往下跳转，跟到路径binding/default_validator.go下，可以看到代码如下，对表单的校验是调用v.validate.Struct(obj)来完成的，这里的validate是validator库中Validate对象，所以在之前使用v.lazyinit()来创建该对象。\n\n// validateStruct receives struct type\nfunc (v *defaultValidator) validateStruct(obj any) error {\n\tv.lazyinit()\n\treturn v.validate.Struct(obj)\n}\n\n\n1\n2\n3\n4\n5\n\n\n再看v.lazyinit()方法，这里使用了once.Do方法，该once是sync.Onec对象，Do中的方法只会执行一次，也就是只会创建一次Validate对象，保持该对象的单例。\n\ntype defaultValidator struct {\n\tonce     sync.Once\n\tvalidate *validator.Validate\n}\n\nfunc (v *defaultValidator) lazyinit() {\n\tv.once.Do(func() {\n\t\tv.validate = validator.New()\n\t\tv.validate.SetTagName("binding")\n\t})\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n那么有这么一种场景，如果我想要对validator中的validate对象进行配置，该怎么办呢？因为上面都是在使用时懒加载才加载的，我们需要提前拿到validate对象并进行配置，该如何处理？\n\n在代码binding/default_validator.go中，提供了Engine方法，我们可以使用该方法给使用这调用提前加载validate对象，并返回该对象，就可以进行配置了。\n\nfunc (v *defaultValidator) Engine() any {\n\tv.lazyinit()\n\treturn v.validate\n}\n\n\n1\n2\n3\n4\n\n\n结论：\n\n * 结构体中的对象可以使用懒加载的方式，在使用的时候再进行创建。\n\n * 可以使用once.Do的方法创建对象保持单例。\n\n * 可以提供方法提前加载对象，然后返回出来进行使用配置\n\n\n# 多种请求参数的校验\n\n我们使用c.ShouldBindJSON(&user)可以对json格式的请求参数进行校验，也可以使用c.ShouldBindXML对xml格式的请求参数进行校验。\n\n在代码binding/binding.go中可以看到定义了多种对request进行校验的全局对象。\n\nvar (\n\tJSON          = jsonBinding{}\n\tXML           = xmlBinding{}\n\tForm          = formBinding{}\n\tQuery         = queryBinding{}\n\tFormPost      = formPostBinding{}\n\tFormMultipart = formMultipartBinding{}\n\tProtoBuf      = protobufBinding{}\n\tMsgPack       = msgpackBinding{}\n\tYAML          = yamlBinding{}\n\tUri           = uriBinding{}\n\tHeader        = headerBinding{}\n\tTOML          = tomlBinding{}\n)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n进入c.ShouldBindJSON方法，可以看到调用了c.ShouldBindWith方法并将表单对象和全局的JSON对象传入其中。\n\n// ShouldBindJSON is a shortcut for c.ShouldBindWith(obj, binding.JSON).\nfunc (c *Context) ShouldBindJSON(obj any) error {\n\treturn c.ShouldBindWith(obj, binding.JSON)\n}\n\n\n1\n2\n3\n4\n\n\n在c.ShouldBindWith中，是直接使用上面的JSON全局对象的bind方法，将requets和表单对象传入其中。\n\n// ShouldBindWith binds the passed struct pointer using the specified binding engine.\n// See the binding package.\nfunc (c *Context) ShouldBindWith(obj any, b binding.Binding) error {\n\treturn b.Bind(c.Request, obj)\n}\n\n\n1\n2\n3\n4\n5\n\n\n再看b.Bind方法，你会发现，它做的事情是：校验请求参数是否为json格式，然后再调用validate方法，该方法就是去创建go-palyground模块中Validate对象，然后调用其struct方法进行参数验证。\n\nfunc (jsonBinding) Bind(req *http.Request, obj any) error {\n\tif req == nil || req.Body == nil {\n\t\treturn errors.New("invalid request")\n\t}\n\treturn decodeJSON(req.Body, obj)\n}\n\nfunc decodeJSON(r io.Reader, obj any) error {\n\tdecoder := json.NewDecoder(r)\n\tif EnableDecoderUseNumber {\n\t\tdecoder.UseNumber()\n\t}\n\tif EnableDecoderDisallowUnknownFields {\n\t\tdecoder.DisallowUnknownFields()\n\t}\n\tif err := decoder.Decode(obj); err != nil {\n\t\treturn err\n\t}\n\treturn validate(obj)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n你再看看ShouldBindXML方法，就会发现是和上面一样的过程，调用的是全局对象XML中的bind方法，然后再校验请求参数是否为xml格式，最终调用validate方法。\n\n总结：\n\n在binding/binding.go中的全局对象都实现了一个bind方法，该方法是对请求参数的格式进行检验，然后最终会调用validate方法，去创建go-palyground模块中Validate对象，再调用其struct对象进行请求参数的内容校验。\n\n创建多个ShouldBindXXX，在不同的方法中使用不同的全局对象，这些对象都有一个相同的方法bind，然后再统一调用bind方法进行校验。\n\n\n# 钩子方法\n\nvalidator库中Validate结构体提供了一系列的钩子方法，在校验中的过程中，提供给使用者来修改其中的部分内容。\n\n我们看一下validator_instance.go文件中Validate结构体，该结构体中包含了hasTagNameFunc和tagNameFunc两个变量，tagNameFunc代表着钩子方法，使用者可以自定方法来赋值给它，hasTagNameFunc是bool类型代表是否配置了钩子方法.\n\ntype Validate struct {\n\ttagName          string\n\tpool             *sync.Pool\n\thasCustomFuncs   bool\n\thasTagNameFunc   bool\n\ttagNameFunc      TagNameFunc\n\tstructLevelFuncs map[reflect.Type]StructLevelFuncCtx\n\tcustomFuncs      map[reflect.Type]CustomTypeFunc\n\taliases          map[string]string\n\tvalidations      map[string]internalValidationFuncWrapper\n\ttransTagFunc     map[ut.Translator]map[string]TranslationFunc // map[<locale>]map[<tag>]TranslationFunc\n\ttagCache         *tagCache\n\tstructCache      *structCache\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n使用者可以调用RegisterTagNameFunc方法来注册自己写的方法\n\nfunc (v *Validate) RegisterTagNameFunc(fn TagNameFunc) {\n\tv.tagNameFunc = fn\n\tv.hasTagNameFunc = true\n}\n\n\n1\n2\n3\n4\n\n\n在代码cache.go中extractStructCache方法中有下面一段代码，通过调用hasTagNameFunc方法来判断是否设置了钩子方法，如果设置了，则调用tagNameFunc来执行使用者自定的方法。\n\n\t\tif v.hasTagNameFunc {\n\t\t\tname := v.tagNameFunc(fld)\n\t\t\tif len(name) > 0 {\n\t\t\t\tcustomName = name\n\t\t\t}\n\t\t}\n\n\n1\n2\n3\n4\n5\n6\n\n\n总结：\n\n * 可以提供钩子方法暴露给使用者参与到执行过程中来。\n\n\n# 对象池的应用\n\n看文件validator_instance.go中的Struct方法，这个方法就是表单的校验的入口方法，可以看到它又调用了StructCtx方法。\n\nfunc (v *Validate) Struct(s interface{}) error {\n\treturn v.StructCtx(context.Background(), s)\n}\n\n\n1\n2\n3\n\n\n再来看看StructCtx方法，其中pool是*sync.Pool类型，调用Get方法获取validate对象，然后再调用其validateStruct方法，其中会进行请求参数的校验，然后如果校验有误，会将错误信息保存在errs中。valudate使用完成后，再put回pool中。\n\n因为每一次校验都需要创建validate对象，所以这里使用了sync.Pool可以复用临时对象，减少内存的分配，降低GC压力。\n\nfunc (v *Validate) StructCtx(ctx context.Context, s interface{}) (err error) {\n\n\tval := reflect.ValueOf(s)\n\ttop := val\n\n\tif val.Kind() == reflect.Ptr && !val.IsNil() {\n\t\tval = val.Elem()\n\t}\n\n\tif val.Kind() != reflect.Struct || val.Type() == timeType {\n\t\treturn &InvalidValidationError{Type: reflect.TypeOf(s)}\n\t}\n\n\t// good to validate\n\tvd := v.pool.Get().(*validate)\n\tvd.top = top\n\tvd.isPartial = false\n\t// vd.hasExcludes = false // only need to reset in StructPartial and StructExcept\n\n\tvd.validateStruct(ctx, top, val, val.Type(), vd.ns[0:0], vd.actualNs[0:0], nil)\n\n\tif len(vd.errs) > 0 {\n\t\terr = vd.errs\n\t\tvd.errs = nil\n\t}\n\n\tv.pool.Put(vd)\n\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n总结：\n\n * 当需要频繁创建相同对象，并且该对象是无状态时，可以使用sync.Pool来提高复用临时对象，减少内存的分配，降低GC压力。\n\n\n# 根据标签校验过程\n\n在懒加载创建validator的Validate对象时，是调用validator_instance.go中New方法来创建该对象，在该方法中初始化所有标签及标签对应的校验方法并保存在Validate对象中的validations变量中\n\nfor k, val := range bakedInValidators {\n\tswitch k {\n\t// these require that even if the value is nil that the validation should run, omitempty still overrides this behaviour\n\tcase requiredIfTag, requiredUnlessTag, requiredWithTag, requiredWithAllTag, requiredWithoutTag, requiredWithoutAllTag,\n\t\texcludedWithTag, excludedWithAllTag, excludedWithoutTag, excludedWithoutAllTag:\n\t\t_ = v.registerValidation(k, wrapFunc(val), true, true)\n\tdefault:\n\t\t// no need to error check here, baked in will always be valid\n\t\t_ = v.registerValidation(k, wrapFunc(val), true, false)\n\t}\n}\n\n\nfunc (v *Validate) registerValidation(tag string, fn FuncCtx, bakedIn bool, nilCheckable bool) error {\n\tif len(tag) == 0 {\n\t\treturn errors.New("function Key cannot be empty")\n\t}\n\n\tif fn == nil {\n\t\treturn errors.New("function cannot be empty")\n\t}\n\n\t_, ok := restrictedTags[tag]\n\tif !bakedIn && (ok || strings.ContainsAny(tag, restrictedTagChars)) {\n\t\tpanic(fmt.Sprintf(restrictedTagErr, tag))\n\t}\n\tv.validations[tag] = internalValidationFuncWrapper{fn: fn, runValidatinOnNil: nilCheckable}\n\treturn nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n我们可以在baked_in.go文件中看到有定义以标签为key，校验方法为value的map对象。\n\nbakedInValidators = map[string]Func{\n\t\t"required":                      hasValue,\n\t\t"required_if":                   requiredIf,\n\t\t"required_unless":               requiredUnless,\n\t\t"required_with":                 requiredWith,\n\t\t"required_with_all":             requiredWithAll,\n\t\t"required_without":              requiredWithout,\n\t\t"required_without_all":          requiredWithoutAll,\n......\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在代码cache.go中extractStructCache方法中，会遍历请求参数的每一个字段，然后根据该字段的tag创建对应的ctag对象，再创建该字段的cField对象，并将ctag传入。\n\n\t\tif len(tag) > 0 {\n\t\t\tctag, _ = v.parseFieldTagsRecursive(tag, fld.Name, "", false)\n\t\t} else {\n\t\t\t// even if field doesn\'t have validations need cTag for traversing to potential inner/nested\n\t\t\t// elements of the field.\n\t\t\tctag = new(cTag)\n\t\t}\n\n\t\tcs.fields = append(cs.fields, &cField{\n\t\t\tidx:        i,\n\t\t\tname:       fld.Name,\n\t\t\taltName:    customName,\n\t\t\tcTags:      ctag,\n\t\t\tnamesEqual: fld.Name == customName,\n\t\t})\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n在上面的v.parseFieldTagsRecursive方法中会将从之前缓存的validatetions集合中找到该ctag的校验方法，然后赋值ctag.fn方法。\n\nif wrapper, ok := v.validations[current.tag]; ok {\n\tcurrent.fn = wrapper.fn\n\tcurrent.runValidationWhenNil = wrapper.runValidatinOnNil\n} else {\n\tpanic(strings.TrimSpace(fmt.Sprintf(undefinedValidation, current.tag, fieldName)))\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n在文件validator.go中traverseField方法校验字段中会调用上面传递的fn方法，返回值为false时，会创建fieldError对象保存在validate的errs中\n\nif !ct.fn(ctx, v) {\n\n\tv.str1 = string(append(ns, cf.altName...))\n\n\tif v.v.hasTagNameFunc {\n\t\tv.str2 = string(append(structNs, cf.name...))\n\t} else {\n\t\tv.str2 = v.str1\n\t}\n\n\tv.errs = append(v.errs,\n\t\t&fieldError{\n\t\t\tv:              v.v,\n\t\t\ttag:            ct.aliasTag,\n\t\t\tactualTag:      ct.tag,\n\t\t\tns:             v.str1,\n\t\t\tstructNs:       v.str2,\n\t\t\tfieldLen:       uint8(len(cf.altName)),\n\t\t\tstructfieldLen: uint8(len(cf.name)),\n\t\t\tvalue:          current.Interface(),\n\t\t\tparam:          ct.param,\n\t\t\tkind:           kind,\n\t\t\ttyp:            typ,\n\t\t},\n)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n最终将这个error在validator_instance.go中的StructCtx方法中返回出去。\n\nvd.validateStruct(ctx, top, val, val.Type(), vd.ns[0:0], vd.actualNs[0:0], nil)\n\nif len(vd.errs) > 0 {\n\terr = vd.errs\n\tvd.errs = nil\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n结论：\n\n * error并不是调用validateStruct返回出来的，而是通过在结构体中创建了一个error，在过程中如果发生了错误则将该错误信息保存在结构体的error变量中，也是一种error的返回方式。\n\n * 先初始化所有的校验方法，然后再根据每个字段选择校验方法进行执行。逻辑非常清晰。\n\n\n# 错误提示信息翻译\n\n从上面的过程可以发现，仅能够发现哪个字段再哪个tag中发生了错误，如下所示：\n\n{\'msg\': "Key: \'User.password\' Error:Field validation for \'password\' failed on the \'required\' tag"}\n\n\n1\n\n\n但是我们需要的时候人性化的错误提示。\n\n在代码translations/zh/zh.go的RegisterDefaultTranslations方法中可以看到定义了每个tag及对应中文提示信息。这些信息会注册到validator的Validate.transTagFunc变量中。\n\nfunc RegisterDefaultTranslations(v *validator.Validate, trans ut.Translator) (err error) {\n\n\ttranslations := []struct {\n\t\ttag             string\n\t\ttranslation     string\n\t\toverride        bool\n\t\tcustomRegisFunc validator.RegisterTranslationsFunc\n\t\tcustomTransFunc validator.TranslationFunc\n\t}{\n\t\t{\n\t\t\ttag:         "required",\n\t\t\ttranslation: "{0}为必填字段",\n\t\t\toverride:    false,\n\t\t},\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n每个字段的错误对象都有Translate方法，当调用方法时，会遍历当前所有错误的字段，然后再找到每个Tag对应的提示信息输出。\n\nfunc (ve ValidationErrors) Translate(ut ut.Translator) ValidationErrorsTranslations {\n\n\ttrans := make(ValidationErrorsTranslations)\n\n\tvar fe *fieldError\n\n\tfor i := 0; i < len(ve); i++ {\n\t\tfe = ve[i].(*fieldError)\n\n\t\t// // in case an Anonymous struct was used, ensure that the key\n\t\t// // would be \'Username\' instead of ".Username"\n\t\t// if len(fe.ns) > 0 && fe.ns[:1] == "." {\n\t\t// \ttrans[fe.ns[1:]] = fe.Translate(ut)\n\t\t// \tcontinue\n\t\t// }\n\n\t\ttrans[fe.ns] = fe.Translate(ut)\n\t}\n\n\treturn trans\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n这个是每一个字段通过tag获取提示信息。\n\nfunc (fe *fieldError) Translate(ut ut.Translator) string {\n\n\tm, ok := fe.v.transTagFunc[ut]\n\tif !ok {\n\t\treturn fe.Error()\n\t}\n\n\tfn, ok := m[fe.tag]\n\tif !ok {\n\t\treturn fe.Error()\n\t}\n\n\treturn fn(ut, fe)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n',normalizedContent:'# 简介\n\n在gin中使用的是validator模块来对表单进行校验的。\n\nvalidator模块github地址\n\n\n# 懒加载validate对象\n\n众所周知，在api层需要使用gin.context中的shouldbindjson方法来对request中的json字段进行校验，例子如下:\n\nfunc login(c *gin.context) {\n\n\tvar user user\n\tif err := c.shouldbindjson(&user); err != nil {\n\n\t\terrs, ok := err.(validator.validationerrors)\n\t\tif !ok {\n\t\t\t// 非校验错误，其他错误直接返回\n\t\t\tc.json(http.statusok, gin.h{"msg": err.error()})\n\t\t\treturn\n\t\t}\n\n\t\tc.json(http.statusok, gin.h{"msg": errs.translate(global.trans)})\n\t\treturn\n\t}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n在c.shourdbindjson中，一直往下跳转，跟到路径binding/default_validator.go下，可以看到代码如下，对表单的校验是调用v.validate.struct(obj)来完成的，这里的validate是validator库中validate对象，所以在之前使用v.lazyinit()来创建该对象。\n\n// validatestruct receives struct type\nfunc (v *defaultvalidator) validatestruct(obj any) error {\n\tv.lazyinit()\n\treturn v.validate.struct(obj)\n}\n\n\n1\n2\n3\n4\n5\n\n\n再看v.lazyinit()方法，这里使用了once.do方法，该once是sync.onec对象，do中的方法只会执行一次，也就是只会创建一次validate对象，保持该对象的单例。\n\ntype defaultvalidator struct {\n\tonce     sync.once\n\tvalidate *validator.validate\n}\n\nfunc (v *defaultvalidator) lazyinit() {\n\tv.once.do(func() {\n\t\tv.validate = validator.new()\n\t\tv.validate.settagname("binding")\n\t})\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n那么有这么一种场景，如果我想要对validator中的validate对象进行配置，该怎么办呢？因为上面都是在使用时懒加载才加载的，我们需要提前拿到validate对象并进行配置，该如何处理？\n\n在代码binding/default_validator.go中，提供了engine方法，我们可以使用该方法给使用这调用提前加载validate对象，并返回该对象，就可以进行配置了。\n\nfunc (v *defaultvalidator) engine() any {\n\tv.lazyinit()\n\treturn v.validate\n}\n\n\n1\n2\n3\n4\n\n\n结论：\n\n * 结构体中的对象可以使用懒加载的方式，在使用的时候再进行创建。\n\n * 可以使用once.do的方法创建对象保持单例。\n\n * 可以提供方法提前加载对象，然后返回出来进行使用配置\n\n\n# 多种请求参数的校验\n\n我们使用c.shouldbindjson(&user)可以对json格式的请求参数进行校验，也可以使用c.shouldbindxml对xml格式的请求参数进行校验。\n\n在代码binding/binding.go中可以看到定义了多种对request进行校验的全局对象。\n\nvar (\n\tjson          = jsonbinding{}\n\txml           = xmlbinding{}\n\tform          = formbinding{}\n\tquery         = querybinding{}\n\tformpost      = formpostbinding{}\n\tformmultipart = formmultipartbinding{}\n\tprotobuf      = protobufbinding{}\n\tmsgpack       = msgpackbinding{}\n\tyaml          = yamlbinding{}\n\turi           = uribinding{}\n\theader        = headerbinding{}\n\ttoml          = tomlbinding{}\n)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n进入c.shouldbindjson方法，可以看到调用了c.shouldbindwith方法并将表单对象和全局的json对象传入其中。\n\n// shouldbindjson is a shortcut for c.shouldbindwith(obj, binding.json).\nfunc (c *context) shouldbindjson(obj any) error {\n\treturn c.shouldbindwith(obj, binding.json)\n}\n\n\n1\n2\n3\n4\n\n\n在c.shouldbindwith中，是直接使用上面的json全局对象的bind方法，将requets和表单对象传入其中。\n\n// shouldbindwith binds the passed struct pointer using the specified binding engine.\n// see the binding package.\nfunc (c *context) shouldbindwith(obj any, b binding.binding) error {\n\treturn b.bind(c.request, obj)\n}\n\n\n1\n2\n3\n4\n5\n\n\n再看b.bind方法，你会发现，它做的事情是：校验请求参数是否为json格式，然后再调用validate方法，该方法就是去创建go-palyground模块中validate对象，然后调用其struct方法进行参数验证。\n\nfunc (jsonbinding) bind(req *http.request, obj any) error {\n\tif req == nil || req.body == nil {\n\t\treturn errors.new("invalid request")\n\t}\n\treturn decodejson(req.body, obj)\n}\n\nfunc decodejson(r io.reader, obj any) error {\n\tdecoder := json.newdecoder(r)\n\tif enabledecoderusenumber {\n\t\tdecoder.usenumber()\n\t}\n\tif enabledecoderdisallowunknownfields {\n\t\tdecoder.disallowunknownfields()\n\t}\n\tif err := decoder.decode(obj); err != nil {\n\t\treturn err\n\t}\n\treturn validate(obj)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n你再看看shouldbindxml方法，就会发现是和上面一样的过程，调用的是全局对象xml中的bind方法，然后再校验请求参数是否为xml格式，最终调用validate方法。\n\n总结：\n\n在binding/binding.go中的全局对象都实现了一个bind方法，该方法是对请求参数的格式进行检验，然后最终会调用validate方法，去创建go-palyground模块中validate对象，再调用其struct对象进行请求参数的内容校验。\n\n创建多个shouldbindxxx，在不同的方法中使用不同的全局对象，这些对象都有一个相同的方法bind，然后再统一调用bind方法进行校验。\n\n\n# 钩子方法\n\nvalidator库中validate结构体提供了一系列的钩子方法，在校验中的过程中，提供给使用者来修改其中的部分内容。\n\n我们看一下validator_instance.go文件中validate结构体，该结构体中包含了hastagnamefunc和tagnamefunc两个变量，tagnamefunc代表着钩子方法，使用者可以自定方法来赋值给它，hastagnamefunc是bool类型代表是否配置了钩子方法.\n\ntype validate struct {\n\ttagname          string\n\tpool             *sync.pool\n\thascustomfuncs   bool\n\thastagnamefunc   bool\n\ttagnamefunc      tagnamefunc\n\tstructlevelfuncs map[reflect.type]structlevelfuncctx\n\tcustomfuncs      map[reflect.type]customtypefunc\n\taliases          map[string]string\n\tvalidations      map[string]internalvalidationfuncwrapper\n\ttranstagfunc     map[ut.translator]map[string]translationfunc // map[<locale>]map[<tag>]translationfunc\n\ttagcache         *tagcache\n\tstructcache      *structcache\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n使用者可以调用registertagnamefunc方法来注册自己写的方法\n\nfunc (v *validate) registertagnamefunc(fn tagnamefunc) {\n\tv.tagnamefunc = fn\n\tv.hastagnamefunc = true\n}\n\n\n1\n2\n3\n4\n\n\n在代码cache.go中extractstructcache方法中有下面一段代码，通过调用hastagnamefunc方法来判断是否设置了钩子方法，如果设置了，则调用tagnamefunc来执行使用者自定的方法。\n\n\t\tif v.hastagnamefunc {\n\t\t\tname := v.tagnamefunc(fld)\n\t\t\tif len(name) > 0 {\n\t\t\t\tcustomname = name\n\t\t\t}\n\t\t}\n\n\n1\n2\n3\n4\n5\n6\n\n\n总结：\n\n * 可以提供钩子方法暴露给使用者参与到执行过程中来。\n\n\n# 对象池的应用\n\n看文件validator_instance.go中的struct方法，这个方法就是表单的校验的入口方法，可以看到它又调用了structctx方法。\n\nfunc (v *validate) struct(s interface{}) error {\n\treturn v.structctx(context.background(), s)\n}\n\n\n1\n2\n3\n\n\n再来看看structctx方法，其中pool是*sync.pool类型，调用get方法获取validate对象，然后再调用其validatestruct方法，其中会进行请求参数的校验，然后如果校验有误，会将错误信息保存在errs中。valudate使用完成后，再put回pool中。\n\n因为每一次校验都需要创建validate对象，所以这里使用了sync.pool可以复用临时对象，减少内存的分配，降低gc压力。\n\nfunc (v *validate) structctx(ctx context.context, s interface{}) (err error) {\n\n\tval := reflect.valueof(s)\n\ttop := val\n\n\tif val.kind() == reflect.ptr && !val.isnil() {\n\t\tval = val.elem()\n\t}\n\n\tif val.kind() != reflect.struct || val.type() == timetype {\n\t\treturn &invalidvalidationerror{type: reflect.typeof(s)}\n\t}\n\n\t// good to validate\n\tvd := v.pool.get().(*validate)\n\tvd.top = top\n\tvd.ispartial = false\n\t// vd.hasexcludes = false // only need to reset in structpartial and structexcept\n\n\tvd.validatestruct(ctx, top, val, val.type(), vd.ns[0:0], vd.actualns[0:0], nil)\n\n\tif len(vd.errs) > 0 {\n\t\terr = vd.errs\n\t\tvd.errs = nil\n\t}\n\n\tv.pool.put(vd)\n\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n总结：\n\n * 当需要频繁创建相同对象，并且该对象是无状态时，可以使用sync.pool来提高复用临时对象，减少内存的分配，降低gc压力。\n\n\n# 根据标签校验过程\n\n在懒加载创建validator的validate对象时，是调用validator_instance.go中new方法来创建该对象，在该方法中初始化所有标签及标签对应的校验方法并保存在validate对象中的validations变量中\n\nfor k, val := range bakedinvalidators {\n\tswitch k {\n\t// these require that even if the value is nil that the validation should run, omitempty still overrides this behaviour\n\tcase requirediftag, requiredunlesstag, requiredwithtag, requiredwithalltag, requiredwithouttag, requiredwithoutalltag,\n\t\texcludedwithtag, excludedwithalltag, excludedwithouttag, excludedwithoutalltag:\n\t\t_ = v.registervalidation(k, wrapfunc(val), true, true)\n\tdefault:\n\t\t// no need to error check here, baked in will always be valid\n\t\t_ = v.registervalidation(k, wrapfunc(val), true, false)\n\t}\n}\n\n\nfunc (v *validate) registervalidation(tag string, fn funcctx, bakedin bool, nilcheckable bool) error {\n\tif len(tag) == 0 {\n\t\treturn errors.new("function key cannot be empty")\n\t}\n\n\tif fn == nil {\n\t\treturn errors.new("function cannot be empty")\n\t}\n\n\t_, ok := restrictedtags[tag]\n\tif !bakedin && (ok || strings.containsany(tag, restrictedtagchars)) {\n\t\tpanic(fmt.sprintf(restrictedtagerr, tag))\n\t}\n\tv.validations[tag] = internalvalidationfuncwrapper{fn: fn, runvalidatinonnil: nilcheckable}\n\treturn nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n我们可以在baked_in.go文件中看到有定义以标签为key，校验方法为value的map对象。\n\nbakedinvalidators = map[string]func{\n\t\t"required":                      hasvalue,\n\t\t"required_if":                   requiredif,\n\t\t"required_unless":               requiredunless,\n\t\t"required_with":                 requiredwith,\n\t\t"required_with_all":             requiredwithall,\n\t\t"required_without":              requiredwithout,\n\t\t"required_without_all":          requiredwithoutall,\n......\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在代码cache.go中extractstructcache方法中，会遍历请求参数的每一个字段，然后根据该字段的tag创建对应的ctag对象，再创建该字段的cfield对象，并将ctag传入。\n\n\t\tif len(tag) > 0 {\n\t\t\tctag, _ = v.parsefieldtagsrecursive(tag, fld.name, "", false)\n\t\t} else {\n\t\t\t// even if field doesn\'t have validations need ctag for traversing to potential inner/nested\n\t\t\t// elements of the field.\n\t\t\tctag = new(ctag)\n\t\t}\n\n\t\tcs.fields = append(cs.fields, &cfield{\n\t\t\tidx:        i,\n\t\t\tname:       fld.name,\n\t\t\taltname:    customname,\n\t\t\tctags:      ctag,\n\t\t\tnamesequal: fld.name == customname,\n\t\t})\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n在上面的v.parsefieldtagsrecursive方法中会将从之前缓存的validatetions集合中找到该ctag的校验方法，然后赋值ctag.fn方法。\n\nif wrapper, ok := v.validations[current.tag]; ok {\n\tcurrent.fn = wrapper.fn\n\tcurrent.runvalidationwhennil = wrapper.runvalidatinonnil\n} else {\n\tpanic(strings.trimspace(fmt.sprintf(undefinedvalidation, current.tag, fieldname)))\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n在文件validator.go中traversefield方法校验字段中会调用上面传递的fn方法，返回值为false时，会创建fielderror对象保存在validate的errs中\n\nif !ct.fn(ctx, v) {\n\n\tv.str1 = string(append(ns, cf.altname...))\n\n\tif v.v.hastagnamefunc {\n\t\tv.str2 = string(append(structns, cf.name...))\n\t} else {\n\t\tv.str2 = v.str1\n\t}\n\n\tv.errs = append(v.errs,\n\t\t&fielderror{\n\t\t\tv:              v.v,\n\t\t\ttag:            ct.aliastag,\n\t\t\tactualtag:      ct.tag,\n\t\t\tns:             v.str1,\n\t\t\tstructns:       v.str2,\n\t\t\tfieldlen:       uint8(len(cf.altname)),\n\t\t\tstructfieldlen: uint8(len(cf.name)),\n\t\t\tvalue:          current.interface(),\n\t\t\tparam:          ct.param,\n\t\t\tkind:           kind,\n\t\t\ttyp:            typ,\n\t\t},\n)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n最终将这个error在validator_instance.go中的structctx方法中返回出去。\n\nvd.validatestruct(ctx, top, val, val.type(), vd.ns[0:0], vd.actualns[0:0], nil)\n\nif len(vd.errs) > 0 {\n\terr = vd.errs\n\tvd.errs = nil\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n结论：\n\n * error并不是调用validatestruct返回出来的，而是通过在结构体中创建了一个error，在过程中如果发生了错误则将该错误信息保存在结构体的error变量中，也是一种error的返回方式。\n\n * 先初始化所有的校验方法，然后再根据每个字段选择校验方法进行执行。逻辑非常清晰。\n\n\n# 错误提示信息翻译\n\n从上面的过程可以发现，仅能够发现哪个字段再哪个tag中发生了错误，如下所示：\n\n{\'msg\': "key: \'user.password\' error:field validation for \'password\' failed on the \'required\' tag"}\n\n\n1\n\n\n但是我们需要的时候人性化的错误提示。\n\n在代码translations/zh/zh.go的registerdefaulttranslations方法中可以看到定义了每个tag及对应中文提示信息。这些信息会注册到validator的validate.transtagfunc变量中。\n\nfunc registerdefaulttranslations(v *validator.validate, trans ut.translator) (err error) {\n\n\ttranslations := []struct {\n\t\ttag             string\n\t\ttranslation     string\n\t\toverride        bool\n\t\tcustomregisfunc validator.registertranslationsfunc\n\t\tcustomtransfunc validator.translationfunc\n\t}{\n\t\t{\n\t\t\ttag:         "required",\n\t\t\ttranslation: "{0}为必填字段",\n\t\t\toverride:    false,\n\t\t},\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n每个字段的错误对象都有translate方法，当调用方法时，会遍历当前所有错误的字段，然后再找到每个tag对应的提示信息输出。\n\nfunc (ve validationerrors) translate(ut ut.translator) validationerrorstranslations {\n\n\ttrans := make(validationerrorstranslations)\n\n\tvar fe *fielderror\n\n\tfor i := 0; i < len(ve); i++ {\n\t\tfe = ve[i].(*fielderror)\n\n\t\t// // in case an anonymous struct was used, ensure that the key\n\t\t// // would be \'username\' instead of ".username"\n\t\t// if len(fe.ns) > 0 && fe.ns[:1] == "." {\n\t\t// \ttrans[fe.ns[1:]] = fe.translate(ut)\n\t\t// \tcontinue\n\t\t// }\n\n\t\ttrans[fe.ns] = fe.translate(ut)\n\t}\n\n\treturn trans\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n这个是每一个字段通过tag获取提示信息。\n\nfunc (fe *fielderror) translate(ut ut.translator) string {\n\n\tm, ok := fe.v.transtagfunc[ut]\n\tif !ok {\n\t\treturn fe.error()\n\t}\n\n\tfn, ok := m[fe.tag]\n\tif !ok {\n\t\treturn fe.error()\n\t}\n\n\treturn fn(ut, fe)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"go简单使用grpc",frontmatter:{tags:["go语言"],title:"go简单使用grpc",date:"2022-09-07T20:10:13.000Z",permalink:"/pages/87014e/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍go是如何使用grpc的",feed:{enable:!0},categories:["编程","go语言"],comment:!0,meta:[{name:"twitter:title",content:"go简单使用grpc"},{name:"twitter:description",content:"介绍go是如何使用grpc的"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/01.go%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8grpc.html"},{property:"og:type",content:"article"},{property:"og:title",content:"go简单使用grpc"},{property:"og:description",content:"介绍go是如何使用grpc的"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/01.go%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8grpc.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-09-07T20:10:13.000Z"},{property:"article:tag",content:"go语言"},{itemprop:"name",content:"go简单使用grpc"},{itemprop:"description",content:"介绍go是如何使用grpc的"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/01.go%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8grpc.html",relativePath:"04.编程/02.go语言/01.go简单使用grpc.md",key:"v-3d85724c",path:"/pages/87014e/",headers:[{level:2,title:"0.相关链接",slug:"_0-相关链接",normalizedTitle:"0.相关链接",charIndex:2},{level:2,title:"1. 定义proto文件",slug:"_1-定义proto文件",normalizedTitle:"1. 定义proto文件",charIndex:143},{level:2,title:"2. 编译proto文件",slug:"_2-编译proto文件",normalizedTitle:"2. 编译proto文件",charIndex:800},{level:2,title:"3. 创建grpc服务端",slug:"_3-创建grpc服务端",normalizedTitle:"3. 创建grpc服务端",charIndex:1378},{level:2,title:"4. 创建grpc客户端",slug:"_4-创建grpc客户端",normalizedTitle:"4. 创建grpc客户端",charIndex:2874},{level:2,title:"5. 运行结果",slug:"_5-运行结果",normalizedTitle:"5. 运行结果",charIndex:4043}],headersStr:"0.相关链接 1. 定义proto文件 2. 编译proto文件 3. 创建grpc服务端 4. 创建grpc客户端 5. 运行结果",content:'# 0.相关链接\n\ngrpc github：https://github.com/grpc/grpc-go\n\n官方文档：https://grpc.io/docs/languages/go/\n\n案例代码：https://github.com/tenqaz/go-examples\n\n\n# 1. 定义proto文件\n\nproto文件是用来预先定义的消息格式。数据包会按照proto文件所定义的消息格式完成二进制码流的编码和解码。\n\nsyntax = "proto3";\n\n// 指定生成的 go 文件存放位置及其包名\noption go_package = "./;proto";\n\n// 定义User rpc服务\nservice User {\n  // 定义rpc服务的方法\n  rpc AddUser (UserRequest) returns (UserResponse);\n  rpc GetUser (GetUserRequest) returns (GetUserResponse);\n}\n\n// 请求的结构体\nmessage UserRequest {\n  string name = 1;\n  uint32 age = 2;\n}\n\n// 响应的结构体\nmessage UserResponse {\n  string msg = 1;\n  int32 code = 2;\n}\n\nmessage GetUserRequest {\n  string name = 1;\n}\n\nmessage GetUserResponse {\n  string name = 1;\n  string age = 2;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 2. 编译proto文件\n\n首先需要安装protoc的二进制文件，是用来编译proto的。\n\n下载地址：https://github.com/protocolbuffers/protobuf/releases\n\n然后再下载安装编译proto文件的插件\n\n$ go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28\n$ go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2\n\n\n1\n2\n\n\n进入proto目录下使用以下命令对proto文件进行编译，会生成两个文件user.pb.go和user_grpc.pb.go两个文件\n\nprotoc --go_out=. --go-grpc_out=. user.proto\n\n\n1\n\n * --go_out=. protobuf相关代码文件生成在该目录下\n * --go-grpc_out=. grpc相关代码文件生成在该目录下\n\n编译后:\n\n * user.pb.go：主要是请求与相应数据包的结构体定义，客户端和服务端都可以通过该结构体进行序列化与反序列化。\n * user_grpc.pb.go：主要是grpc的服务端和客户端代码，通过实现及调用接口来互相沟通。\n\n\n# 3. 创建grpc服务端\n\n我们首先要实现user_grpc.pb.go中的UserServer接口，该接口中的方法是我们在proto文件中定义的rpc服务AddUser和GetUser。\n\n不过，你会发现其中还多了个mustEmbedUnimplementedUserServer方法，但是我们proto文件中并没有定义，这个是用来兼容使用的。你看可以文件中UnimplementedUserServer结构体实现了UserServer接口，自己定义UserService包含UnimplementedUserServer，即使没有实现UserServer所有接口，也不会报错。\n\npackage main\n\nimport (\n\t"context"\n\t"fmt"\n\t"google.golang.org/grpc"\n\t"log"\n\t"net"\n\t"simple_example/proto"\n)\n\n// UserService 定义结构体，实现UserServer\ntype UserService struct {\n\tproto.UnimplementedUserServer\n}\n\nfunc NewUserService() *UserService {\n\treturn &UserService{}\n}\n\n// AddUser 实现rpc方法\nfunc (us *UserService) AddUser(ctx context.Context, request *proto.UserRequest) (*proto.UserResponse, error) {\n\tfmt.Printf("add user success. name = %s, age = %d\\n", request.GetName(), request.GetAge())\n\treturn &proto.UserResponse{Msg: "success", Code: 0}, nil\n}\n\nfunc (us *UserService) GetUser(ctx context.Context, request *proto.GetUserRequest) (*proto.GetUserResponse, error) {\n\tfmt.Printf("get user. name = %s\\n", request.GetName())\n\treturn &proto.GetUserResponse{Name: request.GetName(), Age: 1999}, nil\n}\n\nfunc main() {\n\t// 监听端口\n\tlis, err := net.Listen("tcp", fmt.Sprintf("localhost:%d", 8000))\n\tif err != nil {\n\t\tlog.Fatalf("failed to listen: %v", err)\n\t}\n\tgrpcServer := grpc.NewServer()\n\n\t// 注册rpc服务\n\tproto.RegisterUserServer(grpcServer, NewUserService())\n\tgrpcServer.Serve(lis)\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n\n\n\n# 4. 创建grpc客户端\n\n调用user_grpc.pb.go文件中的NewUserClient方法来创建调用rpc服务的客户端，调用rpc方法时使用user.pb.go中的结构体作为输入与输出。\n\npackage main\n\nimport (\n\t"context"\n\t"fmt"\n\t"google.golang.org/grpc"\n\t"google.golang.org/grpc/credentials/insecure"\n\t"log"\n\t"simple_example/proto"\n)\n\nfunc main() {\n\tvar opts []grpc.DialOption\n\topts = append(opts, grpc.WithTransportCredentials(insecure.NewCredentials()))\n\n\tconn, err := grpc.Dial("localhost:8000", opts...)\n\tif err != nil {\n\t\tlog.Fatalf("fail to dial: %v", err)\n\t}\n\tdefer conn.Close()\n\n\tclient := proto.NewUserClient(conn)\n\n\t// 调用rpc服务AddUser方法\n\tresp, err := client.AddUser(context.Background(), &proto.UserRequest{Name: "zhengwenfeng", Age: 18})\n\tif err != nil {\n\t\tlog.Fatalf("fail to AddUser: %v", err)\n\t}\n\tfmt.Printf("AddUser, msg = %s, code = %d\\n", resp.Msg, resp.Code)\n\n\t// 调用rpc服务GetUser方法\n\tgetuserResp, err := client.GetUser(context.Background(), &proto.GetUserRequest{Name: "zhangsan"})\n\tif err != nil {\n\t\tlog.Fatalf("fail to GetUser: %v", err)\n\t}\n\tfmt.Printf("GetUser, Name = %s, Age = %d", getuserResp.Name, getuserResp.Age)\n\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n\n# 5. 运行结果\n\n首先运行服务端监听rpc服务 然后再运行客户端调用服务。 服务端输出：\n\nadd user success. name = zhengwenfeng, age = 18\nget user success. name = zhangsan\n\n\n1\n2\n\n\n客户端输出：\n\nAddUser, msg = success, code = 0\nGetUser, Name = zhangsan, Age = 1999\n\n\n1\n2\n',normalizedContent:'# 0.相关链接\n\ngrpc github：https://github.com/grpc/grpc-go\n\n官方文档：https://grpc.io/docs/languages/go/\n\n案例代码：https://github.com/tenqaz/go-examples\n\n\n# 1. 定义proto文件\n\nproto文件是用来预先定义的消息格式。数据包会按照proto文件所定义的消息格式完成二进制码流的编码和解码。\n\nsyntax = "proto3";\n\n// 指定生成的 go 文件存放位置及其包名\noption go_package = "./;proto";\n\n// 定义user rpc服务\nservice user {\n  // 定义rpc服务的方法\n  rpc adduser (userrequest) returns (userresponse);\n  rpc getuser (getuserrequest) returns (getuserresponse);\n}\n\n// 请求的结构体\nmessage userrequest {\n  string name = 1;\n  uint32 age = 2;\n}\n\n// 响应的结构体\nmessage userresponse {\n  string msg = 1;\n  int32 code = 2;\n}\n\nmessage getuserrequest {\n  string name = 1;\n}\n\nmessage getuserresponse {\n  string name = 1;\n  string age = 2;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 2. 编译proto文件\n\n首先需要安装protoc的二进制文件，是用来编译proto的。\n\n下载地址：https://github.com/protocolbuffers/protobuf/releases\n\n然后再下载安装编译proto文件的插件\n\n$ go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28\n$ go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2\n\n\n1\n2\n\n\n进入proto目录下使用以下命令对proto文件进行编译，会生成两个文件user.pb.go和user_grpc.pb.go两个文件\n\nprotoc --go_out=. --go-grpc_out=. user.proto\n\n\n1\n\n * --go_out=. protobuf相关代码文件生成在该目录下\n * --go-grpc_out=. grpc相关代码文件生成在该目录下\n\n编译后:\n\n * user.pb.go：主要是请求与相应数据包的结构体定义，客户端和服务端都可以通过该结构体进行序列化与反序列化。\n * user_grpc.pb.go：主要是grpc的服务端和客户端代码，通过实现及调用接口来互相沟通。\n\n\n# 3. 创建grpc服务端\n\n我们首先要实现user_grpc.pb.go中的userserver接口，该接口中的方法是我们在proto文件中定义的rpc服务adduser和getuser。\n\n不过，你会发现其中还多了个mustembedunimplementeduserserver方法，但是我们proto文件中并没有定义，这个是用来兼容使用的。你看可以文件中unimplementeduserserver结构体实现了userserver接口，自己定义userservice包含unimplementeduserserver，即使没有实现userserver所有接口，也不会报错。\n\npackage main\n\nimport (\n\t"context"\n\t"fmt"\n\t"google.golang.org/grpc"\n\t"log"\n\t"net"\n\t"simple_example/proto"\n)\n\n// userservice 定义结构体，实现userserver\ntype userservice struct {\n\tproto.unimplementeduserserver\n}\n\nfunc newuserservice() *userservice {\n\treturn &userservice{}\n}\n\n// adduser 实现rpc方法\nfunc (us *userservice) adduser(ctx context.context, request *proto.userrequest) (*proto.userresponse, error) {\n\tfmt.printf("add user success. name = %s, age = %d\\n", request.getname(), request.getage())\n\treturn &proto.userresponse{msg: "success", code: 0}, nil\n}\n\nfunc (us *userservice) getuser(ctx context.context, request *proto.getuserrequest) (*proto.getuserresponse, error) {\n\tfmt.printf("get user. name = %s\\n", request.getname())\n\treturn &proto.getuserresponse{name: request.getname(), age: 1999}, nil\n}\n\nfunc main() {\n\t// 监听端口\n\tlis, err := net.listen("tcp", fmt.sprintf("localhost:%d", 8000))\n\tif err != nil {\n\t\tlog.fatalf("failed to listen: %v", err)\n\t}\n\tgrpcserver := grpc.newserver()\n\n\t// 注册rpc服务\n\tproto.registeruserserver(grpcserver, newuserservice())\n\tgrpcserver.serve(lis)\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n\n\n\n# 4. 创建grpc客户端\n\n调用user_grpc.pb.go文件中的newuserclient方法来创建调用rpc服务的客户端，调用rpc方法时使用user.pb.go中的结构体作为输入与输出。\n\npackage main\n\nimport (\n\t"context"\n\t"fmt"\n\t"google.golang.org/grpc"\n\t"google.golang.org/grpc/credentials/insecure"\n\t"log"\n\t"simple_example/proto"\n)\n\nfunc main() {\n\tvar opts []grpc.dialoption\n\topts = append(opts, grpc.withtransportcredentials(insecure.newcredentials()))\n\n\tconn, err := grpc.dial("localhost:8000", opts...)\n\tif err != nil {\n\t\tlog.fatalf("fail to dial: %v", err)\n\t}\n\tdefer conn.close()\n\n\tclient := proto.newuserclient(conn)\n\n\t// 调用rpc服务adduser方法\n\tresp, err := client.adduser(context.background(), &proto.userrequest{name: "zhengwenfeng", age: 18})\n\tif err != nil {\n\t\tlog.fatalf("fail to adduser: %v", err)\n\t}\n\tfmt.printf("adduser, msg = %s, code = %d\\n", resp.msg, resp.code)\n\n\t// 调用rpc服务getuser方法\n\tgetuserresp, err := client.getuser(context.background(), &proto.getuserrequest{name: "zhangsan"})\n\tif err != nil {\n\t\tlog.fatalf("fail to getuser: %v", err)\n\t}\n\tfmt.printf("getuser, name = %s, age = %d", getuserresp.name, getuserresp.age)\n\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n\n# 5. 运行结果\n\n首先运行服务端监听rpc服务 然后再运行客户端调用服务。 服务端输出：\n\nadd user success. name = zhengwenfeng, age = 18\nget user success. name = zhangsan\n\n\n1\n2\n\n\n客户端输出：\n\nadduser, msg = success, code = 0\ngetuser, name = zhangsan, age = 1999\n\n\n1\n2\n',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"优化gin表单的错误提示信息",frontmatter:{tags:["go语言","gin"],title:"优化gin表单的错误提示信息",date:"2022-09-11T16:53:33.000Z",permalink:"/pages/cf9a4d/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"如何优化gin框架中表单的错误提示信息",feed:{enable:!0},categories:["编程","go语言"],comment:!0,meta:[{name:"twitter:title",content:"优化gin表单的错误提示信息"},{name:"twitter:description",content:"如何优化gin框架中表单的错误提示信息"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/03.%E4%BC%98%E5%8C%96gin%E8%A1%A8%E5%8D%95%E7%9A%84%E9%94%99%E8%AF%AF%E6%8F%90%E7%A4%BA%E4%BF%A1%E6%81%AF.html"},{property:"og:type",content:"article"},{property:"og:title",content:"优化gin表单的错误提示信息"},{property:"og:description",content:"如何优化gin框架中表单的错误提示信息"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/03.%E4%BC%98%E5%8C%96gin%E8%A1%A8%E5%8D%95%E7%9A%84%E9%94%99%E8%AF%AF%E6%8F%90%E7%A4%BA%E4%BF%A1%E6%81%AF.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-09-11T16:53:33.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"gin"},{itemprop:"name",content:"优化gin表单的错误提示信息"},{itemprop:"description",content:"如何优化gin框架中表单的错误提示信息"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/03.%E4%BC%98%E5%8C%96gin%E8%A1%A8%E5%8D%95%E7%9A%84%E9%94%99%E8%AF%AF%E6%8F%90%E7%A4%BA%E4%BF%A1%E6%81%AF.html",relativePath:"04.编程/02.go语言/03.优化gin表单的错误提示信息.md",key:"v-465edabc",path:"/pages/cf9a4d/",headers:[{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:2},{level:2,title:"简单使用表单检验请求参数",slug:"简单使用表单检验请求参数",normalizedTitle:"简单使用表单检验请求参数",charIndex:27},{level:2,title:"翻译",slug:"翻译",normalizedTitle:"翻译",charIndex:970},{level:2,title:"优化返回字段的key",slug:"优化返回字段的key",normalizedTitle:"优化返回字段的key",charIndex:3105},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:5184}],headersStr:"相关链接 简单使用表单检验请求参数 翻译 优化返回字段的key 总结",content:'# 相关链接\n\ngin官方例子\n\n文章的代码\n\n\n# 简单使用表单检验请求参数\n\n创建一个简单的登录例子，我们对username和password绑定了required标签，代表着请求login接口的参数中必须包含这两个字段。\n\ntype User struct {\n\tUserName string `json:"username" binding:"required"`\n\tPassword string `json:"password" binding:"required"`\n}\n\nfunc login(c *gin.Context) {\n\n\tvar user User\n\tif err := c.ShouldBindJSON(&user); err != nil {\n\t\tc.JSON(http.StatusOK, gin.H{"msg": err.Error()})\n\t\treturn\n\t}\n\n\tif user.UserName != "admin" || user.Password != "123456" {\n\t\tc.JSON(http.StatusUnauthorized, gin.H{"msg": "unauthorized"})\n\t\treturn\n\t}\n\n\tc.JSON(http.StatusOK, gin.H{"msg": "you are logged in"})\n}\n\nfunc main() {\n\tr := gin.Default()\n\tr.POST("/login", login)\n\tr.Run() // 监听并在 0.0.0.0:8080 上启动服务\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n我们使用仅带有username去请求login接口，会输出如下，提示我们Password校验失败了，因为required的标签导致的。但是这个提示并不友好，我们需要进行优化展示。\n\n{\'msg\': "Key: \'User.Password\' Error:Field validation for \'Password\' failed on the \'required\' tag"}\n\n\n1\n\n\n\n# 翻译\n\n我们需要对上面的提示信息进行一个翻译，并且可以支持各种语言的友好性提示。\n\n我们在global/global.go文件中创建一个全局变量，该全局变量在后面的表单翻译中需要使用到\n\nimport ut "github.com/go-playground/universal-translator"\n\nvar (\n\tTrans ut.Translator\n)\n\n\n1\n2\n3\n4\n5\n\n\n在initialize/validator.go文件中编写内容如下，获取gin中的validate对象，然后给该对象绑定中文和英文的友好提示信息，我们可以通过locale来设置我们需要使用中文还是英文的信息。\n\nfunc InitTrans(locale string) (err error) {\n\n\tif v, ok := binding.Validator.Engine().(*validator.Validate); ok {\n\n\t\t// 翻译\n\t\tzhT := zh.New()\n\t\tenT := en.New()\n\t\tuni := ut.New(enT, zhT, enT)\n\n\t\tglobal.Trans, ok = uni.GetTranslator(locale)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf("uni.GetTranslator(%s) error", locale)\n\t\t}\n\n\t\tswitch locale {\n\t\tcase "zh":\n\t\t\tzh_translations.RegisterDefaultTranslations(v, global.Trans)\n\t\tcase "en":\n\t\t\ten_translations.RegisterDefaultTranslations(v, global.Trans)\n\t\tdefault:\n\t\t\ten_translations.RegisterDefaultTranslations(v, global.Trans)\n\t\t}\n\n\t\treturn\n\t}\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n最后在main.go中的main方法下调用上面的InitTrans方法来初始化翻译内容。\n\n再将login方法中ShouldBindJSON返回的error转成validator.ValidationErrors类型，该类型包含一个Translate方法，调用该方法，再将之前的全局变量Trans传入。\n\nfunc login(c *gin.Context) {\n\n\tvar user User\n\tif err := c.ShouldBindJSON(&user); err != nil {\n\n\t\terrs, ok := err.(validator.ValidationErrors)\n\t\tif !ok {\n\t\t\t// 非校验错误，其他错误直接返回\n\t\t\tc.JSON(http.StatusOK, gin.H{"msg": err.Error()})\n\t\t\treturn\n\t\t}\n\n\t\tc.JSON(http.StatusOK, gin.H{"msg": errs.Translate(global.Trans)})\n\t\treturn\n\t}\n\n\tif user.UserName != "admin" || user.Password != "123456" {\n\t\tc.JSON(http.StatusUnauthorized, gin.H{"msg": "unauthorized"})\n\t\treturn\n\t}\n\n\tc.JSON(http.StatusOK, gin.H{"msg": "you are logged in"})\n}\n\nfunc main() {\n\terr := initialize.InitTrans("zh")\n\tif err != nil {\n\t\tfmt.Printf("初始化翻译器错误, err = %s", err.Error())\n\t\treturn\n\t}\n\n\tr := gin.Default()\n\tr.POST("/login", login)\n\tr.Run() // 监听并在 0.0.0.0:8080 上启动服务\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n我们再使用仅带有username字段去请求login接口，输出内容如下。\n\n{\'msg\': {\'User.Password\': \'Password为必填字段\'}}\n\n\n1\n\n\n但是，发现提示信息的key是User.Password，是表单对象和其字段名称，我们应该想要的是：\n\n{\'msg\': {\'password\': \'Password为必填字段\'}}\n\n\n1\n\n\n\n# 优化返回字段的key\n\n我们修改InitTrans方法，通过go-playground提供的方法RegisterTagNameFunc来将我们自定义的方法注册进去，该自定义方法的目的是修改上面的Password改为json中的password，可以改成json标签中的值作为返回。\n\nfunc InitTrans(locale string) (err error) {\n\n\tif v, ok := binding.Validator.Engine().(*validator.Validate); ok {\n\n\t\t//修改返回字段key的格式\n\t\tv.RegisterTagNameFunc(func(fld reflect.StructField) string {\n\t\t\tname := strings.SplitN(fld.Tag.Get("json"), ",", 2)[0]\n\t\t\tif name == "-" {\n\t\t\t\treturn ""\n\t\t\t}\n\t\t\treturn name\n\t\t})\n\n\t\t// 翻译\n\t\tzhT := zh.New()\n\t\tenT := en.New()\n\t\tuni := ut.New(enT, zhT, enT)\n\n\t\tglobal.Trans, ok = uni.GetTranslator(locale)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf("uni.GetTranslator(%s) error", locale)\n\t\t}\n\n\t\tswitch locale {\n\t\tcase "zh":\n\t\t\tzh_translations.RegisterDefaultTranslations(v, global.Trans)\n\t\tcase "en":\n\t\t\ten_translations.RegisterDefaultTranslations(v, global.Trans)\n\t\tdefault:\n\t\t\ten_translations.RegisterDefaultTranslations(v, global.Trans)\n\t\t}\n\n\t\treturn\n\t}\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n再请求，响应如下，发现password已经改好了，但是User也想删除。\n\n{\'msg\': {\'User.password\': \'password为必填字段\'}}\n\n\n1\n\n\n我们在utils/validator.go文件中编写代码如下，该方法是用来删除User的。\n\nfunc RemoveTopStruct(fields map[string]string) map[string]string {\n\tres := map[string]string{}\n\tfor field, err := range fields {\n\t\tres[field[strings.Index(field, ".")+1:]] = err\n\t}\n\treturn res\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n再在翻译返回的错误信息包上该方法。\n\nfunc login(c *gin.Context) {\n\n\tvar user User\n\tif err := c.ShouldBindJSON(&user); err != nil {\n\n\t\terrs, ok := err.(validator.ValidationErrors)\n\t\tif !ok {\n\t\t\t// 非校验错误，其他错误直接返回\n\t\t\tc.JSON(http.StatusOK, gin.H{"msg": err.Error()})\n\t\t\treturn\n\t\t}\n\n\t\tc.JSON(http.StatusOK, gin.H{"msg": utils.RemoveTopStruct(errs.Translate(global.Trans))})\n\t\treturn\n\t}\n\n\tif user.UserName != "admin" || user.Password != "123456" {\n\t\tc.JSON(http.StatusUnauthorized, gin.H{"msg": "unauthorized"})\n\t\treturn\n\t}\n\n\tc.JSON(http.StatusOK, gin.H{"msg": "you are logged in"})\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再执行，相应结果如下，这个就是我们想要的信息。\n\n{\'msg\': {\'password\': \'password为必填字段\'}}\n\n\n1\n\n\n\n# 总结\n\n个人觉的虽然gin灵活小巧，但是功能真的很不完善。每次一次输出友好信息，我们都要手动调用Translate来翻译，并且还需要通过RemoveTopStruct方法来修改返回的信息，按简单的来说，应该由框架来做，我们只需要通过配置，就能自动输出我们想要的友好提示信息才对。',normalizedContent:'# 相关链接\n\ngin官方例子\n\n文章的代码\n\n\n# 简单使用表单检验请求参数\n\n创建一个简单的登录例子，我们对username和password绑定了required标签，代表着请求login接口的参数中必须包含这两个字段。\n\ntype user struct {\n\tusername string `json:"username" binding:"required"`\n\tpassword string `json:"password" binding:"required"`\n}\n\nfunc login(c *gin.context) {\n\n\tvar user user\n\tif err := c.shouldbindjson(&user); err != nil {\n\t\tc.json(http.statusok, gin.h{"msg": err.error()})\n\t\treturn\n\t}\n\n\tif user.username != "admin" || user.password != "123456" {\n\t\tc.json(http.statusunauthorized, gin.h{"msg": "unauthorized"})\n\t\treturn\n\t}\n\n\tc.json(http.statusok, gin.h{"msg": "you are logged in"})\n}\n\nfunc main() {\n\tr := gin.default()\n\tr.post("/login", login)\n\tr.run() // 监听并在 0.0.0.0:8080 上启动服务\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n我们使用仅带有username去请求login接口，会输出如下，提示我们password校验失败了，因为required的标签导致的。但是这个提示并不友好，我们需要进行优化展示。\n\n{\'msg\': "key: \'user.password\' error:field validation for \'password\' failed on the \'required\' tag"}\n\n\n1\n\n\n\n# 翻译\n\n我们需要对上面的提示信息进行一个翻译，并且可以支持各种语言的友好性提示。\n\n我们在global/global.go文件中创建一个全局变量，该全局变量在后面的表单翻译中需要使用到\n\nimport ut "github.com/go-playground/universal-translator"\n\nvar (\n\ttrans ut.translator\n)\n\n\n1\n2\n3\n4\n5\n\n\n在initialize/validator.go文件中编写内容如下，获取gin中的validate对象，然后给该对象绑定中文和英文的友好提示信息，我们可以通过locale来设置我们需要使用中文还是英文的信息。\n\nfunc inittrans(locale string) (err error) {\n\n\tif v, ok := binding.validator.engine().(*validator.validate); ok {\n\n\t\t// 翻译\n\t\tzht := zh.new()\n\t\tent := en.new()\n\t\tuni := ut.new(ent, zht, ent)\n\n\t\tglobal.trans, ok = uni.gettranslator(locale)\n\t\tif !ok {\n\t\t\treturn fmt.errorf("uni.gettranslator(%s) error", locale)\n\t\t}\n\n\t\tswitch locale {\n\t\tcase "zh":\n\t\t\tzh_translations.registerdefaulttranslations(v, global.trans)\n\t\tcase "en":\n\t\t\ten_translations.registerdefaulttranslations(v, global.trans)\n\t\tdefault:\n\t\t\ten_translations.registerdefaulttranslations(v, global.trans)\n\t\t}\n\n\t\treturn\n\t}\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n最后在main.go中的main方法下调用上面的inittrans方法来初始化翻译内容。\n\n再将login方法中shouldbindjson返回的error转成validator.validationerrors类型，该类型包含一个translate方法，调用该方法，再将之前的全局变量trans传入。\n\nfunc login(c *gin.context) {\n\n\tvar user user\n\tif err := c.shouldbindjson(&user); err != nil {\n\n\t\terrs, ok := err.(validator.validationerrors)\n\t\tif !ok {\n\t\t\t// 非校验错误，其他错误直接返回\n\t\t\tc.json(http.statusok, gin.h{"msg": err.error()})\n\t\t\treturn\n\t\t}\n\n\t\tc.json(http.statusok, gin.h{"msg": errs.translate(global.trans)})\n\t\treturn\n\t}\n\n\tif user.username != "admin" || user.password != "123456" {\n\t\tc.json(http.statusunauthorized, gin.h{"msg": "unauthorized"})\n\t\treturn\n\t}\n\n\tc.json(http.statusok, gin.h{"msg": "you are logged in"})\n}\n\nfunc main() {\n\terr := initialize.inittrans("zh")\n\tif err != nil {\n\t\tfmt.printf("初始化翻译器错误, err = %s", err.error())\n\t\treturn\n\t}\n\n\tr := gin.default()\n\tr.post("/login", login)\n\tr.run() // 监听并在 0.0.0.0:8080 上启动服务\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n我们再使用仅带有username字段去请求login接口，输出内容如下。\n\n{\'msg\': {\'user.password\': \'password为必填字段\'}}\n\n\n1\n\n\n但是，发现提示信息的key是user.password，是表单对象和其字段名称，我们应该想要的是：\n\n{\'msg\': {\'password\': \'password为必填字段\'}}\n\n\n1\n\n\n\n# 优化返回字段的key\n\n我们修改inittrans方法，通过go-playground提供的方法registertagnamefunc来将我们自定义的方法注册进去，该自定义方法的目的是修改上面的password改为json中的password，可以改成json标签中的值作为返回。\n\nfunc inittrans(locale string) (err error) {\n\n\tif v, ok := binding.validator.engine().(*validator.validate); ok {\n\n\t\t//修改返回字段key的格式\n\t\tv.registertagnamefunc(func(fld reflect.structfield) string {\n\t\t\tname := strings.splitn(fld.tag.get("json"), ",", 2)[0]\n\t\t\tif name == "-" {\n\t\t\t\treturn ""\n\t\t\t}\n\t\t\treturn name\n\t\t})\n\n\t\t// 翻译\n\t\tzht := zh.new()\n\t\tent := en.new()\n\t\tuni := ut.new(ent, zht, ent)\n\n\t\tglobal.trans, ok = uni.gettranslator(locale)\n\t\tif !ok {\n\t\t\treturn fmt.errorf("uni.gettranslator(%s) error", locale)\n\t\t}\n\n\t\tswitch locale {\n\t\tcase "zh":\n\t\t\tzh_translations.registerdefaulttranslations(v, global.trans)\n\t\tcase "en":\n\t\t\ten_translations.registerdefaulttranslations(v, global.trans)\n\t\tdefault:\n\t\t\ten_translations.registerdefaulttranslations(v, global.trans)\n\t\t}\n\n\t\treturn\n\t}\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n再请求，响应如下，发现password已经改好了，但是user也想删除。\n\n{\'msg\': {\'user.password\': \'password为必填字段\'}}\n\n\n1\n\n\n我们在utils/validator.go文件中编写代码如下，该方法是用来删除user的。\n\nfunc removetopstruct(fields map[string]string) map[string]string {\n\tres := map[string]string{}\n\tfor field, err := range fields {\n\t\tres[field[strings.index(field, ".")+1:]] = err\n\t}\n\treturn res\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n再在翻译返回的错误信息包上该方法。\n\nfunc login(c *gin.context) {\n\n\tvar user user\n\tif err := c.shouldbindjson(&user); err != nil {\n\n\t\terrs, ok := err.(validator.validationerrors)\n\t\tif !ok {\n\t\t\t// 非校验错误，其他错误直接返回\n\t\t\tc.json(http.statusok, gin.h{"msg": err.error()})\n\t\t\treturn\n\t\t}\n\n\t\tc.json(http.statusok, gin.h{"msg": utils.removetopstruct(errs.translate(global.trans))})\n\t\treturn\n\t}\n\n\tif user.username != "admin" || user.password != "123456" {\n\t\tc.json(http.statusunauthorized, gin.h{"msg": "unauthorized"})\n\t\treturn\n\t}\n\n\tc.json(http.statusok, gin.h{"msg": "you are logged in"})\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再执行，相应结果如下，这个就是我们想要的信息。\n\n{\'msg\': {\'password\': \'password为必填字段\'}}\n\n\n1\n\n\n\n# 总结\n\n个人觉的虽然gin灵活小巧，但是功能真的很不完善。每次一次输出友好信息，我们都要手动调用translate来翻译，并且还需要通过removetopstruct方法来修改返回的信息，按简单的来说，应该由框架来做，我们只需要通过配置，就能自动输出我们想要的友好提示信息才对。',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"go中如何处理error",frontmatter:{title:"go中如何处理error",date:"2022-11-14T10:11:11.000Z",permalink:"/pages/d93df5/",tags:["go语言"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"在 go 中有 panic 的机制，但 panic 意味着程序终止，代码不能继续运行了，不能期望调用者来解决它。而 error 是预期中的异常，希望调用者可以对其进行处理的。",categories:["编程","go语言"],comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"go中如何处理error"},{name:"twitter:description",content:"在 go 中有 panic 的机制，但 panic 意味着程序终止，代码不能继续运行了，不能期望调用者来解决它。而 error 是预期中的异常，希望调用者可以对其进行处理的。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/04.go%E4%B8%AD%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86error.html"},{property:"og:type",content:"article"},{property:"og:title",content:"go中如何处理error"},{property:"og:description",content:"在 go 中有 panic 的机制，但 panic 意味着程序终止，代码不能继续运行了，不能期望调用者来解决它。而 error 是预期中的异常，希望调用者可以对其进行处理的。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/04.go%E4%B8%AD%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86error.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-11-14T10:11:11.000Z"},{property:"article:tag",content:"go语言"},{itemprop:"name",content:"go中如何处理error"},{itemprop:"description",content:"在 go 中有 panic 的机制，但 panic 意味着程序终止，代码不能继续运行了，不能期望调用者来解决它。而 error 是预期中的异常，希望调用者可以对其进行处理的。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/04.go%E4%B8%AD%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86error.html",relativePath:"04.编程/02.go语言/04.go中如何处理error.md",key:"v-2afdd346",path:"/pages/d93df5/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. error 是什么？",slug:"_1-error-是什么",normalizedTitle:"1. error 是什么？",charIndex:195},{level:2,title:"2. 错误类型",slug:"_2-错误类型",normalizedTitle:"2. 错误类型",charIndex:1465},{level:3,title:"2.1 Sentinel Error(预定义错误)",slug:"_2-1-sentinel-error-预定义错误",normalizedTitle:"2.1 sentinel error(预定义错误)",charIndex:1477},{level:3,title:"2.2 Error types(自定义错类型)",slug:"_2-2-error-types-自定义错类型",normalizedTitle:"2.2 error types(自定义错类型)",charIndex:2033},{level:3,title:"2.3 Opaque errors(不透明的错误)",slug:"_2-3-opaque-errors-不透明的错误",normalizedTitle:"2.3 opaque errors(不透明的错误)",charIndex:3015},{level:2,title:"3. 优雅的处理错误",slug:"_3-优雅的处理错误",normalizedTitle:"3. 优雅的处理错误",charIndex:3513},{level:3,title:"3.1 无错误的正常流程代码",slug:"_3-1-无错误的正常流程代码",normalizedTitle:"3.1 无错误的正常流程代码",charIndex:3528},{level:3,title:"3.2 减少不必要的判断",slug:"_3-2-减少不必要的判断",normalizedTitle:"3.2 减少不必要的判断",charIndex:3794},{level:3,title:"3.3 将 error 内部存储起来",slug:"_3-3-将-error-内部存储起来",normalizedTitle:"3.3 将 error 内部存储起来",charIndex:4059},{level:3,title:"3.4 将重复操作抽离出来",slug:"_3-4-将重复操作抽离出来",normalizedTitle:"3.4 将重复操作抽离出来",charIndex:4865},{level:2,title:"4. Wrap erros",slug:"_4-wrap-erros",normalizedTitle:"4. wrap erros",charIndex:6248},{level:2,title:"5. pkg/errors",slug:"_5-pkg-errors",normalizedTitle:"5. pkg/errors",charIndex:8186},{level:2,title:"6. error 的最佳实践",slug:"_6-error-的最佳实践",normalizedTitle:"6. error 的最佳实践",charIndex:9741},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:10492}],headersStr:"0. 前言 1. error 是什么？ 2. 错误类型 2.1 Sentinel Error(预定义错误) 2.2 Error types(自定义错类型) 2.3 Opaque errors(不透明的错误) 3. 优雅的处理错误 3.1 无错误的正常流程代码 3.2 减少不必要的判断 3.3 将 error 内部存储起来 3.4 将重复操作抽离出来 4. Wrap erros 5. pkg/errors 6. error 的最佳实践 参考资料",content:'# 0. 前言\n\ngo 中的异常处理和其他语言大不相同，像 Java、C++、python 等语言都是通过抛出 Exception 来处理异常，而 go 是通过返回 error 来判定异常，并进行处理。\n\n在 go 中有 panic 的机制，但 panic 意味着程序终止，代码不能继续运行了，不能期望调用者来解决它。而 error 是预期中的异常，希望调用者可以对其进行处理的。\n\n\n# 1. error 是什么？\n\n举个例子，使用 Open 来打开文件，但是可能该路径的文件不存在，出现异常，在 go 是通过判断 err 是否为 nil 来判定打开文件是否成功。\n\nf, err := os.Open(path)\nif err != nil {\n    // handle error\n}\n\n// do stuff\n\n\n1\n2\n3\n4\n5\n6\n\n\n问题来了，error 是什么？\n\n查看源码会发现，error 是一个包含 Error 方法的接口，返回的是实现了该接口的对象。\n\ntype error interface {  \n   Error() string  \n}\n\n\n1\n2\n3\n\n\n我们一般使用是通过 errors.New()来返回一个实现了 error 接口的对象。这个对象是一个包含了字符串的结构体，然后可以通过 Error 方法来获取字符串。\n\nfunc New(text string) error {  \n   return &errorString{text}  \n}  \n  \n// errorString is a trivial implementation of error.\ntype errorString struct {  \n   s string  \n}  \n  \nfunc (e *errorString) Error() string {  \n   return e.s  \n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n我们可以注意到 New 方法返回的是 errorString 的地址，也就是说，在我们将两个 error 比较相等时，比较是地址，是两个 error 是否为同一个对象，而不是其中的错误字符串。\n\nimport (\n\t"errors"\n\t"fmt"\n)\n\ntype errorString string\n\nfunc (e errorString) Error() string {\n\treturn string(e)\n}\n\nfunc New(text string) error {\n\treturn errorString(text)\n}\n\nvar ErrNamedType = New("EOF")\nvar ErrStructType = errors.New("EOF")\n\nfunc main() {\n\n\tif ErrNamedType == New("EOF") {\n\t\tfmt.Println("Named Type Error")\n\t}\n\n\tif ErrStructType == errors.New("EOF") {\n\t\tfmt.Println("Struct Type Error")\n\t}\n\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n输出：\n\nNamed Type Error\n\n\n1\n\n\n\n# 2. 错误类型\n\n\n# 2.1 Sentinel Error(预定义错误)\n\n其实就是先预定义一些可以预料中的错误，在使用过程中，通过判断 error 是属于哪一种 error 并进行对应的处理。\n\n举个栗子，在 io.EOF 就是一个预定义的错误，它是表示输入流中的结尾。\n\nvar EOF = errors.New("EOF")\n\n\n1\n\n\n在从流中读取字符的时候，会通过判断 error 是否等于 io.EOF 来判定是否读完。注意这里是判断 error 的指针是否相等。\n\nn, err := reader.Read(p)  \nif err != nil {  \n   if err == io.EOF {  \n      fmt.Println("The resource is read!")  \n      break  \n   }  \n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n这种方式不建议使用，原因是：\n\n * 它会成为你 API 的公共部分\n\n因为公共函数需要返回一个固定的 error，那么这个 error 就必须是公开的，那么就需要文档记录，这会增加 API 的表面积。\n\n * 增加调用者的耦合性\n\n调用者必须要知道 io.EOF 这个 error ，并在调用的地方使用该 error 判断是否结束。\n\n\n# 2.2 Error types(自定义错类型)\n\n通过实现 error 接口来创建自定义错误类型。和 Sentinel Error 相比，是通过判断类型来知道是哪种错误，并且可以输出更多的上下文错误信息。\n\n通过自定义 MyError，并实现 error 接口中的 Error 的方法。\n\ntype MyError struct {\n\tMsg  string\n\tFile string\n\tLine int\n}\n\nfunc (e *MyError) Error() string {\n\treturn fmt.Sprintf("%s:%d: %s", e.File, e.Line, e.Msg)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ntest 方法中返回的是自定义的 error，我们通过断言转换 error 成 MyError 类型，然后再输出更多的上下文信息。\n\nfunc test() error {\n\treturn &MyError{"Something happened", "server.go", 42}\n}\n\nfunc main() {\n\terr := test()\n\tswitch err := err.(type) {\n\tcase nil:\n\t\t// success\n\tcase *MyError:\n\t\tfmt.Println("error occured on line:", err.Line)\n\tdefault:\n\t\t// unknown error\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n在标准库 os.PathError 中，自定义了 PathError ，也是相同的用法。\n\ntype PathError struct {\n\tOp   string\n\tPath string\n\tErr  error\n}\n\nfunc (e *PathError) Error() string { return e.Op + " " + e.Path + ": " + e.Err.Error() }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n我们也尽可能避免使用 Error types，因为它和 Sentinel Erorr 一样会和调用者产生耦合，会作为 API 的一部分。\n\n\n# 2.3 Opaque errors(不透明的错误)\n\nError types 是通过判断 error 的类型来走不同的逻辑，而 Opaque errors 是通过判断 error 的行为来走不同的逻辑。\n\n在 net.Error 中定义如下，除了包含 error 外，还包含 Timeout 和 Temporary 方法。\n\ntype Error interface {\n\terror\n\tTimeout() bool \n\tTemporary() bool\n}\n\n\n1\n2\n3\n4\n5\n\n\n除了判断是否有 error 之外，还可以通过方法来判断是哪种类型的 error 然后进行对应的处理。\n\nif netErr, ok := err.(net.Error); ok && netErr.Timeout() {\n\treturn false\n}\n\nif netErr, ok := err.(net.Error); ok && netErr.Temporary() {\n\treturn false\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n它不是扩展 error 更多的信息，而是扩展其方法。\n\n\n# 3. 优雅的处理错误\n\n\n# 3.1 无错误的正常流程代码\n\n无错误的正常流程代码，将成为一条直线，而不是缩进的代码。\n\n错误的写法：\n\n// no\nf, err := os.Open(path)\nif err == nil {\n    // do stuff\n}\n\n// handle error\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n正确的写法：\n\n// ok\nf, err := os.Open(path)\nif err != nil {\n    // handle error\n}\n\n// do stuff\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 3.2 减少不必要的判断\n\nfunc AuthenticateRequest(r *Request) error {\n    err := authenticate(r.User)\n    err != nil {\n        return err\n    }\n    return nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n改为：\n\nfunc AuthenticateRequest(r *Request) error {\n    return authenticate(r.User)\n}\n\n\n1\n2\n3\n\n\n\n# 3.3 将 error 内部存储起来\n\nerr 在内部临时储存，在最后在返回出来。\n\n下面例子中，通过循环读 reader 每一行的数据，每次判断 err 是不是 nil 来判断是否读完，如果是则退出循环，再返回。\n\nfunc CountLines(r io.Reader)  (int, error) {\n\tvar (\n\t\tbr = bufio.NewReader(r)\n\t\tlines int\n\t\terr error\n\t)\n\n\tfor {\n\t\t_, err = br.ReadString(\'\\n\')\n\t\tlines++\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif err != io.EOF {\n\t\treturn 0, err\n\t}\n\n\treturn lines, nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n改进版本：\n\ntype Scanner struct {\n\terr          error     // Sticky error.\n\t...\n}\n\nfunc CountLines(r io.Reader)  (int, error) {\n\tsc := bufio.NewScanner(r)\n\tlines := 0\n\n\tfor sc.Scan() {\n\t\tlines++\n\t}\n\n\treturn lines, sc.Err()\n}\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n每次循环都会判断 Scan 的返回值，当无内容返回时，则会返回 False，则结束循环，并返回结果。循环中出现的 error 会在 Scan 中通过 s.setErr(err) 保存在对象的 err 属性中。\n\n代码明显简洁了许多。\n\n\n# 3.4 将重复操作抽离出来\n\n看看下面的代码，里面多次使用 fmt.Fprintf()并判断其返回值是否为 err\n\ntype Header struct {\n\tKey, Value string\n}\n\ntype Status struct {\n\tCode   int\n\tReason string\n}\n\nfunc WriteResponse(w io.Writer, st Status, headers []Header, body io.Reader) error {\n\t_, err := fmt.Fprintf(w, "HTTP/1.1 %d %s\\r\\n", st.Code, st.Reason)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, h := range headers {\n\t\t_, err := fmt.Fprintf(w, "%s: %s\\r\\n", h.Key, h.Value)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif _, err := fmt.Fprintf(w, "\\r\\n"); err != nil {\n\t\treturn err\n\t}\n\n\t_, err = io.Copy(w, body)\n\treturn err\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n我们创建一个 errWrite 结构体并实现 Write 方法，也就是在原来的 write 方法中包了一层并做好错误判断，然后在每一个 fmt.Fprintf 使用我们定义的 errWrite 进行写入，这样就达到了复用的效果，代码也好看了许多。\n\ntype errWrite struct {\n\tio.Writer\n\terr error\n}\n\nfunc (e *errWrite) Write(buf []byte) (int, error) {\n\tif e.err != nil {\n\t\treturn 0, e.err\n\t}\n\n\tvar n int\n\tn, e.err = e.Writer.Write(buf)\n\treturn n, e.err\n}\n\nfunc WriteResponse(w io.Writer, st Status, headers []Header, body io.Reader) error {\n\tew := &errWrite{Writer: w}\n\tfmt.Fprintf(ew, "HTTP/1.1 %d %s\\r\\n", st.Code, st.Reason)\n\n\tfor _, h := range headers {\n\t\tfmt.Fprintf(ew, "%s: %s\\r\\n", h.Key, h.Value)\n\t}\n\n\tfmt.Fprintf(w, "\\r\\n")\n\n\tio.Copy(ew, body)\n\treturn ew.err\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# 4. Wrap erros\n\n在我们开发中，常常会在错误处理中，记录了日志，并且将错误给返回了。\n\n在 os.Open 找不到文件时会返回 error，处理 error 时，将 error 的信息打上日志，并且将 err 进行返回，在 main 函数中，拿到 error 后再次打上 error 的日志，这个日志和上面有部分是重复的日志。\n\n在代码调用链多的时候，会打上更多的重复日志，日志中出现非常多的噪音，非常影响排查错误。\n\nfunc ReadFile(path string) ([]byte, error) {\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\tlog.Printf("could not open file: %v", err)\n\t\treturn nil, err\n\t}\n\tdefer f.Close()\n\n\tread := bufio.NewReader(f)\n\n\tline, _, err := read.ReadLine()\n\treturn line, err\n}\n\nfunc main() {\n\t_, err := ReadFile("test.txt")\n\tif err != nil {\n\t\tfmt.Println(err)\n\t}\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n运行输出：\n\n2022/11/05 17:03:16 could not open file: open test.txt: The system cannot find t\nhe file specified.\n2022/11/05 17:03:16 open test.txt: The system cannot find the file specified.\n\n\n1\n2\n3\n\n\n可以使用 fmt.Errorf 来对原始错误进行包装，除了原始错误信息之外，在添加额外得信息并返回。\n\nf, err := os.Open(path)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf("open file failed: %w", err)\n\t}\n\n\n1\n2\n3\n4\n\n\n输出：\n\n2022/11/05 17:04:43 open file failed: open test.txt: The system cannot find the\nfile specified.\n\n\n1\n2\n\n\nfmt.Errorf 返回的是一个新的被包装的 error，errors.Is 可以一层一层的剥开包装来判断是否为原始错误，但是它是做指针判断的，这里 os.Open 返回的原始错误是 os.PathError 但是因为返回的是地址，所以无法用 errors.Is 判断。\n\nfunc main() {\n\n\t_, err := ReadFile("test.txt")\n\tvar pathError *os.PathError\n\n\tif errors.Is(err, pathError) {\n\t\tfmt.Println("is PathError")\n\t} else {\n\t\tfmt.Println("no PathError")\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n输出：\n\nno PathError\n\n\n1\n\n\n这里可以用 errors.As 来判断 err 是否为 os.PathError 类型，即使 err 是地址。\n\n这里判断了是否为 os.PathError 错误，并且将返回的 err 转换成了该错误，我们可以调用其中的属性来获取更多的信息。\n\nfunc main() {\n\n\t_, err := ReadFile("test.txt")\n\tvar pathError *os.PathError\n\n\tif errors.As(err, &pathError) {\n\t\tfmt.Println(pathError.Path)\n\t}\n\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n输出：\n\ntest.txt\n\n\n1\n\n\n还可以通过 errors.UnWrap 来获取底层错误，将原始错误给解析出来。\n\nfunc main() {\n\t_, err := ReadFile("test.txt")\n\terr = errors.Unwrap(err)\n\tfmt.Printf("ori err: %v", err)\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 5. pkg/errors\n\n上面介绍的都是原生的 errors 处理模块，现在介绍 pkg/errors 模块，完全兼容原生 errors，并且对其进行增强，主要是添加了保存堆栈的能力。\n\n可以使用 errors.Wrap 进行对 error 的包装，并添加额外的信息。\n\nfunc ReadFile(path string) ([]byte, error) {\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, "could not open file")\n\t}\n\tdefer f.Close()\n\n\tread := bufio.NewReader(f)\n\n\tline, _, err := read.ReadLine()\n\treturn line, err\n}\n\nfunc main() {\n\t_, err := ReadFile("test.txt")\n\tif err != nil {\n\t\tfmt.Println(err)\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n输出：\n\ncould not open file: open test.txt: The system cannot find the file specified.\n\n\n1\n\n\n但它还有一个更强的功能是会保存当前的堆栈信息，使用%+v 可以打印出来。\n\nfunc main() {\n\t_, err := ReadFile("test.txt")\n\tif err != nil {\n\t\tfmt.Printf("stack track: \\n%+v", err)\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n输出：\n\nstack track:\nopen test.txt: The system cannot find the file specified.\ncould not open file\nmain.ReadFile\n        D:/code/go_demo/main3.go:13\nmain.main\n        D:/code/go_demo/main3.go:24\nruntime.main\n        D:/install/go18.3/src/runtime/proc.go:250\nruntime.goexit\n        D:/install/go18.3/src/runtime/asm_amd64.s:1571\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n如果不想保存堆栈信息，只添加额外的信息，可以使用 errors.WithMessage 添加。\n\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(err, "could not open file")\n\t}\n\n\n1\n2\n3\n4\n\n\n输出：\n\ncould not open file: open test.txt: The system cannot find the file specified.\n\n\n1\n\n\n还有几个常见的方法\n\n// 生成错误的同时带上堆栈信息\nfunc New(message string) error\n\n// 只附加调用堆栈信息\nfunc WithStack(err error) error\n\n// 获得最根本的错误原因\nfunc Cause(err error) error\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 6. error 的最佳实践\n\n处理 error 的方式这么多，我们该如何最优的使用它们呢？有以下几个方法：\n\n * 在自己的应用代码中，使用 errors.New 或者 errors.Errorf 来返回错误\n\nfunc parseArgs(args []string) error {\n\tif len(args) < 3 {\n\t\treturn errors.Errorf("not enough arguments")\n\t}\n\n\treturn nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n * 如果调用其他包内的函数，通常简单的直接返回。\n\nif err != nil {\n\treturn err\n}\n\n\n1\n2\n3\n\n * 如果和其他库进行协作，考虑使用 errors.Wrap 或者 errors.Wrapf 保存堆栈信息。同样适用于和标准库协作的时候。\n\nf, err := os.Open(path)\nif err != nil {\n\treturn errors.Wrapf(err, "failed to open %q", path)\n\n\n1\n2\n3\n\n\n * 直接返回错误，而不是每个错误产生的地方到处打日志。\n\n * 在程序的顶部或者是工作的 goroutine 顶部（请求入口），使用 %+v 把堆栈详情记录。\n\nfunc main() {\n\terr := app.Run()\n\tif err != nil {\n\t\tfmt.Printf("FATAL: %+V\\n", err)\n\t\tos.Exit(1)\n\t}\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * 使用 errors.Cause 获取 root error，再进行和 sentinel error 判定。\n\n\n# 参考资料\n\n * io.EOF 设计的缺陷',normalizedContent:'# 0. 前言\n\ngo 中的异常处理和其他语言大不相同，像 java、c++、python 等语言都是通过抛出 exception 来处理异常，而 go 是通过返回 error 来判定异常，并进行处理。\n\n在 go 中有 panic 的机制，但 panic 意味着程序终止，代码不能继续运行了，不能期望调用者来解决它。而 error 是预期中的异常，希望调用者可以对其进行处理的。\n\n\n# 1. error 是什么？\n\n举个例子，使用 open 来打开文件，但是可能该路径的文件不存在，出现异常，在 go 是通过判断 err 是否为 nil 来判定打开文件是否成功。\n\nf, err := os.open(path)\nif err != nil {\n    // handle error\n}\n\n// do stuff\n\n\n1\n2\n3\n4\n5\n6\n\n\n问题来了，error 是什么？\n\n查看源码会发现，error 是一个包含 error 方法的接口，返回的是实现了该接口的对象。\n\ntype error interface {  \n   error() string  \n}\n\n\n1\n2\n3\n\n\n我们一般使用是通过 errors.new()来返回一个实现了 error 接口的对象。这个对象是一个包含了字符串的结构体，然后可以通过 error 方法来获取字符串。\n\nfunc new(text string) error {  \n   return &errorstring{text}  \n}  \n  \n// errorstring is a trivial implementation of error.\ntype errorstring struct {  \n   s string  \n}  \n  \nfunc (e *errorstring) error() string {  \n   return e.s  \n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n我们可以注意到 new 方法返回的是 errorstring 的地址，也就是说，在我们将两个 error 比较相等时，比较是地址，是两个 error 是否为同一个对象，而不是其中的错误字符串。\n\nimport (\n\t"errors"\n\t"fmt"\n)\n\ntype errorstring string\n\nfunc (e errorstring) error() string {\n\treturn string(e)\n}\n\nfunc new(text string) error {\n\treturn errorstring(text)\n}\n\nvar errnamedtype = new("eof")\nvar errstructtype = errors.new("eof")\n\nfunc main() {\n\n\tif errnamedtype == new("eof") {\n\t\tfmt.println("named type error")\n\t}\n\n\tif errstructtype == errors.new("eof") {\n\t\tfmt.println("struct type error")\n\t}\n\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n输出：\n\nnamed type error\n\n\n1\n\n\n\n# 2. 错误类型\n\n\n# 2.1 sentinel error(预定义错误)\n\n其实就是先预定义一些可以预料中的错误，在使用过程中，通过判断 error 是属于哪一种 error 并进行对应的处理。\n\n举个栗子，在 io.eof 就是一个预定义的错误，它是表示输入流中的结尾。\n\nvar eof = errors.new("eof")\n\n\n1\n\n\n在从流中读取字符的时候，会通过判断 error 是否等于 io.eof 来判定是否读完。注意这里是判断 error 的指针是否相等。\n\nn, err := reader.read(p)  \nif err != nil {  \n   if err == io.eof {  \n      fmt.println("the resource is read!")  \n      break  \n   }  \n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n这种方式不建议使用，原因是：\n\n * 它会成为你 api 的公共部分\n\n因为公共函数需要返回一个固定的 error，那么这个 error 就必须是公开的，那么就需要文档记录，这会增加 api 的表面积。\n\n * 增加调用者的耦合性\n\n调用者必须要知道 io.eof 这个 error ，并在调用的地方使用该 error 判断是否结束。\n\n\n# 2.2 error types(自定义错类型)\n\n通过实现 error 接口来创建自定义错误类型。和 sentinel error 相比，是通过判断类型来知道是哪种错误，并且可以输出更多的上下文错误信息。\n\n通过自定义 myerror，并实现 error 接口中的 error 的方法。\n\ntype myerror struct {\n\tmsg  string\n\tfile string\n\tline int\n}\n\nfunc (e *myerror) error() string {\n\treturn fmt.sprintf("%s:%d: %s", e.file, e.line, e.msg)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ntest 方法中返回的是自定义的 error，我们通过断言转换 error 成 myerror 类型，然后再输出更多的上下文信息。\n\nfunc test() error {\n\treturn &myerror{"something happened", "server.go", 42}\n}\n\nfunc main() {\n\terr := test()\n\tswitch err := err.(type) {\n\tcase nil:\n\t\t// success\n\tcase *myerror:\n\t\tfmt.println("error occured on line:", err.line)\n\tdefault:\n\t\t// unknown error\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n在标准库 os.patherror 中，自定义了 patherror ，也是相同的用法。\n\ntype patherror struct {\n\top   string\n\tpath string\n\terr  error\n}\n\nfunc (e *patherror) error() string { return e.op + " " + e.path + ": " + e.err.error() }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n我们也尽可能避免使用 error types，因为它和 sentinel erorr 一样会和调用者产生耦合，会作为 api 的一部分。\n\n\n# 2.3 opaque errors(不透明的错误)\n\nerror types 是通过判断 error 的类型来走不同的逻辑，而 opaque errors 是通过判断 error 的行为来走不同的逻辑。\n\n在 net.error 中定义如下，除了包含 error 外，还包含 timeout 和 temporary 方法。\n\ntype error interface {\n\terror\n\ttimeout() bool \n\ttemporary() bool\n}\n\n\n1\n2\n3\n4\n5\n\n\n除了判断是否有 error 之外，还可以通过方法来判断是哪种类型的 error 然后进行对应的处理。\n\nif neterr, ok := err.(net.error); ok && neterr.timeout() {\n\treturn false\n}\n\nif neterr, ok := err.(net.error); ok && neterr.temporary() {\n\treturn false\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n它不是扩展 error 更多的信息，而是扩展其方法。\n\n\n# 3. 优雅的处理错误\n\n\n# 3.1 无错误的正常流程代码\n\n无错误的正常流程代码，将成为一条直线，而不是缩进的代码。\n\n错误的写法：\n\n// no\nf, err := os.open(path)\nif err == nil {\n    // do stuff\n}\n\n// handle error\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n正确的写法：\n\n// ok\nf, err := os.open(path)\nif err != nil {\n    // handle error\n}\n\n// do stuff\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 3.2 减少不必要的判断\n\nfunc authenticaterequest(r *request) error {\n    err := authenticate(r.user)\n    err != nil {\n        return err\n    }\n    return nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n改为：\n\nfunc authenticaterequest(r *request) error {\n    return authenticate(r.user)\n}\n\n\n1\n2\n3\n\n\n\n# 3.3 将 error 内部存储起来\n\nerr 在内部临时储存，在最后在返回出来。\n\n下面例子中，通过循环读 reader 每一行的数据，每次判断 err 是不是 nil 来判断是否读完，如果是则退出循环，再返回。\n\nfunc countlines(r io.reader)  (int, error) {\n\tvar (\n\t\tbr = bufio.newreader(r)\n\t\tlines int\n\t\terr error\n\t)\n\n\tfor {\n\t\t_, err = br.readstring(\'\\n\')\n\t\tlines++\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif err != io.eof {\n\t\treturn 0, err\n\t}\n\n\treturn lines, nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n改进版本：\n\ntype scanner struct {\n\terr          error     // sticky error.\n\t...\n}\n\nfunc countlines(r io.reader)  (int, error) {\n\tsc := bufio.newscanner(r)\n\tlines := 0\n\n\tfor sc.scan() {\n\t\tlines++\n\t}\n\n\treturn lines, sc.err()\n}\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n每次循环都会判断 scan 的返回值，当无内容返回时，则会返回 false，则结束循环，并返回结果。循环中出现的 error 会在 scan 中通过 s.seterr(err) 保存在对象的 err 属性中。\n\n代码明显简洁了许多。\n\n\n# 3.4 将重复操作抽离出来\n\n看看下面的代码，里面多次使用 fmt.fprintf()并判断其返回值是否为 err\n\ntype header struct {\n\tkey, value string\n}\n\ntype status struct {\n\tcode   int\n\treason string\n}\n\nfunc writeresponse(w io.writer, st status, headers []header, body io.reader) error {\n\t_, err := fmt.fprintf(w, "http/1.1 %d %s\\r\\n", st.code, st.reason)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, h := range headers {\n\t\t_, err := fmt.fprintf(w, "%s: %s\\r\\n", h.key, h.value)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif _, err := fmt.fprintf(w, "\\r\\n"); err != nil {\n\t\treturn err\n\t}\n\n\t_, err = io.copy(w, body)\n\treturn err\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n我们创建一个 errwrite 结构体并实现 write 方法，也就是在原来的 write 方法中包了一层并做好错误判断，然后在每一个 fmt.fprintf 使用我们定义的 errwrite 进行写入，这样就达到了复用的效果，代码也好看了许多。\n\ntype errwrite struct {\n\tio.writer\n\terr error\n}\n\nfunc (e *errwrite) write(buf []byte) (int, error) {\n\tif e.err != nil {\n\t\treturn 0, e.err\n\t}\n\n\tvar n int\n\tn, e.err = e.writer.write(buf)\n\treturn n, e.err\n}\n\nfunc writeresponse(w io.writer, st status, headers []header, body io.reader) error {\n\tew := &errwrite{writer: w}\n\tfmt.fprintf(ew, "http/1.1 %d %s\\r\\n", st.code, st.reason)\n\n\tfor _, h := range headers {\n\t\tfmt.fprintf(ew, "%s: %s\\r\\n", h.key, h.value)\n\t}\n\n\tfmt.fprintf(w, "\\r\\n")\n\n\tio.copy(ew, body)\n\treturn ew.err\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# 4. wrap erros\n\n在我们开发中，常常会在错误处理中，记录了日志，并且将错误给返回了。\n\n在 os.open 找不到文件时会返回 error，处理 error 时，将 error 的信息打上日志，并且将 err 进行返回，在 main 函数中，拿到 error 后再次打上 error 的日志，这个日志和上面有部分是重复的日志。\n\n在代码调用链多的时候，会打上更多的重复日志，日志中出现非常多的噪音，非常影响排查错误。\n\nfunc readfile(path string) ([]byte, error) {\n\tf, err := os.open(path)\n\tif err != nil {\n\t\tlog.printf("could not open file: %v", err)\n\t\treturn nil, err\n\t}\n\tdefer f.close()\n\n\tread := bufio.newreader(f)\n\n\tline, _, err := read.readline()\n\treturn line, err\n}\n\nfunc main() {\n\t_, err := readfile("test.txt")\n\tif err != nil {\n\t\tfmt.println(err)\n\t}\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n运行输出：\n\n2022/11/05 17:03:16 could not open file: open test.txt: the system cannot find t\nhe file specified.\n2022/11/05 17:03:16 open test.txt: the system cannot find the file specified.\n\n\n1\n2\n3\n\n\n可以使用 fmt.errorf 来对原始错误进行包装，除了原始错误信息之外，在添加额外得信息并返回。\n\nf, err := os.open(path)\n\tif err != nil {\n\t\treturn nil, fmt.errorf("open file failed: %w", err)\n\t}\n\n\n1\n2\n3\n4\n\n\n输出：\n\n2022/11/05 17:04:43 open file failed: open test.txt: the system cannot find the\nfile specified.\n\n\n1\n2\n\n\nfmt.errorf 返回的是一个新的被包装的 error，errors.is 可以一层一层的剥开包装来判断是否为原始错误，但是它是做指针判断的，这里 os.open 返回的原始错误是 os.patherror 但是因为返回的是地址，所以无法用 errors.is 判断。\n\nfunc main() {\n\n\t_, err := readfile("test.txt")\n\tvar patherror *os.patherror\n\n\tif errors.is(err, patherror) {\n\t\tfmt.println("is patherror")\n\t} else {\n\t\tfmt.println("no patherror")\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n输出：\n\nno patherror\n\n\n1\n\n\n这里可以用 errors.as 来判断 err 是否为 os.patherror 类型，即使 err 是地址。\n\n这里判断了是否为 os.patherror 错误，并且将返回的 err 转换成了该错误，我们可以调用其中的属性来获取更多的信息。\n\nfunc main() {\n\n\t_, err := readfile("test.txt")\n\tvar patherror *os.patherror\n\n\tif errors.as(err, &patherror) {\n\t\tfmt.println(patherror.path)\n\t}\n\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n输出：\n\ntest.txt\n\n\n1\n\n\n还可以通过 errors.unwrap 来获取底层错误，将原始错误给解析出来。\n\nfunc main() {\n\t_, err := readfile("test.txt")\n\terr = errors.unwrap(err)\n\tfmt.printf("ori err: %v", err)\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 5. pkg/errors\n\n上面介绍的都是原生的 errors 处理模块，现在介绍 pkg/errors 模块，完全兼容原生 errors，并且对其进行增强，主要是添加了保存堆栈的能力。\n\n可以使用 errors.wrap 进行对 error 的包装，并添加额外的信息。\n\nfunc readfile(path string) ([]byte, error) {\n\tf, err := os.open(path)\n\tif err != nil {\n\t\treturn nil, errors.wrap(err, "could not open file")\n\t}\n\tdefer f.close()\n\n\tread := bufio.newreader(f)\n\n\tline, _, err := read.readline()\n\treturn line, err\n}\n\nfunc main() {\n\t_, err := readfile("test.txt")\n\tif err != nil {\n\t\tfmt.println(err)\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n输出：\n\ncould not open file: open test.txt: the system cannot find the file specified.\n\n\n1\n\n\n但它还有一个更强的功能是会保存当前的堆栈信息，使用%+v 可以打印出来。\n\nfunc main() {\n\t_, err := readfile("test.txt")\n\tif err != nil {\n\t\tfmt.printf("stack track: \\n%+v", err)\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n输出：\n\nstack track:\nopen test.txt: the system cannot find the file specified.\ncould not open file\nmain.readfile\n        d:/code/go_demo/main3.go:13\nmain.main\n        d:/code/go_demo/main3.go:24\nruntime.main\n        d:/install/go18.3/src/runtime/proc.go:250\nruntime.goexit\n        d:/install/go18.3/src/runtime/asm_amd64.s:1571\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n如果不想保存堆栈信息，只添加额外的信息，可以使用 errors.withmessage 添加。\n\n\tf, err := os.open(path)\n\tif err != nil {\n\t\treturn nil, errors.withmessage(err, "could not open file")\n\t}\n\n\n1\n2\n3\n4\n\n\n输出：\n\ncould not open file: open test.txt: the system cannot find the file specified.\n\n\n1\n\n\n还有几个常见的方法\n\n// 生成错误的同时带上堆栈信息\nfunc new(message string) error\n\n// 只附加调用堆栈信息\nfunc withstack(err error) error\n\n// 获得最根本的错误原因\nfunc cause(err error) error\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 6. error 的最佳实践\n\n处理 error 的方式这么多，我们该如何最优的使用它们呢？有以下几个方法：\n\n * 在自己的应用代码中，使用 errors.new 或者 errors.errorf 来返回错误\n\nfunc parseargs(args []string) error {\n\tif len(args) < 3 {\n\t\treturn errors.errorf("not enough arguments")\n\t}\n\n\treturn nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n * 如果调用其他包内的函数，通常简单的直接返回。\n\nif err != nil {\n\treturn err\n}\n\n\n1\n2\n3\n\n * 如果和其他库进行协作，考虑使用 errors.wrap 或者 errors.wrapf 保存堆栈信息。同样适用于和标准库协作的时候。\n\nf, err := os.open(path)\nif err != nil {\n\treturn errors.wrapf(err, "failed to open %q", path)\n\n\n1\n2\n3\n\n\n * 直接返回错误，而不是每个错误产生的地方到处打日志。\n\n * 在程序的顶部或者是工作的 goroutine 顶部（请求入口），使用 %+v 把堆栈详情记录。\n\nfunc main() {\n\terr := app.run()\n\tif err != nil {\n\t\tfmt.printf("fatal: %+v\\n", err)\n\t\tos.exit(1)\n\t}\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * 使用 errors.cause 获取 root error，再进行和 sentinel error 判定。\n\n\n# 参考资料\n\n * io.eof 设计的缺陷',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"tcp缓存引起的日志丢失",frontmatter:{title:"tcp缓存引起的日志丢失",date:"2023-11-09T15:49:47.000Z",permalink:"/pages/36b0b2/",tags:["go语言","logstash","编程"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"logstash从数据源拉取日志，然后通过tcp插件发送到proxy进程中。在业务侧发现日志量明显少了，所以有了这一次的问题排查。",comment:!0,categories:["编程","go语言"],feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20231109171607.png"},{name:"twitter:title",content:"tcp缓存引起的日志丢失"},{name:"twitter:description",content:"logstash从数据源拉取日志，然后通过tcp插件发送到proxy进程中。在业务侧发现日志量明显少了，所以有了这一次的问题排查。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20231109171607.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/05.tcp%E7%BC%93%E5%AD%98%E5%BC%95%E8%B5%B7%E7%9A%84%E6%97%A5%E5%BF%97%E4%B8%A2%E5%A4%B1.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tcp缓存引起的日志丢失"},{property:"og:description",content:"logstash从数据源拉取日志，然后通过tcp插件发送到proxy进程中。在业务侧发现日志量明显少了，所以有了这一次的问题排查。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20231109171607.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/05.tcp%E7%BC%93%E5%AD%98%E5%BC%95%E8%B5%B7%E7%9A%84%E6%97%A5%E5%BF%97%E4%B8%A2%E5%A4%B1.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-11-09T15:49:47.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"logstash"},{property:"article:tag",content:"编程"},{itemprop:"name",content:"tcp缓存引起的日志丢失"},{itemprop:"description",content:"logstash从数据源拉取日志，然后通过tcp插件发送到proxy进程中。在业务侧发现日志量明显少了，所以有了这一次的问题排查。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20231109171607.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/05.tcp%E7%BC%93%E5%AD%98%E5%BC%95%E8%B5%B7%E7%9A%84%E6%97%A5%E5%BF%97%E4%B8%A2%E5%A4%B1.html",relativePath:"04.编程/02.go语言/05.tcp缓存引起的日志丢失.md",key:"v-2f3e170c",path:"/pages/36b0b2/",headers:[{level:2,title:"背景",slug:"背景",normalizedTitle:"背景",charIndex:2},{level:2,title:"问题排查定位",slug:"问题排查定位",normalizedTitle:"问题排查定位",charIndex:78},{level:2,title:"代码排查",slug:"代码排查",normalizedTitle:"代码排查",charIndex:1167},{level:2,title:"解决方法",slug:"解决方法",normalizedTitle:"解决方法",charIndex:2432},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:2749}],headersStr:"背景 问题排查定位 代码排查 解决方法 总结",content:'# 背景\n\nlogstash从数据源拉取日志，然后通过tcp插件发送到proxy进程中。在业务侧发现日志量明显少了，所以有了这一次的问题排查。\n\n\n\n\n# 问题排查定位\n\n首先从logstash侧开始检查。我们先看logstash的日志，没有明显的报错信息。\n\n然后再查看logstash管道的状态。可以很明显的看到，在output管道中，in远远大于out，也就是logstash拉取的日志已经到了output管道，但是无法输出出去，并且duration_in_millis时间很长，这个代表着发出去的速率很慢，这是什么原因呢？\n\ncurl -XGET \'localhost:9600/_node/stats/pipelines/azure_event_hubs?pretty\'\n\n{\n    ...\n"outputs" : [ {\n        "id" : "99b12e190d297be5d6113d04cf10089a3dccbaef7eed0cc41515e8e5af5f4595",\n        "name" : "tcp",\n        "events" : {\n        "in" : 341,\n        "out" : 69,\n        "duration_in_millis" : 519709\n        }\n    } \n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n要么是发送方的原因，要么是接收方的原因。我先从发送方进行排查，我在output管道中，除了tcp插件外，还添加了stdout插件，也就是日志来了除了会通过tcp发送外，还会打印在标准输出中。\n\noutput {\n\n    tcp {\n        ...\n    }\n\n    stdout {}\n\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n然后等待一段时间，然后再查看该管道的信息，stdout插件的in和out完全相等，但tcp插件in和out还是相差甚大，也就是output管道应该没问题。\n\n我再假设proxy端有问题。日志是可以从logstash端发送到proxy端的，只是很慢，并且还有其他数据源也在往proxy端发送日志，也没有这个问题，所以我突然想到，该数据源的日志很大，会不会是这个原因导致的呢？\n\n我从上面标准输出中抓了一条日志出来，134k大小，然后我手动的用nc命令将日志发送到proxy，因为日志很大，我是将日志写入到文件，然后再用管道的方式发送的\n\ncat test.txt | nc \n\n\n1\n\n\n通过查看proxy的日志发现，其根本没有收到该条日志。那么问题原因找到了，就是因为日志太大，导致日志发生了丢失。\n\n\n# 代码排查\n\nproxy服务的是golang写的，通过查看代码，这里使用了bufio.NewScanner来循环读取连接中的数据。\n\n\tscanner := bufio.NewScanner(conn)\n\n\tfor scanner.Scan() {\n\t\t// 处理数据\n\t\tmsg := scanner.Text()\n        ...\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看NewScanner方法可以看到有一个maxTokenSize参数，然后用的默认值MaxScanTokenSize\n\nfunc NewScanner(r io.Reader) *Scanner {\n\treturn &Scanner{\n\t\tr:            r,\n\t\tsplit:        ScanLines,\n\t\tmaxTokenSize: MaxScanTokenSize,\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n再跳转，有一个初始化缓存大小startBufSize为4k和最大的缓存大小MaxScanTokenSize为64k。但是我们的日志大小为134k，已经大于最大大小了，所以无法接收到该日志，也就是因为这个原因导致了日志发生了丢失。\n\nconst (\n\tMaxScanTokenSize = 64 * 1024\n\n\tstartBufSize = 4096\n)\n\n\n1\n2\n3\n4\n5\n\n\n我们再看下Scan方法，有一段代码如下，如果拿到的数据的大小大于maxTokenSize，则会使用s.setErr(ErrTooLong)记录错误，然后返回false\n\n\nfunc (s *Scanner) Scan() bool {\n\n    ..\n    const maxInt = int(^uint(0) >> 1)\n    if len(s.buf) >= s.maxTokenSize || len(s.buf) > maxInt/2 {\n        s.setErr(ErrTooLong)\n        return false\n    }\n    newSize := len(s.buf) * 2\n    if newSize == 0 {\n        newSize = startBufSize\n    }\n    if newSize > s.maxTokenSize {\n        newSize = s.maxTokenSize\n    }\n    newBuf := make([]byte, newSize)\n    copy(newBuf, s.buf[s.start:s.end])\n    ...\n\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n但是我们在业务代码中，并没有判断该错误，也就是如果Scan方法虽然返回了false，循环结束了，但是并没有任何错误信息。也就是无法发现该问题。\n\n\n# 解决方法\n\n 1. 将TCP的最大缓存大小修改为配置文件可配置的，这样如果日志很大，可以修改配置增大缓存上限。库中有提供Buffer方法来设置该上限。\n\n 2. 在Scan发生错误时，打印错误日志，代码如下：\n\n\nscanner := bufio.NewScanner(conn)\n\nfor scanner.Scan() {\n    // 处理数据\n    msg := scanner.Text()\n    ...\n\nif err := scanner.Err(); err != nil {\n    log.Errorf("扫描输入时发生错误：%s", err)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 总结\n\n 1. 要提高自己的排查的手段，熟悉组件提供的排查机制，让你事半功倍。\n 2. 每一个提供的参数都至关重要，所以我们都需要有一定的理解，可以减少BUG的发生',normalizedContent:'# 背景\n\nlogstash从数据源拉取日志，然后通过tcp插件发送到proxy进程中。在业务侧发现日志量明显少了，所以有了这一次的问题排查。\n\n\n\n\n# 问题排查定位\n\n首先从logstash侧开始检查。我们先看logstash的日志，没有明显的报错信息。\n\n然后再查看logstash管道的状态。可以很明显的看到，在output管道中，in远远大于out，也就是logstash拉取的日志已经到了output管道，但是无法输出出去，并且duration_in_millis时间很长，这个代表着发出去的速率很慢，这是什么原因呢？\n\ncurl -xget \'localhost:9600/_node/stats/pipelines/azure_event_hubs?pretty\'\n\n{\n    ...\n"outputs" : [ {\n        "id" : "99b12e190d297be5d6113d04cf10089a3dccbaef7eed0cc41515e8e5af5f4595",\n        "name" : "tcp",\n        "events" : {\n        "in" : 341,\n        "out" : 69,\n        "duration_in_millis" : 519709\n        }\n    } \n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n要么是发送方的原因，要么是接收方的原因。我先从发送方进行排查，我在output管道中，除了tcp插件外，还添加了stdout插件，也就是日志来了除了会通过tcp发送外，还会打印在标准输出中。\n\noutput {\n\n    tcp {\n        ...\n    }\n\n    stdout {}\n\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n然后等待一段时间，然后再查看该管道的信息，stdout插件的in和out完全相等，但tcp插件in和out还是相差甚大，也就是output管道应该没问题。\n\n我再假设proxy端有问题。日志是可以从logstash端发送到proxy端的，只是很慢，并且还有其他数据源也在往proxy端发送日志，也没有这个问题，所以我突然想到，该数据源的日志很大，会不会是这个原因导致的呢？\n\n我从上面标准输出中抓了一条日志出来，134k大小，然后我手动的用nc命令将日志发送到proxy，因为日志很大，我是将日志写入到文件，然后再用管道的方式发送的\n\ncat test.txt | nc \n\n\n1\n\n\n通过查看proxy的日志发现，其根本没有收到该条日志。那么问题原因找到了，就是因为日志太大，导致日志发生了丢失。\n\n\n# 代码排查\n\nproxy服务的是golang写的，通过查看代码，这里使用了bufio.newscanner来循环读取连接中的数据。\n\n\tscanner := bufio.newscanner(conn)\n\n\tfor scanner.scan() {\n\t\t// 处理数据\n\t\tmsg := scanner.text()\n        ...\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看newscanner方法可以看到有一个maxtokensize参数，然后用的默认值maxscantokensize\n\nfunc newscanner(r io.reader) *scanner {\n\treturn &scanner{\n\t\tr:            r,\n\t\tsplit:        scanlines,\n\t\tmaxtokensize: maxscantokensize,\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n再跳转，有一个初始化缓存大小startbufsize为4k和最大的缓存大小maxscantokensize为64k。但是我们的日志大小为134k，已经大于最大大小了，所以无法接收到该日志，也就是因为这个原因导致了日志发生了丢失。\n\nconst (\n\tmaxscantokensize = 64 * 1024\n\n\tstartbufsize = 4096\n)\n\n\n1\n2\n3\n4\n5\n\n\n我们再看下scan方法，有一段代码如下，如果拿到的数据的大小大于maxtokensize，则会使用s.seterr(errtoolong)记录错误，然后返回false\n\n\nfunc (s *scanner) scan() bool {\n\n    ..\n    const maxint = int(^uint(0) >> 1)\n    if len(s.buf) >= s.maxtokensize || len(s.buf) > maxint/2 {\n        s.seterr(errtoolong)\n        return false\n    }\n    newsize := len(s.buf) * 2\n    if newsize == 0 {\n        newsize = startbufsize\n    }\n    if newsize > s.maxtokensize {\n        newsize = s.maxtokensize\n    }\n    newbuf := make([]byte, newsize)\n    copy(newbuf, s.buf[s.start:s.end])\n    ...\n\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n但是我们在业务代码中，并没有判断该错误，也就是如果scan方法虽然返回了false，循环结束了，但是并没有任何错误信息。也就是无法发现该问题。\n\n\n# 解决方法\n\n 1. 将tcp的最大缓存大小修改为配置文件可配置的，这样如果日志很大，可以修改配置增大缓存上限。库中有提供buffer方法来设置该上限。\n\n 2. 在scan发生错误时，打印错误日志，代码如下：\n\n\nscanner := bufio.newscanner(conn)\n\nfor scanner.scan() {\n    // 处理数据\n    msg := scanner.text()\n    ...\n\nif err := scanner.err(); err != nil {\n    log.errorf("扫描输入时发生错误：%s", err)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 总结\n\n 1. 要提高自己的排查的手段，熟悉组件提供的排查机制，让你事半功倍。\n 2. 每一个提供的参数都至关重要，所以我们都需要有一定的理解，可以减少bug的发生',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"Go协程池深度解析：原理、实现与最佳实践",frontmatter:{title:"Go协程池深度解析：原理、实现与最佳实践",date:"2025-06-09T20:07:50.000Z",permalink:"/pages/d2c214/",categories:["编程","go语言","go语言高性能编程"],tags:["go语言","go高语言性能编程"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"深入解析Go协程池的工作原理、实现方式及性能优化策略，包含基准测试对比和实际应用场景分析",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17494714259921749471425027.png"},{name:"twitter:title",content:"Go协程池深度解析：原理、实现与最佳实践"},{name:"twitter:description",content:"深入解析Go协程池的工作原理、实现方式及性能优化策略，包含基准测试对比和实际应用场景分析"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17494714259921749471425027.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/01.Go%E5%8D%8F%E7%A8%8B%E6%B1%A0%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%EF%BC%9A%E5%8E%9F%E7%90%86%E3%80%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go协程池深度解析：原理、实现与最佳实践"},{property:"og:description",content:"深入解析Go协程池的工作原理、实现方式及性能优化策略，包含基准测试对比和实际应用场景分析"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17494714259921749471425027.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/01.Go%E5%8D%8F%E7%A8%8B%E6%B1%A0%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%EF%BC%9A%E5%8E%9F%E7%90%86%E3%80%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-09T20:07:50.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"go高语言性能编程"},{itemprop:"name",content:"Go协程池深度解析：原理、实现与最佳实践"},{itemprop:"description",content:"深入解析Go协程池的工作原理、实现方式及性能优化策略，包含基准测试对比和实际应用场景分析"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17494714259921749471425027.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/01.Go%E5%8D%8F%E7%A8%8B%E6%B1%A0%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%EF%BC%9A%E5%8E%9F%E7%90%86%E3%80%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html",relativePath:"04.编程/02.go语言/07.go语言高性能编程/01.Go协程池深度解析：原理、实现与最佳实践.md",key:"v-66d9b7c0",path:"/pages/d2c214/",headers:[{level:2,title:"为什么需要协程池?",slug:"为什么需要协程池",normalizedTitle:"为什么需要协程池?",charIndex:2},{level:2,title:"怎么使用协程池?",slug:"怎么使用协程池",normalizedTitle:"怎么使用协程池?",charIndex:171},{level:2,title:"Worker Pools 该设置成多大？",slug:"worker-pools-该设置成多大",normalizedTitle:"worker pools 该设置成多大？",charIndex:1090},{level:2,title:"BenchMark",slug:"benchmark",normalizedTitle:"benchmark",charIndex:1314},{level:2,title:"什么时候使用 Worker Pools?",slug:"什么时候使用-worker-pools",normalizedTitle:"什么时候使用 worker pools?",charIndex:2892},{level:2,title:"什么时候该避免使用 Worker pools?",slug:"什么时候该避免使用-worker-pools",normalizedTitle:"什么时候该避免使用 worker pools?",charIndex:2959}],headersStr:"为什么需要协程池? 怎么使用协程池? Worker Pools 该设置成多大？ BenchMark 什么时候使用 Worker Pools? 什么时候该避免使用 Worker pools?",content:'# 为什么需要协程池?\n\ngoroutine 虽然是轻量级的并发模型，但是协程也是有栈空间的，并且有上下文切换的开销，当协程数量增加时，性能可能会急剧的下降，甚至导致程序崩溃。\n\n而协程池限制 gorotinue 的数量，并从共享的任务队列中提取任务执行，从而让 goroutine可控，不会超过其处理的能力，保证服务的稳定性。\n\n\n\n\n# 怎么使用协程池?\n\n提前创建 5 个worker，再创建一个 jobs channel 用于传递任务，最后在不断地将任务生产到队列中，worker获取到任务后执行，最后将 jobs close掉，协程也就都退出了，最后程序退出。\n\nfunc worker(id int, jobs <-chan int, results chan<- [32]byte) {\n    for j := range jobs {\n        results <- doWork(j)\n    }\n}\n\nfunc doWork(n int) [32]byte {\n    data := []byte(fmt.Sprintf("payload-%d", n))\n    return sha256.Sum256(data) //\n}\n\nfunc main() {\n    jobs := make(chan int, 100)\n    results := make(chan [32]byte, 100)\n\n    for w := 1; w <= 5; w++ {\n        go worker(w, jobs, results)\n    }\n\n    for j := 1; j <= 10; j++ {\n        jobs <- j\n    }\n    close(jobs)\n\n    for a := 1; a <= 10; a++ {\n        <-results\n    }\n\n    fmt.Println("ending")\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n可以自己实现，也可以直接利用已经实现好的开源协程池。\n\nhttps://github.com/Jeffail/tunny\n\nhttps://github.com/panjf2000/ants\n\nhttps://github.com/bytedance/gopkg/tree/main/util/gopool\n\n\n# Worker Pools 该设置成多大？\n\n池中的协程最优的协程数量和 CPU 核数密切相关。可以使用 runtime.NumCPU() 或 runtime.GOMAXPROCS(0) 来获取 CPU 核数。\n\n对于 CPU 密集型任务，通常工作协程数少于或等于逻辑 CPU 核数，可以让 CPU 利用率达到最大。而对于 IO 密集型任务，可以让工作协程数大于CPU核数，以为遇到 IO 会进行阻塞，也就是工作协程大部分时间处于阻塞状态。\n\n\n# BenchMark\n\n使用协程池和不使用协程池处理 10000 个任务的 BenchMark 比较\n\nconst (\n    numJobs     = 10000\n    workerCount = 10\n)\n\nfunc doWork(n int) [32]byte {\n    data := []byte(fmt.Sprintf("payload-%d", n))\n    return sha256.Sum256(data)\n}\n\nfunc BenchmarkUnboundedGoroutines(b *testing.B) {\n    for range b.N {\n        var wg sync.WaitGroup\n        wg.Add(numJobs)\n\n        for j := 0; j < numJobs; j++ {\n            go func(job int) {\n                _ = doWork(job)\n                wg.Done()\n            }(j)\n        }\n        wg.Wait()\n    }\n}\n\nfunc worker(jobs <-chan int, wg *sync.WaitGroup) {\n    for job := range jobs {\n        _ = doWork(job)\n        wg.Done()\n    }\n}\n\nfunc BenchmarkWorkerPool(b *testing.B) {\n    for range b.N {\n        var wg sync.WaitGroup\n        wg.Add(numJobs)\n\n        jobs := make(chan int, numJobs)\n        for w := 0; w < workerCount; w++ {\n            go worker(jobs, &wg)\n        }\n\n        for j := 0; j < numJobs; j++ {\n            jobs <- j\n        }\n\n        close(jobs)\n        wg.Wait()\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n\n\n运行结果如下，使用协程池使用的资源更少，更快的完成工作。\n\n $ go test -bench=. -benchmem .  \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkUnboundedGoroutines-12              486           2501263 ns/op          639942 B/op      39754 allocs/op\nBenchmarkWorkerPool-12                       776           1540660 ns/op          320554 B/op      19758 allocs/op\nPASS\nok      main/demo       3.343s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 什么时候使用 Worker Pools?\n\n * 有大量或无限制的任务流处理。\n * 为了程序的稳定性，限制并行操作的数量。\n\n\n# 什么时候该避免使用 Worker pools?\n\n * 对任务的延迟非常敏感，需要立即执行。\n * 低负载的情况下，使用协程池反而增高了成本。\n * 工作量较小并且是有限的。',normalizedContent:'# 为什么需要协程池?\n\ngoroutine 虽然是轻量级的并发模型，但是协程也是有栈空间的，并且有上下文切换的开销，当协程数量增加时，性能可能会急剧的下降，甚至导致程序崩溃。\n\n而协程池限制 gorotinue 的数量，并从共享的任务队列中提取任务执行，从而让 goroutine可控，不会超过其处理的能力，保证服务的稳定性。\n\n\n\n\n# 怎么使用协程池?\n\n提前创建 5 个worker，再创建一个 jobs channel 用于传递任务，最后在不断地将任务生产到队列中，worker获取到任务后执行，最后将 jobs close掉，协程也就都退出了，最后程序退出。\n\nfunc worker(id int, jobs <-chan int, results chan<- [32]byte) {\n    for j := range jobs {\n        results <- dowork(j)\n    }\n}\n\nfunc dowork(n int) [32]byte {\n    data := []byte(fmt.sprintf("payload-%d", n))\n    return sha256.sum256(data) //\n}\n\nfunc main() {\n    jobs := make(chan int, 100)\n    results := make(chan [32]byte, 100)\n\n    for w := 1; w <= 5; w++ {\n        go worker(w, jobs, results)\n    }\n\n    for j := 1; j <= 10; j++ {\n        jobs <- j\n    }\n    close(jobs)\n\n    for a := 1; a <= 10; a++ {\n        <-results\n    }\n\n    fmt.println("ending")\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n可以自己实现，也可以直接利用已经实现好的开源协程池。\n\nhttps://github.com/jeffail/tunny\n\nhttps://github.com/panjf2000/ants\n\nhttps://github.com/bytedance/gopkg/tree/main/util/gopool\n\n\n# worker pools 该设置成多大？\n\n池中的协程最优的协程数量和 cpu 核数密切相关。可以使用 runtime.numcpu() 或 runtime.gomaxprocs(0) 来获取 cpu 核数。\n\n对于 cpu 密集型任务，通常工作协程数少于或等于逻辑 cpu 核数，可以让 cpu 利用率达到最大。而对于 io 密集型任务，可以让工作协程数大于cpu核数，以为遇到 io 会进行阻塞，也就是工作协程大部分时间处于阻塞状态。\n\n\n# benchmark\n\n使用协程池和不使用协程池处理 10000 个任务的 benchmark 比较\n\nconst (\n    numjobs     = 10000\n    workercount = 10\n)\n\nfunc dowork(n int) [32]byte {\n    data := []byte(fmt.sprintf("payload-%d", n))\n    return sha256.sum256(data)\n}\n\nfunc benchmarkunboundedgoroutines(b *testing.b) {\n    for range b.n {\n        var wg sync.waitgroup\n        wg.add(numjobs)\n\n        for j := 0; j < numjobs; j++ {\n            go func(job int) {\n                _ = dowork(job)\n                wg.done()\n            }(j)\n        }\n        wg.wait()\n    }\n}\n\nfunc worker(jobs <-chan int, wg *sync.waitgroup) {\n    for job := range jobs {\n        _ = dowork(job)\n        wg.done()\n    }\n}\n\nfunc benchmarkworkerpool(b *testing.b) {\n    for range b.n {\n        var wg sync.waitgroup\n        wg.add(numjobs)\n\n        jobs := make(chan int, numjobs)\n        for w := 0; w < workercount; w++ {\n            go worker(jobs, &wg)\n        }\n\n        for j := 0; j < numjobs; j++ {\n            jobs <- j\n        }\n\n        close(jobs)\n        wg.wait()\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n\n\n运行结果如下，使用协程池使用的资源更少，更快的完成工作。\n\n $ go test -bench=. -benchmem .  \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkunboundedgoroutines-12              486           2501263 ns/op          639942 b/op      39754 allocs/op\nbenchmarkworkerpool-12                       776           1540660 ns/op          320554 b/op      19758 allocs/op\npass\nok      main/demo       3.343s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 什么时候使用 worker pools?\n\n * 有大量或无限制的任务流处理。\n * 为了程序的稳定性，限制并行操作的数量。\n\n\n# 什么时候该避免使用 worker pools?\n\n * 对任务的延迟非常敏感，需要立即执行。\n * 低负载的情况下，使用协程池反而增高了成本。\n * 工作量较小并且是有限的。',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"使用etcd分布式锁导致的协程泄露与死锁问题",frontmatter:{title:"使用etcd分布式锁导致的协程泄露与死锁问题",date:"2025-05-13T16:18:01.000Z",permalink:"/pages/91d2d9/",categories:["编程","go语言"],tags:["go语言","分布","工作记录"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文记录自己在工作中排查etcd应用分布式锁而导致的泄露与死锁问题，并通过分析源码找到根因，最终解决。",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"使用etcd分布式锁导致的协程泄露与死锁问题"},{name:"twitter:description",content:"本文记录自己在工作中排查etcd应用分布式锁而导致的泄露与死锁问题，并通过分析源码找到根因，最终解决。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/06.%E4%BD%BF%E7%94%A8etcd%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AF%BC%E8%87%B4%E7%9A%84%E5%8D%8F%E7%A8%8B%E6%B3%84%E9%9C%B2%E4%B8%8E%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98.html"},{property:"og:type",content:"article"},{property:"og:title",content:"使用etcd分布式锁导致的协程泄露与死锁问题"},{property:"og:description",content:"本文记录自己在工作中排查etcd应用分布式锁而导致的泄露与死锁问题，并通过分析源码找到根因，最终解决。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/06.%E4%BD%BF%E7%94%A8etcd%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AF%BC%E8%87%B4%E7%9A%84%E5%8D%8F%E7%A8%8B%E6%B3%84%E9%9C%B2%E4%B8%8E%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-05-13T16:18:01.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"分布"},{property:"article:tag",content:"工作记录"},{itemprop:"name",content:"使用etcd分布式锁导致的协程泄露与死锁问题"},{itemprop:"description",content:"本文记录自己在工作中排查etcd应用分布式锁而导致的泄露与死锁问题，并通过分析源码找到根因，最终解决。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/06.%E4%BD%BF%E7%94%A8etcd%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AF%BC%E8%87%B4%E7%9A%84%E5%8D%8F%E7%A8%8B%E6%B3%84%E9%9C%B2%E4%B8%8E%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98.html",relativePath:"04.编程/02.go语言/06.使用etcd分布式锁导致的协程泄露与死锁问题.md",key:"v-569242f6",path:"/pages/91d2d9/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"问题重现",slug:"问题重现",normalizedTitle:"问题重现",charIndex:62},{level:3,title:"现象描述",slug:"现象描述",normalizedTitle:"现象描述",charIndex:71},{level:3,title:"最小复现代码",slug:"最小复现代码",normalizedTitle:"最小复现代码",charIndex:243},{level:2,title:"根因分析",slug:"根因分析",normalizedTitle:"根因分析",charIndex:672},{level:3,title:"架构示意图",slug:"架构示意图",normalizedTitle:"架构示意图",charIndex:681},{level:3,title:"源码关键路径",slug:"源码关键路径",normalizedTitle:"源码关键路径",charIndex:1044},{level:2,title:"解决方案",slug:"解决方案",normalizedTitle:"解决方案",charIndex:1205},{level:2,title:"最佳实践",slug:"最佳实践",normalizedTitle:"最佳实践",charIndex:1732},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:1842}],headersStr:"简介 问题重现 现象描述 最小复现代码 根因分析 架构示意图 源码关键路径 解决方案 最佳实践 总结",content:'# 简介\n\n本文记录自己在工作中排查etcd应用分布式锁而导致的泄露与死锁问题，并通过分析源码找到根因，最终解决。\n\n\n# 问题重现\n\n\n# 现象描述\n\n服务出现数据入库失败，且伴随内存持续增长。关键现象：\n\n 1. 锁残留：通过etcdctl get --prefix /my-lock/可看到锁KEY长期存在\n 2. 租约续期：etcdctl lease timetolive显示租约TTL不断重置\n 3. 资源增长：Go程序协程数随请求量线性增长（可通过pprof观测）\n\n\n# 最小复现代码\n\nfunc main() {\n\t// ... etcd client初始化代码不变...\n\n\t// 关键问题点1：缺失session关闭\n\tsession, _ := concurrency.NewSession(cli)\n\t// defer session.Close() // 故意注释导致协程泄漏\n\n\t// 关键问题点2：未释放锁\n\tmutex := concurrency.NewMutex(session, "/my-lock/")\n\tctx, _ := context.WithTimeout(context.Background(), 5*time.Second)\n\t_ = mutex.Lock(ctx)\n\t\n\t// ...业务逻辑代码...\n\t\n\t// 关键问题点3：阻止程序退出（仅用于demo）\n\tselect {} \n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n# 根因分析\n\n\n# 架构示意图\n\n+--------------+      定期续约      +------+\n|  Go routine  |-----------------\x3e| etcd |\n+--------------+  (KeepAlive)     +------+\n       ▲\n       │ 未调用Close()\n       └──────+\n              |\n+---------------------------+\n| session.Close() 核心作用：|\n| 1. 停止续约协程           |\n| 2. 释放租约              |\n+---------------------------+\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 源码关键路径\n\n协程泄漏路径： NewSession() → go keepAlive协程 → client.KeepAlive() → 后台协程续约(sendKeepAliveLoop)\n\n资源释放路径： session.Close() → Orphan() → 关闭上下文 → 触发keepAlive协程退出\n\n\n# 解决方案\n\n在创建session后，确保调用Close()方法，及时释放资源。\n\nfunc main() {\n\t// ...初始化代码不变...\n\n\tsession, err := concurrency.NewSession(cli)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer session.Close() // 新增关键修复\n\n\tmutex := concurrency.NewMutex(session, "/my-lock/")\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer cancel() // 确保上下文取消\n\n\tif err := mutex.Lock(ctx); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tdefer mutex.Unlock(context.TODO()) // 双保险释放锁\n\n\t// ...业务逻辑...\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n\n# 最佳实践\n\n 1. 资源释放三原则：\n\n * 对每个NewSession()必须配对defer Close()\n * 锁操作必须包裹在Lock()/Unlock()中\n * 使用带超时的上下文（建议不超过5s）\n\n\n# 总结\n\n 1. etcd特性：会话型锁的设计需要客户端主动维护生命周期\n 2. 调试技巧：使用go tool pprof观察goroutine增长趋势',normalizedContent:'# 简介\n\n本文记录自己在工作中排查etcd应用分布式锁而导致的泄露与死锁问题，并通过分析源码找到根因，最终解决。\n\n\n# 问题重现\n\n\n# 现象描述\n\n服务出现数据入库失败，且伴随内存持续增长。关键现象：\n\n 1. 锁残留：通过etcdctl get --prefix /my-lock/可看到锁key长期存在\n 2. 租约续期：etcdctl lease timetolive显示租约ttl不断重置\n 3. 资源增长：go程序协程数随请求量线性增长（可通过pprof观测）\n\n\n# 最小复现代码\n\nfunc main() {\n\t// ... etcd client初始化代码不变...\n\n\t// 关键问题点1：缺失session关闭\n\tsession, _ := concurrency.newsession(cli)\n\t// defer session.close() // 故意注释导致协程泄漏\n\n\t// 关键问题点2：未释放锁\n\tmutex := concurrency.newmutex(session, "/my-lock/")\n\tctx, _ := context.withtimeout(context.background(), 5*time.second)\n\t_ = mutex.lock(ctx)\n\t\n\t// ...业务逻辑代码...\n\t\n\t// 关键问题点3：阻止程序退出（仅用于demo）\n\tselect {} \n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n# 根因分析\n\n\n# 架构示意图\n\n+--------------+      定期续约      +------+\n|  go routine  |-----------------\x3e| etcd |\n+--------------+  (keepalive)     +------+\n       ▲\n       │ 未调用close()\n       └──────+\n              |\n+---------------------------+\n| session.close() 核心作用：|\n| 1. 停止续约协程           |\n| 2. 释放租约              |\n+---------------------------+\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 源码关键路径\n\n协程泄漏路径： newsession() → go keepalive协程 → client.keepalive() → 后台协程续约(sendkeepaliveloop)\n\n资源释放路径： session.close() → orphan() → 关闭上下文 → 触发keepalive协程退出\n\n\n# 解决方案\n\n在创建session后，确保调用close()方法，及时释放资源。\n\nfunc main() {\n\t// ...初始化代码不变...\n\n\tsession, err := concurrency.newsession(cli)\n\tif err != nil {\n\t\tlog.fatal(err)\n\t}\n\tdefer session.close() // 新增关键修复\n\n\tmutex := concurrency.newmutex(session, "/my-lock/")\n\tctx, cancel := context.withtimeout(context.background(), 5*time.second)\n\tdefer cancel() // 确保上下文取消\n\n\tif err := mutex.lock(ctx); err != nil {\n\t\tlog.fatal(err)\n\t}\n\tdefer mutex.unlock(context.todo()) // 双保险释放锁\n\n\t// ...业务逻辑...\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n\n# 最佳实践\n\n 1. 资源释放三原则：\n\n * 对每个newsession()必须配对defer close()\n * 锁操作必须包裹在lock()/unlock()中\n * 使用带超时的上下文（建议不超过5s）\n\n\n# 总结\n\n 1. etcd特性：会话型锁的设计需要客户端主动维护生命周期\n 2. 调试技巧：使用go tool pprof观察goroutine增长趋势',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"Go语言遍历性能深度解析：从原理到优化实践",frontmatter:{title:"Go语言遍历性能深度解析：从原理到优化实践",date:"2025-06-14T10:43:04.000Z",permalink:"/pages/88360d/",categories:["编程","go语言","go语言高性能编程"],tags:["go语言","go语言高性能编程"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"在Go语言中，遍历是日常开发中最常见的操作之一。不同的遍历方式会对性能产生显著影响。本文将深入分析Go语言中遍历的性能特点，并探讨如何优化遍历以提高代码效率。",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"Go语言遍历性能深度解析：从原理到优化实践"},{name:"twitter:description",content:"在Go语言中，遍历是日常开发中最常见的操作之一。不同的遍历方式会对性能产生显著影响。本文将深入分析Go语言中遍历的性能特点，并探讨如何优化遍历以提高代码效率。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/03.Go%E8%AF%AD%E8%A8%80%E9%81%8D%E5%8E%86%E6%80%A7%E8%83%BD%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go语言遍历性能深度解析：从原理到优化实践"},{property:"og:description",content:"在Go语言中，遍历是日常开发中最常见的操作之一。不同的遍历方式会对性能产生显著影响。本文将深入分析Go语言中遍历的性能特点，并探讨如何优化遍历以提高代码效率。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/03.Go%E8%AF%AD%E8%A8%80%E9%81%8D%E5%8E%86%E6%80%A7%E8%83%BD%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-14T10:43:04.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"go语言高性能编程"},{itemprop:"name",content:"Go语言遍历性能深度解析：从原理到优化实践"},{itemprop:"description",content:"在Go语言中，遍历是日常开发中最常见的操作之一。不同的遍历方式会对性能产生显著影响。本文将深入分析Go语言中遍历的性能特点，并探讨如何优化遍历以提高代码效率。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/03.Go%E8%AF%AD%E8%A8%80%E9%81%8D%E5%8E%86%E6%80%A7%E8%83%BD%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5.html",relativePath:"04.编程/02.go语言/07.go语言高性能编程/03.Go语言遍历性能深度解析：从原理到优化实践.md",key:"v-deed5aca",path:"/pages/88360d/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"三种遍历方式对比",slug:"三种遍历方式对比",normalizedTitle:"三种遍历方式对比",charIndex:122},{level:2,title:"[]int Benchmark测试",slug:"int-benchmark测试",normalizedTitle:"[]int benchmark测试",charIndex:372},{level:2,title:"[]struct Benchmark 测试",slug:"struct-benchmark-测试",normalizedTitle:"[]struct benchmark 测试",charIndex:1513},{level:2,title:"[]*struch Benchmark 测试",slug:"struch-benchmark-测试",normalizedTitle:"[]*struch benchmark 测试",charIndex:2836},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:4284}],headersStr:"前言 三种遍历方式对比 []int Benchmark测试 []struct Benchmark 测试 []*struch Benchmark 测试 总结",content:"# 前言\n\n在Go语言中，遍历是日常开发中最常见的操作之一。不同的遍历方式会对性能产生显著影响。本文将深入分析：\n\n 1. 基本切片遍历的性能特点\n 2. 结构体切片的遍历优化\n 3. 指针切片的性能优势\n 4. 实际场景中的最佳实践\n\n\n# 三种遍历方式对比\n\nGo语言中主要有三种遍历切片的方式：\n\n// 1. 索引遍历\nfor i := 0; i < len(slice); i++ {\n    // 使用slice[i]\n}\n\n// 2. range遍历值\nfor _, v := range slice {\n    // 使用v\n}\n\n// 3. range遍历索引和值\nfor i, v := range slice {\n    // 使用i和v\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# []int Benchmark测试\n\nfunc BenchmarkIndexLoop(b *testing.B) {\n    slice := make([]int, 1000)\n    for i := 0; i < b.N; i++ {\n        for j := 0; j < len(slice); j++ {\n            _ = slice[j]\n        }\n    }\n}\n\nfunc BenchmarkRangeValue(b *testing.B) {\n    slice := make([]int, 1000)\n    for i := 0; i < b.N; i++ {\n        for _, v := range slice {\n            _ = v\n        }\n    }\n}\n\nfunc BenchmarkRangeIndexValue(b *testing.B) {\n    slice := make([]int, 1000)\n    for i := 0; i < b.N; i++ {\n        for j, v := range slice {\n            _, _ = j, v\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n测试结果如下，可以发现三者性能接近，基本相差不大。\n\n% go test -bench=. -benchmem .\ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkIndexLoop-12            4721586               235.7 ns/op             0 B/op          0 allocs/op\nBenchmarkRangeValue-12           5085130               234.3 ns/op             0 B/op          0 allocs/op\nBenchmarkRangeIndexValue-12      5101604               233.9 ns/op             0 B/op          0 allocs/op\nPASS\nok      main/demo       4.560s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# []struct Benchmark 测试\n\n\ntype Item struct {\n\tID   int\n\tData [4096]byte // 增加数据量以放大性能差异\n}\n\nfunc BenchmarkStructIndex(b *testing.B) {\n\tvar slice [1000]Item\n\tfor i := 0; i < b.N; i++ {\n\t\tvar tmp int\n\t\tfor j := 0; j < len(slice); j++ {\n\t\t\ttmp = slice[j].ID\n\t\t}\n\t\t_ = tmp\n\t}\n}\n\nfunc BenchmarkStructRangeValue(b *testing.B) {\n\tvar slice [1000]Item\n\tfor i := 0; i < b.N; i++ {\n\t\tvar tmp int\n\t\tfor _, v := range slice {\n\t\t\ttmp = v.ID\n\t\t}\n\t\t_ = tmp\n\t}\n}\n\nfunc BenchmarkStructRangeIndexValue(b *testing.B) {\n\tvar slice [1000]Item\n\tfor i := 0; i < b.N; i++ {\n\t\tvar tmp int\n\t\tfor j := range slice {\n\t\t\ttmp = slice[j].ID\n\t\t}\n\t\t_ = tmp\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n\n\n运行结果如下，可以发现通过索引的方式取值的两种方式相差不大，但是直接取值的方式性能差了 500 多倍，这是因为直接取值时会进行数据的复制，而索引取值不会进行数据的复制。\n\n$ go test  -bench=. -benchmem . \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkStructIndex-12                  4735326               237.9 ns/op             0 B/op          0 allocs/op\nBenchmarkStructRangeValue-12               17096             69135 ns/op               0 B/op          0 allocs/op\nBenchmarkStructRangeIndexValue-12        5123646               234.6 ns/op             0 B/op          0 allocs/op\nPASS\nok      main/demo       4.983s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# []*struch Benchmark 测试\n\n\ntype Item struct {\n\tID   int\n\tData [4096]byte // 增加数据量以放大性能差异\n}\n\nfunc BenchmarkStructIndex(b *testing.B) {\n\tvar slice [1000]*Item\n\tfor i := range slice {\n\t\tslice[i] = &Item{}\n\t}\n\tfor i := 0; i < b.N; i++ {\n\t\tvar tmp int\n\t\tfor j := 0; j < len(slice); j++ {\n\t\t\ttmp = slice[j].ID\n\t\t}\n\t\t_ = tmp\n\t}\n}\n\nfunc BenchmarkStructRangeValue(b *testing.B) {\n\tvar slice [1000]*Item\n\tfor i := range slice {\n\t\tslice[i] = &Item{}\n\t}\n\tfor i := 0; i < b.N; i++ {\n\t\tvar tmp int\n\t\tfor _, v := range slice {\n\t\t\ttmp = v.ID\n\t\t}\n\t\t_ = tmp\n\t}\n}\n\nfunc BenchmarkStructRangeIndexValue(b *testing.B) {\n\tvar slice [1000]*Item\n\tfor i := range slice {\n\t\tslice[i] = &Item{}\n\t}\n\tfor i := 0; i < b.N; i++ {\n\t\tvar tmp int\n\t\tfor j := range slice {\n\t\t\ttmp = slice[j].ID\n\t\t}\n\t\t_ = tmp\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n\n\n运行结果如下，三者性能相近，但是有个好处是可以直接修改指针对应结构体的值。\n\ngo test  -bench=. -benchmem .\ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkStructIndex-12                  1864108               656.9 ns/op             2 B/op          0 allocs/op\nBenchmarkStructRangeValue-12             1577792               748.6 ns/op             3 B/op          0 allocs/op\nBenchmarkStructRangeIndexValue-12        1843874               661.4 ns/op             2 B/op          0 allocs/op\nPASS\nok      main/demo       5.995s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 总结\n\n根据测试结果，我们得出以下结论：\n\n 1. 基础类型切片：三种遍历方式性能相当，可按编码习惯选择\n 2. 大结构体切片：\n    * 避免使用for _, v := range直接值遍历\n    * 优先使用索引遍历或range索引遍历\n 3. 需要修改元素时：\n    * 使用指针切片([]*T)性能接近且更灵活\n 4. 性能关键路径：\n    * 对大结构体集合操作，索引遍历性能最优\n    * 对小结构体或基础类型，差异可忽略\n\n记住：没有绝对的最佳方式，只有最适合当前场景的选择！",normalizedContent:"# 前言\n\n在go语言中，遍历是日常开发中最常见的操作之一。不同的遍历方式会对性能产生显著影响。本文将深入分析：\n\n 1. 基本切片遍历的性能特点\n 2. 结构体切片的遍历优化\n 3. 指针切片的性能优势\n 4. 实际场景中的最佳实践\n\n\n# 三种遍历方式对比\n\ngo语言中主要有三种遍历切片的方式：\n\n// 1. 索引遍历\nfor i := 0; i < len(slice); i++ {\n    // 使用slice[i]\n}\n\n// 2. range遍历值\nfor _, v := range slice {\n    // 使用v\n}\n\n// 3. range遍历索引和值\nfor i, v := range slice {\n    // 使用i和v\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# []int benchmark测试\n\nfunc benchmarkindexloop(b *testing.b) {\n    slice := make([]int, 1000)\n    for i := 0; i < b.n; i++ {\n        for j := 0; j < len(slice); j++ {\n            _ = slice[j]\n        }\n    }\n}\n\nfunc benchmarkrangevalue(b *testing.b) {\n    slice := make([]int, 1000)\n    for i := 0; i < b.n; i++ {\n        for _, v := range slice {\n            _ = v\n        }\n    }\n}\n\nfunc benchmarkrangeindexvalue(b *testing.b) {\n    slice := make([]int, 1000)\n    for i := 0; i < b.n; i++ {\n        for j, v := range slice {\n            _, _ = j, v\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n测试结果如下，可以发现三者性能接近，基本相差不大。\n\n% go test -bench=. -benchmem .\ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkindexloop-12            4721586               235.7 ns/op             0 b/op          0 allocs/op\nbenchmarkrangevalue-12           5085130               234.3 ns/op             0 b/op          0 allocs/op\nbenchmarkrangeindexvalue-12      5101604               233.9 ns/op             0 b/op          0 allocs/op\npass\nok      main/demo       4.560s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# []struct benchmark 测试\n\n\ntype item struct {\n\tid   int\n\tdata [4096]byte // 增加数据量以放大性能差异\n}\n\nfunc benchmarkstructindex(b *testing.b) {\n\tvar slice [1000]item\n\tfor i := 0; i < b.n; i++ {\n\t\tvar tmp int\n\t\tfor j := 0; j < len(slice); j++ {\n\t\t\ttmp = slice[j].id\n\t\t}\n\t\t_ = tmp\n\t}\n}\n\nfunc benchmarkstructrangevalue(b *testing.b) {\n\tvar slice [1000]item\n\tfor i := 0; i < b.n; i++ {\n\t\tvar tmp int\n\t\tfor _, v := range slice {\n\t\t\ttmp = v.id\n\t\t}\n\t\t_ = tmp\n\t}\n}\n\nfunc benchmarkstructrangeindexvalue(b *testing.b) {\n\tvar slice [1000]item\n\tfor i := 0; i < b.n; i++ {\n\t\tvar tmp int\n\t\tfor j := range slice {\n\t\t\ttmp = slice[j].id\n\t\t}\n\t\t_ = tmp\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n\n\n运行结果如下，可以发现通过索引的方式取值的两种方式相差不大，但是直接取值的方式性能差了 500 多倍，这是因为直接取值时会进行数据的复制，而索引取值不会进行数据的复制。\n\n$ go test  -bench=. -benchmem . \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkstructindex-12                  4735326               237.9 ns/op             0 b/op          0 allocs/op\nbenchmarkstructrangevalue-12               17096             69135 ns/op               0 b/op          0 allocs/op\nbenchmarkstructrangeindexvalue-12        5123646               234.6 ns/op             0 b/op          0 allocs/op\npass\nok      main/demo       4.983s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# []*struch benchmark 测试\n\n\ntype item struct {\n\tid   int\n\tdata [4096]byte // 增加数据量以放大性能差异\n}\n\nfunc benchmarkstructindex(b *testing.b) {\n\tvar slice [1000]*item\n\tfor i := range slice {\n\t\tslice[i] = &item{}\n\t}\n\tfor i := 0; i < b.n; i++ {\n\t\tvar tmp int\n\t\tfor j := 0; j < len(slice); j++ {\n\t\t\ttmp = slice[j].id\n\t\t}\n\t\t_ = tmp\n\t}\n}\n\nfunc benchmarkstructrangevalue(b *testing.b) {\n\tvar slice [1000]*item\n\tfor i := range slice {\n\t\tslice[i] = &item{}\n\t}\n\tfor i := 0; i < b.n; i++ {\n\t\tvar tmp int\n\t\tfor _, v := range slice {\n\t\t\ttmp = v.id\n\t\t}\n\t\t_ = tmp\n\t}\n}\n\nfunc benchmarkstructrangeindexvalue(b *testing.b) {\n\tvar slice [1000]*item\n\tfor i := range slice {\n\t\tslice[i] = &item{}\n\t}\n\tfor i := 0; i < b.n; i++ {\n\t\tvar tmp int\n\t\tfor j := range slice {\n\t\t\ttmp = slice[j].id\n\t\t}\n\t\t_ = tmp\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n\n\n运行结果如下，三者性能相近，但是有个好处是可以直接修改指针对应结构体的值。\n\ngo test  -bench=. -benchmem .\ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkstructindex-12                  1864108               656.9 ns/op             2 b/op          0 allocs/op\nbenchmarkstructrangevalue-12             1577792               748.6 ns/op             3 b/op          0 allocs/op\nbenchmarkstructrangeindexvalue-12        1843874               661.4 ns/op             2 b/op          0 allocs/op\npass\nok      main/demo       5.995s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 总结\n\n根据测试结果，我们得出以下结论：\n\n 1. 基础类型切片：三种遍历方式性能相当，可按编码习惯选择\n 2. 大结构体切片：\n    * 避免使用for _, v := range直接值遍历\n    * 优先使用索引遍历或range索引遍历\n 3. 需要修改元素时：\n    * 使用指针切片([]*t)性能接近且更灵活\n 4. 性能关键路径：\n    * 对大结构体集合操作，索引遍历性能最优\n    * 对小结构体或基础类型，差异可忽略\n\n记住：没有绝对的最佳方式，只有最适合当前场景的选择！",charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"Go语言Interface Boxing原理与性能优化指南",frontmatter:{title:"Go语言Interface Boxing原理与性能优化指南",date:"2025-06-14T09:34:09.000Z",permalink:"/pages/49057b/",categories:["编程","go语言","go语言高性能编程"],tags:["go语言","go语言高性能编程"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"深入解析Go语言接口装箱(Boxing)机制，包含性能影响分析、基准测试对比及最佳实践建议",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"Go语言Interface Boxing原理与性能优化指南"},{name:"twitter:description",content:"深入解析Go语言接口装箱(Boxing)机制，包含性能影响分析、基准测试对比及最佳实践建议"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/02.Go%E8%AF%AD%E8%A8%80Interface%20Boxing%E5%8E%9F%E7%90%86%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go语言Interface Boxing原理与性能优化指南"},{property:"og:description",content:"深入解析Go语言接口装箱(Boxing)机制，包含性能影响分析、基准测试对比及最佳实践建议"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/02.Go%E8%AF%AD%E8%A8%80Interface%20Boxing%E5%8E%9F%E7%90%86%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-14T09:34:09.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"go语言高性能编程"},{itemprop:"name",content:"Go语言Interface Boxing原理与性能优化指南"},{itemprop:"description",content:"深入解析Go语言接口装箱(Boxing)机制，包含性能影响分析、基准测试对比及最佳实践建议"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/02.Go%E8%AF%AD%E8%A8%80Interface%20Boxing%E5%8E%9F%E7%90%86%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97.html",relativePath:"04.编程/02.go语言/07.go语言高性能编程/02.Go语言Interface Boxing原理与性能优化指南.md",key:"v-2835a650",path:"/pages/49057b/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"Interface Boxing原理",slug:"interface-boxing原理",normalizedTitle:"interface boxing原理",charIndex:123},{level:2,title:"基础示例分析",slug:"基础示例分析",normalizedTitle:"基础示例分析",charIndex:258},{level:3,title:"值类型赋值",slug:"值类型赋值",normalizedTitle:"值类型赋值",charIndex:269},{level:3,title:"对比具体类型",slug:"对比具体类型",normalizedTitle:"对比具体类型",charIndex:665},{level:2,title:"结构体示例",slug:"结构体示例",normalizedTitle:"结构体示例",charIndex:1241},{level:3,title:"值类型结构体",slug:"值类型结构体",normalizedTitle:"值类型结构体",charIndex:1251},{level:3,title:"指针类型结构体",slug:"指针类型结构体",normalizedTitle:"指针类型结构体",charIndex:1665},{level:2,title:"性能基准测试",slug:"性能基准测试",normalizedTitle:"性能基准测试",charIndex:2176},{level:3,title:"值类型",slug:"值类型",normalizedTitle:"值类型",charIndex:269},{level:3,title:"切片操作性能",slug:"切片操作性能",normalizedTitle:"切片操作性能",charIndex:3087},{level:3,title:"函数调用性能",slug:"函数调用性能",normalizedTitle:"函数调用性能",charIndex:4164},{level:2,title:"什么时候允许Interface Boxing?",slug:"什么时候允许interface-boxing",normalizedTitle:"什么时候允许interface boxing?",charIndex:4876},{level:2,title:"最佳实践",slug:"最佳实践",normalizedTitle:"最佳实践",charIndex:5386}],headersStr:"前言 Interface Boxing原理 基础示例分析 值类型赋值 对比具体类型 结构体示例 值类型结构体 指针类型结构体 性能基准测试 值类型 切片操作性能 函数调用性能 什么时候允许Interface Boxing? 最佳实践",content:'# 前言\n\n在Go语言中，interface{} 是一种强大的抽象机制，但将具体类型赋值给 interface{} (称为Boxing)会带来一定的性能开销。本文将深入分析 interface boxing 的原理、性能影响及优化实践。\n\n\n# Interface Boxing原理\n\n将具体类型的值赋值给interface{}的过程称为Boxing。在这个过程中：\n\n 1. 值会在堆上分配新内存并拷贝\n 2. 将指针及对应类型赋值给interface{}变量\n 3. 这会带来额外性能开销并增加GC压力\n\n\n# 基础示例分析\n\n\n# 值类型赋值\n\n将整型 1 赋值给 interface{} 变量 demo 中\n\nfunc main() {\n\tvar demo interface{}\n\tdemo = 1   // 发生boxing，整型1逃逸到堆\n\tfmt.Println(demo)\n}\n\n\n1\n2\n3\n4\n5\n\n\n运行时添加 -gcflags="-m" 参数，查看逃逸分析的结果。可以看到 1 逃逸到堆中了。\n\n$ go run -gcflags="-m" main.go \n# command-line-arguments\n./main.go:12:13: inlining call to fmt.Println\n./main.go:11:9: 1 escapes to heap\n./main.go:12:13: ... argument does not escape\n1\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 对比具体类型\n\n我们在对比用具体的类型来赋值 1，可以看到是没有逃逸的，但是发现 demo 发生了逃逸到堆，这是为什么呢？\n\nfunc main() {\n\tvar demo int\n\tdemo = 1\n\tfmt.Println(demo)\n}\n\n\n\n1\n2\n3\n4\n5\n6\n\n\n% go run -gcflags="-m" main.go \n# command-line-arguments\n./main.go:12:13: inlining call to fmt.Println\n./main.go:12:13: ... argument does not escape\n./main.go:12:14: demo escapes to heap\n1\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看 fmt.Println 的源码实现可以发现，其参数是 interface{} 类型，将 demo 传参给 Println 时，也会发生 Boxing 过程，也会发生在堆中申请新内存以及复制的过程，所以会发生逃逸。\n\ntype any = interface{}\n\nfunc Println(a ...any) (n int, err error) {\n\treturn Fprintln(os.Stdout, a...)\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 结构体示例\n\n\n# 值类型结构体\n\n将一个结构体赋值给 inteface{}\n\ntype Person struct {\n\tName string\n}\n\nfunc main() {\n\tvar demo interface{}\n\tdemo = Person{}\n\tfmt.Println(demo)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以看到 Person{} 是有发生逃逸的，这里就是发生了 Boxing\n\n$ go run -gcflags="-m" main.go \n# command-line-arguments\n./main.go:12:13: inlining call to fmt.Println\n./main.go:11:15: Person{} escapes to heap\n./main.go:12:13: ... argument does not escape\n{}\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 指针类型结构体\n\n再来看直接将指针赋值给 interface{}\n\ntype Person struct {\n\tName string\n}\n\nfunc main() {\n\tvar demo interface{}\n\tdemo = &Person{}\n\tfmt.Println(demo)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以看到这里依然发生了堆逃逸，这是因为 &Person{} 取地址操作本身就是在堆上申请内存的，然后将地址赋值给 interface{} 的变量，这里是没有发生 boxing 的。\n\ngo run -gcflags="-m" main.go \n# command-line-arguments\n./main.go:12:13: inlining call to fmt.Println\n./main.go:11:9: &Person{} escapes to heap\n./main.go:12:13: ... argument does not escape\n&{}\n\n\n1\n2\n3\n4\n5\n6\n\n\n那么问题来了，这两种方式都会在堆上申请内存，那么两种方式是不是没有区别呢？\n\n\n# 性能基准测试\n\n\n# 值类型\n\nfunc BenchmarkBoxedNotInterface(b *testing.B) {\n\tjobs := make([]int, 0, 1000)\n\tfor range b.N {\n\t\tjobs = jobs[:0]\n\t\tfor j := 0; j < 1000; j++ {\n\t\t\tjobs = append(jobs, j)\n\t\t}\n\t}\n}\n\nfunc BenchmarkBoxedWithInterface(b *testing.B) {\n\tjobs := make([]interface{}, 0, 1000)\n\tfor range b.N {\n\t\tjobs = jobs[:0]\n\t\tfor j := 0; j < 1000; j++ {\n\t\t\tjobs = append(jobs, j)\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\nBenchmarkBoxedNotInterface 完全不需要申请堆内存，并且比 BenchmarkBoxedWithInterface 要快20多倍。\n\n$ go test -bench=. -benchmem\ngoos: darwin\ngoarch: arm64\npkg: code/interface_demo\ncpu: Apple M4 Pro\nBenchmarkBoxedNotInterface-12            4832395               249.5 ns/op             0 B/op          0 allocs/op\nBenchmarkBoxedWithInterface-12            232382              4596 ns/op            5952 B/op        744 allocs/op\nPASS\nok      code/interface_demo     9.662s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 切片操作性能\n\n我们来对上面两种方式来进行 Benchmark 看看两者性能对比。\n\n\ntype Worker interface {\n\tWork()\n}\n\ntype LargeJob struct {\n\tpayload [4096]byte\n}\n\nfunc (LargeJob) Work() {}\n\nfunc BenchmarkBoxedLargeSlice(b *testing.B) {\n\tjobs := make([]Worker, 0, 1000)\n\tfor range b.N {\n\t\tjobs = jobs[:0]\n\t\tfor j := 0; j < 1000; j++ {\n\t\t\tvar job LargeJob\n\t\t\tjobs = append(jobs, job)\n\t\t}\n\t}\n}\n\nfunc BenchmarkPointerLargeSlice(b *testing.B) {\n\tjobs := make([]Worker, 0, 1000)\n\tfor range b.N {\n\t\tjobs := jobs[:0]\n\t\tfor j := 0; j < 1000; j++ {\n\t\t\tjob := &LargeJob{}\n\t\t\tjobs = append(jobs, job)\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n运行结果如下，可以看到两者内存申请是差不多的，但是效率上使用指针的要快上 15%，\n\n$ go test -bench=. -benchmem . \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkBoxedLargeSlice-12                 2935            406307 ns/op         4096014 B/op       1000 allocs/op\nBenchmarkPointerLargeSlice-12               3434            342263 ns/op         4096010 B/op       1000 allocs/op\nPASS\nok      main/demo       3.589s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 函数调用性能\n\n\nvar sink Worker\n\nfunc call(w Worker) {\n\tsink = w\n}\n\nfunc BenchmarkCallWithValue(b *testing.B) {\n\tfor range b.N {\n\t\tvar j LargeJob\n\t\tcall(j)\n\t}\n}\n\nfunc BenchmarkCallWithPointer(b *testing.B) {\n\tfor range b.N {\n\t\tj := &LargeJob{}\n\t\tcall(j)\n\t}\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n运行结果如下，可以看到两者内存申请差不多，但指针传递效率要更高。\n\n% go test -bench=. -benchmem . \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkCallWithValue-12        2959195               388.3 ns/op          4096 B/op          1 allocs/op\nBenchmarkCallWithPointer-12      3513249               339.7 ns/op          4096 B/op          1 allocs/op\nPASS\nok      main/demo       3.419s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 什么时候允许Interface Boxing?\n\n * 接口支持解耦和模块化，所以合理的使用接口来设计 API，即使有 Interface Boxing 的成本也是值得花费的\n\ntype Storage interface {\n    Save([]byte) error\n}\nfunc Process(s Storage) { /* ... */ }\n\n\n1\n2\n3\n4\n\n * 如果值很小，成本也是忽略不计的\n\nvar i interface{}\ni = 123 // safe and cheap\n\n\n1\n2\n\n * 如果只是短暂的使用，开销也是小的\n\n可以看到fmt.Println 中的实现是用接口作为接收参数\n\nfunc Println(a ...any) (n int, err error) {\n\treturn Fprintln(os.Stdout, a...)\n}\n\n\n1\n2\n3\n\n\n这里即使有Interface Boxing，但只是短暂的一次，成本也低。\n\nfmt.Println("value:", someStruct) // implicit boxing is fine\n\n\n1\n\n\n\n# 最佳实践\n\n * 传递给接口时使用指针。可以避免内存的重复复制与申请。\n * 如果设计 API 时，类型已经确定并且是稳定的，尽可能避免使用 interface 。\n * 尽可能使用特定类型的容器。',normalizedContent:'# 前言\n\n在go语言中，interface{} 是一种强大的抽象机制，但将具体类型赋值给 interface{} (称为boxing)会带来一定的性能开销。本文将深入分析 interface boxing 的原理、性能影响及优化实践。\n\n\n# interface boxing原理\n\n将具体类型的值赋值给interface{}的过程称为boxing。在这个过程中：\n\n 1. 值会在堆上分配新内存并拷贝\n 2. 将指针及对应类型赋值给interface{}变量\n 3. 这会带来额外性能开销并增加gc压力\n\n\n# 基础示例分析\n\n\n# 值类型赋值\n\n将整型 1 赋值给 interface{} 变量 demo 中\n\nfunc main() {\n\tvar demo interface{}\n\tdemo = 1   // 发生boxing，整型1逃逸到堆\n\tfmt.println(demo)\n}\n\n\n1\n2\n3\n4\n5\n\n\n运行时添加 -gcflags="-m" 参数，查看逃逸分析的结果。可以看到 1 逃逸到堆中了。\n\n$ go run -gcflags="-m" main.go \n# command-line-arguments\n./main.go:12:13: inlining call to fmt.println\n./main.go:11:9: 1 escapes to heap\n./main.go:12:13: ... argument does not escape\n1\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 对比具体类型\n\n我们在对比用具体的类型来赋值 1，可以看到是没有逃逸的，但是发现 demo 发生了逃逸到堆，这是为什么呢？\n\nfunc main() {\n\tvar demo int\n\tdemo = 1\n\tfmt.println(demo)\n}\n\n\n\n1\n2\n3\n4\n5\n6\n\n\n% go run -gcflags="-m" main.go \n# command-line-arguments\n./main.go:12:13: inlining call to fmt.println\n./main.go:12:13: ... argument does not escape\n./main.go:12:14: demo escapes to heap\n1\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看 fmt.println 的源码实现可以发现，其参数是 interface{} 类型，将 demo 传参给 println 时，也会发生 boxing 过程，也会发生在堆中申请新内存以及复制的过程，所以会发生逃逸。\n\ntype any = interface{}\n\nfunc println(a ...any) (n int, err error) {\n\treturn fprintln(os.stdout, a...)\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 结构体示例\n\n\n# 值类型结构体\n\n将一个结构体赋值给 inteface{}\n\ntype person struct {\n\tname string\n}\n\nfunc main() {\n\tvar demo interface{}\n\tdemo = person{}\n\tfmt.println(demo)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以看到 person{} 是有发生逃逸的，这里就是发生了 boxing\n\n$ go run -gcflags="-m" main.go \n# command-line-arguments\n./main.go:12:13: inlining call to fmt.println\n./main.go:11:15: person{} escapes to heap\n./main.go:12:13: ... argument does not escape\n{}\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 指针类型结构体\n\n再来看直接将指针赋值给 interface{}\n\ntype person struct {\n\tname string\n}\n\nfunc main() {\n\tvar demo interface{}\n\tdemo = &person{}\n\tfmt.println(demo)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以看到这里依然发生了堆逃逸，这是因为 &person{} 取地址操作本身就是在堆上申请内存的，然后将地址赋值给 interface{} 的变量，这里是没有发生 boxing 的。\n\ngo run -gcflags="-m" main.go \n# command-line-arguments\n./main.go:12:13: inlining call to fmt.println\n./main.go:11:9: &person{} escapes to heap\n./main.go:12:13: ... argument does not escape\n&{}\n\n\n1\n2\n3\n4\n5\n6\n\n\n那么问题来了，这两种方式都会在堆上申请内存，那么两种方式是不是没有区别呢？\n\n\n# 性能基准测试\n\n\n# 值类型\n\nfunc benchmarkboxednotinterface(b *testing.b) {\n\tjobs := make([]int, 0, 1000)\n\tfor range b.n {\n\t\tjobs = jobs[:0]\n\t\tfor j := 0; j < 1000; j++ {\n\t\t\tjobs = append(jobs, j)\n\t\t}\n\t}\n}\n\nfunc benchmarkboxedwithinterface(b *testing.b) {\n\tjobs := make([]interface{}, 0, 1000)\n\tfor range b.n {\n\t\tjobs = jobs[:0]\n\t\tfor j := 0; j < 1000; j++ {\n\t\t\tjobs = append(jobs, j)\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\nbenchmarkboxednotinterface 完全不需要申请堆内存，并且比 benchmarkboxedwithinterface 要快20多倍。\n\n$ go test -bench=. -benchmem\ngoos: darwin\ngoarch: arm64\npkg: code/interface_demo\ncpu: apple m4 pro\nbenchmarkboxednotinterface-12            4832395               249.5 ns/op             0 b/op          0 allocs/op\nbenchmarkboxedwithinterface-12            232382              4596 ns/op            5952 b/op        744 allocs/op\npass\nok      code/interface_demo     9.662s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 切片操作性能\n\n我们来对上面两种方式来进行 benchmark 看看两者性能对比。\n\n\ntype worker interface {\n\twork()\n}\n\ntype largejob struct {\n\tpayload [4096]byte\n}\n\nfunc (largejob) work() {}\n\nfunc benchmarkboxedlargeslice(b *testing.b) {\n\tjobs := make([]worker, 0, 1000)\n\tfor range b.n {\n\t\tjobs = jobs[:0]\n\t\tfor j := 0; j < 1000; j++ {\n\t\t\tvar job largejob\n\t\t\tjobs = append(jobs, job)\n\t\t}\n\t}\n}\n\nfunc benchmarkpointerlargeslice(b *testing.b) {\n\tjobs := make([]worker, 0, 1000)\n\tfor range b.n {\n\t\tjobs := jobs[:0]\n\t\tfor j := 0; j < 1000; j++ {\n\t\t\tjob := &largejob{}\n\t\t\tjobs = append(jobs, job)\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n运行结果如下，可以看到两者内存申请是差不多的，但是效率上使用指针的要快上 15%，\n\n$ go test -bench=. -benchmem . \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkboxedlargeslice-12                 2935            406307 ns/op         4096014 b/op       1000 allocs/op\nbenchmarkpointerlargeslice-12               3434            342263 ns/op         4096010 b/op       1000 allocs/op\npass\nok      main/demo       3.589s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 函数调用性能\n\n\nvar sink worker\n\nfunc call(w worker) {\n\tsink = w\n}\n\nfunc benchmarkcallwithvalue(b *testing.b) {\n\tfor range b.n {\n\t\tvar j largejob\n\t\tcall(j)\n\t}\n}\n\nfunc benchmarkcallwithpointer(b *testing.b) {\n\tfor range b.n {\n\t\tj := &largejob{}\n\t\tcall(j)\n\t}\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n运行结果如下，可以看到两者内存申请差不多，但指针传递效率要更高。\n\n% go test -bench=. -benchmem . \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkcallwithvalue-12        2959195               388.3 ns/op          4096 b/op          1 allocs/op\nbenchmarkcallwithpointer-12      3513249               339.7 ns/op          4096 b/op          1 allocs/op\npass\nok      main/demo       3.419s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 什么时候允许interface boxing?\n\n * 接口支持解耦和模块化，所以合理的使用接口来设计 api，即使有 interface boxing 的成本也是值得花费的\n\ntype storage interface {\n    save([]byte) error\n}\nfunc process(s storage) { /* ... */ }\n\n\n1\n2\n3\n4\n\n * 如果值很小，成本也是忽略不计的\n\nvar i interface{}\ni = 123 // safe and cheap\n\n\n1\n2\n\n * 如果只是短暂的使用，开销也是小的\n\n可以看到fmt.println 中的实现是用接口作为接收参数\n\nfunc println(a ...any) (n int, err error) {\n\treturn fprintln(os.stdout, a...)\n}\n\n\n1\n2\n3\n\n\n这里即使有interface boxing，但只是短暂的一次，成本也低。\n\nfmt.println("value:", somestruct) // implicit boxing is fine\n\n\n1\n\n\n\n# 最佳实践\n\n * 传递给接口时使用指针。可以避免内存的重复复制与申请。\n * 如果设计 api 时，类型已经确定并且是稳定的，尽可能避免使用 interface 。\n * 尽可能使用特定类型的容器。',charsets:{cjk:!0},lastUpdated:"2025/09/22, 16:52:15",lastUpdatedTimestamp:1758531135e3},{title:"Go语言零拷贝技术完全指南",frontmatter:{title:"Go语言零拷贝技术完全指南",date:"2025-06-14T11:42:51.000Z",permalink:"/pages/4f7497/",categories:["编程","go语言","go语言高性能编程"],tags:["go语言","go语言高性能编程"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"深入解析Go语言中零拷贝技术的实现原理、性能优势及最佳实践，包含详细基准测试数据和实际应用场景分析",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17498741316891749874131178.png"},{name:"twitter:title",content:"Go语言零拷贝技术完全指南"},{name:"twitter:description",content:"深入解析Go语言中零拷贝技术的实现原理、性能优势及最佳实践，包含详细基准测试数据和实际应用场景分析"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17498741316891749874131178.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/04.Go%E8%AF%AD%E8%A8%80%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%8A%80%E6%9C%AF%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go语言零拷贝技术完全指南"},{property:"og:description",content:"深入解析Go语言中零拷贝技术的实现原理、性能优势及最佳实践，包含详细基准测试数据和实际应用场景分析"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17498741316891749874131178.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/04.Go%E8%AF%AD%E8%A8%80%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%8A%80%E6%9C%AF%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-14T11:42:51.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"go语言高性能编程"},{itemprop:"name",content:"Go语言零拷贝技术完全指南"},{itemprop:"description",content:"深入解析Go语言中零拷贝技术的实现原理、性能优势及最佳实践，包含详细基准测试数据和实际应用场景分析"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17498741316891749874131178.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/04.Go%E8%AF%AD%E8%A8%80%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%8A%80%E6%9C%AF%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97.html",relativePath:"04.编程/02.go语言/07.go语言高性能编程/04.Go语言零拷贝技术完全指南.md",key:"v-1c8f04f0",path:"/pages/4f7497/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"io.CopyBuffer",slug:"io-copybuffer",normalizedTitle:"io.copybuffer",charIndex:181},{level:2,title:"高效数据访问切片",slug:"高效数据访问切片",normalizedTitle:"高效数据访问切片",charIndex:456},{level:2,title:"mmap",slug:"mmap",normalizedTitle:"mmap",charIndex:1438},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:3011}],headersStr:"前言 io.CopyBuffer 高效数据访问切片 mmap 总结",content:'# 前言\n\n零拷贝(Zero-Copy)是高性能编程中的关键技术，它通过避免不必要的数据复制，可以显著提升I/O密集型应用的性能。本文将深入探讨：\n\n * 零拷贝的核心原理与优势\n * Go语言中实现零拷贝的三种主要方式\n * 实际场景中的性能对比数据\n * 如何根据业务场景选择最佳方案\n\n通过本文，你将掌握如何在自己的项目中应用这些技术来提升性能。\n\n\n# io.CopyBuffer\n\n在读写时使用 io.Reader 和 io.Writer 接口时，可以使用 io.CopyBuffer 来提供重复使用的缓存区，避免了重复的分配中间的缓存。\n\nfunc StreamData(src io.Reader, dst io.Writer) error {\n    buf := make([]byte, 4096) // Reusable buffer\n    _, err := io.CopyBuffer(dst, src, buf)\n    return err\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 高效数据访问切片\n\n切片的底层是一个数组，所以基于该数组返回一个切片可以减少内存的拷贝，而不是将切片拷贝到一个新的切片中\n\nfunc process(buffer []byte) []byte {\n    return buffer[128:256] // returns a slice reference without copying\n}\n\n\n1\n2\n3\n\n\nBenchmark\n\n针对显示复制和零复制切片的性能基准测试比较\n\nfunc BenchmarkCopy(b *testing.B) {\n\tdata := make([]byte, 64*1024)\n\tfor range b.N {\n\t\tbuf := make([]byte, len(data))\n\t\tcopy(buf, data)\n\t}\n}\n\nfunc BenchmarkSlice(b *testing.B) {\n\tdata := make([]byte, 64*1024)\n\tfor range b.N {\n\t\t_ = data[:]\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n运行结果如下，BenchmarkCopy 每次都会分配新的内存，并进行数据的复制操作，而 BenchmarkSlice都是对相同的数组进行切片，没有任何的分配内存和复制数据的操作，BenchmarkSlice无论是运行还是内存上都优于 BenchmarkCopy\n\n$ go test -bench=. -benchmem .  \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkCopy-12          356439              3546 ns/op           65536 B/op          1 allocs/op\nBenchmarkSlice-12       1000000000               0.2336 ns/op          0 B/op          0 allocs/op\nPASS\nok      main/demo       2.918s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# mmap\n\n正常读取文件时，是需要将磁盘中的文件读取到内核空间，再复制到用户空间进行访问。\n\n\n\n而使用mmap的方式，是直接将磁盘中的文件映射到内存中直接访问，减少了将内核空间与用户空间数据的复制。\n\n\n\n代码示例\n\nimport "golang.org/x/exp/mmap"\n\nfunc ReadFileZeroCopy(path string) ([]byte, error) {\n    r, err := mmap.Open(path)\n    if err != nil {\n        return nil, err\n    }\n    defer r.Close()\n\n    data := make([]byte, r.Len())\n    _, err = r.ReadAt(data, 0)\n    return data, err\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n基准测试\n\n使用 os.Open 和 mmap.Open 对 5M 文件的读取性能的基准测试。\n\nfunc BenchmarkReadWithCopy(b *testing.B) {\n\tf, err := os.Open("./5MB.bin")\n\tif err != nil {\n\t\tb.Fatalf("failed to open file: %v", err)\n\t}\n\tdefer f.Close()\n\n\tbuf := make([]byte, 4*1024*1024) // 4MB buffer\n\tfor range b.N {\n\t\t_, err := f.ReadAt(buf, 0)\n\t\tif err != nil && err != io.EOF {\n\t\t\tb.Fatal(err)\n\t\t}\n\t}\n}\n\nfunc BenchmarkReadWithMmap(b *testing.B) {\n\tr, err := mmap.Open("./5MB.bin")\n\tif err != nil {\n\t\tb.Fatalf("failed to mmap file: %v", err)\n\t}\n\tdefer r.Close()\n\n\tbuf := make([]byte, r.Len())\n\tfor range b.N {\n\t\t_, err := r.ReadAt(buf, 0)\n\t\tif err != nil && err != io.EOF {\n\t\t\tb.Fatal(err)\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n运行结果如下，使用mmap比标准读要快不少，内存申请上也要少。\n\n$ go test -bench=. -benchmem .              \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkReadWithCopy-12           13136             90918 ns/op             319 B/op          0 allocs/op\nBenchmarkReadWithMmap-12           19350             65262 ns/op             270 B/op          0 allocs/op\nPASS\nok      main/demo       7.067s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 总结\n\n根据测试结果，我们得出以下结论：\n\n 1. 缓冲区重用：\n    \n    * 使用io.CopyBuffer重用缓冲区\n    * 适合流式数据传输场景\n\n 2. 切片操作：\n    \n    * 优先使用切片引用而非完整复制\n    * 特别适合大块数据处理\n\n 3. 文件读取：\n    \n    * 大文件处理优先考虑mmap\n    * 注意mmap的内存映射特性\n\n 4. 适用场景：\n    \n    * 高吞吐量网络应用\n    * 大文件处理\n    * 内存敏感型应用\n\n记住：零拷贝虽好，但也要考虑代码可读性和维护成本，在性能关键路径上使用效果最佳！',normalizedContent:'# 前言\n\n零拷贝(zero-copy)是高性能编程中的关键技术，它通过避免不必要的数据复制，可以显著提升i/o密集型应用的性能。本文将深入探讨：\n\n * 零拷贝的核心原理与优势\n * go语言中实现零拷贝的三种主要方式\n * 实际场景中的性能对比数据\n * 如何根据业务场景选择最佳方案\n\n通过本文，你将掌握如何在自己的项目中应用这些技术来提升性能。\n\n\n# io.copybuffer\n\n在读写时使用 io.reader 和 io.writer 接口时，可以使用 io.copybuffer 来提供重复使用的缓存区，避免了重复的分配中间的缓存。\n\nfunc streamdata(src io.reader, dst io.writer) error {\n    buf := make([]byte, 4096) // reusable buffer\n    _, err := io.copybuffer(dst, src, buf)\n    return err\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 高效数据访问切片\n\n切片的底层是一个数组，所以基于该数组返回一个切片可以减少内存的拷贝，而不是将切片拷贝到一个新的切片中\n\nfunc process(buffer []byte) []byte {\n    return buffer[128:256] // returns a slice reference without copying\n}\n\n\n1\n2\n3\n\n\nbenchmark\n\n针对显示复制和零复制切片的性能基准测试比较\n\nfunc benchmarkcopy(b *testing.b) {\n\tdata := make([]byte, 64*1024)\n\tfor range b.n {\n\t\tbuf := make([]byte, len(data))\n\t\tcopy(buf, data)\n\t}\n}\n\nfunc benchmarkslice(b *testing.b) {\n\tdata := make([]byte, 64*1024)\n\tfor range b.n {\n\t\t_ = data[:]\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n运行结果如下，benchmarkcopy 每次都会分配新的内存，并进行数据的复制操作，而 benchmarkslice都是对相同的数组进行切片，没有任何的分配内存和复制数据的操作，benchmarkslice无论是运行还是内存上都优于 benchmarkcopy\n\n$ go test -bench=. -benchmem .  \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkcopy-12          356439              3546 ns/op           65536 b/op          1 allocs/op\nbenchmarkslice-12       1000000000               0.2336 ns/op          0 b/op          0 allocs/op\npass\nok      main/demo       2.918s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# mmap\n\n正常读取文件时，是需要将磁盘中的文件读取到内核空间，再复制到用户空间进行访问。\n\n\n\n而使用mmap的方式，是直接将磁盘中的文件映射到内存中直接访问，减少了将内核空间与用户空间数据的复制。\n\n\n\n代码示例\n\nimport "golang.org/x/exp/mmap"\n\nfunc readfilezerocopy(path string) ([]byte, error) {\n    r, err := mmap.open(path)\n    if err != nil {\n        return nil, err\n    }\n    defer r.close()\n\n    data := make([]byte, r.len())\n    _, err = r.readat(data, 0)\n    return data, err\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n基准测试\n\n使用 os.open 和 mmap.open 对 5m 文件的读取性能的基准测试。\n\nfunc benchmarkreadwithcopy(b *testing.b) {\n\tf, err := os.open("./5mb.bin")\n\tif err != nil {\n\t\tb.fatalf("failed to open file: %v", err)\n\t}\n\tdefer f.close()\n\n\tbuf := make([]byte, 4*1024*1024) // 4mb buffer\n\tfor range b.n {\n\t\t_, err := f.readat(buf, 0)\n\t\tif err != nil && err != io.eof {\n\t\t\tb.fatal(err)\n\t\t}\n\t}\n}\n\nfunc benchmarkreadwithmmap(b *testing.b) {\n\tr, err := mmap.open("./5mb.bin")\n\tif err != nil {\n\t\tb.fatalf("failed to mmap file: %v", err)\n\t}\n\tdefer r.close()\n\n\tbuf := make([]byte, r.len())\n\tfor range b.n {\n\t\t_, err := r.readat(buf, 0)\n\t\tif err != nil && err != io.eof {\n\t\t\tb.fatal(err)\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n运行结果如下，使用mmap比标准读要快不少，内存申请上也要少。\n\n$ go test -bench=. -benchmem .              \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkreadwithcopy-12           13136             90918 ns/op             319 b/op          0 allocs/op\nbenchmarkreadwithmmap-12           19350             65262 ns/op             270 b/op          0 allocs/op\npass\nok      main/demo       7.067s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 总结\n\n根据测试结果，我们得出以下结论：\n\n 1. 缓冲区重用：\n    \n    * 使用io.copybuffer重用缓冲区\n    * 适合流式数据传输场景\n\n 2. 切片操作：\n    \n    * 优先使用切片引用而非完整复制\n    * 特别适合大块数据处理\n\n 3. 文件读取：\n    \n    * 大文件处理优先考虑mmap\n    * 注意mmap的内存映射特性\n\n 4. 适用场景：\n    \n    * 高吞吐量网络应用\n    * 大文件处理\n    * 内存敏感型应用\n\n记住：零拷贝虽好，但也要考虑代码可读性和维护成本，在性能关键路径上使用效果最佳！',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"Go语言不可变数据共享：无锁并发编程实践",frontmatter:{title:"Go语言不可变数据共享：无锁并发编程实践",date:"2025-06-14T14:06:39.000Z",permalink:"/pages/b03207/",categories:["编程","go语言","go语言高性能编程"],tags:["go语言","go语言高性能编程"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"深入解析Go语言中不可变数据共享模式的实现原理、性能优势及最佳实践",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"Go语言不可变数据共享：无锁并发编程实践"},{name:"twitter:description",content:"深入解析Go语言中不可变数据共享模式的实现原理、性能优势及最佳实践"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/05.Go%E8%AF%AD%E8%A8%80%E4%B8%8D%E5%8F%AF%E5%8F%98%E6%95%B0%E6%8D%AE%E5%85%B1%E4%BA%AB%EF%BC%9A%E6%97%A0%E9%94%81%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go语言不可变数据共享：无锁并发编程实践"},{property:"og:description",content:"深入解析Go语言中不可变数据共享模式的实现原理、性能优势及最佳实践"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/05.Go%E8%AF%AD%E8%A8%80%E4%B8%8D%E5%8F%AF%E5%8F%98%E6%95%B0%E6%8D%AE%E5%85%B1%E4%BA%AB%EF%BC%9A%E6%97%A0%E9%94%81%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-14T14:06:39.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"go语言高性能编程"},{itemprop:"name",content:"Go语言不可变数据共享：无锁并发编程实践"},{itemprop:"description",content:"深入解析Go语言中不可变数据共享模式的实现原理、性能优势及最佳实践"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/05.Go%E8%AF%AD%E8%A8%80%E4%B8%8D%E5%8F%AF%E5%8F%98%E6%95%B0%E6%8D%AE%E5%85%B1%E4%BA%AB%EF%BC%9A%E6%97%A0%E9%94%81%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5.html",relativePath:"04.编程/02.go语言/07.go语言高性能编程/05.Go语言不可变数据共享：无锁并发编程实践.md",key:"v-e7a69188",path:"/pages/b03207/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"案例一：共享配置",slug:"案例一-共享配置",normalizedTitle:"案例一：共享配置",charIndex:93},{level:2,title:"案例二：不可变路由表",slug:"案例二-不可变路由表",normalizedTitle:"案例二：不可变路由表",charIndex:1280},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:2285}],headersStr:"前言 案例一：共享配置 案例二：不可变路由表 总结",content:'# 前言\n\n对共享数据的并发访问往往需要用到锁，而这是一个常见的性能瓶颈。而不可变数据共享式一种不需要用锁来保护共享数据的方式，创建后的数据永远不改变，这样就不会有竞争问题了。\n\n\n# 案例一：共享配置\n\n 1. 创建配置结构体\n\n// config.go\ntype Config struct {\n    LogLevel string\n    Timeout  time.Duration\n    Features map[string]bool // 必须深拷贝，原始map的修改会影响已创建的配置\n}\n\n\n1\n2\n3\n4\n5\n6\n\n 2. 每次获取配置都是独立的\n\nfunc NewConfig(logLevel string, timeout time.Duration, features map[string]bool) *Config {\n    copiedFeatures := make(map[string]bool, len(features))\n    for k, v := range features {\n        copiedFeatures[k] = v\n    }\n\n    return &Config{\n        LogLevel: logLevel,\n        Timeout:  timeout,\n        Features: copiedFeatures,\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n 3. 使用 atomic.Value 来存储并安全的更新当前配置\n\nvar currentConfig atomic.Pointer[Config] // Go 1.19+ 特性\n\n// LoadInitialConfig 初始化配置（必须保证线程安全）\nfunc LoadInitialConfig() {\n    cfg := NewConfig("info", 5*time.Second, map[string]bool{"beta": true})\n    currentConfig.Store(cfg) // 原子存储初始配置\n}\n\n// GetConfig 安全获取当前配置（零锁消耗）\nfunc GetConfig() *Config {\n    return currentConfig.Load() // 原子加载指针\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n 4. 在处理程序中使用\n\nfunc handler(w http.ResponseWriter, r *http.Request) {\n    cfg := GetConfig()\n    if cfg.Features["beta"] {\n        // Enable beta path\n    }\n    // Use cfg.Timeout, cfg.LogLevel, etc.\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 案例二：不可变路由表\n\n 1. 创建路由结构体\n\ntype Route struct {\n    Path    string\n    Backend string\n}\n\ntype RoutingTable struct {\n    Routes []Route\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 2. 每次获取都是全新版本\n\n‍func NewRoutingTable(routes []Route) *RoutingTable {\n    copied := make([]Route, len(routes))\n    copy(copied, routes)\n    return &RoutingTable{Routes: copied}\n}\n\n\n1\n2\n3\n4\n5\n\n 3. 以原子的方式存储及修改\n\nvar currentRoutes atomic.Pointer[RoutingTable]\n\nfunc LoadInitialRoutes() {\n    table := NewRoutingTable([]Route{\n        {Path: "/api", Backend: "http://api.internal"},\n        {Path: "/admin", Backend: "http://admin.internal"},\n    })\n    currentRoutes.Store(table)\n}\n\nfunc GetRoutingTable() *RoutingTable {\n    return currentRoutes.Load()\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n 4. 并发路由请求\n\nfunc routeRequest(path string) string {\n    table := GetRoutingTable()\n    for _, route := range table.Routes {\n        if strings.HasPrefix(path, route.Path) {\n            return route.Backend\n        }\n    }\n    return ""\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 总结\n\n应用场景\n\n * 读多写少：配置信息、路由表等低频变更数据\n * 高性能要求：需要避免锁竞争的热点路径\n\n注意事项\n\n * 深拷贝成本：当数据结构复杂时（嵌套map/slice），需要考虑拷贝性能\n * 内存消耗：每次更新都会创建新对象，需权衡内存与性能\n * 原子性保证：更新操作必须完全替换配置对象，避免部分更新',normalizedContent:'# 前言\n\n对共享数据的并发访问往往需要用到锁，而这是一个常见的性能瓶颈。而不可变数据共享式一种不需要用锁来保护共享数据的方式，创建后的数据永远不改变，这样就不会有竞争问题了。\n\n\n# 案例一：共享配置\n\n 1. 创建配置结构体\n\n// config.go\ntype config struct {\n    loglevel string\n    timeout  time.duration\n    features map[string]bool // 必须深拷贝，原始map的修改会影响已创建的配置\n}\n\n\n1\n2\n3\n4\n5\n6\n\n 2. 每次获取配置都是独立的\n\nfunc newconfig(loglevel string, timeout time.duration, features map[string]bool) *config {\n    copiedfeatures := make(map[string]bool, len(features))\n    for k, v := range features {\n        copiedfeatures[k] = v\n    }\n\n    return &config{\n        loglevel: loglevel,\n        timeout:  timeout,\n        features: copiedfeatures,\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n 3. 使用 atomic.value 来存储并安全的更新当前配置\n\nvar currentconfig atomic.pointer[config] // go 1.19+ 特性\n\n// loadinitialconfig 初始化配置（必须保证线程安全）\nfunc loadinitialconfig() {\n    cfg := newconfig("info", 5*time.second, map[string]bool{"beta": true})\n    currentconfig.store(cfg) // 原子存储初始配置\n}\n\n// getconfig 安全获取当前配置（零锁消耗）\nfunc getconfig() *config {\n    return currentconfig.load() // 原子加载指针\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n 4. 在处理程序中使用\n\nfunc handler(w http.responsewriter, r *http.request) {\n    cfg := getconfig()\n    if cfg.features["beta"] {\n        // enable beta path\n    }\n    // use cfg.timeout, cfg.loglevel, etc.\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 案例二：不可变路由表\n\n 1. 创建路由结构体\n\ntype route struct {\n    path    string\n    backend string\n}\n\ntype routingtable struct {\n    routes []route\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 2. 每次获取都是全新版本\n\n‍func newroutingtable(routes []route) *routingtable {\n    copied := make([]route, len(routes))\n    copy(copied, routes)\n    return &routingtable{routes: copied}\n}\n\n\n1\n2\n3\n4\n5\n\n 3. 以原子的方式存储及修改\n\nvar currentroutes atomic.pointer[routingtable]\n\nfunc loadinitialroutes() {\n    table := newroutingtable([]route{\n        {path: "/api", backend: "http://api.internal"},\n        {path: "/admin", backend: "http://admin.internal"},\n    })\n    currentroutes.store(table)\n}\n\nfunc getroutingtable() *routingtable {\n    return currentroutes.load()\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n 4. 并发路由请求\n\nfunc routerequest(path string) string {\n    table := getroutingtable()\n    for _, route := range table.routes {\n        if strings.hasprefix(path, route.path) {\n            return route.backend\n        }\n    }\n    return ""\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 总结\n\n应用场景\n\n * 读多写少：配置信息、路由表等低频变更数据\n * 高性能要求：需要避免锁竞争的热点路径\n\n注意事项\n\n * 深拷贝成本：当数据结构复杂时（嵌套map/slice），需要考虑拷贝性能\n * 内存消耗：每次更新都会创建新对象，需权衡内存与性能\n * 原子性保证：更新操作必须完全替换配置对象，避免部分更新',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:24:58",lastUpdatedTimestamp:1749918298e3},{title:"Go语言内存预分配完全指南",frontmatter:{title:"Go语言内存预分配完全指南",date:"2025-06-14T14:51:20.000Z",permalink:"/pages/d7dbc7/",categories:["编程","go语言","go语言高性能编程"],tags:["go语言","go语言高性能编程"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"深入解析Go语言中Slice和Map的内存预分配技术，包含性能对比测试和实际应用场景分析",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17584416417421758441641274.png"},{name:"twitter:title",content:"Go语言内存预分配完全指南"},{name:"twitter:description",content:"深入解析Go语言中Slice和Map的内存预分配技术，包含性能对比测试和实际应用场景分析"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17584416417421758441641274.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/06.Go%E8%AF%AD%E8%A8%80%E5%86%85%E5%AD%98%E9%A2%84%E5%88%86%E9%85%8D%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go语言内存预分配完全指南"},{property:"og:description",content:"深入解析Go语言中Slice和Map的内存预分配技术，包含性能对比测试和实际应用场景分析"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17584416417421758441641274.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/06.Go%E8%AF%AD%E8%A8%80%E5%86%85%E5%AD%98%E9%A2%84%E5%88%86%E9%85%8D%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-14T14:51:20.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"go语言高性能编程"},{itemprop:"name",content:"Go语言内存预分配完全指南"},{itemprop:"description",content:"深入解析Go语言中Slice和Map的内存预分配技术，包含性能对比测试和实际应用场景分析"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17584416417421758441641274.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/06.Go%E8%AF%AD%E8%A8%80%E5%86%85%E5%AD%98%E9%A2%84%E5%88%86%E9%85%8D%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97.html",relativePath:"04.编程/02.go语言/07.go语言高性能编程/06.Go语言内存预分配完全指南.md",key:"v-2bccd8fe",path:"/pages/d7dbc7/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"Slice 预分配",slug:"slice-预分配",normalizedTitle:"slice 预分配",charIndex:89},{level:2,title:"Benchmark",slug:"benchmark",normalizedTitle:"benchmark",charIndex:643},{level:2,title:"Map 预分配",slug:"map-预分配",normalizedTitle:"map 预分配",charIndex:1489},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:1668}],headersStr:"前言 Slice 预分配 Benchmark Map 预分配 总结",content:'# 前言\n\nSlice 和 Map 会动态的扩展来适用新的元素数量，空间不足时是会进行分配新的内存、复制、以及旧内存的回收操作，而频繁的调整大小的操作会显著的降低性能。\n\n\n# Slice 预分配\n\n没有指定长度的创建一个切片， 切片不断地新增元素时，可以看到其容量也是在不断地递增，我们知道切片的底层是数组，是不可变的，所以它会不断地创建的新的数组，然后元素的内容复制到新的数组中，从而导致内存的分配、复制和 GC 的压力。\n\n\n\nimport "fmt"\n\nfunc main() {\n\tvar result []int\n    s := make([]int, 0)\n\tfor i := 0; i < 1000; i++ {\n\t\ts = append(s, i)\n\t\tfmt.Printf("Len: %d, Cap: %d\\n", len(s), cap(s))\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n运行输出：\n\nLen: 1, Cap: 1\nLen: 2, Cap: 2\nLen: 3, Cap: 4\nLen: 4, Cap: 4\nLen: 5, Cap: 8\n\n\n1\n2\n3\n4\n5\n\n\n而我们指定切片的大小，则可以避免以上压力。\n\nresult := make([]int, 0, 1000)\nfor i := 0; i < 10000; i++ {\n    result = append(result, i)\n}\n\n\n1\n2\n3\n4\n\n\n\n# Benchmark\n\nimport (\n\t"testing"\n)\n\nfunc BenchmarkAppendNoPrealloc(b *testing.B) {\n\tfor range b.N {\n\t\tvar s []int\n\t\tfor j := 0; j < 10000; j++ {\n\t\t\ts = append(s, j)\n\t\t}\n\t}\n}\n\nfunc BenchmarkAppendWithPrealloc(b *testing.B) {\n\tfor range b.N {\n\t\ts := make([]int, 0, 10000)\n\t\tfor j := 0; j < 10000; j++ {\n\t\t\ts = append(s, j)\n\t\t}\n\t}\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n运行结果如下，可以看到吞吐量变大了，速度快了近 4 倍，内存分配的大小和次数变少了。\n\n$ go test -bench=. -benchmem .                              \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkAppendNoPrealloc-12               44973             24788 ns/op          357628 B/op         19 allocs/op\nBenchmarkAppendWithPrealloc-12            185312              6448 ns/op           81920 B/op          1 allocs/op\nPASS\nok      main/demo       5.005s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Map 预分配\n\nMap 底层是一个哈希表，也是一个类似于数组的结构，所以我们也可以使用make来对其进行大小的初始化操作。\n\nm := make(map[int]string, 10000)\nfor i := 0; i < 10000; i++ {\n    m[i] = fmt.Sprintf("val-%d", i)\n}\n\n\n1\n2\n3\n4\n\n\n\n# 总结\n\n应用场景\n\n * Slice 和 Map 的数量已知或者可预测时。\n * 程序是一个高吞吐量数据处理的服务。\n\n注意事项\n\n数据数量变化很大不可以预测。过度的分配会导致大量的内存浪费。',normalizedContent:'# 前言\n\nslice 和 map 会动态的扩展来适用新的元素数量，空间不足时是会进行分配新的内存、复制、以及旧内存的回收操作，而频繁的调整大小的操作会显著的降低性能。\n\n\n# slice 预分配\n\n没有指定长度的创建一个切片， 切片不断地新增元素时，可以看到其容量也是在不断地递增，我们知道切片的底层是数组，是不可变的，所以它会不断地创建的新的数组，然后元素的内容复制到新的数组中，从而导致内存的分配、复制和 gc 的压力。\n\n\n\nimport "fmt"\n\nfunc main() {\n\tvar result []int\n    s := make([]int, 0)\n\tfor i := 0; i < 1000; i++ {\n\t\ts = append(s, i)\n\t\tfmt.printf("len: %d, cap: %d\\n", len(s), cap(s))\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n运行输出：\n\nlen: 1, cap: 1\nlen: 2, cap: 2\nlen: 3, cap: 4\nlen: 4, cap: 4\nlen: 5, cap: 8\n\n\n1\n2\n3\n4\n5\n\n\n而我们指定切片的大小，则可以避免以上压力。\n\nresult := make([]int, 0, 1000)\nfor i := 0; i < 10000; i++ {\n    result = append(result, i)\n}\n\n\n1\n2\n3\n4\n\n\n\n# benchmark\n\nimport (\n\t"testing"\n)\n\nfunc benchmarkappendnoprealloc(b *testing.b) {\n\tfor range b.n {\n\t\tvar s []int\n\t\tfor j := 0; j < 10000; j++ {\n\t\t\ts = append(s, j)\n\t\t}\n\t}\n}\n\nfunc benchmarkappendwithprealloc(b *testing.b) {\n\tfor range b.n {\n\t\ts := make([]int, 0, 10000)\n\t\tfor j := 0; j < 10000; j++ {\n\t\t\ts = append(s, j)\n\t\t}\n\t}\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n运行结果如下，可以看到吞吐量变大了，速度快了近 4 倍，内存分配的大小和次数变少了。\n\n$ go test -bench=. -benchmem .                              \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkappendnoprealloc-12               44973             24788 ns/op          357628 b/op         19 allocs/op\nbenchmarkappendwithprealloc-12            185312              6448 ns/op           81920 b/op          1 allocs/op\npass\nok      main/demo       5.005s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# map 预分配\n\nmap 底层是一个哈希表，也是一个类似于数组的结构，所以我们也可以使用make来对其进行大小的初始化操作。\n\nm := make(map[int]string, 10000)\nfor i := 0; i < 10000; i++ {\n    m[i] = fmt.sprintf("val-%d", i)\n}\n\n\n1\n2\n3\n4\n\n\n\n# 总结\n\n应用场景\n\n * slice 和 map 的数量已知或者可预测时。\n * 程序是一个高吞吐量数据处理的服务。\n\n注意事项\n\n数据数量变化很大不可以预测。过度的分配会导致大量的内存浪费。',charsets:{cjk:!0},lastUpdated:"2025/09/22, 16:52:15",lastUpdatedTimestamp:1758531135e3},{title:"Go语言原子操作完全指南",frontmatter:{title:"Go语言原子操作完全指南",date:"2025-06-14T15:02:33.000Z",permalink:"/pages/821b25/",categories:["编程","go语言","go语言高性能编程"],tags:["go语言","go语言高性能编程"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"深入解析Go语言原子操作的实现原理、性能优势及最佳实践，包含详细基准测试数据和实际应用场景分析",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"Go语言原子操作完全指南"},{name:"twitter:description",content:"深入解析Go语言原子操作的实现原理、性能优势及最佳实践，包含详细基准测试数据和实际应用场景分析"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/07.Go%E8%AF%AD%E8%A8%80%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go语言原子操作完全指南"},{property:"og:description",content:"深入解析Go语言原子操作的实现原理、性能优势及最佳实践，包含详细基准测试数据和实际应用场景分析"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/07.Go%E8%AF%AD%E8%A8%80%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-14T15:02:33.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"go语言高性能编程"},{itemprop:"name",content:"Go语言原子操作完全指南"},{itemprop:"description",content:"深入解析Go语言原子操作的实现原理、性能优势及最佳实践，包含详细基准测试数据和实际应用场景分析"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/07.Go%E8%AF%AD%E8%A8%80%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E5%AE%8C%E5%85%A8%E6%8C%87%E5%8D%97.html",relativePath:"04.编程/02.go语言/07.go语言高性能编程/07.Go语言原子操作完全指南.md",key:"v-6dda71f1",path:"/pages/821b25/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"原子操作 vs 互斥锁",slug:"原子操作-vs-互斥锁",normalizedTitle:"原子操作 vs 互斥锁",charIndex:160},{level:2,title:"原子操作使用场景",slug:"原子操作使用场景",normalizedTitle:"原子操作使用场景",charIndex:300},{level:3,title:"1. 计数器实现",slug:"_1-计数器实现",normalizedTitle:"1. 计数器实现",charIndex:313},{level:3,title:"2. 状态标志控制",slug:"_2-状态标志控制",normalizedTitle:"2. 状态标志控制",charIndex:551},{level:3,title:"3. 单次初始化(替代sync.Once)",slug:"_3-单次初始化-替代sync-once",normalizedTitle:"3. 单次初始化(替代sync.once)",charIndex:785},{level:3,title:"4. 无锁栈数据结构实现",slug:"_4-无锁栈数据结构实现",normalizedTitle:"4. 无锁栈数据结构实现",charIndex:975},{level:2,title:"性能对比测试",slug:"性能对比测试",normalizedTitle:"性能对比测试",charIndex:1273},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:2117}],headersStr:"前言 原子操作 vs 互斥锁 原子操作使用场景 1. 计数器实现 2. 状态标志控制 3. 单次初始化(替代sync.Once) 4. 无锁栈数据结构实现 性能对比测试 总结",content:"# 前言\n\n原子操作是指不可中断的一个或一系列操作，这些操作要么全部执行成功，要么全部不执行。在Go语言中，通过sync/atomic包提供原子操作支持。允许在不适用互斥锁的情况下安全地并发访问共享数据，加锁会引入协调开销，性能可能会下降，而原子操作使用 CPU 指令直接在硬件层面进行操作，从而有更高的性能。\n\n\n# 原子操作 vs 互斥锁\n\n特性     原子操作           互斥锁\n性能     更高(CPU指令级支持)   较低(需要系统调用)\n使用场景   简单内存操作         复杂代码块保护\n可操作性   有限(仅支持基本类型)    灵活(可保护任意代码)\n\n\n# 原子操作使用场景\n\n\n# 1. 计数器实现\n\nvar requestCount atomic.Int64 // Go 1.19+新版API\n\n// 处理请求时安全递增计数器\nfunc HandleRequest() {\n    requestCount.Add(1) // 原子递增\n}\n\n// 获取当前请求数\nfunc GetRequestCount() int64 {\n    return requestCount.Load()\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 2. 状态标志控制\n\nvar shutdown atomic.Int32\n\nfunc mainLoop() {\n    for {\n        if shutdown.Load() == 1 {\n            break\n        }\n        // do work\n    }\n}\n\nfunc stop() {\n    shutdown.Store(1)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# 3. 单次初始化(替代sync.Once)\n\nvar initialized atomic.Int32\n\nfunc maybeInit() {\n    if initialized.CompareAndSwap(0, 1) {\n        // 只有第一个调用者会执行这里\n    }\n\n    // 其他调用者直接返回\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 4. 无锁栈数据结构实现\n\ntype node struct {\n    next *node\n    val  any\n}\n\nvar head atomic.Pointer[node]\n\nfunc push(n *node) {\n    for {\n        old := head.Load()\n        n.next = old\n        if head.CompareAndSwap(old, n) {\n            return\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n# 性能对比测试\n\n针对使用互斥锁和原子操作的 Benchmark\n\nfunc BenchmarkAtomicIncrement(b *testing.B) {\n\tvar counter atomic.Int64\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\tcounter.Add(1)\n\t\t}\n\t})\n}\n\nfunc BenchmarkMutexIncrement(b *testing.B) {\n\tvar (\n\t\tcounter int64\n\t\tmu      sync.Mutex\n\t)\n\tb.RunParallel(func(pb *testing.PB) {\n\t\tfor pb.Next() {\n\t\t\tmu.Lock()\n\t\t\tcounter++\n\t\t\tmu.Unlock()\n\t\t}\n\t})\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n运行结果如下，原子操作要比加互斥锁快上约 40%。\n\n$ go test  -bench=. -benchmem .\ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkAtomicIncrement-12     22237474                55.00 ns/op            0 B/op          0 allocs/op\nBenchmarkMutexIncrement-12      13650686                84.53 ns/op            0 B/op          0 allocs/op\nPASS\nok      main/demo       2.841s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 总结\n\n * 优先使用原子操作的场景：\n   \n   * 计数器、状态标志等简单共享变量\n   * 性能敏感的并发控制\n   * 无锁数据结构实现\n\n * 需要使用互斥锁的场景：\n   \n   * 保护复杂逻辑代码块\n   * 需要保护多个变量的不变\n   * 执行IO操作等耗时任务时",normalizedContent:"# 前言\n\n原子操作是指不可中断的一个或一系列操作，这些操作要么全部执行成功，要么全部不执行。在go语言中，通过sync/atomic包提供原子操作支持。允许在不适用互斥锁的情况下安全地并发访问共享数据，加锁会引入协调开销，性能可能会下降，而原子操作使用 cpu 指令直接在硬件层面进行操作，从而有更高的性能。\n\n\n# 原子操作 vs 互斥锁\n\n特性     原子操作           互斥锁\n性能     更高(cpu指令级支持)   较低(需要系统调用)\n使用场景   简单内存操作         复杂代码块保护\n可操作性   有限(仅支持基本类型)    灵活(可保护任意代码)\n\n\n# 原子操作使用场景\n\n\n# 1. 计数器实现\n\nvar requestcount atomic.int64 // go 1.19+新版api\n\n// 处理请求时安全递增计数器\nfunc handlerequest() {\n    requestcount.add(1) // 原子递增\n}\n\n// 获取当前请求数\nfunc getrequestcount() int64 {\n    return requestcount.load()\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 2. 状态标志控制\n\nvar shutdown atomic.int32\n\nfunc mainloop() {\n    for {\n        if shutdown.load() == 1 {\n            break\n        }\n        // do work\n    }\n}\n\nfunc stop() {\n    shutdown.store(1)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# 3. 单次初始化(替代sync.once)\n\nvar initialized atomic.int32\n\nfunc maybeinit() {\n    if initialized.compareandswap(0, 1) {\n        // 只有第一个调用者会执行这里\n    }\n\n    // 其他调用者直接返回\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 4. 无锁栈数据结构实现\n\ntype node struct {\n    next *node\n    val  any\n}\n\nvar head atomic.pointer[node]\n\nfunc push(n *node) {\n    for {\n        old := head.load()\n        n.next = old\n        if head.compareandswap(old, n) {\n            return\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n# 性能对比测试\n\n针对使用互斥锁和原子操作的 benchmark\n\nfunc benchmarkatomicincrement(b *testing.b) {\n\tvar counter atomic.int64\n\tb.runparallel(func(pb *testing.pb) {\n\t\tfor pb.next() {\n\t\t\tcounter.add(1)\n\t\t}\n\t})\n}\n\nfunc benchmarkmutexincrement(b *testing.b) {\n\tvar (\n\t\tcounter int64\n\t\tmu      sync.mutex\n\t)\n\tb.runparallel(func(pb *testing.pb) {\n\t\tfor pb.next() {\n\t\t\tmu.lock()\n\t\t\tcounter++\n\t\t\tmu.unlock()\n\t\t}\n\t})\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n运行结果如下，原子操作要比加互斥锁快上约 40%。\n\n$ go test  -bench=. -benchmem .\ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkatomicincrement-12     22237474                55.00 ns/op            0 b/op          0 allocs/op\nbenchmarkmutexincrement-12      13650686                84.53 ns/op            0 b/op          0 allocs/op\npass\nok      main/demo       2.841s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 总结\n\n * 优先使用原子操作的场景：\n   \n   * 计数器、状态标志等简单共享变量\n   * 性能敏感的并发控制\n   * 无锁数据结构实现\n\n * 需要使用互斥锁的场景：\n   \n   * 保护复杂逻辑代码块\n   * 需要保护多个变量的不变\n   * 执行io操作等耗时任务时",charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"Go语言堆栈分配与逃逸分析深度解析",frontmatter:{title:"Go语言堆栈分配与逃逸分析深度解析",date:"2025-06-14T17:30:57.000Z",permalink:"/pages/c19d45/",categories:["编程","go语言","go语言高性能编程"],tags:["go语言","go语言高性能编程"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"深入解析Go语言堆栈分配机制与逃逸分析原理，包含性能对比测试和实际优化建议",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"Go语言堆栈分配与逃逸分析深度解析"},{name:"twitter:description",content:"深入解析Go语言堆栈分配机制与逃逸分析原理，包含性能对比测试和实际优化建议"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/08.Go%E8%AF%AD%E8%A8%80%E5%A0%86%E6%A0%88%E5%88%86%E9%85%8D%E4%B8%8E%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go语言堆栈分配与逃逸分析深度解析"},{property:"og:description",content:"深入解析Go语言堆栈分配机制与逃逸分析原理，包含性能对比测试和实际优化建议"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/08.Go%E8%AF%AD%E8%A8%80%E5%A0%86%E6%A0%88%E5%88%86%E9%85%8D%E4%B8%8E%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-14T17:30:57.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"go语言高性能编程"},{itemprop:"name",content:"Go语言堆栈分配与逃逸分析深度解析"},{itemprop:"description",content:"深入解析Go语言堆栈分配机制与逃逸分析原理，包含性能对比测试和实际优化建议"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/08.Go%E8%AF%AD%E8%A8%80%E5%A0%86%E6%A0%88%E5%88%86%E9%85%8D%E4%B8%8E%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90.html",relativePath:"04.编程/02.go语言/07.go语言高性能编程/08.Go语言堆栈分配与逃逸分析深度解析.md",key:"v-ccb4316a",path:"/pages/c19d45/",headers:[{level:2,title:"1. 前言",slug:"_1-前言",normalizedTitle:"1. 前言",charIndex:2},{level:3,title:"1.1 为什么需要关注堆栈分配？",slug:"_1-1-为什么需要关注堆栈分配",normalizedTitle:"1.1 为什么需要关注堆栈分配？",charIndex:12},{level:3,title:"1.2 什么是逃逸分析？",slug:"_1-2-什么是逃逸分析",normalizedTitle:"1.2 什么是逃逸分析？",charIndex:166},{level:2,title:"2. 逃逸分析实战",slug:"_2-逃逸分析实战",normalizedTitle:"2. 逃逸分析实战",charIndex:243},{level:3,title:"2.1 如何查看逃逸分析结果",slug:"_2-1-如何查看逃逸分析结果",normalizedTitle:"2.1 如何查看逃逸分析结果",charIndex:257},{level:3,title:"2.2常见的逃逸场景",slug:"_2-2常见的逃逸场景",normalizedTitle:"2.2常见的逃逸场景",charIndex:542},{level:2,title:"3. 堆与栈的性能基准测试",slug:"_3-堆与栈的性能基准测试",normalizedTitle:"3. 堆与栈的性能基准测试",charIndex:1106},{level:2,title:"4. 最佳实践",slug:"_4-最佳实践",normalizedTitle:"4. 最佳实践",charIndex:2892},{level:3,title:"4.1 优化栈分配场景",slug:"_4-1-优化栈分配场景",normalizedTitle:"4.1 优化栈分配场景",charIndex:2904},{level:3,title:"4.2 不必强求栈分配的场景",slug:"_4-2-不必强求栈分配的场景",normalizedTitle:"4.2 不必强求栈分配的场景",charIndex:2959},{level:2,title:"5. 总结",slug:"_5-总结",normalizedTitle:"5. 总结",charIndex:3044}],headersStr:"1. 前言 1.1 为什么需要关注堆栈分配？ 1.2 什么是逃逸分析？ 2. 逃逸分析实战 2.1 如何查看逃逸分析结果 2.2常见的逃逸场景 3. 堆与栈的性能基准测试 4. 最佳实践 4.1 优化栈分配场景 4.2 不必强求栈分配的场景 5. 总结",content:'# 1. 前言\n\n\n# 1.1 为什么需要关注堆栈分配？\n\n在Go语言中，内存分配主要有两种方式：\n\n * 栈分配：轻量快速，函数结束时自动释放，不产生垃圾\n * 堆分配：需要垃圾回收(GC)参与，开销较大\n\n关键区别：\n\n * 栈分配比堆分配快10-100倍\n * 栈分配不会增加GC压力\n * 堆分配的对象生命周期更长\n\n\n# 1.2 什么是逃逸分析？\n\n逃逸分析是Go编译器在编译时进行的一种优化技术，它会分析变量的生命周期和使用方式，自动决定将变量分配在栈上还是堆上。\n\n\n# 2. 逃逸分析实战\n\n\n# 2.1 如何查看逃逸分析结果\n\n在下面代码中，将x的变量的地址返回出去了，这个时候会将x放到堆上。\n\nfunc allocate() *int {\n\tx := 42\n\treturn &x // x escapes to the heap\n}\n\nfunc main() {\n\tallocate()\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n通过添加参数-gcflags="-m"可以看到如下逃逸的信息\n\n$ go build -gcflags="-m"  main.go\n...\n./main.go:4:2: moved to heap: x\n\n\n1\n2\n3\n\n\n\n# 2.2常见的逃逸场景\n\n 1. 返回局部变量指针\n\nfunc escape() *int {\n    x := 10\n    return &x // escapes\n}\n\n\n1\n2\n3\n4\n\n 2. 闭包使用局部变量\n\nfunc closureEscape() func() int {\n    x := 5\n    return func() int { return x } // x escapes\n}\n\n\n1\n2\n3\n4\n\n 3. 接口类型转换\n\nfunc toInterface(i int) interface{} {\n    return i // escapes if type info needed at runtime\n}\n\n\n1\n2\n3\n\n 4. 全局变量赋值\n\nvar global *int\n\nfunc assignGlobal() {\n    x := 7\n    global = &x // escapes\n}\n\n\n1\n2\n3\n4\n5\n6\n\n 5. 大尺寸对象\n\nfunc makeLargeSlice() []int {\n    s := make([]int, 10000) // may escape due to size\n    return s\n}\n\n\n1\n2\n3\n4\n\n\n\n# 3. 堆与栈的性能基准测试\n\ntype Data struct {\n\tA, B, C int\n}\n\n// 栈分配\nfunc StackAlloc() Data {\n    return Data{1, 2, 3} // stays on stack\n}\n\n// 堆分配\nfunc HeapAlloc() *Data {\n    return &Data{1, 2, 3} // escapes to heap\n}\n\nfunc BenchmarkStackAlloc(b *testing.B) {\n    for b.Loop() {\n        _ = StackAlloc()\n    }\n}\n\nfunc BenchmarkHeapAlloc(b *testing.B) {\n    for b.Loop() {\n        _ = HeapAlloc()\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n通过运行会发现两者区别并不大，而且竟然没有堆的申请。这是因为编译器很聪明，它发现通过HeapAlloc返回的指针没有任何意义，所以也就把它放在了栈上。\n\n$ go test -bench=. -benchmem .  \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkStackAlloc-12          1000000000               0.2373 ns/op          0 B/op          0 allocs/op\nBenchmarkHeapAlloc-12           1000000000               0.2253 ns/op          0 B/op          0 allocs/op\nPASS\nok      main/demo       1.176s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n我需要强制让它分配到堆上，使用全局赋值，修改代码后如下\n\ntype Data struct {\n\tA, B, C int\n}\n\nvar sink *Data\n\nfunc HeapAllocEscape() {\n\td := &Data{1, 2, 3}\n\tsink = d // d escapes to heap\n}\n\nfunc StackAlloc() Data {\n\treturn Data{1, 2, 3} // stays on stack\n}\n\nfunc BenchmarkStackAlloc(b *testing.B) {\n\tfor range b.N {\n\t\t_ = StackAlloc()\n\t}\n}\n\nfunc BenchmarkHeapAlloc(b *testing.B) {\n\tfor range b.N {\n\t\tHeapAllocEscape()\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n运行结果如下，使用堆存储的开销：35倍的慢调用，24 字节的分配和 1 次垃圾回收的对象。\n\n$ go test -bench=. -benchmem .  \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkStackAlloc-12          1000000000               0.2285 ns/op          0 B/op          0 allocs/op\nBenchmarkHeapAlloc-12           147388731                8.117 ns/op          24 B/op          1 allocs/op\nPASS\nok      main/demo       3.064s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 4. 最佳实践\n\n\n# 4.1 优化栈分配场景\n\n * GC 压力大的时候\n * 对于短期的小对象\n * 高频调用的函数内部\n\n\n# 4.2 不必强求栈分配的场景\n\n * 工厂方法返回对象指针(Go惯用法)\n * 对象需要跨函数生命周期。\n * 不频繁创建的小对象\n * 优化会影响代码可读性时\n\n\n# 5. 总结\n\n 1. 逃逸分析是Go的重要优化手段，自动决定变量分配位置。\n 2. 栈分配性能优势明显，适合短生命周期对象。\n 3. 堆分配虽然较慢，但在某些场景下是必要且合理的。\n 4. 优化时要平衡性能与代码质量，避免过度优化。',normalizedContent:'# 1. 前言\n\n\n# 1.1 为什么需要关注堆栈分配？\n\n在go语言中，内存分配主要有两种方式：\n\n * 栈分配：轻量快速，函数结束时自动释放，不产生垃圾\n * 堆分配：需要垃圾回收(gc)参与，开销较大\n\n关键区别：\n\n * 栈分配比堆分配快10-100倍\n * 栈分配不会增加gc压力\n * 堆分配的对象生命周期更长\n\n\n# 1.2 什么是逃逸分析？\n\n逃逸分析是go编译器在编译时进行的一种优化技术，它会分析变量的生命周期和使用方式，自动决定将变量分配在栈上还是堆上。\n\n\n# 2. 逃逸分析实战\n\n\n# 2.1 如何查看逃逸分析结果\n\n在下面代码中，将x的变量的地址返回出去了，这个时候会将x放到堆上。\n\nfunc allocate() *int {\n\tx := 42\n\treturn &x // x escapes to the heap\n}\n\nfunc main() {\n\tallocate()\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n通过添加参数-gcflags="-m"可以看到如下逃逸的信息\n\n$ go build -gcflags="-m"  main.go\n...\n./main.go:4:2: moved to heap: x\n\n\n1\n2\n3\n\n\n\n# 2.2常见的逃逸场景\n\n 1. 返回局部变量指针\n\nfunc escape() *int {\n    x := 10\n    return &x // escapes\n}\n\n\n1\n2\n3\n4\n\n 2. 闭包使用局部变量\n\nfunc closureescape() func() int {\n    x := 5\n    return func() int { return x } // x escapes\n}\n\n\n1\n2\n3\n4\n\n 3. 接口类型转换\n\nfunc tointerface(i int) interface{} {\n    return i // escapes if type info needed at runtime\n}\n\n\n1\n2\n3\n\n 4. 全局变量赋值\n\nvar global *int\n\nfunc assignglobal() {\n    x := 7\n    global = &x // escapes\n}\n\n\n1\n2\n3\n4\n5\n6\n\n 5. 大尺寸对象\n\nfunc makelargeslice() []int {\n    s := make([]int, 10000) // may escape due to size\n    return s\n}\n\n\n1\n2\n3\n4\n\n\n\n# 3. 堆与栈的性能基准测试\n\ntype data struct {\n\ta, b, c int\n}\n\n// 栈分配\nfunc stackalloc() data {\n    return data{1, 2, 3} // stays on stack\n}\n\n// 堆分配\nfunc heapalloc() *data {\n    return &data{1, 2, 3} // escapes to heap\n}\n\nfunc benchmarkstackalloc(b *testing.b) {\n    for b.loop() {\n        _ = stackalloc()\n    }\n}\n\nfunc benchmarkheapalloc(b *testing.b) {\n    for b.loop() {\n        _ = heapalloc()\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n通过运行会发现两者区别并不大，而且竟然没有堆的申请。这是因为编译器很聪明，它发现通过heapalloc返回的指针没有任何意义，所以也就把它放在了栈上。\n\n$ go test -bench=. -benchmem .  \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkstackalloc-12          1000000000               0.2373 ns/op          0 b/op          0 allocs/op\nbenchmarkheapalloc-12           1000000000               0.2253 ns/op          0 b/op          0 allocs/op\npass\nok      main/demo       1.176s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n我需要强制让它分配到堆上，使用全局赋值，修改代码后如下\n\ntype data struct {\n\ta, b, c int\n}\n\nvar sink *data\n\nfunc heapallocescape() {\n\td := &data{1, 2, 3}\n\tsink = d // d escapes to heap\n}\n\nfunc stackalloc() data {\n\treturn data{1, 2, 3} // stays on stack\n}\n\nfunc benchmarkstackalloc(b *testing.b) {\n\tfor range b.n {\n\t\t_ = stackalloc()\n\t}\n}\n\nfunc benchmarkheapalloc(b *testing.b) {\n\tfor range b.n {\n\t\theapallocescape()\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n运行结果如下，使用堆存储的开销：35倍的慢调用，24 字节的分配和 1 次垃圾回收的对象。\n\n$ go test -bench=. -benchmem .  \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkstackalloc-12          1000000000               0.2285 ns/op          0 b/op          0 allocs/op\nbenchmarkheapalloc-12           147388731                8.117 ns/op          24 b/op          1 allocs/op\npass\nok      main/demo       3.064s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 4. 最佳实践\n\n\n# 4.1 优化栈分配场景\n\n * gc 压力大的时候\n * 对于短期的小对象\n * 高频调用的函数内部\n\n\n# 4.2 不必强求栈分配的场景\n\n * 工厂方法返回对象指针(go惯用法)\n * 对象需要跨函数生命周期。\n * 不频繁创建的小对象\n * 优化会影响代码可读性时\n\n\n# 5. 总结\n\n 1. 逃逸分析是go的重要优化手段，自动决定变量分配位置。\n 2. 栈分配性能优势明显，适合短生命周期对象。\n 3. 堆分配虽然较慢，但在某些场景下是必要且合理的。\n 4. 优化时要平衡性能与代码质量，避免过度优化。',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:24:58",lastUpdatedTimestamp:1749918298e3},{title:"Go语言空结构体：零内存消耗的高效编程",frontmatter:{title:"Go语言空结构体：零内存消耗的高效编程",date:"2025-06-14T19:41:46.000Z",permalink:"/pages/df4833/",categories:["编程","go语言","go语言高性能编程"],tags:["go语言","go语言高性能编程"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"深入解析Go语言空结构体的特性及其在高性能场景下的应用实践",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"Go语言空结构体：零内存消耗的高效编程"},{name:"twitter:description",content:"深入解析Go语言空结构体的特性及其在高性能场景下的应用实践"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/09.Go%E8%AF%AD%E8%A8%80%E7%A9%BA%E7%BB%93%E6%9E%84%E4%BD%93%EF%BC%9A%E9%9B%B6%E5%86%85%E5%AD%98%E6%B6%88%E8%80%97%E7%9A%84%E9%AB%98%E6%95%88%E7%BC%96%E7%A8%8B.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go语言空结构体：零内存消耗的高效编程"},{property:"og:description",content:"深入解析Go语言空结构体的特性及其在高性能场景下的应用实践"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/09.Go%E8%AF%AD%E8%A8%80%E7%A9%BA%E7%BB%93%E6%9E%84%E4%BD%93%EF%BC%9A%E9%9B%B6%E5%86%85%E5%AD%98%E6%B6%88%E8%80%97%E7%9A%84%E9%AB%98%E6%95%88%E7%BC%96%E7%A8%8B.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-14T19:41:46.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"go语言高性能编程"},{itemprop:"name",content:"Go语言空结构体：零内存消耗的高效编程"},{itemprop:"description",content:"深入解析Go语言空结构体的特性及其在高性能场景下的应用实践"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/09.Go%E8%AF%AD%E8%A8%80%E7%A9%BA%E7%BB%93%E6%9E%84%E4%BD%93%EF%BC%9A%E9%9B%B6%E5%86%85%E5%AD%98%E6%B6%88%E8%80%97%E7%9A%84%E9%AB%98%E6%95%88%E7%BC%96%E7%A8%8B.html",relativePath:"04.编程/02.go语言/07.go语言高性能编程/09.Go语言空结构体：零内存消耗的高效编程.md",key:"v-3b2ad750",path:"/pages/df4833/",headers:[{level:2,title:"1. 前言",slug:"_1-前言",normalizedTitle:"1. 前言",charIndex:2},{level:2,title:"2. 应用场景",slug:"_2-应用场景",normalizedTitle:"2. 应用场景",charIndex:111},{level:3,title:"2.1 实现 Set 数据结构",slug:"_2-1-实现-set-数据结构",normalizedTitle:"2.1 实现 set 数据结构",charIndex:123},{level:3,title:"2.2 作为channel的信号",slug:"_2-2-作为channel的信号",normalizedTitle:"2.2 作为channel的信号",charIndex:619},{level:3,title:"2.3 仅包含方法的结构体",slug:"_2-3-仅包含方法的结构体",normalizedTitle:"2.3 仅包含方法的结构体",charIndex:956},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:1313}],headersStr:"1. 前言 2. 应用场景 2.1 实现 Set 数据结构 2.2 作为channel的信号 2.3 仅包含方法的结构体 3. 总结",content:'# 1. 前言\n\n空结构体不占用任何内存空间，所有空结构体实例共享相同的内存地址。这种特性使其成为Go语言中实现高效数据结构和并发模式的理想选择。本文将深入探讨空结构体的工作原理及其在高性能编程中的典型应用场景。\n\n\n# 2. 应用场景\n\n\n# 2.1 实现 Set 数据结构\n\nGo标准库没有Set类型，但可以用map[T]struct{}高效实现：\n\ntype Set map[string]struct{}\n\n// 检查元素是否存在\nfunc (s Set) Has(key string) bool {\n\t_, ok := s[key]\n\treturn ok\n}\n\n// 添加元素\nfunc (s Set) Add(key string) {\n\ts[key] = struct{}{}\n}\n\n// 删除元素\nfunc (s Set) Delete(key string) {\n\tdelete(s, key)\n}\n\nfunc main() {\n\ts := make(Set)\n\ts.Add("Tom")\n\ts.Add("Sam")\n\tfmt.Println(s.Has("Tom"))   // true\n\tfmt.Println(s.Has("Jack"))  // false\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# 2.2 作为channel的信号\n\n空结构体常用于channel通信，表示纯信号通知：\n\nfunc worker(done chan struct{}) {\n    // 模拟工作\n    time.Sleep(time.Second)\n    \n    // 发送完成信号\n    done <- struct{}{}\n}\n\nfunc main() {\n    done := make(chan struct{})\n    go worker(done)\n    \n    // 等待工作完成\n    <-done\n    fmt.Println("Work done")\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n# 2.3 仅包含方法的结构体\n\n当只需要方法不需要存储数据时：\n\ntype Logger struct{} // 不需要状态存储\n\nfunc (l Logger) Info(msg string) {\n    fmt.Printf("[INFO] %s\\n", msg)\n}\n\nfunc (l Logger) Error(msg string) {\n    fmt.Printf("[ERROR] %s\\n", msg)\n}\n\nfunc main() {\n    var log Logger\n    log.Info("System started")\n    log.Error("Connection failed")\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# 3. 总结\n\n空结构体是Go语言中实现高性能代码的重要工具，特别适用于：\n\n 1. 需要集合语义但不需要存储数据的场景\n 2. 纯信号通知的并发通信\n 3. 无状态的方法集合\n\n合理使用空结构体可以显著降低内存占用，提升程序性能。',normalizedContent:'# 1. 前言\n\n空结构体不占用任何内存空间，所有空结构体实例共享相同的内存地址。这种特性使其成为go语言中实现高效数据结构和并发模式的理想选择。本文将深入探讨空结构体的工作原理及其在高性能编程中的典型应用场景。\n\n\n# 2. 应用场景\n\n\n# 2.1 实现 set 数据结构\n\ngo标准库没有set类型，但可以用map[t]struct{}高效实现：\n\ntype set map[string]struct{}\n\n// 检查元素是否存在\nfunc (s set) has(key string) bool {\n\t_, ok := s[key]\n\treturn ok\n}\n\n// 添加元素\nfunc (s set) add(key string) {\n\ts[key] = struct{}{}\n}\n\n// 删除元素\nfunc (s set) delete(key string) {\n\tdelete(s, key)\n}\n\nfunc main() {\n\ts := make(set)\n\ts.add("tom")\n\ts.add("sam")\n\tfmt.println(s.has("tom"))   // true\n\tfmt.println(s.has("jack"))  // false\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# 2.2 作为channel的信号\n\n空结构体常用于channel通信，表示纯信号通知：\n\nfunc worker(done chan struct{}) {\n    // 模拟工作\n    time.sleep(time.second)\n    \n    // 发送完成信号\n    done <- struct{}{}\n}\n\nfunc main() {\n    done := make(chan struct{})\n    go worker(done)\n    \n    // 等待工作完成\n    <-done\n    fmt.println("work done")\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n# 2.3 仅包含方法的结构体\n\n当只需要方法不需要存储数据时：\n\ntype logger struct{} // 不需要状态存储\n\nfunc (l logger) info(msg string) {\n    fmt.printf("[info] %s\\n", msg)\n}\n\nfunc (l logger) error(msg string) {\n    fmt.printf("[error] %s\\n", msg)\n}\n\nfunc main() {\n    var log logger\n    log.info("system started")\n    log.error("connection failed")\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# 3. 总结\n\n空结构体是go语言中实现高性能代码的重要工具，特别适用于：\n\n 1. 需要集合语义但不需要存储数据的场景\n 2. 纯信号通知的并发通信\n 3. 无状态的方法集合\n\n合理使用空结构体可以显著降低内存占用，提升程序性能。',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"Go语言字符串拼接性能对比与优化指南",frontmatter:{title:"Go语言字符串拼接性能对比与优化指南",date:"2025-06-14T20:18:52.000Z",permalink:"/pages/d4c8eb/",categories:["编程","go语言","go语言高性能编程"],tags:[null],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文详细对比了Go语言中6种字符串拼接方式的性能差异，通过基准测试数据揭示最佳实践，并提供实际开发中的优化建议。",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"Go语言字符串拼接性能对比与优化指南"},{name:"twitter:description",content:"本文详细对比了Go语言中6种字符串拼接方式的性能差异，通过基准测试数据揭示最佳实践，并提供实际开发中的优化建议。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/11.Go%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%8B%BC%E6%8E%A5%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go语言字符串拼接性能对比与优化指南"},{property:"og:description",content:"本文详细对比了Go语言中6种字符串拼接方式的性能差异，通过基准测试数据揭示最佳实践，并提供实际开发中的优化建议。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/11.Go%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%8B%BC%E6%8E%A5%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-14T20:18:52.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"Go语言字符串拼接性能对比与优化指南"},{itemprop:"description",content:"本文详细对比了Go语言中6种字符串拼接方式的性能差异，通过基准测试数据揭示最佳实践，并提供实际开发中的优化建议。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/11.Go%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%8B%BC%E6%8E%A5%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94%E4%B8%8E%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97.html",relativePath:"04.编程/02.go语言/07.go语言高性能编程/11.Go语言字符串拼接性能对比与优化指南.md",key:"v-d6123402",path:"/pages/d4c8eb/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"基准测试大比拼",slug:"基准测试大比拼",normalizedTitle:"基准测试大比拼",charIndex:221},{level:2,title:"性能分析",slug:"性能分析",normalizedTitle:"性能分析",charIndex:2904},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:3098}],headersStr:"简介 基准测试大比拼 性能分析 总结",content:'# 简介\n\n在Go语言中，常见的字符串拼接方式有以下6种：\n\n 1. +号拼接：最简单的拼接方式\n 2. fmt.Sprintf：格式化拼接\n 3. strings.Builder：专门优化的字符串构建器\n 4. bytes.Buffer：字节缓冲区\n 5. []byte转换：字节切片转换\n 6. 预分配[]byte：预先分配足够空间的字节切片\n\n本文主要是针对上面各种方式进行基准测试，帮助我们在以后的编码过程中选择最优的方式。\n\n\n# 基准测试大比拼\n\nconst letterBytes = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"\n\nfunc randomString(n int) string {\n\tb := make([]byte, n)\n\tfor i := range b {\n\t\tb[i] = letterBytes[rand.Intn(len(letterBytes))]\n\t}\n\treturn string(b)\n}\n\nfunc plusConcat(n int, str string) string {\n\ts := ""\n\tfor i := 0; i < n; i++ {\n\t\ts += str\n\t}\n\treturn s\n}\n\nfunc sprintfConcat(n int, str string) string {\n\ts := ""\n\tfor i := 0; i < n; i++ {\n\t\ts = fmt.Sprintf("%s%s", s, str)\n\t}\n\treturn s\n}\n\nfunc builderConcat(n int, str string) string {\n\tvar builder strings.Builder\n\tfor i := 0; i < n; i++ {\n\t\tbuilder.WriteString(str)\n\t}\n\treturn builder.String()\n}\n\nfunc bufferConcat(n int, s string) string {\n\tbuf := new(bytes.Buffer)\n\tfor i := 0; i < n; i++ {\n\t\tbuf.WriteString(s)\n\t}\n\treturn buf.String()\n}\n\nfunc byteConcat(n int, str string) string {\n\tbuf := make([]byte, 0)\n\tfor i := 0; i < n; i++ {\n\t\tbuf = append(buf, str...)\n\t}\n\treturn string(buf)\n}\n\nfunc preByteConcat(n int, str string) string {\n\tbuf := make([]byte, 0, n*len(str))\n\tfor i := 0; i < n; i++ {\n\t\tbuf = append(buf, str...)\n\t}\n\treturn string(buf)\n}\n\nfunc benchmark(b *testing.B, f func(int, string) string) {\n\tvar str = randomString(10)\n\tfor i := 0; i < b.N; i++ {\n\t\tf(10000, str)\n\t}\n}\n\nfunc BenchmarkPlusConcat(b *testing.B)    { benchmark(b, plusConcat) }\nfunc BenchmarkSprintfConcat(b *testing.B) { benchmark(b, sprintfConcat) }\nfunc BenchmarkBuilderConcat(b *testing.B) { benchmark(b, builderConcat) }\nfunc BenchmarkBufferConcat(b *testing.B)  { benchmark(b, bufferConcat) }\nfunc BenchmarkByteConcat(b *testing.B)    { benchmark(b, byteConcat) }\nfunc BenchmarkPreByteConcat(b *testing.B) { benchmark(b, preByteConcat) }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n\n\n结果如下：\n\ngo test  -bench=. -benchmem .\ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkPlusConcat-12                36          32238928 ns/op        530999857 B/op     10045 allocs/op\nBenchmarkSprintfConcat-12             20          56848854 ns/op        833393446 B/op     34184 allocs/op\nBenchmarkBuilderConcat-12          23143             51218 ns/op          514804 B/op         23 allocs/op\nBenchmarkBufferConcat-12           29152             40997 ns/op          368578 B/op         13 allocs/op\nBenchmarkByteConcat-12             19549             60984 ns/op          621301 B/op         24 allocs/op\nBenchmarkPreByteConcat-12          50913             24879 ns/op          212994 B/op          2 allocs/op\nPASS\nok      main/demo       10.263s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 性能分析\n\n+号和fmt.Sprintf性能差的原因：\n\n 1. 每次操作都会创建新的字符串\n 2. 产生大量内存分配和垃圾回收压力\n\nstrings.Builder/bytes.Buffer表现好的原因\n\n 1. 内部使用[]byte缓冲区\n 2. 按需扩容，减少内存分配次数\n\n预分配[]byte最佳的原因\n\n 1. 一次性分配足够内存\n 2. 完全避免了扩容带来的性能损耗\n\n\n# 总结\n\n通过测试我们发现：\n\n * 预分配[]byte性能最佳，适合高性能场景\n * strings.Builder是通用场景的最佳选择\n * +号和fmt.Sprintf在循环拼接中性能极差\n\n在实际开发中，应根据场景选择合适的方法，在代码可读性和性能之间取得平衡。',normalizedContent:'# 简介\n\n在go语言中，常见的字符串拼接方式有以下6种：\n\n 1. +号拼接：最简单的拼接方式\n 2. fmt.sprintf：格式化拼接\n 3. strings.builder：专门优化的字符串构建器\n 4. bytes.buffer：字节缓冲区\n 5. []byte转换：字节切片转换\n 6. 预分配[]byte：预先分配足够空间的字节切片\n\n本文主要是针对上面各种方式进行基准测试，帮助我们在以后的编码过程中选择最优的方式。\n\n\n# 基准测试大比拼\n\nconst letterbytes = "abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz"\n\nfunc randomstring(n int) string {\n\tb := make([]byte, n)\n\tfor i := range b {\n\t\tb[i] = letterbytes[rand.intn(len(letterbytes))]\n\t}\n\treturn string(b)\n}\n\nfunc plusconcat(n int, str string) string {\n\ts := ""\n\tfor i := 0; i < n; i++ {\n\t\ts += str\n\t}\n\treturn s\n}\n\nfunc sprintfconcat(n int, str string) string {\n\ts := ""\n\tfor i := 0; i < n; i++ {\n\t\ts = fmt.sprintf("%s%s", s, str)\n\t}\n\treturn s\n}\n\nfunc builderconcat(n int, str string) string {\n\tvar builder strings.builder\n\tfor i := 0; i < n; i++ {\n\t\tbuilder.writestring(str)\n\t}\n\treturn builder.string()\n}\n\nfunc bufferconcat(n int, s string) string {\n\tbuf := new(bytes.buffer)\n\tfor i := 0; i < n; i++ {\n\t\tbuf.writestring(s)\n\t}\n\treturn buf.string()\n}\n\nfunc byteconcat(n int, str string) string {\n\tbuf := make([]byte, 0)\n\tfor i := 0; i < n; i++ {\n\t\tbuf = append(buf, str...)\n\t}\n\treturn string(buf)\n}\n\nfunc prebyteconcat(n int, str string) string {\n\tbuf := make([]byte, 0, n*len(str))\n\tfor i := 0; i < n; i++ {\n\t\tbuf = append(buf, str...)\n\t}\n\treturn string(buf)\n}\n\nfunc benchmark(b *testing.b, f func(int, string) string) {\n\tvar str = randomstring(10)\n\tfor i := 0; i < b.n; i++ {\n\t\tf(10000, str)\n\t}\n}\n\nfunc benchmarkplusconcat(b *testing.b)    { benchmark(b, plusconcat) }\nfunc benchmarksprintfconcat(b *testing.b) { benchmark(b, sprintfconcat) }\nfunc benchmarkbuilderconcat(b *testing.b) { benchmark(b, builderconcat) }\nfunc benchmarkbufferconcat(b *testing.b)  { benchmark(b, bufferconcat) }\nfunc benchmarkbyteconcat(b *testing.b)    { benchmark(b, byteconcat) }\nfunc benchmarkprebyteconcat(b *testing.b) { benchmark(b, prebyteconcat) }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n\n\n结果如下：\n\ngo test  -bench=. -benchmem .\ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkplusconcat-12                36          32238928 ns/op        530999857 b/op     10045 allocs/op\nbenchmarksprintfconcat-12             20          56848854 ns/op        833393446 b/op     34184 allocs/op\nbenchmarkbuilderconcat-12          23143             51218 ns/op          514804 b/op         23 allocs/op\nbenchmarkbufferconcat-12           29152             40997 ns/op          368578 b/op         13 allocs/op\nbenchmarkbyteconcat-12             19549             60984 ns/op          621301 b/op         24 allocs/op\nbenchmarkprebyteconcat-12          50913             24879 ns/op          212994 b/op          2 allocs/op\npass\nok      main/demo       10.263s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 性能分析\n\n+号和fmt.sprintf性能差的原因：\n\n 1. 每次操作都会创建新的字符串\n 2. 产生大量内存分配和垃圾回收压力\n\nstrings.builder/bytes.buffer表现好的原因\n\n 1. 内部使用[]byte缓冲区\n 2. 按需扩容，减少内存分配次数\n\n预分配[]byte最佳的原因\n\n 1. 一次性分配足够内存\n 2. 完全避免了扩容带来的性能损耗\n\n\n# 总结\n\n通过测试我们发现：\n\n * 预分配[]byte性能最佳，适合高性能场景\n * strings.builder是通用场景的最佳选择\n * +号和fmt.sprintf在循环拼接中性能极差\n\n在实际开发中，应根据场景选择合适的方法，在代码可读性和性能之间取得平衡。',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"Go语言延迟初始化(Lazy Initialization)最佳实践",frontmatter:{title:"Go语言延迟初始化(Lazy Initialization)最佳实践",date:"2025-06-14T20:32:05.000Z",permalink:"/pages/f9a2a3/",categories:["编程","go语言","go语言高性能编程"],tags:["go语言","go语言高性能编程"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"入解析Go语言中延迟初始化的实现原理和最佳实践，包括sync.Once、sync.OnceValue和sync.OnceValues的使用场景和性能优势",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"Go语言延迟初始化(Lazy Initialization)最佳实践"},{name:"twitter:description",content:"入解析Go语言中延迟初始化的实现原理和最佳实践，包括sync.Once、sync.OnceValue和sync.OnceValues的使用场景和性能优势"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/12.Go%E8%AF%AD%E8%A8%80%E5%BB%B6%E8%BF%9F%E5%88%9D%E5%A7%8B%E5%8C%96(Lazy%20Initialization)%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go语言延迟初始化(Lazy Initialization)最佳实践"},{property:"og:description",content:"入解析Go语言中延迟初始化的实现原理和最佳实践，包括sync.Once、sync.OnceValue和sync.OnceValues的使用场景和性能优势"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/12.Go%E8%AF%AD%E8%A8%80%E5%BB%B6%E8%BF%9F%E5%88%9D%E5%A7%8B%E5%8C%96(Lazy%20Initialization)%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-14T20:32:05.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"go语言高性能编程"},{itemprop:"name",content:"Go语言延迟初始化(Lazy Initialization)最佳实践"},{itemprop:"description",content:"入解析Go语言中延迟初始化的实现原理和最佳实践，包括sync.Once、sync.OnceValue和sync.OnceValues的使用场景和性能优势"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/12.Go%E8%AF%AD%E8%A8%80%E5%BB%B6%E8%BF%9F%E5%88%9D%E5%A7%8B%E5%8C%96(Lazy%20Initialization)%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html",relativePath:"04.编程/02.go语言/07.go语言高性能编程/12.Go语言延迟初始化(Lazy Initialization)最佳实践.md",key:"v-1ba8c576",path:"/pages/f9a2a3/",headers:[{level:2,title:"1. 简介",slug:"_1-简介",normalizedTitle:"1. 简介",charIndex:2},{level:2,title:"2. 延迟初始化实现",slug:"_2-延迟初始化实现",normalizedTitle:"2. 延迟初始化实现",charIndex:79},{level:3,title:"2.1 sync.Once",slug:"_2-1-sync-once",normalizedTitle:"2.1 sync.once",charIndex:94},{level:3,title:"2.2 sync.OnceValue (Go 1.21+)",slug:"_2-2-sync-oncevalue-go-1-21",normalizedTitle:"2.2 sync.oncevalue (go 1.21+)",charIndex:476},{level:3,title:"2.3 错误处理方案：sync.OnceValues",slug:"_2-3-错误处理方案-sync-oncevalues",normalizedTitle:"2.3 错误处理方案：sync.oncevalues",charIndex:784},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:1095}],headersStr:"1. 简介 2. 延迟初始化实现 2.1 sync.Once 2.2 sync.OnceValue (Go 1.21+) 2.3 错误处理方案：sync.OnceValues 3. 总结",content:'# 1. 简介\n\n在有些资源初始化成本很高，甚至在某些代码路径未触发根本没有必要初始化，可以将对象的创建、配置等耗时操作推迟到真正需要使用时才执行。\n\n\n# 2. 延迟初始化实现\n\n\n# 2.1 sync.Once\n\nsync.Once 是Go标准库提供的线程安全初始化工具，确保初始化代码只执行一次：\n\nvar (\n    resource *MyResource  // 需要延迟初始化的资源\n    once     sync.Once    // 控制初始化的同步原语\n)\n\nfunc getResource() *MyResource {\n    once.Do(func() {\n        resource = &MyResource{\n            // 初始化代码\n        }\n    })\n    return resource\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n特点：\n\n * 线程安全，适合并发场景\n * 初始化逻辑与业务代码耦合\n * 需要额外定义全局变量\n\n\n# 2.2 sync.OnceValue (Go 1.21+)\n\nGo 1.21引入了更简洁的sync.OnceValue，适合返回单个值的场景：\n\nvar getResource = sync.OnceValue(func() *MyResource {\n    return &MyResource{\n        // 初始化代码\n    }\n})\n\n// 使用示例\nfunc main() {\n    res := getResource()  // 第一次调用时初始化\n    _ = getResource()     // 后续调用直接返回缓存值\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 2.3 错误处理方案：sync.OnceValues\n\n当初始化可能返回错误时，使用sync.OnceValues：\n\nvar getConfig = sync.OnceValues(func() (*Config, error) {\n    return loadConfig("config.yml")\n})\n\nfunc main() {\n    config, err := getConfig()\n    if err != nil {\n        log.Fatal("加载配置失败:", err)\n    }\n    // 使用配置...\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 3. 总结\n\n在以下场景中适合使用延迟初始化:\n\n * 资源初始化成本非常高。\n * 为了提高启动性能和内存效率。\n * 当并非所有的资源都需要在运行时立即使用，甚至根本不需要使用。',normalizedContent:'# 1. 简介\n\n在有些资源初始化成本很高，甚至在某些代码路径未触发根本没有必要初始化，可以将对象的创建、配置等耗时操作推迟到真正需要使用时才执行。\n\n\n# 2. 延迟初始化实现\n\n\n# 2.1 sync.once\n\nsync.once 是go标准库提供的线程安全初始化工具，确保初始化代码只执行一次：\n\nvar (\n    resource *myresource  // 需要延迟初始化的资源\n    once     sync.once    // 控制初始化的同步原语\n)\n\nfunc getresource() *myresource {\n    once.do(func() {\n        resource = &myresource{\n            // 初始化代码\n        }\n    })\n    return resource\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n特点：\n\n * 线程安全，适合并发场景\n * 初始化逻辑与业务代码耦合\n * 需要额外定义全局变量\n\n\n# 2.2 sync.oncevalue (go 1.21+)\n\ngo 1.21引入了更简洁的sync.oncevalue，适合返回单个值的场景：\n\nvar getresource = sync.oncevalue(func() *myresource {\n    return &myresource{\n        // 初始化代码\n    }\n})\n\n// 使用示例\nfunc main() {\n    res := getresource()  // 第一次调用时初始化\n    _ = getresource()     // 后续调用直接返回缓存值\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 2.3 错误处理方案：sync.oncevalues\n\n当初始化可能返回错误时，使用sync.oncevalues：\n\nvar getconfig = sync.oncevalues(func() (*config, error) {\n    return loadconfig("config.yml")\n})\n\nfunc main() {\n    config, err := getconfig()\n    if err != nil {\n        log.fatal("加载配置失败:", err)\n    }\n    // 使用配置...\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 3. 总结\n\n在以下场景中适合使用延迟初始化:\n\n * 资源初始化成本非常高。\n * 为了提高启动性能和内存效率。\n * 当并非所有的资源都需要在运行时立即使用，甚至根本不需要使用。',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"Go语言结构体内存对齐完全指南",frontmatter:{title:"Go语言结构体内存对齐完全指南",date:"2025-06-14T19:54:38.000Z",permalink:"/pages/13969e/",categories:["编程","go语言","go语言高性能编程"],tags:["go语言","go语言高性能编程"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"深入解析Go语言结构体内存对齐原理与优化实践，包含性能测试数据和实用工具推荐",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17499021159591749902115421.png"},{name:"twitter:title",content:"Go语言结构体内存对齐完全指南"},{name:"twitter:description",content:"深入解析Go语言结构体内存对齐原理与优化实践，包含性能测试数据和实用工具推荐"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17499021159591749902115421.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/10.Go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BB%93%E6%9E%84%E4%BD%93%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go语言结构体内存对齐完全指南"},{property:"og:description",content:"深入解析Go语言结构体内存对齐原理与优化实践，包含性能测试数据和实用工具推荐"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17499021159591749902115421.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/10.Go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BB%93%E6%9E%84%E4%BD%93%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-14T19:54:38.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"go语言高性能编程"},{itemprop:"name",content:"Go语言结构体内存对齐完全指南"},{itemprop:"description",content:"深入解析Go语言结构体内存对齐原理与优化实践，包含性能测试数据和实用工具推荐"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17499021159591749902115421.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/10.Go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BB%93%E6%9E%84%E4%BD%93%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90.html",relativePath:"04.编程/02.go语言/07.go语言高性能编程/10.Go语言高性能编程之结构体内存对齐.md",key:"v-3ff27440",path:"/pages/13969e/",headers:[{level:2,title:"1. 简介",slug:"_1-简介",normalizedTitle:"1. 简介",charIndex:2},{level:2,title:"2. 使用结构体内存对齐效果是怎么样的？",slug:"_2-使用结构体内存对齐效果是怎么样的",normalizedTitle:"2. 使用结构体内存对齐效果是怎么样的？",charIndex:85},{level:2,title:"3. 什么是结构体内存对齐？",slug:"_3-什么是结构体内存对齐",normalizedTitle:"3. 什么是结构体内存对齐？",charIndex:575},{level:2,title:"4. 针对结构体是否对齐的基准测试",slug:"_4-针对结构体是否对齐的基准测试",normalizedTitle:"4. 针对结构体是否对齐的基准测试",charIndex:985},{level:2,title:"5. 兼容硬件平台与架构",slug:"_5-兼容硬件平台与架构",normalizedTitle:"5. 兼容硬件平台与架构",charIndex:1796},{level:2,title:"6. 内存对齐规则",slug:"_6-内存对齐规则",normalizedTitle:"6. 内存对齐规则",charIndex:2223},{level:3,title:"6.1 对齐系数",slug:"_6-1-对齐系数",normalizedTitle:"6.1 对齐系数",charIndex:2237},{level:3,title:"6.2 字段偏移量",slug:"_6-2-字段偏移量",normalizedTitle:"6.2 字段偏移量",charIndex:2871},{level:3,title:"6.3 struct 内存对齐规则",slug:"_6-3-struct-内存对齐规则",normalizedTitle:"6.3 struct 内存对齐规则",charIndex:2947},{level:3,title:"6.4 struct{} 作为结构体最后一个字段",slug:"_6-4-struct-作为结构体最后一个字段",normalizedTitle:"6.4 struct{} 作为结构体最后一个字段",charIndex:3473},{level:2,title:"7. fieldalignment linter",slug:"_7-fieldalignment-linter",normalizedTitle:"7. fieldalignment linter",charIndex:4201},{level:2,title:"8. 最佳实践",slug:"_8-最佳实践",normalizedTitle:"8. 最佳实践",charIndex:4883}],headersStr:"1. 简介 2. 使用结构体内存对齐效果是怎么样的？ 3. 什么是结构体内存对齐？ 4. 针对结构体是否对齐的基准测试 5. 兼容硬件平台与架构 6. 内存对齐规则 6.1 对齐系数 6.2 字段偏移量 6.3 struct 内存对齐规则 6.4 struct{} 作为结构体最后一个字段 7. fieldalignment linter 8. 最佳实践",content:'# 1. 简介\n\n在Go语言开发中，结构体内存对齐是影响程序性能和内存效率的关键因素。本文将从底层原理出发，详细解析内存对齐的工作机制及其对程序性能的实际影响。\n\n\n# 2. 使用结构体内存对齐效果是怎么样的？\n\n创建两个结构体，其中的成员变量数量和类型完成一致，只有顺序摆放的不一样。\n\nimport (\n\t"fmt"\n\t"unsafe"\n)\n\ntype PoorlyAligned struct {\n\tflag  bool\n\tcount int64\n\tid    byte\n}\n\ntype WellAligned struct {\n\tcount int64\n\tflag  bool\n\tid    byte\n}\n\nfunc main() {\n\tfmt.Println(unsafe.Sizeof(PoorlyAligned{}))\n\tfmt.Println(unsafe.Sizeof(WellAligned{}))\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n运行结果如下，可以看到 PoorlyAligned 的内存大小是24，而 WellAligned 的内存大小是 16\n\n24\n16\n\n\n1\n2\n\n\n为什么改了变量的顺序，却在内存中的大小则不一样了呢？\n\n\n# 3. 什么是结构体内存对齐？\n\nCPU 访问内存时是根据字长来访问而不是字节。比如 32 位的 CPU 字长是 4 字节，64 位的 CPU 时 8 字节。这么设计的目的是减少 CPU 访问内存的次数，提高吞吐量。\n\n这个时候我们看到结构体 PoorlyAligned，bool是 4 字节，int64 是 8 字节，byte是 4 字节，CPU 读取 bool 变量 flag 时，因为字长是 8 字节，必须得读 8 个字节，所以必须得补上空的 4 个字节。而 int64 的 count 变量本身是 8 字节的不需要补位，读byte 的 id 时和 flag 一样也需要补 4 个字节，最终是 24 个字节。\n\n\n\n再看到结构体 WellAligned，顺序是 count、flag、id，count 可以一次取走，而 bool 可以和 id 在同一次一起取走，所以最终只需要在内存存储 16 个字节。\n\n\n\n\n# 4. 针对结构体是否对齐的基准测试\n\nfunc BenchmarkPoorlyAligned(b *testing.B) {\n\tfor range b.N {\n\t\tvar items = make([]PoorlyAligned, 10_000_000)\n\t\tfor j := range items {\n\t\t\titems[j].count = int64(j)\n\t\t}\n\t}\n}\n\nfunc BenchmarkWellAligned(b *testing.B) {\n\tfor range b.N {\n\t\tvar items = make([]WellAligned, 10_000_000)\n\t\tfor j := range items {\n\t\t\titems[j].count = int64(j)\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n运行结果如下，内存对齐在速度上要快上约 35%，内存分配要少上约 50%\n\n$ go test -bench=. -benchmem . \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkPoorlyAligned-12            248           4575658 ns/op        240001038 B/op         1 allocs/op\nBenchmarkWellAligned-12              356           3392792 ns/op        160006157 B/op         1 allocs/op\nPASS\nok      main/demo       5.126s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 5. 兼容硬件平台与架构\n\n接下来看这么一种情况，f1 int8占用 1 个字节，f2 int16占用 2 个字节，f3 int8 也占用 1 个字节，但是输出的字节大小却是 6 而不是 4，因为这里也做了内存对齐。\n\ntype S1 struct { \n\tf1 int8\n\tf2 int16\n\tf3 int8\n}\n\nfunc main() {\n\ts1 := S1{}\n\tfmt.Println(unsafe.Sizeof(s1))\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n运行输出：\n\n6\n\n\n1\n\n\n问题来了，操作系统一个字长 8 个字节，那么无论是 4 还是 6 CPU 都能够一次拿到整体数据，效率是一样的呀。\n\n这是因为，内存对齐不仅仅是为了保证 CPU 的读取效率，还有就是为了兼容硬件平台和架构做的限制，比如在 CPU 是 ARM架构 时强制要做内存对齐的，不做的话则会直接报错。\n\n那么这里的对齐规则是怎么样的呢？\n\n\n# 6. 内存对齐规则\n\n\n# 6.1 对齐系数\n\n字段类型不仅有类型大小，还有类型对齐系数， 其有以下两个规则\n\n * Go原始类型的对齐系数与类型长度相等。\n\n可以使用unsafe.Alignof来查看类型的对齐系数，可以发现两者是一致的。\n\nfunc main() {\n\tfmt.Println(unsafe.Sizeof(int64(1)))      // 8\n\tfmt.Println(unsafe.Sizeof(float32(32)))   // 4\n\n\tfmt.Println(unsafe.Alignof(int64(1)))     // 8\n\tfmt.Println(unsafe.Alignof(float32(32)))  //4\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n * Go结构体类型的对齐系数是最长字段的对齐系数和系统对齐系数两者中的最小的那个。\n\n可以看到结构体的对齐系数是 2，这是因为最长字段是 f2 其对齐系数是 2，操作系统是 64 位，其对齐系数是 8，取最小的也就是 2\n\ntype S1 struct { \n\tf1 int8\n\tf2 int16\n\tf3 int8\n}\n\nfunc main() {\n\ts1 := S1{}\n\tfmt.Println(unsafe.Sizeof(s1))    // 6\n\tfmt.Println(unsafe.Alignof(s1))   // 2\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 6.2 字段偏移量\n\n字段偏移量是指在结构体内存对齐后字段从起始位置开始的偏移量，也就是从起始位置开始计算的字节数，第一个字段的偏移量是 0。\n\n\n# 6.3 struct 内存对齐规则\n\n对齐规则如下：\n\n * 结构体中的每个字段所在的偏移量必须是其对齐系数的整数倍，如果不能保证则需要添加空的字节来保证内存对齐。\n * 结构体的长度一定要是其本身对齐系数的整数倍。\n\n知道规则后，再回到之前的 S1 的例子：\n\n * f1 的偏移量为0，占用 1 个字节，默认是对齐的。\n * f2 的对齐系数是2，如果从偏移量 1 开始存储，则不是2的倍数，必须前面空出一个，从偏移量2开始，才是对齐系数的倍数，所以从偏移量从2开始存储，并存储2个字节\n * f3 的对齐系数是1，从偏移量 5 开始存储，存储 1 个字节，是对齐的。\n * 本结构体的对齐系数是 2，而大小需要时对齐系数的整数倍，而根据前面几步的长度是 5，不能对齐，所以还需要空出一个字节才能使结构体对齐，也就是长度为 6 字节\n\ntype S1 struct {   // 长度:6, 对齐系数: 2\n\tf1 int8        // 长度:1, 对齐系数: 1\n\tf2 int16       // 长度:2, 对齐系数: 2\n\tf3 int8        // 长度:1, 对齐系数: 1\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n\n\n# 6.4 struct{} 作为结构体最后一个字段\n\nstruct{}这样的空结构体的大小是为 0 的，如果其作为其他结构体字段的时候，是不占用内存的，也不需要考虑内存对齐的问题，但只有一种情况例外，就是struct{}作为结构体的最后一个字段时，是会进行内存对齐的，而其对齐规则是：会被填充对齐到前一个字段的大小。\n\n这是因为如果有指针指向该字段, 返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）\n\n具体案例如下，demo1、demo2、demo3中的struct{}的都会按照前一个字段的大小进行填充对齐。\n\ntype demo1 struct {\n\tc int8\n\ta struct{}\n}\n\ntype demo2 struct {\n\tc int16\n\ta struct{}\n}\n\ntype demo3 struct {\n\tc int32\n\ta struct{}\n}\n\ntype demo4 struct {\n\ta struct{}\n\tc int32\n}\n\nfunc main() {\n\tfmt.Println(unsafe.Sizeof(demo1{})) // 2\n\tfmt.Println(unsafe.Sizeof(demo2{})) // 4\n\tfmt.Println(unsafe.Sizeof(demo3{})) // 8\n\tfmt.Println(unsafe.Sizeof(demo4{})) // 4\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n\n# 7. fieldalignment linter\n\n通过使用fieldalignment linter工具可以提前发现内存对齐问题，可以帮助我们来对结构体中的字段顺序进行正确的排列，减少内存的占用，提高运行的效率。\n\n该结构体通过上面的分析，长度为 6，为了内存对齐是补了 2 个字节的。\n\ntype S1 struct {\n\tf1 int8\n\tf2 int16\n\tf3 int8\n}\n\n\n1\n2\n3\n4\n5\n\n\n在项目中新增文件.golangci.yaml，内容如下，主要是将 fieldalignmeng 功能开启\n\nversion: 2\nlinters:\n  default: all\n  enable:\n    - govet\n  settings:\n    govet:\n      enable:\n        - fieldalignment\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n然后运行golangci-lint会有提示，结构体的大小可以被优化，从 6 到 4\n\n$ golangci-lint run\n...\nmain.go:9:9: fieldalignment: struct of size 6 could be 4 (govet)\ntype S1 struct {\n...\n\n\n1\n2\n3\n4\n5\n\n\n修改结构体中字段顺序为不需要补齐内存的方式，再次运行上面的命令后，上面的提示错误信息就没有了。\n\ntype S1 struct {\n\tf1 int8\n\tf3 int8\n\tf2 int16\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 8. 最佳实践\n\n * 通过对字段的排序来减少内部无意义的填充。\n * 尽可能将类型大小相同的字段放在一起，避免大小交替。\n * 使用 fieldalignment linter 对代码进行校验，通过工具自动捕获',normalizedContent:'# 1. 简介\n\n在go语言开发中，结构体内存对齐是影响程序性能和内存效率的关键因素。本文将从底层原理出发，详细解析内存对齐的工作机制及其对程序性能的实际影响。\n\n\n# 2. 使用结构体内存对齐效果是怎么样的？\n\n创建两个结构体，其中的成员变量数量和类型完成一致，只有顺序摆放的不一样。\n\nimport (\n\t"fmt"\n\t"unsafe"\n)\n\ntype poorlyaligned struct {\n\tflag  bool\n\tcount int64\n\tid    byte\n}\n\ntype wellaligned struct {\n\tcount int64\n\tflag  bool\n\tid    byte\n}\n\nfunc main() {\n\tfmt.println(unsafe.sizeof(poorlyaligned{}))\n\tfmt.println(unsafe.sizeof(wellaligned{}))\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n运行结果如下，可以看到 poorlyaligned 的内存大小是24，而 wellaligned 的内存大小是 16\n\n24\n16\n\n\n1\n2\n\n\n为什么改了变量的顺序，却在内存中的大小则不一样了呢？\n\n\n# 3. 什么是结构体内存对齐？\n\ncpu 访问内存时是根据字长来访问而不是字节。比如 32 位的 cpu 字长是 4 字节，64 位的 cpu 时 8 字节。这么设计的目的是减少 cpu 访问内存的次数，提高吞吐量。\n\n这个时候我们看到结构体 poorlyaligned，bool是 4 字节，int64 是 8 字节，byte是 4 字节，cpu 读取 bool 变量 flag 时，因为字长是 8 字节，必须得读 8 个字节，所以必须得补上空的 4 个字节。而 int64 的 count 变量本身是 8 字节的不需要补位，读byte 的 id 时和 flag 一样也需要补 4 个字节，最终是 24 个字节。\n\n\n\n再看到结构体 wellaligned，顺序是 count、flag、id，count 可以一次取走，而 bool 可以和 id 在同一次一起取走，所以最终只需要在内存存储 16 个字节。\n\n\n\n\n# 4. 针对结构体是否对齐的基准测试\n\nfunc benchmarkpoorlyaligned(b *testing.b) {\n\tfor range b.n {\n\t\tvar items = make([]poorlyaligned, 10_000_000)\n\t\tfor j := range items {\n\t\t\titems[j].count = int64(j)\n\t\t}\n\t}\n}\n\nfunc benchmarkwellaligned(b *testing.b) {\n\tfor range b.n {\n\t\tvar items = make([]wellaligned, 10_000_000)\n\t\tfor j := range items {\n\t\t\titems[j].count = int64(j)\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n运行结果如下，内存对齐在速度上要快上约 35%，内存分配要少上约 50%\n\n$ go test -bench=. -benchmem . \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkpoorlyaligned-12            248           4575658 ns/op        240001038 b/op         1 allocs/op\nbenchmarkwellaligned-12              356           3392792 ns/op        160006157 b/op         1 allocs/op\npass\nok      main/demo       5.126s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 5. 兼容硬件平台与架构\n\n接下来看这么一种情况，f1 int8占用 1 个字节，f2 int16占用 2 个字节，f3 int8 也占用 1 个字节，但是输出的字节大小却是 6 而不是 4，因为这里也做了内存对齐。\n\ntype s1 struct { \n\tf1 int8\n\tf2 int16\n\tf3 int8\n}\n\nfunc main() {\n\ts1 := s1{}\n\tfmt.println(unsafe.sizeof(s1))\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n运行输出：\n\n6\n\n\n1\n\n\n问题来了，操作系统一个字长 8 个字节，那么无论是 4 还是 6 cpu 都能够一次拿到整体数据，效率是一样的呀。\n\n这是因为，内存对齐不仅仅是为了保证 cpu 的读取效率，还有就是为了兼容硬件平台和架构做的限制，比如在 cpu 是 arm架构 时强制要做内存对齐的，不做的话则会直接报错。\n\n那么这里的对齐规则是怎么样的呢？\n\n\n# 6. 内存对齐规则\n\n\n# 6.1 对齐系数\n\n字段类型不仅有类型大小，还有类型对齐系数， 其有以下两个规则\n\n * go原始类型的对齐系数与类型长度相等。\n\n可以使用unsafe.alignof来查看类型的对齐系数，可以发现两者是一致的。\n\nfunc main() {\n\tfmt.println(unsafe.sizeof(int64(1)))      // 8\n\tfmt.println(unsafe.sizeof(float32(32)))   // 4\n\n\tfmt.println(unsafe.alignof(int64(1)))     // 8\n\tfmt.println(unsafe.alignof(float32(32)))  //4\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n * go结构体类型的对齐系数是最长字段的对齐系数和系统对齐系数两者中的最小的那个。\n\n可以看到结构体的对齐系数是 2，这是因为最长字段是 f2 其对齐系数是 2，操作系统是 64 位，其对齐系数是 8，取最小的也就是 2\n\ntype s1 struct { \n\tf1 int8\n\tf2 int16\n\tf3 int8\n}\n\nfunc main() {\n\ts1 := s1{}\n\tfmt.println(unsafe.sizeof(s1))    // 6\n\tfmt.println(unsafe.alignof(s1))   // 2\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 6.2 字段偏移量\n\n字段偏移量是指在结构体内存对齐后字段从起始位置开始的偏移量，也就是从起始位置开始计算的字节数，第一个字段的偏移量是 0。\n\n\n# 6.3 struct 内存对齐规则\n\n对齐规则如下：\n\n * 结构体中的每个字段所在的偏移量必须是其对齐系数的整数倍，如果不能保证则需要添加空的字节来保证内存对齐。\n * 结构体的长度一定要是其本身对齐系数的整数倍。\n\n知道规则后，再回到之前的 s1 的例子：\n\n * f1 的偏移量为0，占用 1 个字节，默认是对齐的。\n * f2 的对齐系数是2，如果从偏移量 1 开始存储，则不是2的倍数，必须前面空出一个，从偏移量2开始，才是对齐系数的倍数，所以从偏移量从2开始存储，并存储2个字节\n * f3 的对齐系数是1，从偏移量 5 开始存储，存储 1 个字节，是对齐的。\n * 本结构体的对齐系数是 2，而大小需要时对齐系数的整数倍，而根据前面几步的长度是 5，不能对齐，所以还需要空出一个字节才能使结构体对齐，也就是长度为 6 字节\n\ntype s1 struct {   // 长度:6, 对齐系数: 2\n\tf1 int8        // 长度:1, 对齐系数: 1\n\tf2 int16       // 长度:2, 对齐系数: 2\n\tf3 int8        // 长度:1, 对齐系数: 1\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n\n\n# 6.4 struct{} 作为结构体最后一个字段\n\nstruct{}这样的空结构体的大小是为 0 的，如果其作为其他结构体字段的时候，是不占用内存的，也不需要考虑内存对齐的问题，但只有一种情况例外，就是struct{}作为结构体的最后一个字段时，是会进行内存对齐的，而其对齐规则是：会被填充对齐到前一个字段的大小。\n\n这是因为如果有指针指向该字段, 返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）\n\n具体案例如下，demo1、demo2、demo3中的struct{}的都会按照前一个字段的大小进行填充对齐。\n\ntype demo1 struct {\n\tc int8\n\ta struct{}\n}\n\ntype demo2 struct {\n\tc int16\n\ta struct{}\n}\n\ntype demo3 struct {\n\tc int32\n\ta struct{}\n}\n\ntype demo4 struct {\n\ta struct{}\n\tc int32\n}\n\nfunc main() {\n\tfmt.println(unsafe.sizeof(demo1{})) // 2\n\tfmt.println(unsafe.sizeof(demo2{})) // 4\n\tfmt.println(unsafe.sizeof(demo3{})) // 8\n\tfmt.println(unsafe.sizeof(demo4{})) // 4\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n\n# 7. fieldalignment linter\n\n通过使用fieldalignment linter工具可以提前发现内存对齐问题，可以帮助我们来对结构体中的字段顺序进行正确的排列，减少内存的占用，提高运行的效率。\n\n该结构体通过上面的分析，长度为 6，为了内存对齐是补了 2 个字节的。\n\ntype s1 struct {\n\tf1 int8\n\tf2 int16\n\tf3 int8\n}\n\n\n1\n2\n3\n4\n5\n\n\n在项目中新增文件.golangci.yaml，内容如下，主要是将 fieldalignmeng 功能开启\n\nversion: 2\nlinters:\n  default: all\n  enable:\n    - govet\n  settings:\n    govet:\n      enable:\n        - fieldalignment\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n然后运行golangci-lint会有提示，结构体的大小可以被优化，从 6 到 4\n\n$ golangci-lint run\n...\nmain.go:9:9: fieldalignment: struct of size 6 could be 4 (govet)\ntype s1 struct {\n...\n\n\n1\n2\n3\n4\n5\n\n\n修改结构体中字段顺序为不需要补齐内存的方式，再次运行上面的命令后，上面的提示错误信息就没有了。\n\ntype s1 struct {\n\tf1 int8\n\tf3 int8\n\tf2 int16\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 8. 最佳实践\n\n * 通过对字段的排序来减少内部无意义的填充。\n * 尽可能将类型大小相同的字段放在一起，避免大小交替。\n * 使用 fieldalignment linter 对代码进行校验，通过工具自动捕获',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"Go语言高效IO缓冲技术详解",frontmatter:{title:"Go语言高效IO缓冲技术详解",date:"2025-06-14T22:47:01.000Z",permalink:"/pages/d8ed61/",categories:["编程","go语言","go语言高性能编程"],tags:["go语言","go语言高性能编程"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"深入解析Go语言中缓冲I/O的工作原理、性能优势及最佳实践，包含基准测试数据对比和实际应用场景分析",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"Go语言高效IO缓冲技术详解"},{name:"twitter:description",content:"深入解析Go语言中缓冲I/O的工作原理、性能优势及最佳实践，包含基准测试数据对比和实际应用场景分析"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/13.Go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%95%88IO%E7%BC%93%E5%86%B2%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Go语言高效IO缓冲技术详解"},{property:"og:description",content:"深入解析Go语言中缓冲I/O的工作原理、性能优势及最佳实践，包含基准测试数据对比和实际应用场景分析"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/13.Go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%95%88IO%E7%BC%93%E5%86%B2%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-06-14T22:47:01.000Z"},{property:"article:tag",content:"go语言"},{property:"article:tag",content:"go语言高性能编程"},{itemprop:"name",content:"Go语言高效IO缓冲技术详解"},{itemprop:"description",content:"深入解析Go语言中缓冲I/O的工作原理、性能优势及最佳实践，包含基准测试数据对比和实际应用场景分析"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go%E8%AF%AD%E8%A8%80/07.go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B/13.Go%E8%AF%AD%E8%A8%80%E9%AB%98%E6%95%88IO%E7%BC%93%E5%86%B2%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3.html",relativePath:"04.编程/02.go语言/07.go语言高性能编程/13.Go语言高效IO缓冲技术详解.md",key:"v-99455fdc",path:"/pages/d8ed61/",headers:[{level:2,title:"1. 简介",slug:"_1-简介",normalizedTitle:"1. 简介",charIndex:2},{level:2,title:"2. 不带缓冲的写入",slug:"_2-不带缓冲的写入",normalizedTitle:"2. 不带缓冲的写入",charIndex:187},{level:2,title:"3. 带缓冲的写入",slug:"_3-带缓冲的写入",normalizedTitle:"3. 带缓冲的写入",charIndex:374},{level:2,title:"4. 控制缓冲区容量",slug:"_4-控制缓冲区容量",normalizedTitle:"4. 控制缓冲区容量",charIndex:609},{level:2,title:"5. 带缓冲与不带缓冲的 Benchmark",slug:"_5-带缓冲与不带缓冲的-benchmark",normalizedTitle:"5. 带缓冲与不带缓冲的 benchmark",charIndex:760},{level:2,title:"6. 总结",slug:"_6-总结",normalizedTitle:"6. 总结",charIndex:2681}],headersStr:"1. 简介 2. 不带缓冲的写入 3. 带缓冲的写入 4. 控制缓冲区容量 5. 带缓冲与不带缓冲的 Benchmark 6. 总结",content:'# 1. 简介\n\n在计算机系统中，I/O操作（如文件读写、网络通信）是性能瓶颈的主要来源之一。主要原因包括：\n\n 1. 系统调用开销：每次直接I/O操作都涉及用户态和内核态的上下文切换\n 2. 硬件限制：磁盘和网络设备更适合大块数据传输\n 3. 频繁小数据操作：大量小数据写入会显著降低性能\n\n缓冲技术通过在内存中聚合数据，减少实际I/O操作次数，可显著提升性能。\n\n\n# 2. 不带缓冲的写入\n\n直接频繁调用系统API，性能最差：\n\n// 每次写入都触发系统调用\nf, _ := os.Create("output.txt")\ndefer f.Close()\n\nfor i := 0; i < 10000; i++ {\n    f.Write([]byte("line\\n"))  // 高成本操作\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 3. 带缓冲的写入\n\n使用bufio.Writer自动缓冲：\n\nf, _ := os.Create("output.txt")\ndefer f.Close()\n\nbuf := bufio.NewWriter(f)  // 默认4KB缓冲\nfor i := 0; i < 10000; i++ {\n    buf.WriteString("line\\n")  // 内存操作\n}\nbuf.Flush()  // 最终写入磁盘\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 4. 控制缓冲区容量\n\n根据场景调整缓冲区大小：\n\nf, _ := os.Create("output.txt")\ndefer f.Close()\n\n// 16KB缓冲，适合大文件写入\nbuf := bufio.NewWriterSize(f, 16*1024)  \n\n\n1\n2\n3\n4\n5\n\n\n\n# 5. 带缓冲与不带缓冲的 Benchmark\n\n比较通过直接调用os.File.Write相比，使用bufio.Writer向磁盘写入一百万行数据。\n\npackage perf\n\nimport (\n    "bufio"\n    "io"\n    "os"\n    "strconv"\n    "sync"\n    "testing"\n)\n\ntype Data struct {\n    Value []byte\n}\n\nvar dataPool = sync.Pool{\n    New: func() any {\n        return &Data{Value: make([]byte, 0, 32)}\n    },\n}\n\nconst N = 10000\n\nfunc writeNotBuffered(w io.Writer, count int) {\n    for i := 0; i < count; i++ {\n        d := dataPool.Get().(*Data)\n        d.Value = strconv.AppendInt(d.Value[:0], int64(i), 10)\n        w.Write(d.Value)\n        w.Write([]byte(":val\\n"))\n        dataPool.Put(d)\n    }\n}\n\nfunc writeBuffered(w io.Writer, count int) {\n    buf := bufio.NewWriterSize(w, 16*1024)\n    for i := 0; i < count; i++ {\n        d := dataPool.Get().(*Data)\n        d.Value = strconv.AppendInt(d.Value[:0], int64(i), 10)\n        buf.Write(d.Value)\n        buf.Write([]byte(":val\\n"))\n        dataPool.Put(d)\n    }\n    buf.Flush()\n}\n\nfunc BenchmarkWriteNotBuffered(b *testing.B) {\n    for b.Loop() {\n        f, _ := os.CreateTemp("", "nobuf")\n        writeNotBuffered(f, N)\n        f.Close()\n        os.Remove(f.Name())\n    }\n}\n\nfunc BenchmarkWriteBuffered(b *testing.B) {\n    for b.Loop() {\n        f, _ := os.CreateTemp("", "buf")\n        writeBuffered(f, N)\n        f.Close()\n        os.Remove(f.Name())\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n\n\n运行结果如下，带缓冲的性能提升了约 62 倍，但内存申请多了 30%。\n\n$ go test -bench=. -benchmem .  \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: Apple M4 Pro\nBenchmarkWriteNotBuffered-12                  64          18470001 ns/op           53758 B/op      10007 allocs/op\nBenchmarkWriteBuffered-12                   3984            297904 ns/op           70122 B/op      10008 allocs/op\nPASS\nok      main/demo       3.530s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 6. 总结\n\n应用场景\n\n 1. 频繁的执行小数据量的 I/O。\n 2. 减少系统调用。\n 3. 高吞吐量比延迟更重要。\n\n不适用场景\n\n 1. 实时性要求高。\n 2. 过度缓冲导致内存使用不受控制。',normalizedContent:'# 1. 简介\n\n在计算机系统中，i/o操作（如文件读写、网络通信）是性能瓶颈的主要来源之一。主要原因包括：\n\n 1. 系统调用开销：每次直接i/o操作都涉及用户态和内核态的上下文切换\n 2. 硬件限制：磁盘和网络设备更适合大块数据传输\n 3. 频繁小数据操作：大量小数据写入会显著降低性能\n\n缓冲技术通过在内存中聚合数据，减少实际i/o操作次数，可显著提升性能。\n\n\n# 2. 不带缓冲的写入\n\n直接频繁调用系统api，性能最差：\n\n// 每次写入都触发系统调用\nf, _ := os.create("output.txt")\ndefer f.close()\n\nfor i := 0; i < 10000; i++ {\n    f.write([]byte("line\\n"))  // 高成本操作\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 3. 带缓冲的写入\n\n使用bufio.writer自动缓冲：\n\nf, _ := os.create("output.txt")\ndefer f.close()\n\nbuf := bufio.newwriter(f)  // 默认4kb缓冲\nfor i := 0; i < 10000; i++ {\n    buf.writestring("line\\n")  // 内存操作\n}\nbuf.flush()  // 最终写入磁盘\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 4. 控制缓冲区容量\n\n根据场景调整缓冲区大小：\n\nf, _ := os.create("output.txt")\ndefer f.close()\n\n// 16kb缓冲，适合大文件写入\nbuf := bufio.newwritersize(f, 16*1024)  \n\n\n1\n2\n3\n4\n5\n\n\n\n# 5. 带缓冲与不带缓冲的 benchmark\n\n比较通过直接调用os.file.write相比，使用bufio.writer向磁盘写入一百万行数据。\n\npackage perf\n\nimport (\n    "bufio"\n    "io"\n    "os"\n    "strconv"\n    "sync"\n    "testing"\n)\n\ntype data struct {\n    value []byte\n}\n\nvar datapool = sync.pool{\n    new: func() any {\n        return &data{value: make([]byte, 0, 32)}\n    },\n}\n\nconst n = 10000\n\nfunc writenotbuffered(w io.writer, count int) {\n    for i := 0; i < count; i++ {\n        d := datapool.get().(*data)\n        d.value = strconv.appendint(d.value[:0], int64(i), 10)\n        w.write(d.value)\n        w.write([]byte(":val\\n"))\n        datapool.put(d)\n    }\n}\n\nfunc writebuffered(w io.writer, count int) {\n    buf := bufio.newwritersize(w, 16*1024)\n    for i := 0; i < count; i++ {\n        d := datapool.get().(*data)\n        d.value = strconv.appendint(d.value[:0], int64(i), 10)\n        buf.write(d.value)\n        buf.write([]byte(":val\\n"))\n        datapool.put(d)\n    }\n    buf.flush()\n}\n\nfunc benchmarkwritenotbuffered(b *testing.b) {\n    for b.loop() {\n        f, _ := os.createtemp("", "nobuf")\n        writenotbuffered(f, n)\n        f.close()\n        os.remove(f.name())\n    }\n}\n\nfunc benchmarkwritebuffered(b *testing.b) {\n    for b.loop() {\n        f, _ := os.createtemp("", "buf")\n        writebuffered(f, n)\n        f.close()\n        os.remove(f.name())\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n\n\n运行结果如下，带缓冲的性能提升了约 62 倍，但内存申请多了 30%。\n\n$ go test -bench=. -benchmem .  \ngoos: darwin\ngoarch: arm64\npkg: main/demo\ncpu: apple m4 pro\nbenchmarkwritenotbuffered-12                  64          18470001 ns/op           53758 b/op      10007 allocs/op\nbenchmarkwritebuffered-12                   3984            297904 ns/op           70122 b/op      10008 allocs/op\npass\nok      main/demo       3.530s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 6. 总结\n\n应用场景\n\n 1. 频繁的执行小数据量的 i/o。\n 2. 减少系统调用。\n 3. 高吞吐量比延迟更重要。\n\n不适用场景\n\n 1. 实时性要求高。\n 2. 过度缓冲导致内存使用不受控制。',charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"快速了解iptables",frontmatter:{title:"快速了解iptables",date:"2023-05-15T19:19:11.000Z",permalink:"/pages/72ba9a/",categories:["编程","linux"],tags:["linux","计算机网络","Linux网络虚拟化"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"iptables是一个在Linux操作系统上使用的防火墙工具，它可以用于配置和管理网络数据包的过滤、转发和修改等操作。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/2023-04-13-2330-20230514151755-we6q131.png"},{name:"twitter:title",content:"快速了解iptables"},{name:"twitter:description",content:"iptables是一个在Linux操作系统上使用的防火墙工具，它可以用于配置和管理网络数据包的过滤、转发和修改等操作。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/2023-04-13-2330-20230514151755-we6q131.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/03.linux/01.%E5%BF%AB%E9%80%9F%E4%BA%86%E8%A7%A3iptables.html"},{property:"og:type",content:"article"},{property:"og:title",content:"快速了解iptables"},{property:"og:description",content:"iptables是一个在Linux操作系统上使用的防火墙工具，它可以用于配置和管理网络数据包的过滤、转发和修改等操作。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/2023-04-13-2330-20230514151755-we6q131.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/03.linux/01.%E5%BF%AB%E9%80%9F%E4%BA%86%E8%A7%A3iptables.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-05-15T19:19:11.000Z"},{property:"article:tag",content:"linux"},{property:"article:tag",content:"计算机网络"},{property:"article:tag",content:"Linux网络虚拟化"},{itemprop:"name",content:"快速了解iptables"},{itemprop:"description",content:"iptables是一个在Linux操作系统上使用的防火墙工具，它可以用于配置和管理网络数据包的过滤、转发和修改等操作。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/2023-04-13-2330-20230514151755-we6q131.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/03.linux/01.%E5%BF%AB%E9%80%9F%E4%BA%86%E8%A7%A3iptables.html",relativePath:"04.编程/03.linux/01.快速了解iptables.md",key:"v-7f2a6202",path:"/pages/72ba9a/",headers:[{level:2,title:"初识",slug:"初识",normalizedTitle:"初识",charIndex:2},{level:3,title:"iptables是什么？",slug:"iptables是什么",normalizedTitle:"iptables是什么？",charIndex:9},{level:3,title:"Netfilter是什么？",slug:"netfilter是什么",normalizedTitle:"netfilter是什么？",charIndex:267},{level:3,title:"iptables实现",slug:"iptables实现",normalizedTitle:"iptables实现",charIndex:1020},{level:2,title:"iptables三板斧：table、chain和rule",slug:"iptables三板斧-table、chain和rule",normalizedTitle:"iptables三板斧：table、chain和rule",charIndex:1140},{level:3,title:"chain",slug:"chain",normalizedTitle:"chain",charIndex:1158},{level:3,title:"table",slug:"table",normalizedTitle:"table",charIndex:11},{level:3,title:"rule",slug:"rule",normalizedTitle:"rule",charIndex:1164},{level:2,title:"iptables命令使用",slug:"iptables命令使用",normalizedTitle:"iptables命令使用",charIndex:2402},{level:3,title:"参数",slug:"参数",normalizedTitle:"参数",charIndex:2419},{level:3,title:"常规武器",slug:"常规武器",normalizedTitle:"常规武器",charIndex:3390},{level:2,title:"巨人的肩膀",slug:"巨人的肩膀",normalizedTitle:"巨人的肩膀",charIndex:4926}],headersStr:"初识 iptables是什么？ Netfilter是什么？ iptables实现 iptables三板斧：table、chain和rule chain table rule iptables命令使用 参数 常规武器 巨人的肩膀",content:"# 初识\n\n\n# iptables是什么？\n\niptables是一个在Linux操作系统上使用的防火墙工具，它可以用于配置和管理网络数据包的过滤、转发和修改等操作。\n\n 1. 过滤数据包：iptables可以根据不同的规则过滤网络数据包，例如根据源IP地址、目标IP地址、端口号等进行过滤。\n\n 2. 转发数据包：iptables可以将网络数据包从一个接口转发到另一个接口，实现网络数据的转发功能。\n\n 3. 修改数据包：iptables可以修改网络数据包的源IP地址、目标IP地址、端口号等信息，实现网络数据的伪装和欺骗。\n\n\n# Netfilter是什么？\n\nNetfilter是Linux内核中的一个网络数据包过滤框架，它可以在数据包进入和离开网络接口时进行拦截和处理。iptables就是基于Netfilter框架实现的一个用户空间工具，它可以通过调用Netfilter提供的API来实现网络数据包的过滤、转发和修改等操作。\n\nnetfilter的架构就是在整个网络流程的若干位置放置一些钩子，并在每个钩子上挂载一些处理函数进行处理。\n\nIP层的5个钩子点的位置，分别是PREROUTING、POSTROUTING、INPUT、OUTPUT和FORWARD。原理图如下：\n\n‍\n\n‍\n\n当网卡上收到一个包送达协议栈时，最先经过的netfilter钩子是PREROUTING，如果确实有用户埋了这个钩子函数，那么内核将在这里对数据包进行目的地址转换（DNAT）。不管在PREROUTING有没有做过DNAT，内核都会通过查本地路由表决定这个数据包是发送给本地进程还是发送给其他机器。如果是发送给其他机器（或其他network namespace），就相当于把本地当作路由器，就会经过netfilter的FORWARD钩子，用户可以在此处设置包过滤钩子函数，例如iptables的reject函数。所有马上要发到协议栈外的包都会经过POSTROUTING钩子，用户可以在这里埋下源地址转换（SNAT）或源地址伪装（Masquerade，简称Masq）的钩子函数。如果经过上面的路由决策，内核决定把包发给本地进程，就会经过INPUT钩子。本地进程收到数据包后，回程报文会先经过OUTPUT钩子，然后经过一次路由决策（例如，决定从机器的哪块网卡出去，下一跳地址是多少等），最后出协议栈的网络包同样会经过POSTROUTING钩子。\n\n\n# iptables实现\n\niptables的底层实现是通过Linux内核中的Netfilter框架来实现的。iptables是用户空间的一个程序，通过netlink和内核的netfilter框架打交道，负责往钩子上配置回调函数。\n\n\n\n\n# iptables三板斧：table、chain和rule\n\n\n# chain\n\niptables有5条内置链分别对应着netfilter的5个钩子：\n\n * INPUT链：一般用于处理输入本地进程的数据包。\n * OUTPUT链：一般用于处理本地进程的输出数据包。\n * FORWARD链：一般用于处理转发到其他机器/network namespace的数\n   据包。\n * PREROUTING链：可以在此处进行DNAT。\n * POSTROUTING链：可以在此处进行SNAT。\n\n\n# table\n\n除了5条内置链之外，还可以在表中定义自己的链：\n\n * filter 表：用于过滤数据包，是默认的表。它包含 INPUT、OUTPUT 和 FORWARD 三个链，分别用于处理进入本机的数据包、从本机发出的数据包和转发的数据包。\n\n * nat 表：用于网络地址转换（NAT）。它包含 PREROUTING、POSTROUTING 和 OUTPUT 三个链，分别用于处理进入本机前的数据包、从本机发出的数据包和本机生成的数据包。\n\n * mangle 表：用于修改数据包的特定字段。如 TTL、TOS 等。它包含 PREROUTING、INPUT、FORWARD、OUTPUT 和 POSTROUTING 五个链，分别用于处理进入本机前的数据包、进入本机的数据包、转发的数据包、从本机发出的数据包和本机生成的数据包。\n\n * raw 表：用于配置连接追踪系统。它包含 PREROUTING 和 OUTPUT 两个链，分别用于处理进入本机前的数据包和从本机发出的数据包。\n\n这5张表的优先级从高到低是：raw、mangle、nat、filter、security。\n\niptables表与链的对应关系图如下：\n\n‍\n\n\n\n不同的表挂不同的链，这是为了分类管理iptables规则（rule）的，系统所有的iptables规则都被划分到不同的表集合中。\n\n\n# rule\n\niptables的规则就是挂载netfilter钩子上的函数，用来修改数据包的内容或者过滤数据包等操作，iptables的表就是所有规则的5个逻辑集合。\n\niptables规则如何编写？\n\n一条iptables规则包含两部分信息：匹配条件和动作。\n\n匹配条件即为匹配数据包被这条iptables规则“捕获”的条件，例如协议类型、源IP、目的IP、源端口、目的端口、连接状态等。每条iptables规则允许多个匹配条件任意组合，从而实现多条件的匹配，多条件之间是逻辑与（&&）关系。\n\n常见动作如下：\n\n * ACCEPT：允许数据包通过。\n\n * DROP：丢弃数据包，不给出任何响应。\n\n * REJECT：拒绝数据包，给出响应告知发送方被拒绝。\n\n * SNAT：源地址转换，用于网络地址转换（NAT）。\n\n * DNAT：目标地址转换，用于网络地址转换（NAT）。\n\n * REDIRECT：重定向数据包到指定端口或 IP 地址。\n\n\n# iptables命令使用\n\n\n# 参数\n\n * -A：添加规则到指定链的末尾。\n   例如：iptables -A INPUT -s 192.168.1.0/24 -j DROP\n\n * -D：删除指定链中的规则。\n   例如：iptables -D INPUT -s 192.168.1.0/24 -j DROP\n\n * -I：插入规则到指定链的开头或指定位置。\n   例如：iptables -I INPUT 2 -s 192.168.1.0/24 -j DROP\n\n * -R：替换指定链中的规则。\n   例如：iptables -R INPUT 2 -s 192.168.1.0/24 -j DROP\n\n * -L：列出指定链中的规则。\n   例如：iptables -L INPUT\n\n * -F：清空指定链中的规则。\n   例如：iptables -F INPUT\n\n * -N：创建新的自定义链。\n   例如：iptables -N MYCHAIN\n\n * -X：删除指定的自定义链。\n   例如：iptables -X MYCHAIN\n\n * -P：设置指定链的默认策略。\n   例如：iptables -P INPUT DROP\n\n * -s：指定源 IP 地址或地址段。\n   例如：iptables -A INPUT -s 192.168.1.0/24 -j DROP\n\n * -d：指定目标 IP 地址或地址段。\n   例如：iptables -A OUTPUT -d 192.168.1.0/24 -j DROP\n\n * -p：指定协议类型。\n   例如：iptables -A INPUT -p tcp -j DROP\n\n * -m：指定匹配模块。\n   例如：iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n\n * -j：指定动作。\n   例如：iptables -A INPUT -s 192.168.1.0/24 -j DROP\n\n * -i：指定进入接口。\n   例如：iptables -A INPUT -i eth0 -j DROP\n\n * -o：指定输出接口。\n   例如：iptables -A OUTPUT -o eth0 -j DROP\n\n\n# 常规武器\n\n 1. 查看所有iptables规则\n\niptables -L -n\n\n\n1\n\n 2. 配置防火墙规则策略\n\n * 配置允许SSH连接\n\niptables -A INPUT -s 10.20.30.40/24 -p tcp --dport 22 -j ACCECT\n\n\n1\n\n\n-A INPUT 是以追加的方式增加该规则在INPUT链上，-s 10.20.30.40/24 -p tcp --dport 22 是匹配上源地址为10.20.30.40/24网段，tcp协议和目的端口22的数据包，-j ACCET 表示允许该数据包进行连接。这里没有指定表默认是filter表。\n\n * 阻止来自某个IP/网段的所有连接\n\niptables -A INPUT -s 10.10.10.10 -j DROP\n\n\n1\n\n\n-j DROP 会发送给源地址为10.10.10.10一个连接拒绝的回程报文。\n\n * 封锁端口\n\niptables -A OUTPUT -p tcp --dport 1234 -j DROP\n\n\n1\n\n\n禁止本地进程访问外部1234端口。因为是在挂载OUTPUT链上该条规则，所以是屏蔽本地进程对外的连接。如果想要禁止外部连接访问本地1234端口，则需要在INPUT链上新增规则。\n\niptables -A INPUT -p tcp --dport 1234 -j DROP\n\n\n1\n\n * 端口转发\n\niptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j REDIRECT --to-port 8080\n\n\n1\n\n\n该条规则添加到PREROUTING链下的nat表中，匹配上eth0网卡上所有目的端口为80的tcp数据包，匹配上则将转发到8080端口上。因为将目的端口改变了，则需要写到nat表中。\n\n * 禁ping\n\niptables -A INPUT -p icmp -j DROP\n\n\n1\n\n\n在INPUT链filter表中新增禁止icmp协议数据包的规则。\n\n 3. DNAT\n\niptables -t nat -A PREROUTING -d 1.2.3.4 -p tcp --dport 80 -j DNAT --to-destination 10.20.30.40:8080\n\n\n1\n\n\n和端口转发原理差不多，区别在于，端口转发不修改IP地址，而这里修改了目的IP地址。在nat表PREROUTING中新增目的地址为1.2.3.4，目的端口80的tcp数据包的DNAT动作，将目的地址改为了10.20.30.40:8080。\n\nDNAT仅发生在nat表的PREROUTING链中，并且该操作需要确保开启ipforward功能。\n\n 4. SNAT\n\niptables -t nat -A POSTROUTING -s 192.168.1.2 -j SNAT --to-source 10.172.16.1\n\n\n1\n\n\n在nat表POSTROUTING链中新增将源地址192.168.1.2的数据包进行SNAT操作，改为源地址10.172.16.1.\n\nSNAT操作仅可发生在nat表的POSTROUTING链中。\n\n 5. 保存与恢复\n\niptables规则修改仅是临时的，重启则丢失，执行以下命令永久保存。\n\niptables-save\n\n\n1\n\n\n也可将规则保存在文件中\n\niptables-save > iptables.bak\n\n\n1\n\n\n后续可以通过以下命令进行恢复\n\niptables-restore < iptables.bak\n\n\n1\n\n\n\n# 巨人的肩膀\n\n * 《kubernetes网络权威指南》\n\n‍",normalizedContent:"# 初识\n\n\n# iptables是什么？\n\niptables是一个在linux操作系统上使用的防火墙工具，它可以用于配置和管理网络数据包的过滤、转发和修改等操作。\n\n 1. 过滤数据包：iptables可以根据不同的规则过滤网络数据包，例如根据源ip地址、目标ip地址、端口号等进行过滤。\n\n 2. 转发数据包：iptables可以将网络数据包从一个接口转发到另一个接口，实现网络数据的转发功能。\n\n 3. 修改数据包：iptables可以修改网络数据包的源ip地址、目标ip地址、端口号等信息，实现网络数据的伪装和欺骗。\n\n\n# netfilter是什么？\n\nnetfilter是linux内核中的一个网络数据包过滤框架，它可以在数据包进入和离开网络接口时进行拦截和处理。iptables就是基于netfilter框架实现的一个用户空间工具，它可以通过调用netfilter提供的api来实现网络数据包的过滤、转发和修改等操作。\n\nnetfilter的架构就是在整个网络流程的若干位置放置一些钩子，并在每个钩子上挂载一些处理函数进行处理。\n\nip层的5个钩子点的位置，分别是prerouting、postrouting、input、output和forward。原理图如下：\n\n‍\n\n‍\n\n当网卡上收到一个包送达协议栈时，最先经过的netfilter钩子是prerouting，如果确实有用户埋了这个钩子函数，那么内核将在这里对数据包进行目的地址转换（dnat）。不管在prerouting有没有做过dnat，内核都会通过查本地路由表决定这个数据包是发送给本地进程还是发送给其他机器。如果是发送给其他机器（或其他network namespace），就相当于把本地当作路由器，就会经过netfilter的forward钩子，用户可以在此处设置包过滤钩子函数，例如iptables的reject函数。所有马上要发到协议栈外的包都会经过postrouting钩子，用户可以在这里埋下源地址转换（snat）或源地址伪装（masquerade，简称masq）的钩子函数。如果经过上面的路由决策，内核决定把包发给本地进程，就会经过input钩子。本地进程收到数据包后，回程报文会先经过output钩子，然后经过一次路由决策（例如，决定从机器的哪块网卡出去，下一跳地址是多少等），最后出协议栈的网络包同样会经过postrouting钩子。\n\n\n# iptables实现\n\niptables的底层实现是通过linux内核中的netfilter框架来实现的。iptables是用户空间的一个程序，通过netlink和内核的netfilter框架打交道，负责往钩子上配置回调函数。\n\n\n\n\n# iptables三板斧：table、chain和rule\n\n\n# chain\n\niptables有5条内置链分别对应着netfilter的5个钩子：\n\n * input链：一般用于处理输入本地进程的数据包。\n * output链：一般用于处理本地进程的输出数据包。\n * forward链：一般用于处理转发到其他机器/network namespace的数\n   据包。\n * prerouting链：可以在此处进行dnat。\n * postrouting链：可以在此处进行snat。\n\n\n# table\n\n除了5条内置链之外，还可以在表中定义自己的链：\n\n * filter 表：用于过滤数据包，是默认的表。它包含 input、output 和 forward 三个链，分别用于处理进入本机的数据包、从本机发出的数据包和转发的数据包。\n\n * nat 表：用于网络地址转换（nat）。它包含 prerouting、postrouting 和 output 三个链，分别用于处理进入本机前的数据包、从本机发出的数据包和本机生成的数据包。\n\n * mangle 表：用于修改数据包的特定字段。如 ttl、tos 等。它包含 prerouting、input、forward、output 和 postrouting 五个链，分别用于处理进入本机前的数据包、进入本机的数据包、转发的数据包、从本机发出的数据包和本机生成的数据包。\n\n * raw 表：用于配置连接追踪系统。它包含 prerouting 和 output 两个链，分别用于处理进入本机前的数据包和从本机发出的数据包。\n\n这5张表的优先级从高到低是：raw、mangle、nat、filter、security。\n\niptables表与链的对应关系图如下：\n\n‍\n\n\n\n不同的表挂不同的链，这是为了分类管理iptables规则（rule）的，系统所有的iptables规则都被划分到不同的表集合中。\n\n\n# rule\n\niptables的规则就是挂载netfilter钩子上的函数，用来修改数据包的内容或者过滤数据包等操作，iptables的表就是所有规则的5个逻辑集合。\n\niptables规则如何编写？\n\n一条iptables规则包含两部分信息：匹配条件和动作。\n\n匹配条件即为匹配数据包被这条iptables规则“捕获”的条件，例如协议类型、源ip、目的ip、源端口、目的端口、连接状态等。每条iptables规则允许多个匹配条件任意组合，从而实现多条件的匹配，多条件之间是逻辑与（&&）关系。\n\n常见动作如下：\n\n * accept：允许数据包通过。\n\n * drop：丢弃数据包，不给出任何响应。\n\n * reject：拒绝数据包，给出响应告知发送方被拒绝。\n\n * snat：源地址转换，用于网络地址转换（nat）。\n\n * dnat：目标地址转换，用于网络地址转换（nat）。\n\n * redirect：重定向数据包到指定端口或 ip 地址。\n\n\n# iptables命令使用\n\n\n# 参数\n\n * -a：添加规则到指定链的末尾。\n   例如：iptables -a input -s 192.168.1.0/24 -j drop\n\n * -d：删除指定链中的规则。\n   例如：iptables -d input -s 192.168.1.0/24 -j drop\n\n * -i：插入规则到指定链的开头或指定位置。\n   例如：iptables -i input 2 -s 192.168.1.0/24 -j drop\n\n * -r：替换指定链中的规则。\n   例如：iptables -r input 2 -s 192.168.1.0/24 -j drop\n\n * -l：列出指定链中的规则。\n   例如：iptables -l input\n\n * -f：清空指定链中的规则。\n   例如：iptables -f input\n\n * -n：创建新的自定义链。\n   例如：iptables -n mychain\n\n * -x：删除指定的自定义链。\n   例如：iptables -x mychain\n\n * -p：设置指定链的默认策略。\n   例如：iptables -p input drop\n\n * -s：指定源 ip 地址或地址段。\n   例如：iptables -a input -s 192.168.1.0/24 -j drop\n\n * -d：指定目标 ip 地址或地址段。\n   例如：iptables -a output -d 192.168.1.0/24 -j drop\n\n * -p：指定协议类型。\n   例如：iptables -a input -p tcp -j drop\n\n * -m：指定匹配模块。\n   例如：iptables -a input -m state --state established,related -j accept\n\n * -j：指定动作。\n   例如：iptables -a input -s 192.168.1.0/24 -j drop\n\n * -i：指定进入接口。\n   例如：iptables -a input -i eth0 -j drop\n\n * -o：指定输出接口。\n   例如：iptables -a output -o eth0 -j drop\n\n\n# 常规武器\n\n 1. 查看所有iptables规则\n\niptables -l -n\n\n\n1\n\n 2. 配置防火墙规则策略\n\n * 配置允许ssh连接\n\niptables -a input -s 10.20.30.40/24 -p tcp --dport 22 -j accect\n\n\n1\n\n\n-a input 是以追加的方式增加该规则在input链上，-s 10.20.30.40/24 -p tcp --dport 22 是匹配上源地址为10.20.30.40/24网段，tcp协议和目的端口22的数据包，-j accet 表示允许该数据包进行连接。这里没有指定表默认是filter表。\n\n * 阻止来自某个ip/网段的所有连接\n\niptables -a input -s 10.10.10.10 -j drop\n\n\n1\n\n\n-j drop 会发送给源地址为10.10.10.10一个连接拒绝的回程报文。\n\n * 封锁端口\n\niptables -a output -p tcp --dport 1234 -j drop\n\n\n1\n\n\n禁止本地进程访问外部1234端口。因为是在挂载output链上该条规则，所以是屏蔽本地进程对外的连接。如果想要禁止外部连接访问本地1234端口，则需要在input链上新增规则。\n\niptables -a input -p tcp --dport 1234 -j drop\n\n\n1\n\n * 端口转发\n\niptables -t nat -a prerouting -i eth0 -p tcp --dport 80 -j redirect --to-port 8080\n\n\n1\n\n\n该条规则添加到prerouting链下的nat表中，匹配上eth0网卡上所有目的端口为80的tcp数据包，匹配上则将转发到8080端口上。因为将目的端口改变了，则需要写到nat表中。\n\n * 禁ping\n\niptables -a input -p icmp -j drop\n\n\n1\n\n\n在input链filter表中新增禁止icmp协议数据包的规则。\n\n 3. dnat\n\niptables -t nat -a prerouting -d 1.2.3.4 -p tcp --dport 80 -j dnat --to-destination 10.20.30.40:8080\n\n\n1\n\n\n和端口转发原理差不多，区别在于，端口转发不修改ip地址，而这里修改了目的ip地址。在nat表prerouting中新增目的地址为1.2.3.4，目的端口80的tcp数据包的dnat动作，将目的地址改为了10.20.30.40:8080。\n\ndnat仅发生在nat表的prerouting链中，并且该操作需要确保开启ipforward功能。\n\n 4. snat\n\niptables -t nat -a postrouting -s 192.168.1.2 -j snat --to-source 10.172.16.1\n\n\n1\n\n\n在nat表postrouting链中新增将源地址192.168.1.2的数据包进行snat操作，改为源地址10.172.16.1.\n\nsnat操作仅可发生在nat表的postrouting链中。\n\n 5. 保存与恢复\n\niptables规则修改仅是临时的，重启则丢失，执行以下命令永久保存。\n\niptables-save\n\n\n1\n\n\n也可将规则保存在文件中\n\niptables-save > iptables.bak\n\n\n1\n\n\n后续可以通过以下命令进行恢复\n\niptables-restore < iptables.bak\n\n\n1\n\n\n\n# 巨人的肩膀\n\n * 《kubernetes网络权威指南》\n\n‍",charsets:{cjk:!0},lastUpdated:"2025/02/09, 23:47:02",lastUpdatedTimestamp:1739116022e3},{title:"理解Linux TunTap设备",frontmatter:{title:"理解Linux TunTap设备",date:"2023-05-26T10:20:08.000Z",permalink:"/pages/143447/",categories:["编程","linux"],tags:["linux","计算机网络","Linux网络虚拟化"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"TUN/TAP是操作系统内核中的虚拟网络设备，可以完成用户空间与内核空间的数据的交互。网络协议栈中的数据通过该设备可以进入到用户空间中，而用户空间中的程序通过该设备空间进入到内核空间的网络协议栈。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/2023-04-13-2330-20230507110448-2vjzt36.png"},{name:"twitter:title",content:"理解Linux TunTap设备"},{name:"twitter:description",content:"TUN/TAP是操作系统内核中的虚拟网络设备，可以完成用户空间与内核空间的数据的交互。网络协议栈中的数据通过该设备可以进入到用户空间中，而用户空间中的程序通过该设备空间进入到内核空间的网络协议栈。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/2023-04-13-2330-20230507110448-2vjzt36.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/03.linux/02.%E7%90%86%E8%A7%A3Linux%20TunTap%E8%AE%BE%E5%A4%87.html"},{property:"og:type",content:"article"},{property:"og:title",content:"理解Linux TunTap设备"},{property:"og:description",content:"TUN/TAP是操作系统内核中的虚拟网络设备，可以完成用户空间与内核空间的数据的交互。网络协议栈中的数据通过该设备可以进入到用户空间中，而用户空间中的程序通过该设备空间进入到内核空间的网络协议栈。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/2023-04-13-2330-20230507110448-2vjzt36.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/03.linux/02.%E7%90%86%E8%A7%A3Linux%20TunTap%E8%AE%BE%E5%A4%87.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-05-26T10:20:08.000Z"},{property:"article:tag",content:"linux"},{property:"article:tag",content:"计算机网络"},{property:"article:tag",content:"Linux网络虚拟化"},{itemprop:"name",content:"理解Linux TunTap设备"},{itemprop:"description",content:"TUN/TAP是操作系统内核中的虚拟网络设备，可以完成用户空间与内核空间的数据的交互。网络协议栈中的数据通过该设备可以进入到用户空间中，而用户空间中的程序通过该设备空间进入到内核空间的网络协议栈。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/2023-04-13-2330-20230507110448-2vjzt36.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/03.linux/02.%E7%90%86%E8%A7%A3Linux%20TunTap%E8%AE%BE%E5%A4%87.html",relativePath:"04.编程/03.linux/02.理解Linux TunTap设备.md",key:"v-26efa3da",path:"/pages/143447/",headers:[{level:2,title:"入门",slug:"入门",normalizedTitle:"入门",charIndex:2},{level:2,title:"应用程序通过tun设备获取ping数据包",slug:"应用程序通过tun设备获取ping数据包",normalizedTitle:"应用程序通过tun设备获取ping数据包",charIndex:293},{level:2,title:"使用tun设备完成基于UDP的容器跨节点通信",slug:"使用tun设备完成基于udp的容器跨节点通信",normalizedTitle:"使用tun设备完成基于udp的容器跨节点通信",charIndex:3535},{level:2,title:"巨人的肩膀",slug:"巨人的肩膀",normalizedTitle:"巨人的肩膀",charIndex:8804}],headersStr:"入门 应用程序通过tun设备获取ping数据包 使用tun设备完成基于UDP的容器跨节点通信 巨人的肩膀",content:'# 入门\n\nTUN/TAP是操作系统内核中的虚拟网络设备，可以完成用户空间与内核空间的数据的交互。网络协议栈中的数据通过该设备可以进入到用户空间中，而用户空间中的程序通过该设备空间进入到内核空间的网络协议栈。\n\nTUN模拟的是三层设备，操作三层的数据包，而TAP模拟的二层设备，操作二层的数据包。\n\n> 物理网卡与虚拟网卡的区别是，物理网卡是外界与内核空间的网络协议栈数据交互的门户，而虚拟网卡是用户空间和内核空间交互的门户。\n\n/dev/net/tun 是linux提供的字符设备，写入该设备的数据会发送到虚拟网卡中，而发送到虚拟网卡中的数据也会出现在字符设备中。\n\n\n\n‍\n\n\n# 应用程序通过tun设备获取ping数据包\n\n\n\napp程序通过打开tun字符设备创建出tun虚拟网卡。然后通过ping命令发送ICMP数据包到网络协议栈中，这个过程是从用户空间到内核空间，再通过路由将数据包转发到tun虚拟网卡中，因为tun网卡特性，会进入到打开该tun设备用户空间app程序中。\n\napp程序代码如下：\n\nimport os\nimport struct\nfrom fcntl import ioctl\n\nBUFFER_SIZE = 4096\n\n# 完成虚拟网卡的注册\nTUNSETIFF = 0x400454ca\n\n# 设备模式\nIFF_TUN = 0x0001\nIFF_TAP = 0x0002\n\n\ndef create_tunnel(tun_name=\'tun%d\', tun_mode=IFF_TUN):\n    # 以读写的方式打开字符设备tun，获取到设备描述符\n    tun_fd = os.open("/dev/net/tun", os.O_RDWR)\n\n    # 对该设备进行配置，设备名称和设备模式。\n    ifn = ioctl(tun_fd, TUNSETIFF, struct.pack(b"16sH", tun_name.encode(), tun_mode))\n\n    # 获取到设备名称\n    tun_name = ifn[:16].decode().strip("\\x00")\n    return tun_fd, tun_name\n\n\ndef main():\n    tun_fd, tun_name = create_tunnel()\n\n    while True:\n        data = os.read(tun_fd, BUFFER_SIZE)\n        print(f"get data from tun. data size = {len(data)}")\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n运行后输出：\n\n# python3 tun_demo.py\nOpen tun/tap device: tun0 for reading...\n\n\n1\n2\n\n\n通过ip a 命令发现tun设备已经创建，但其状态为DOWN\n\n# ip a | grep -C tun\n45: tun0: <POINTOPOINT,MULTICAST,NOARP> mtu 1500 qdisc noop state DOWN group default qlen 500\n    link/none\n\n\n1\n2\n3\n\n\n对其设置一个ip并将它状态设置为UP\n\nip a add 192.37.1.2/24 dev tun0\nip link set tun0 up\n\n\n1\n2\n\n\n配置好ip后，会发现自动配置了如下路由:\n\n...\n192.37.1.0/24 dev tun0 proto kernel scope link src 192.37.1.2 \n...\n\n\n1\n2\n3\n\n\n再次查看tun设备，发现已经配置好\n\n# ip a | grep tun0\n45: tun0: <POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 500\n    inet 192.37.1.1/24 scope global tun0\n\n\n1\n2\n3\n\n\n并且这时会发现tun0已经接收到了3个数据包\n\n# python3 tun_demo.py\nOpen tun/tap device: tun0 for reading...\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 52\n\n\n1\n2\n3\n4\n5\n\n\n这时候使用tcpdump监听tun0，执行ping 192.37.1.2，是有回包的，但是tcpdump却没有抓到任何包。\n\n> ping命令会根据目标IP地址和子网掩码来判断数据包的目的地，如果目的地在本地网络中，ping命令会直接将数据包发送到本地网络，而不是通过TUN设备发送。\n\n# tcpdump -i tun0 -n\n...\n\n# ping 192.37.1.2 -c 3\nPING 192.37.1.2 (192.37.1.2) 56(84) bytes of data.\n64 bytes from 192.37.1.2: icmp_seq=1 ttl=64 time=0.148 ms\n64 bytes from 192.37.1.2: icmp_seq=2 ttl=64 time=0.114 ms\n64 bytes from 192.37.1.2: icmp_seq=3 ttl=64 time=0.316 ms\n\n--- 192.37.1.2 ping statistics ---\n3 packets transmitted, 3 received, 0% packet loss, time 1999ms\nrtt min/avg/max/mdev = 0.114/0.192/0.316/0.089 ms\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n改为ping 192.37.1.3，可以看到程序收到了收到了数据包，tcpdump也抓到了包，但是因为没有做任何的处理也没有回包，所以ping命令看到不到回包。\n\n# python3 tun_demo.py\nOpen tun/tap device: tun0 for reading...\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 52\n\nget data from tun. data size = 88\nget data from tun. data size = 88\nget data from tun. data size = 88\n\n# tcpdump -i tun0 -n\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on tun0, link-type RAW (Raw IP), capture size 262144 bytes\n22:56:41.018149 IP 192.37.1.2 > 192.37.1.3: ICMP echo request, id 22559, seq 1, length 64\n22:56:42.018871 IP 192.37.1.2 > 192.37.1.3: ICMP echo request, id 22559, seq 2, length 64\n22:56:43.022732 IP 192.37.1.2 > 192.37.1.3: ICMP echo request, id 22559, seq 3, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n‍\n\n\n# 使用tun设备完成基于UDP的容器跨节点通信\n\n使用tun设备基于UDP完成容器跨节点通信。如下图所示：\n\n‍\n\n\n\n通信流程是，在Node1中的NS1进行ping Node2中NS2的veth0网卡的IP，ICMP的IP包会通过veth0到达veth1中，并进入到宿主机的网络协议栈，通过路由配置达到tun设备，这时app服务从tun设备中读取到IP包数据，然后将其封装在UDP包中，并通过eth0网卡发送到Node2的eth0网卡上，通过网络协议栈解包达到app程序中，拿到里面的IP包，将其写入到tun设备中，进入到网络协议栈中，通过路由达到veth1中，然后到达net ns1的veth0网卡。\n\napp程序简单实现如下：\n\nimport os\nimport socket\nimport struct\nimport threading\nfrom fcntl import ioctl\nimport click\n\nBIND_ADDRESS = (\'0.0.0.0\', 7000)\nBUFFER_SIZE = 4096\n\nTUNSETIFF = 0x400454ca\nIFF_TUN = 0x0001\nIFF_TAP = 0x0002\n\n\ndef create_tunnel(tun_name=\'tun%d\', tun_mode=IFF_TUN):\n    tun_fd = os.open("/dev/net/tun", os.O_RDWR)\n    ifn = ioctl(tun_fd, TUNSETIFF, struct.pack(b"16sH", tun_name.encode(), tun_mode))\n    tun_name = ifn[:16].decode().strip("\\x00")\n    return tun_fd, tun_name\n\n\ndef start_tunnel(tun_name):\n    os.popen(f"ip link set {tun_name} up")\n\n\ndef udp_server(udp_socket, tun_fd):\n    while True:\n        data, addr = udp_socket.recvfrom(2048)\n        print("get data from udp.")\n        if not data:\n            break\n\n        os.write(tun_fd, data)\n\n\n@click.command()\n@click.option("--peer_node_ip", "-p", required=True, help="对端节点IP")\ndef main(peer_node_ip):\n    peer_node_addr = (peer_node_ip, 7000)\n\n    tun_fd, tun_name = create_tunnel()\n    start_tunnel(tun_name)\n\n    udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    udp_socket.bind(BIND_ADDRESS)\n\n    t = threading.Thread(target=udp_server, args=(udp_socket, tun_fd))\n    t.daemon = True\n    t.start()\n\n    while True:\n        data = os.read(tun_fd, BUFFER_SIZE)\n        print(f"get data from tun. data size = {len(data)}")\n        udp_socket.sendto(data, peer_node_addr)\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n\n\n在Node1中运行该程序，设置Node2 IP\n\npython3 tun_app.py -p 10.65.132.187\n\n\n1\n\n\n可以看到已经创建了tun设备\n\n# ip link show tun0\n...\n109: tun0: <POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 500\n    link/none \n    inet6 fe80::8e98:91a4:6537:d77a/64 scope link flags 800 \n       valid_lft forever preferred_lft forever\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n在Node1中创建Network Namespace命名为net1，使用它来完成模拟容器网络。\n\nip netns add net1\n\n\n1\n\n\n然后创建veth pair，它们是一对网卡，分别为命名为veth0和veth1\n\nip link add veth0 type veth peer name veth1\n\n\n1\n\n\n将其一端接入到net1中，并设置好其IP地址为10.1.1.2/24\n\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 10.1.1.2/24 dev veth0\nip netns exec net1 ip link set dev veth0 up\n\n\n1\n2\n3\n\n\n开启在宿主机上的veth1网卡，并设置其IP为10.1.1.1/24\n\nip a add 10.1.1.1/24 dev veth1\nip link set dev veth1 up\n\n\n1\n2\n\n\n再将net1中的默认路由设置成都走veth0，这样，ping Node2中net2的网络包可以到veth1中，也就进入到了宿主机的网络协议栈中。\n\nip netns exec net1 ip r add default via 10.1.1.1 dev veth0\n\n\n1\n\n\n在宿主机上还需要添加路由，访问Node2中net2时都路由到tun0设备\n\nip r add 10.1.2.0/24 dev tun0\n\n\n1\n\n\n这时，在Node1 net1中ping Node2 net2时，正常来说是可以在app中看到从tun收到IP包的，虽然没有回包，那是因为app程序收到包后没有做任何回包操作。\n\n# ip netns exec net1 ping 10.1.2.2 -c 3\nPING 10.1.2.2 (10.1.2.2) 56(84) bytes of data.\n--- 10.1.2.2 ping statistics ---\n3 packets transmitted, 0 received, 100% packet loss, time 2001ms\n\n\n1\n2\n3\n4\n\n\n我们通过tcpdump抓取veth1网卡，可以看到收到了ARP请求，想要获取10.1.2.2的MAC地址，但是一直获取不到，所以导致IP包无法通过路由达到TUN设备\n\n# tcpdump -i veth1 -n\n00:45:13.988076 ARP, Request who-has 10.1.2.2 tell 10.1.1.2, length 28\n\n\n1\n2\n\n\n这个时候需要开启veth1的arp代理，将veth1的MAC地址作为ARP的回复。\n\necho 1 >  /proc/sys/net/ipv4/conf/veth1/proxy_arp\n\n\n1\n\n\n再次ping Node2 net2时，可以看到tcpdump看到ARP中回复的MAC地址为veth1的地址。\n\n# tcpdump -i veth1 -n\n00:45:13.988076 ARP, Request who-has 10.1.2.2 tell 10.1.1.2, length 28\n00:45:13.988100 ARP, Reply 10.1.2.2 is-at 4e:7c:bf:fe:4d:0f, length 28\n\n# ip a | grep -C 3 veth1\n...\n107: veth1@if108: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000\n    link/ether 4e:7c:bf:fe:4d:0f brd ff:ff:ff:ff:ff:ff link-netnsid 3\n    inet 10.1.1.1/24 scope global veth1\n       valid_lft forever preferred_lft forever\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n并且app程序中也从tun设备中获取到了IP包。\n\n# python3 tun_app.py -p 10.65.132.187\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 88\nget data from tun. data size = 88\nget data from tun. data size = 88\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n到这一步，Node1的基本配置完成，接下来配置Node2，配置的方法与Node1一致，在Node2执行命令如下:\n\n# 开启app程序\npython3 tun_app.py -p 10.61.74.37\n\n# 新增network namespace net2\nip netns add net2\n\n# 新增veth pair设备\nip link add veth0 type veth peer name veth1\n\n# 配置veth pair设备\nip link set dev veth0 netns net2\nip netns exec net2 ip addr add 10.1.2.2/24 dev veth0\nip netns exec net2 ip link set dev veth0 up\n\nip a add 10.1.2.1/24 dev veth1\nip link set dev veth1 up\n\n# 添加默认路由\nip netns exec net2 ip r add default via 10.1.2.1 dev veth0\n\n# 添加tun0设备路由\nip r add 10.1.1.0/24 dev tun0\n\n# 开启arp代理\necho 1 >  /proc/sys/net/ipv4/conf/veth1/proxy_arp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n配置完成后，在Node1的net1中ping Node2的net2，可以ping通有回包。\n\n# ip netns exec net1 ping 10.1.2.2 \nPING 10.1.2.2 (10.1.2.2) 56(84) bytes of data.\n64 bytes from 10.1.2.2: icmp_seq=1 ttl=62 time=5.46 ms\n64 bytes from 10.1.2.2: icmp_seq=2 ttl=62 time=4.67 ms\n64 bytes from 10.1.2.2: icmp_seq=3 ttl=62 time=5.52 ms\n\n\n1\n2\n3\n4\n5\n\n\n\n# 巨人的肩膀\n\n * Linux Tun/Tap 介绍\n\n * 理解 Linux 虚拟网卡设备 tun/tap 的一切\n\n * 基于tun设备实现在用户空间可以ping通外部节点(golang版本)\n\n * 一起动手写一个VPN\n\n‍',normalizedContent:'# 入门\n\ntun/tap是操作系统内核中的虚拟网络设备，可以完成用户空间与内核空间的数据的交互。网络协议栈中的数据通过该设备可以进入到用户空间中，而用户空间中的程序通过该设备空间进入到内核空间的网络协议栈。\n\ntun模拟的是三层设备，操作三层的数据包，而tap模拟的二层设备，操作二层的数据包。\n\n> 物理网卡与虚拟网卡的区别是，物理网卡是外界与内核空间的网络协议栈数据交互的门户，而虚拟网卡是用户空间和内核空间交互的门户。\n\n/dev/net/tun 是linux提供的字符设备，写入该设备的数据会发送到虚拟网卡中，而发送到虚拟网卡中的数据也会出现在字符设备中。\n\n\n\n‍\n\n\n# 应用程序通过tun设备获取ping数据包\n\n\n\napp程序通过打开tun字符设备创建出tun虚拟网卡。然后通过ping命令发送icmp数据包到网络协议栈中，这个过程是从用户空间到内核空间，再通过路由将数据包转发到tun虚拟网卡中，因为tun网卡特性，会进入到打开该tun设备用户空间app程序中。\n\napp程序代码如下：\n\nimport os\nimport struct\nfrom fcntl import ioctl\n\nbuffer_size = 4096\n\n# 完成虚拟网卡的注册\ntunsetiff = 0x400454ca\n\n# 设备模式\niff_tun = 0x0001\niff_tap = 0x0002\n\n\ndef create_tunnel(tun_name=\'tun%d\', tun_mode=iff_tun):\n    # 以读写的方式打开字符设备tun，获取到设备描述符\n    tun_fd = os.open("/dev/net/tun", os.o_rdwr)\n\n    # 对该设备进行配置，设备名称和设备模式。\n    ifn = ioctl(tun_fd, tunsetiff, struct.pack(b"16sh", tun_name.encode(), tun_mode))\n\n    # 获取到设备名称\n    tun_name = ifn[:16].decode().strip("\\x00")\n    return tun_fd, tun_name\n\n\ndef main():\n    tun_fd, tun_name = create_tunnel()\n\n    while true:\n        data = os.read(tun_fd, buffer_size)\n        print(f"get data from tun. data size = {len(data)}")\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n运行后输出：\n\n# python3 tun_demo.py\nopen tun/tap device: tun0 for reading...\n\n\n1\n2\n\n\n通过ip a 命令发现tun设备已经创建，但其状态为down\n\n# ip a | grep -c tun\n45: tun0: <pointopoint,multicast,noarp> mtu 1500 qdisc noop state down group default qlen 500\n    link/none\n\n\n1\n2\n3\n\n\n对其设置一个ip并将它状态设置为up\n\nip a add 192.37.1.2/24 dev tun0\nip link set tun0 up\n\n\n1\n2\n\n\n配置好ip后，会发现自动配置了如下路由:\n\n...\n192.37.1.0/24 dev tun0 proto kernel scope link src 192.37.1.2 \n...\n\n\n1\n2\n3\n\n\n再次查看tun设备，发现已经配置好\n\n# ip a | grep tun0\n45: tun0: <pointopoint,multicast,noarp,up,lower_up> mtu 1500 qdisc pfifo_fast state unknown group default qlen 500\n    inet 192.37.1.1/24 scope global tun0\n\n\n1\n2\n3\n\n\n并且这时会发现tun0已经接收到了3个数据包\n\n# python3 tun_demo.py\nopen tun/tap device: tun0 for reading...\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 52\n\n\n1\n2\n3\n4\n5\n\n\n这时候使用tcpdump监听tun0，执行ping 192.37.1.2，是有回包的，但是tcpdump却没有抓到任何包。\n\n> ping命令会根据目标ip地址和子网掩码来判断数据包的目的地，如果目的地在本地网络中，ping命令会直接将数据包发送到本地网络，而不是通过tun设备发送。\n\n# tcpdump -i tun0 -n\n...\n\n# ping 192.37.1.2 -c 3\nping 192.37.1.2 (192.37.1.2) 56(84) bytes of data.\n64 bytes from 192.37.1.2: icmp_seq=1 ttl=64 time=0.148 ms\n64 bytes from 192.37.1.2: icmp_seq=2 ttl=64 time=0.114 ms\n64 bytes from 192.37.1.2: icmp_seq=3 ttl=64 time=0.316 ms\n\n--- 192.37.1.2 ping statistics ---\n3 packets transmitted, 3 received, 0% packet loss, time 1999ms\nrtt min/avg/max/mdev = 0.114/0.192/0.316/0.089 ms\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n改为ping 192.37.1.3，可以看到程序收到了收到了数据包，tcpdump也抓到了包，但是因为没有做任何的处理也没有回包，所以ping命令看到不到回包。\n\n# python3 tun_demo.py\nopen tun/tap device: tun0 for reading...\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 52\n\nget data from tun. data size = 88\nget data from tun. data size = 88\nget data from tun. data size = 88\n\n# tcpdump -i tun0 -n\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on tun0, link-type raw (raw ip), capture size 262144 bytes\n22:56:41.018149 ip 192.37.1.2 > 192.37.1.3: icmp echo request, id 22559, seq 1, length 64\n22:56:42.018871 ip 192.37.1.2 > 192.37.1.3: icmp echo request, id 22559, seq 2, length 64\n22:56:43.022732 ip 192.37.1.2 > 192.37.1.3: icmp echo request, id 22559, seq 3, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n‍\n\n\n# 使用tun设备完成基于udp的容器跨节点通信\n\n使用tun设备基于udp完成容器跨节点通信。如下图所示：\n\n‍\n\n\n\n通信流程是，在node1中的ns1进行ping node2中ns2的veth0网卡的ip，icmp的ip包会通过veth0到达veth1中，并进入到宿主机的网络协议栈，通过路由配置达到tun设备，这时app服务从tun设备中读取到ip包数据，然后将其封装在udp包中，并通过eth0网卡发送到node2的eth0网卡上，通过网络协议栈解包达到app程序中，拿到里面的ip包，将其写入到tun设备中，进入到网络协议栈中，通过路由达到veth1中，然后到达net ns1的veth0网卡。\n\napp程序简单实现如下：\n\nimport os\nimport socket\nimport struct\nimport threading\nfrom fcntl import ioctl\nimport click\n\nbind_address = (\'0.0.0.0\', 7000)\nbuffer_size = 4096\n\ntunsetiff = 0x400454ca\niff_tun = 0x0001\niff_tap = 0x0002\n\n\ndef create_tunnel(tun_name=\'tun%d\', tun_mode=iff_tun):\n    tun_fd = os.open("/dev/net/tun", os.o_rdwr)\n    ifn = ioctl(tun_fd, tunsetiff, struct.pack(b"16sh", tun_name.encode(), tun_mode))\n    tun_name = ifn[:16].decode().strip("\\x00")\n    return tun_fd, tun_name\n\n\ndef start_tunnel(tun_name):\n    os.popen(f"ip link set {tun_name} up")\n\n\ndef udp_server(udp_socket, tun_fd):\n    while true:\n        data, addr = udp_socket.recvfrom(2048)\n        print("get data from udp.")\n        if not data:\n            break\n\n        os.write(tun_fd, data)\n\n\n@click.command()\n@click.option("--peer_node_ip", "-p", required=true, help="对端节点ip")\ndef main(peer_node_ip):\n    peer_node_addr = (peer_node_ip, 7000)\n\n    tun_fd, tun_name = create_tunnel()\n    start_tunnel(tun_name)\n\n    udp_socket = socket.socket(socket.af_inet, socket.sock_dgram)\n    udp_socket.bind(bind_address)\n\n    t = threading.thread(target=udp_server, args=(udp_socket, tun_fd))\n    t.daemon = true\n    t.start()\n\n    while true:\n        data = os.read(tun_fd, buffer_size)\n        print(f"get data from tun. data size = {len(data)}")\n        udp_socket.sendto(data, peer_node_addr)\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n\n\n在node1中运行该程序，设置node2 ip\n\npython3 tun_app.py -p 10.65.132.187\n\n\n1\n\n\n可以看到已经创建了tun设备\n\n# ip link show tun0\n...\n109: tun0: <pointopoint,multicast,noarp,up,lower_up> mtu 1500 qdisc pfifo_fast state unknown group default qlen 500\n    link/none \n    inet6 fe80::8e98:91a4:6537:d77a/64 scope link flags 800 \n       valid_lft forever preferred_lft forever\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n在node1中创建network namespace命名为net1，使用它来完成模拟容器网络。\n\nip netns add net1\n\n\n1\n\n\n然后创建veth pair，它们是一对网卡，分别为命名为veth0和veth1\n\nip link add veth0 type veth peer name veth1\n\n\n1\n\n\n将其一端接入到net1中，并设置好其ip地址为10.1.1.2/24\n\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 10.1.1.2/24 dev veth0\nip netns exec net1 ip link set dev veth0 up\n\n\n1\n2\n3\n\n\n开启在宿主机上的veth1网卡，并设置其ip为10.1.1.1/24\n\nip a add 10.1.1.1/24 dev veth1\nip link set dev veth1 up\n\n\n1\n2\n\n\n再将net1中的默认路由设置成都走veth0，这样，ping node2中net2的网络包可以到veth1中，也就进入到了宿主机的网络协议栈中。\n\nip netns exec net1 ip r add default via 10.1.1.1 dev veth0\n\n\n1\n\n\n在宿主机上还需要添加路由，访问node2中net2时都路由到tun0设备\n\nip r add 10.1.2.0/24 dev tun0\n\n\n1\n\n\n这时，在node1 net1中ping node2 net2时，正常来说是可以在app中看到从tun收到ip包的，虽然没有回包，那是因为app程序收到包后没有做任何回包操作。\n\n# ip netns exec net1 ping 10.1.2.2 -c 3\nping 10.1.2.2 (10.1.2.2) 56(84) bytes of data.\n--- 10.1.2.2 ping statistics ---\n3 packets transmitted, 0 received, 100% packet loss, time 2001ms\n\n\n1\n2\n3\n4\n\n\n我们通过tcpdump抓取veth1网卡，可以看到收到了arp请求，想要获取10.1.2.2的mac地址，但是一直获取不到，所以导致ip包无法通过路由达到tun设备\n\n# tcpdump -i veth1 -n\n00:45:13.988076 arp, request who-has 10.1.2.2 tell 10.1.1.2, length 28\n\n\n1\n2\n\n\n这个时候需要开启veth1的arp代理，将veth1的mac地址作为arp的回复。\n\necho 1 >  /proc/sys/net/ipv4/conf/veth1/proxy_arp\n\n\n1\n\n\n再次ping node2 net2时，可以看到tcpdump看到arp中回复的mac地址为veth1的地址。\n\n# tcpdump -i veth1 -n\n00:45:13.988076 arp, request who-has 10.1.2.2 tell 10.1.1.2, length 28\n00:45:13.988100 arp, reply 10.1.2.2 is-at 4e:7c:bf:fe:4d:0f, length 28\n\n# ip a | grep -c 3 veth1\n...\n107: veth1@if108: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up group default qlen 1000\n    link/ether 4e:7c:bf:fe:4d:0f brd ff:ff:ff:ff:ff:ff link-netnsid 3\n    inet 10.1.1.1/24 scope global veth1\n       valid_lft forever preferred_lft forever\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n并且app程序中也从tun设备中获取到了ip包。\n\n# python3 tun_app.py -p 10.65.132.187\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 88\nget data from tun. data size = 88\nget data from tun. data size = 88\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n到这一步，node1的基本配置完成，接下来配置node2，配置的方法与node1一致，在node2执行命令如下:\n\n# 开启app程序\npython3 tun_app.py -p 10.61.74.37\n\n# 新增network namespace net2\nip netns add net2\n\n# 新增veth pair设备\nip link add veth0 type veth peer name veth1\n\n# 配置veth pair设备\nip link set dev veth0 netns net2\nip netns exec net2 ip addr add 10.1.2.2/24 dev veth0\nip netns exec net2 ip link set dev veth0 up\n\nip a add 10.1.2.1/24 dev veth1\nip link set dev veth1 up\n\n# 添加默认路由\nip netns exec net2 ip r add default via 10.1.2.1 dev veth0\n\n# 添加tun0设备路由\nip r add 10.1.1.0/24 dev tun0\n\n# 开启arp代理\necho 1 >  /proc/sys/net/ipv4/conf/veth1/proxy_arp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n配置完成后，在node1的net1中ping node2的net2，可以ping通有回包。\n\n# ip netns exec net1 ping 10.1.2.2 \nping 10.1.2.2 (10.1.2.2) 56(84) bytes of data.\n64 bytes from 10.1.2.2: icmp_seq=1 ttl=62 time=5.46 ms\n64 bytes from 10.1.2.2: icmp_seq=2 ttl=62 time=4.67 ms\n64 bytes from 10.1.2.2: icmp_seq=3 ttl=62 time=5.52 ms\n\n\n1\n2\n3\n4\n5\n\n\n\n# 巨人的肩膀\n\n * linux tun/tap 介绍\n\n * 理解 linux 虚拟网卡设备 tun/tap 的一切\n\n * 基于tun设备实现在用户空间可以ping通外部节点(golang版本)\n\n * 一起动手写一个vpn\n\n‍',charsets:{cjk:!0},lastUpdated:"2025/02/09, 23:47:02",lastUpdatedTimestamp:1739116022e3},{title:"理解Linux IPIP隧道",frontmatter:{title:"理解Linux IPIP隧道",date:"2023-05-26T13:11:26.000Z",permalink:"/pages/c128e7/",categories:["编程","linux"],tags:["linux","计算机网络","Linux网络虚拟化"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"IPIP隧道的工作原理是将源主机的IP数据包封装在一个新的IP数据包中，新的IP数据包的目的地址是隧道的另一端。在隧道的另一端，接收方将解封装原始IP数据包，并将其传递到目标主机。IPIP隧道可以在不同的网络之间建立连接，例如在IPv4网络和IPv6网络之间建立连接。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_ipip-20230526095538-83tl82w.png"},{name:"twitter:title",content:"理解Linux IPIP隧道"},{name:"twitter:description",content:"IPIP隧道的工作原理是将源主机的IP数据包封装在一个新的IP数据包中，新的IP数据包的目的地址是隧道的另一端。在隧道的另一端，接收方将解封装原始IP数据包，并将其传递到目标主机。IPIP隧道可以在不同的网络之间建立连接，例如在IPv4网络和IPv6网络之间建立连接。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_ipip-20230526095538-83tl82w.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/03.linux/04.%E7%90%86%E8%A7%A3Linux%20IPIP%E9%9A%A7%E9%81%93.html"},{property:"og:type",content:"article"},{property:"og:title",content:"理解Linux IPIP隧道"},{property:"og:description",content:"IPIP隧道的工作原理是将源主机的IP数据包封装在一个新的IP数据包中，新的IP数据包的目的地址是隧道的另一端。在隧道的另一端，接收方将解封装原始IP数据包，并将其传递到目标主机。IPIP隧道可以在不同的网络之间建立连接，例如在IPv4网络和IPv6网络之间建立连接。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_ipip-20230526095538-83tl82w.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/03.linux/04.%E7%90%86%E8%A7%A3Linux%20IPIP%E9%9A%A7%E9%81%93.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-05-26T13:11:26.000Z"},{property:"article:tag",content:"linux"},{property:"article:tag",content:"计算机网络"},{property:"article:tag",content:"Linux网络虚拟化"},{itemprop:"name",content:"理解Linux IPIP隧道"},{itemprop:"description",content:"IPIP隧道的工作原理是将源主机的IP数据包封装在一个新的IP数据包中，新的IP数据包的目的地址是隧道的另一端。在隧道的另一端，接收方将解封装原始IP数据包，并将其传递到目标主机。IPIP隧道可以在不同的网络之间建立连接，例如在IPv4网络和IPv6网络之间建立连接。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_ipip-20230526095538-83tl82w.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/03.linux/04.%E7%90%86%E8%A7%A3Linux%20IPIP%E9%9A%A7%E9%81%93.html",relativePath:"04.编程/03.linux/04.理解Linux IPIP隧道.md",key:"v-32e66a02",path:"/pages/c128e7/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"使用IPIP隧道实现跨主机网络",slug:"使用ipip隧道实现跨主机网络",normalizedTitle:"使用ipip隧道实现跨主机网络",charIndex:190},{level:2,title:"巨人的肩膀",slug:"巨人的肩膀",normalizedTitle:"巨人的肩膀",charIndex:1895}],headersStr:"简介 使用IPIP隧道实现跨主机网络 巨人的肩膀",content:"# 简介\n\nIPIP隧道是一种点对点的隧道协议，用于在IPv4网络上传输IPv4或IPv6数据包。\n\nIPIP隧道的工作原理是将源主机的IP数据包封装在一个新的IP数据包中，新的IP数据包的目的地址是隧道的另一端。在隧道的另一端，接收方将解封装原始IP数据包，并将其传递到目标主机。IPIP隧道可以在不同的网络之间建立连接，例如在IPv4网络和IPv6网络之间建立连接。\n\n\n# 使用IPIP隧道实现跨主机网络\n\n\n\n首先在Node1创建tun设备并设置为ipip模式，local设置为本地IP地址10.65.132.187，remote设置为对端IP10.65.132.187，这两个是隧道外层IP，然后再设置隧道内层IP，10.10.100.10到10.10.200.10。\n\nip tunnel add tun1 mode ipip remote 10.65.132.188 local 10.65.132.187\nip link set tun1 up\nip a add 10.10.100.10 peer 10.10.200.10 dev tun1\n\n\n1\n2\n3\n\n\n可以看到添加了一条路由，发送到目的地址10.10.200.10的包都会转发到tun1设备中\n\n# ip r\n...\n10.10.200.10 dev tun1 proto kernel scope link src 10.10.100.10\n...\n\n\n1\n2\n3\n4\n\n\ntun设备会将进入的IP包封装到一个IP包中，源地址是之前设置的外层local IP，而目的地址是外层remote IP，然后再通过路由达到从ens18网卡出去到Node2中。\n\n在Node2上创建tun设备，配置和Node1一样\n\nip tunnel add tun2 mode ipip remote 10.65.132.187 local 10.65.132.188\nip link set tun2 up\nip a add 10.10.200.10 peer 10.10.100.10 dev tun2\n\n\n\n1\n2\n3\n4\n\n\n然后在Node1上ping Node2的tun设备\n\nping 10.10.200.10 -c 1\n\n\n1\n\n\n通过tcpdump在Node2抓包如下：\n\n20:16:40.011992 IP 10.65.132.187 > 10.65.132.188: IP 10.10.100.10 > 10.10.200.10: ICMP echo request, id 17609, seq 1, length 64 (ipip-proto-4)\n20:16:40.012099 IP 10.65.132.188 > 10.65.132.187: IP 10.10.200.10 > 10.10.100.10: ICMP echo reply, id 17609, seq 1, length 64 (ipip-proto-4)\n\n\n1\n2\n\n\n数据包达到Node2后，是一个两层IP数据包，从Node2的ens18网卡出来后，解封数据包，发现内层的目的IP是10.10.200.10也就是tun2的地址，然后将数据包发到tun2设备。\n\ntun2设备收到数据包后再根据上面相同步骤进行封装数据包回包给tun1，最终整个ping过程完成。\n\nIPIP隧道是通过IP地址来标识网络设备的，所以不需要使用MAC地址，直接通过IP地址即可。通过查看tun设备信息，可以看到其是不存在mac地址的。\n\n# ip -d link show tun1\n59: tun1@NONE: <POINTOPOINT,NOARP,UP,LOWER_UP> mtu 1480 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/ipip 10.65.132.187 peer 10.65.132.188 promiscuity 0 minmtu 68 maxmtu 65515 \n    ipip ipip remote 10.65.132.188 local 10.65.132.187 ttl inherit pmtudisc addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n\n\n\n# 巨人的肩膀\n\n * 《Kubernetes网络权威指南》\n\n‍",normalizedContent:"# 简介\n\nipip隧道是一种点对点的隧道协议，用于在ipv4网络上传输ipv4或ipv6数据包。\n\nipip隧道的工作原理是将源主机的ip数据包封装在一个新的ip数据包中，新的ip数据包的目的地址是隧道的另一端。在隧道的另一端，接收方将解封装原始ip数据包，并将其传递到目标主机。ipip隧道可以在不同的网络之间建立连接，例如在ipv4网络和ipv6网络之间建立连接。\n\n\n# 使用ipip隧道实现跨主机网络\n\n\n\n首先在node1创建tun设备并设置为ipip模式，local设置为本地ip地址10.65.132.187，remote设置为对端ip10.65.132.187，这两个是隧道外层ip，然后再设置隧道内层ip，10.10.100.10到10.10.200.10。\n\nip tunnel add tun1 mode ipip remote 10.65.132.188 local 10.65.132.187\nip link set tun1 up\nip a add 10.10.100.10 peer 10.10.200.10 dev tun1\n\n\n1\n2\n3\n\n\n可以看到添加了一条路由，发送到目的地址10.10.200.10的包都会转发到tun1设备中\n\n# ip r\n...\n10.10.200.10 dev tun1 proto kernel scope link src 10.10.100.10\n...\n\n\n1\n2\n3\n4\n\n\ntun设备会将进入的ip包封装到一个ip包中，源地址是之前设置的外层local ip，而目的地址是外层remote ip，然后再通过路由达到从ens18网卡出去到node2中。\n\n在node2上创建tun设备，配置和node1一样\n\nip tunnel add tun2 mode ipip remote 10.65.132.187 local 10.65.132.188\nip link set tun2 up\nip a add 10.10.200.10 peer 10.10.100.10 dev tun2\n\n\n\n1\n2\n3\n4\n\n\n然后在node1上ping node2的tun设备\n\nping 10.10.200.10 -c 1\n\n\n1\n\n\n通过tcpdump在node2抓包如下：\n\n20:16:40.011992 ip 10.65.132.187 > 10.65.132.188: ip 10.10.100.10 > 10.10.200.10: icmp echo request, id 17609, seq 1, length 64 (ipip-proto-4)\n20:16:40.012099 ip 10.65.132.188 > 10.65.132.187: ip 10.10.200.10 > 10.10.100.10: icmp echo reply, id 17609, seq 1, length 64 (ipip-proto-4)\n\n\n1\n2\n\n\n数据包达到node2后，是一个两层ip数据包，从node2的ens18网卡出来后，解封数据包，发现内层的目的ip是10.10.200.10也就是tun2的地址，然后将数据包发到tun2设备。\n\ntun2设备收到数据包后再根据上面相同步骤进行封装数据包回包给tun1，最终整个ping过程完成。\n\nipip隧道是通过ip地址来标识网络设备的，所以不需要使用mac地址，直接通过ip地址即可。通过查看tun设备信息，可以看到其是不存在mac地址的。\n\n# ip -d link show tun1\n59: tun1@none: <pointopoint,noarp,up,lower_up> mtu 1480 qdisc noqueue state unknown mode default group default qlen 1000\n    link/ipip 10.65.132.187 peer 10.65.132.188 promiscuity 0 minmtu 68 maxmtu 65515 \n    ipip ipip remote 10.65.132.188 local 10.65.132.187 ttl inherit pmtudisc addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n\n\n\n# 巨人的肩膀\n\n * 《kubernetes网络权威指南》\n\n‍",charsets:{cjk:!0},lastUpdated:"2025/02/09, 23:47:02",lastUpdatedTimestamp:1739116022e3},{title:"理解VXLAN网络",frontmatter:{title:"理解VXLAN网络",date:"2023-05-26T11:38:14.000Z",permalink:"/pages/8a4b28/",categories:["编程","linux"],tags:["linux","计算机网络","Linux网络虚拟化"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"在三层可达的网络中部署VXLAN，在每个VXLAN网络端点中都有一个VTEP设备，负责将VXLAN协议的数据包进行UDP数据包的封包和解包，可以将其理解为隧道，将VXLAN数据包从逻辑网络转发到物理网络",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20230526124522.png"},{name:"twitter:title",content:"理解VXLAN网络"},{name:"twitter:description",content:"在三层可达的网络中部署VXLAN，在每个VXLAN网络端点中都有一个VTEP设备，负责将VXLAN协议的数据包进行UDP数据包的封包和解包，可以将其理解为隧道，将VXLAN数据包从逻辑网络转发到物理网络"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20230526124522.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/03.linux/03.%E7%90%86%E8%A7%A3VXLAN%E7%BD%91%E7%BB%9C.html"},{property:"og:type",content:"article"},{property:"og:title",content:"理解VXLAN网络"},{property:"og:description",content:"在三层可达的网络中部署VXLAN，在每个VXLAN网络端点中都有一个VTEP设备，负责将VXLAN协议的数据包进行UDP数据包的封包和解包，可以将其理解为隧道，将VXLAN数据包从逻辑网络转发到物理网络"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20230526124522.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/03.linux/03.%E7%90%86%E8%A7%A3VXLAN%E7%BD%91%E7%BB%9C.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2023-05-26T11:38:14.000Z"},{property:"article:tag",content:"linux"},{property:"article:tag",content:"计算机网络"},{property:"article:tag",content:"Linux网络虚拟化"},{itemprop:"name",content:"理解VXLAN网络"},{itemprop:"description",content:"在三层可达的网络中部署VXLAN，在每个VXLAN网络端点中都有一个VTEP设备，负责将VXLAN协议的数据包进行UDP数据包的封包和解包，可以将其理解为隧道，将VXLAN数据包从逻辑网络转发到物理网络"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20230526124522.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/03.linux/03.%E7%90%86%E8%A7%A3VXLAN%E7%BD%91%E7%BB%9C.html",relativePath:"04.编程/03.linux/03.理解VXLAN网络.md",key:"v-5973e693",path:"/pages/8a4b28/",headers:[{level:2,title:"什么是VXLAN?",slug:"什么是vxlan",normalizedTitle:"什么是vxlan?",charIndex:2},{level:2,title:"点对点的VXLAN",slug:"点对点的vxlan",normalizedTitle:"点对点的vxlan",charIndex:159},{level:3,title:"实操",slug:"实操",normalizedTitle:"实操",charIndex:205},{level:3,title:"开测",slug:"开测",normalizedTitle:"开测",charIndex:2072},{level:2,title:"VXLAN的多播模式",slug:"vxlan的多播模式",normalizedTitle:"vxlan的多播模式",charIndex:4578},{level:3,title:"通信过程",slug:"通信过程",normalizedTitle:"通信过程",charIndex:4633},{level:3,title:"环境准备",slug:"环境准备",normalizedTitle:"环境准备",charIndex:5250},{level:3,title:"开始分析",slug:"开始分析",normalizedTitle:"开始分析",charIndex:6883},{level:2,title:"VXLAN多播模式+桥接",slug:"vxlan多播模式-桥接",normalizedTitle:"vxlan多播模式+桥接",charIndex:9655},{level:3,title:"通信过程",slug:"通信过程-2",normalizedTitle:"通信过程",charIndex:4633},{level:3,title:"环境准备",slug:"环境准备-2",normalizedTitle:"环境准备",charIndex:5250},{level:3,title:"开始分析",slug:"开始分析-2",normalizedTitle:"开始分析",charIndex:6883},{level:2,title:"巨人的肩膀",slug:"巨人的肩膀",normalizedTitle:"巨人的肩膀",charIndex:13468}],headersStr:"什么是VXLAN? 点对点的VXLAN 实操 开测 VXLAN的多播模式 通信过程 环境准备 开始分析 VXLAN多播模式+桥接 通信过程 环境准备 开始分析 巨人的肩膀",content:"# 什么是VXLAN?\n\n在三层可达的网络中部署VXLAN，在每个VXLAN网络端点中都有一个VTEP设备，负责将VXLAN协议的数据包进行UDP数据包的封包和解包，可以将其理解为隧道，将VXLAN数据包从逻辑网络转发到物理网络\n\nVXLAN使用24位的VXLAN网络标识符（VNI）来标识不同的虚拟网络\n\n\n\n\n# 点对点的VXLAN\n\n在已经知道对端VTEP所在节点，是如何进行跨节点通信的。\n\n\n\n\n# 实操\n\n在Node上新增VTEP设备vxlan0，创建命令如下：\n\nip link add vxlan0 type vxlan id 42 dstport 4789 remote 10.65.132.188 local 10.65.132.187 dev ens18\n\n\n1\n\n * remote是对端节点的IP\n * local是本节点IP\n * id是VNI的值\n * dstport 是VTEP设备的端口\n\n创建好后，需要给它配置IP并启用\n\nip a add 172.17.1.2/24 dev vxlan0\nip link set vxlan0 up\n\n\n1\n2\n\n\nvxlan0详情如下：\n\n# ip -d link show dev vxlan0\n114: vxlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/ether 86:45:5c:56:49:42 brd ff:ff:ff:ff:ff:ff promiscuity 0 \n    vxlan id 42 remote 10.65.132.187 local 10.61.74.37 dev ens18 srcport 0 0 dstport 4789 ageing 300 noudpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n\n\n并且可以看到路由中新增一条记录，所有目的地址是172.17.1.0/24网段的包都要走vxlan0转发。\n\n# ip r\n...\n172.17.1.0/24 dev vxlan0 proto kernel scope link src 172.17.1.2\n...\n\n\n1\n2\n3\n4\n\n\n同时fdb表中新增以下记录，代表着，所有进过vxlan0包的外部UDP目的地址都会设置为10.65.132.187，并从ens18网卡出去。\n\n]# bridge fdb | grep vxlan0\n00:00:00:00:00:00 dev vxlan0 dst 10.65.132.187 via ens18 self permanent\n\n\n1\n2\n\n\n到这里，Node1已经配置好了，我们重复上面操作设置Node2，只需要将部分IP修改即可。\n\n# 将Node1中remote和local反过来即可.\nip link add vxlan0 type vxlan id 42 dstport 4789 remote 10.65.132.187 dev ens18 local 10.65.132.188 dev ens18\n\n# vxlan0 地址设置为172.17.1.3/24\nip a add 172.17.1.3/24 dev vxlan0\nip link set vxlan0 up\n\n# ip -d link show vxlan0\n20: vxlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/ether 12:09:3d:c0:97:32 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535 \n    vxlan id 42 remote 10.65.132.187 local 10.65.132.188 dev ens18 srcport 0 0 dstport 4789 ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 开测\n\n在Node2上监听Node1的udp数据包\n\ntcpdump -i ens18 udp and host 10.65.132.187 -n\n\n\n1\n\n\n然后在Node1中ping Node2的VTEP设备地址172.17.1.3\n\n[root@k8s-master-07rf9 ~]# ping 172.17.1.3 -c 3\nPING 172.17.1.3 (172.17.1.3) 56(84) bytes of data.\n64 bytes from 172.17.1.3: icmp_seq=1 ttl=64 time=0.841 ms\n64 bytes from 172.17.1.3: icmp_seq=2 ttl=64 time=0.382 ms\n64 bytes from 172.17.1.3: icmp_seq=3 ttl=64 time=0.377 ms\n\n\n1\n2\n3\n4\n5\n\n\n可以看到tcpdump抓到的数据包如下，先收到了Node1的发过来封装了ARP数据包的数据包，想要知道Node2中VTEP设备的MAC地址，然后回给了Node1，Node1收到后，将MAC地址填充，再将封装了ICMP的VXLAN数据包发送到Node2，Node2中VTEP收到包并解包，最后回包给Node1\n\n[root@k8s-work01-1zapn ~]# tcpdump -i ens18 udp and host 10.65.132.187 -n\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type EN10MB (Ethernet), capture size 262144 bytes\n19:23:36.705418 IP 10.65.132.187.34062 > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Request who-has 172.17.1.3 tell 172.17.1.2, length 28\n19:23:36.705574 IP 10.65.132.188.20835 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Reply 172.17.1.3 is-at 3a:84:39:cc:05:93, length 28\n19:23:36.705880 IP 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.2 > 172.17.1.3: ICMP echo request, id 25707, seq 1, length 64\n19:23:36.705986 IP 10.65.132.188.62793 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.3 > 172.17.1.2: ICMP echo reply, id 25707, seq 1, length 64\n19:23:37.708701 IP 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.2 > 172.17.1.3: ICMP echo request, id 25707, seq 2, length 64\n19:23:37.708846 IP 10.65.132.188.62793 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.3 > 172.17.1.2: ICMP echo reply, id 25707, seq 2, length 64\n19:23:38.732737 IP 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.2 > 172.17.1.3: ICMP echo request, id 25707, seq 3, length 64\n19:23:38.732846 IP 10.65.132.188.62793 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.3 > 172.17.1.2: ICMP echo reply, id 25707, seq 3, length 64\n19:23:41.804637 IP 10.65.132.188.20835 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Request who-has 172.17.1.2 tell 172.17.1.3, length 28\n19:23:41.804917 IP 10.65.132.187.34062 > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Reply 172.17.1.2 is-at c2:a1:4e:56:7d:eb, length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# VXLAN的多播模式\n\n在我们不知道VTEP所在节点的情况下，并且需要使用多个VTEP组建逻辑网络。\n\n\n# 通信过程\n\n\n\n 1. 在Node1上通过ping Node2上vxlan0设备ip，数据包通过路由到达vxlan0，vxlan0发现目的IP和源IP属于同一网段，需要知道对方的MAC地址，因此需要发送ARP查询报文。\n 2. ARP报文中，源MAC地址为Node1上vxlan0的mac地址，目的mac地址为255.255.255.255也就是广播地址，并且添加VXLAN头部VNI=42\n 3. 因为不知道对端的VTEP设备在哪台节点上，所以vxlan0会向多播地址224.1.1.1发送多播报文。\n 4. 多播组中所有的主机都会收到报文，并且内核会判断该数据包为VXLAN报文，根据VNI发送给VTEP设备。\n 5. Node2中vxlan0收到报文后，解包拿到ARP报文，然后通过ARP报文学习到了将Node1的vxlan0的mac地址与Node1 IP的映射关系记录到FDB表中，并且生成ARP应答报文。\n 6. ARP应答报文中，目的主机Node1的MAC地址和目的主机Node1中vxlan0的MAC地址都通过发过来的ARP报文中学习到，所以可以直接通过单播进行回复。\n 7. Node1收到ARP回复的报文后，通过报文内容，将Node2的主机地址和vxlan0的MAC地址的映射关系缓存到FDB表中。\n 8. 现在双方都已经通过ARP报文获得了双方的建立ICMP通信的所有信息，可以直接通过通过单播进行通信。\n\n\n# 环境准备\n\n首先在Node1中新增VTEP设备vxlan0，VNI为42，通信端口4789，主机地址为10.65.132.187，设置多播地址为224.1.1.1，数据包通过ens18真实网卡出去。\n\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.187 group 224.1.1.1 dev ens18\n\n\n1\n\n\n给vxlan0添加地址172.17.1.2/24，并把它拉起\n\nip addr add 172.17.1.2/24 dev vxlan0\nip link set vxlan0 up\n\n\n1\n2\n\n\n查看vxlan0的详细信息\n\n# ip -d link  show vxlan0\n22: vxlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/ether 4e:92:72:79:59:ed brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535 \n    vxlan id 42 group 224.1.1.1 local 10.65.132.187 dev ens18 srcport 0 0 dstport 4789 ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535\n\n\n1\n2\n3\n4\n\n\n再看看fdb表，意思是，vxlan0封包的时候，默认会使用224.1.1.1作为VXLAN包也就是外部UDP的目的IP。\n\n# bridge fdb | grep vxlan0\n00:00:00:00:00:00 dev vxlan0 dst 224.1.1.1 via ens18 self permanent\n\n\n1\n2\n\n\n在Node2上重复上述操作\n\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.188 group 224.1.1.1 dev ens18\n\nip addr add 172.17.1.3/24 dev vxlan0\nip link set vxlan0 up\n\n# ip -d link show vxlan0\n11: vxlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/ether ba:d8:43:67:8d:fb brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535 \n    vxlan id 42 group 224.1.1.1 local 10.65.132.188 dev ens18 srcport 0 0 dstport 4789 ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 开始分析\n\n先使用tcpdump来监听Node2中ens18网卡中来自Node1的UDP数据包，然后在Node1上ping Node2中vxlan0设备。\n\n可以看到是可以ping通的。\n\n# ping 172.17.1.3 -c 1\nPING 172.17.1.3 (172.17.1.3) 56(84) bytes of data.\n64 bytes from 172.17.1.3: icmp_seq=1 ttl=64 time=0.807 ms\n\n--- 172.17.1.3 ping statistics ---\n1 packets transmitted, 1 received, 0% packet loss, time 0ms\nrtt min/avg/max/mdev = 0.807/0.807/0.807/0.000 ms\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n再来看看抓到的包：\n\n 1. 第一个数据包，可以看到Node2收到了来自Node1的 VXLAN数据包，vni为42，目的地址是多播IP224.1.1.1，因为我们创建的VTEP设备设置了该多播IP，所以会接收该数据包。且里面封装了ARP数据包，需要将172.17.1.3的MAC地址告诉172.17.1.2。\n 2. 第二个数据包可以看到回复了一个VXLAN数据包，里面包含了ARP应答包，将172.17.1.3的mac地址也就是vxlan0的地址回复过去。\n 3. 第三个数据包是Node1 vxlan0根据对方的MAC地址和Node2的IP地址，直接单播发送包含了ICMP数据包的VXLAN数据包到Node2\n 4. 第四个数据包时Node2 vxlan0进行回复ICMP，也是包裹在一个VXLAN数据包中，发送到Node1中。\n\n# tcpdump -i ens18 udp and host 10.65.132.187 -n\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type EN10MB (Ethernet), capture size 262144 bytes\n\n10:31:34.560469 IP 10.65.132.187.34062 > 224.1.1.1.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Request who-has 172.17.1.3 tell 172.17.1.2, length 28\n10:31:34.560616 IP 10.65.132.188.20835 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Reply 172.17.1.3 is-at ba:d8:43:67:8d:fb, length 28\n10:31:34.560819 IP 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.2 > 172.17.1.3: ICMP echo request, id 46810, seq 1, length 64\n10:31:34.560935 IP 10.65.132.188.62793 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.3 > 172.17.1.2: ICMP echo reply, id 46810, seq 1, length 64\n10:31:39.661990 IP 10.65.132.188.20835 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Request who-has 172.17.1.2 tell 172.17.1.3, length 28\n10:31:39.662329 IP 10.65.132.187.34062 > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Reply 172.17.1.2 is-at 4e:92:72:79:59:ed, length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n再次ping Node2的vxlan0设备，通过抓包可以看到，不需要发送ARP报文了，是因为Node1已经缓存了ARP。\n\n第一个数据包目的IP不再是224.1.1.1多播地址了，而是Node2的地址。是因为vxlan0也已经缓存到fdb表中。\n\n10:49:36.712777 IP 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.2 > 172.17.1.3: ICMP echo request, id 41695, seq 1, length 64\n10:49:36.712973 IP 10.65.132.188.62793 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.3 > 172.17.1.2: ICMP echo reply, id 41695, seq 1, length 64\n\n\n1\n2\n3\n4\n\n\n查看arp缓存\n\n# arp | grep vxlan0\n172.17.1.3               ether   ba:d8:43:67:8d:fb   C                     vxlan0\n\n\n1\n2\n\n\n查看fdb表，添加了Node2中vxlan0的MAC地址和Node2地址的映射表项。\n\n# bridge fdb | grep vxlan0\n00:00:00:00:00:00 dev vxlan0 dst 224.1.1.1 via ens18 self permanent\nba:d8:43:67:8d:fb dev vxlan0 dst 10.65.132.188 self\n\n\n1\n2\n3\n\n\n\n# VXLAN多播模式+桥接\n\n在VXLAN的多播的基础上再加上桥接网络。\n\n\n# 通信过程\n\n桥接网络模拟及通信到宿主机过程可以参考手动实现docker容器bridge网络模型\n\n数据包达到网桥后，然后再转发到vxlan0中，接下来的流程也与上面将的多播是一致的。\n\n\n\n\n# 环境准备\n\n在Node1上运行如下命令准备环境\n\n# 添加VTEP设备\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.187 group 224.1.1.1 dev ens18\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set vxlan0 master bridge0\nip link set vxlan0 up\nip link set bridge0 up\n\n# 添加net1模拟容器\nip netns add net1\nip link add veth0 type veth peer name veth1\nip link set dev veth0 up\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n# 设置net1中网络配置\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n在Node2中重复上面操作，将172.19.1.3/24绑定到另一个Network Namespace net3中\n\n# 添加VTEP设备\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.188 group 224.1.1.1 dev ens18\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set vxlan0 master bridge0\nip link set vxlan0 up\nip link set bridge0 up\n\n# 添加net1模拟容器\nip netns add net3\nip link add veth0 type veth peer name veth1\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n# 设置net1中网络配置\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.1.3/24 dev veth0\nip netns exec net3 ip link set veth0 up\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n\n# 开始分析\n\n在Node1的net1中ping Node2中的net3，可以看到有回包，说明网络是通的。\n\n# ip netns exec net1 ping 172.19.1.3 -c 2\nPING 172.19.1.3 (172.19.1.3) 56(84) bytes of data.\n64 bytes from 172.19.1.3: icmp_seq=1 ttl=64 time=0.992 ms\n64 bytes from 172.19.1.3: icmp_seq=2 ttl=64 time=0.605 ms\n\n\n1\n2\n3\n4\n\n\n通过监听Node2的网卡ens18，抓到以下的包：\n\n 1. 首先是Node1发送包含ARP的UDP包到多播地址224.1.1.1，因为Node2是属于该多播地址，所以会接收该包，并通过vxlan0进行解包，最终拿到ARP包，然后发送vxlan0的mac地址进行arp回包，也是通过封装到UDP包中发送Node1中，然后再通过vxlan0->bridge进入到net1中，net1中收到ARP后，将Node2的容器IP地址和mac地址缓存到ARP中。\n\n 2. 并且在fdb表中添加一项，net3的的mac地址与Node2的IP地址映射关系\n\n 3. 接下来是通过ARP缓存找到MAC地址并添加到ICMP的IP包上，然后再将其封装到UDP包中，UDP的源IP是通过查询fdb表得到的，可以直接通过单播发送。\n\n7:15:47.595683 IP 10.65.132.187.34062 > 224.1.1.1.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Request who-has 172.19.1.3 tell 172.19.1.2, length 28\n17:15:47.595863 IP 10.65.132.188.20835 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Reply 172.19.1.3 is-at 02:fd:f9:7f:61:a7, length 28\n17:15:47.596172 IP 10.65.132.187.42208 > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.19.1.2 > 172.19.1.3: ICMP echo request, id 51397, seq 1, length 64\n17:15:47.596295 IP 10.65.132.188.22080 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.19.1.3 > 172.19.1.2: ICMP echo reply, id 51397, seq 1, length 64\n17:15:48.596543 IP 10.65.132.187.42208 > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.19.1.2 > 172.19.1.3: ICMP echo request, id 51397, seq 2, length 64\n17:15:48.596724 IP 10.65.132.188.22080 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.19.1.3 > 172.19.1.2: ICMP echo reply, id 51397, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n可以看到net1中已经缓存了net3的ip地址与mac地址\n\n# Node1\n# ip netns exec net1 arp \nAddress                  HWtype  HWaddress           Flags Mask            Iface\n172.19.1.3               ether   02:fd:f9:7f:61:a7   C                     veth0\n\n\n1\n2\n3\n4\n\n\nnet3中的mac地址和net1中的arp缓存是对应上的。\n\n# ip netns exec net3 ip -d link show veth0\n34: veth0@if33: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000\n    link/ether 02:fd:f9:7f:61:a7 brd ff:ff:ff:ff:ff:ff link-netnsid 0 promiscuity 0 minmtu 68 maxmtu 65535 \n    veth addrgenmode eui64 numtxqueues 8 numrxqueues 8 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n\n\n查看fdb表，新增了net3的mac地址和Node2的IP地址映射关系\n\n# bridge fdb | grep vxlan0\n02:fd:f9:7f:61:a7 dev vxlan0 dst 10.65.132.188 self\n\n\n1\n2\n\n\n\n# 巨人的肩膀\n\n * 《kubernetes网络权威指南》",normalizedContent:"# 什么是vxlan?\n\n在三层可达的网络中部署vxlan，在每个vxlan网络端点中都有一个vtep设备，负责将vxlan协议的数据包进行udp数据包的封包和解包，可以将其理解为隧道，将vxlan数据包从逻辑网络转发到物理网络\n\nvxlan使用24位的vxlan网络标识符（vni）来标识不同的虚拟网络\n\n\n\n\n# 点对点的vxlan\n\n在已经知道对端vtep所在节点，是如何进行跨节点通信的。\n\n\n\n\n# 实操\n\n在node上新增vtep设备vxlan0，创建命令如下：\n\nip link add vxlan0 type vxlan id 42 dstport 4789 remote 10.65.132.188 local 10.65.132.187 dev ens18\n\n\n1\n\n * remote是对端节点的ip\n * local是本节点ip\n * id是vni的值\n * dstport 是vtep设备的端口\n\n创建好后，需要给它配置ip并启用\n\nip a add 172.17.1.2/24 dev vxlan0\nip link set vxlan0 up\n\n\n1\n2\n\n\nvxlan0详情如下：\n\n# ip -d link show dev vxlan0\n114: vxlan0: <broadcast,multicast,up,lower_up> mtu 1450 qdisc noqueue state unknown mode default group default qlen 1000\n    link/ether 86:45:5c:56:49:42 brd ff:ff:ff:ff:ff:ff promiscuity 0 \n    vxlan id 42 remote 10.65.132.187 local 10.61.74.37 dev ens18 srcport 0 0 dstport 4789 ageing 300 noudpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n\n\n并且可以看到路由中新增一条记录，所有目的地址是172.17.1.0/24网段的包都要走vxlan0转发。\n\n# ip r\n...\n172.17.1.0/24 dev vxlan0 proto kernel scope link src 172.17.1.2\n...\n\n\n1\n2\n3\n4\n\n\n同时fdb表中新增以下记录，代表着，所有进过vxlan0包的外部udp目的地址都会设置为10.65.132.187，并从ens18网卡出去。\n\n]# bridge fdb | grep vxlan0\n00:00:00:00:00:00 dev vxlan0 dst 10.65.132.187 via ens18 self permanent\n\n\n1\n2\n\n\n到这里，node1已经配置好了，我们重复上面操作设置node2，只需要将部分ip修改即可。\n\n# 将node1中remote和local反过来即可.\nip link add vxlan0 type vxlan id 42 dstport 4789 remote 10.65.132.187 dev ens18 local 10.65.132.188 dev ens18\n\n# vxlan0 地址设置为172.17.1.3/24\nip a add 172.17.1.3/24 dev vxlan0\nip link set vxlan0 up\n\n# ip -d link show vxlan0\n20: vxlan0: <broadcast,multicast,up,lower_up> mtu 1450 qdisc noqueue state unknown mode default group default qlen 1000\n    link/ether 12:09:3d:c0:97:32 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535 \n    vxlan id 42 remote 10.65.132.187 local 10.65.132.188 dev ens18 srcport 0 0 dstport 4789 ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 开测\n\n在node2上监听node1的udp数据包\n\ntcpdump -i ens18 udp and host 10.65.132.187 -n\n\n\n1\n\n\n然后在node1中ping node2的vtep设备地址172.17.1.3\n\n[root@k8s-master-07rf9 ~]# ping 172.17.1.3 -c 3\nping 172.17.1.3 (172.17.1.3) 56(84) bytes of data.\n64 bytes from 172.17.1.3: icmp_seq=1 ttl=64 time=0.841 ms\n64 bytes from 172.17.1.3: icmp_seq=2 ttl=64 time=0.382 ms\n64 bytes from 172.17.1.3: icmp_seq=3 ttl=64 time=0.377 ms\n\n\n1\n2\n3\n4\n5\n\n\n可以看到tcpdump抓到的数据包如下，先收到了node1的发过来封装了arp数据包的数据包，想要知道node2中vtep设备的mac地址，然后回给了node1，node1收到后，将mac地址填充，再将封装了icmp的vxlan数据包发送到node2，node2中vtep收到包并解包，最后回包给node1\n\n[root@k8s-work01-1zapn ~]# tcpdump -i ens18 udp and host 10.65.132.187 -n\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type en10mb (ethernet), capture size 262144 bytes\n19:23:36.705418 ip 10.65.132.187.34062 > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\narp, request who-has 172.17.1.3 tell 172.17.1.2, length 28\n19:23:36.705574 ip 10.65.132.188.20835 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\narp, reply 172.17.1.3 is-at 3a:84:39:cc:05:93, length 28\n19:23:36.705880 ip 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.2 > 172.17.1.3: icmp echo request, id 25707, seq 1, length 64\n19:23:36.705986 ip 10.65.132.188.62793 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.3 > 172.17.1.2: icmp echo reply, id 25707, seq 1, length 64\n19:23:37.708701 ip 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.2 > 172.17.1.3: icmp echo request, id 25707, seq 2, length 64\n19:23:37.708846 ip 10.65.132.188.62793 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.3 > 172.17.1.2: icmp echo reply, id 25707, seq 2, length 64\n19:23:38.732737 ip 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.2 > 172.17.1.3: icmp echo request, id 25707, seq 3, length 64\n19:23:38.732846 ip 10.65.132.188.62793 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.3 > 172.17.1.2: icmp echo reply, id 25707, seq 3, length 64\n19:23:41.804637 ip 10.65.132.188.20835 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\narp, request who-has 172.17.1.2 tell 172.17.1.3, length 28\n19:23:41.804917 ip 10.65.132.187.34062 > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\narp, reply 172.17.1.2 is-at c2:a1:4e:56:7d:eb, length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# vxlan的多播模式\n\n在我们不知道vtep所在节点的情况下，并且需要使用多个vtep组建逻辑网络。\n\n\n# 通信过程\n\n\n\n 1. 在node1上通过ping node2上vxlan0设备ip，数据包通过路由到达vxlan0，vxlan0发现目的ip和源ip属于同一网段，需要知道对方的mac地址，因此需要发送arp查询报文。\n 2. arp报文中，源mac地址为node1上vxlan0的mac地址，目的mac地址为255.255.255.255也就是广播地址，并且添加vxlan头部vni=42\n 3. 因为不知道对端的vtep设备在哪台节点上，所以vxlan0会向多播地址224.1.1.1发送多播报文。\n 4. 多播组中所有的主机都会收到报文，并且内核会判断该数据包为vxlan报文，根据vni发送给vtep设备。\n 5. node2中vxlan0收到报文后，解包拿到arp报文，然后通过arp报文学习到了将node1的vxlan0的mac地址与node1 ip的映射关系记录到fdb表中，并且生成arp应答报文。\n 6. arp应答报文中，目的主机node1的mac地址和目的主机node1中vxlan0的mac地址都通过发过来的arp报文中学习到，所以可以直接通过单播进行回复。\n 7. node1收到arp回复的报文后，通过报文内容，将node2的主机地址和vxlan0的mac地址的映射关系缓存到fdb表中。\n 8. 现在双方都已经通过arp报文获得了双方的建立icmp通信的所有信息，可以直接通过通过单播进行通信。\n\n\n# 环境准备\n\n首先在node1中新增vtep设备vxlan0，vni为42，通信端口4789，主机地址为10.65.132.187，设置多播地址为224.1.1.1，数据包通过ens18真实网卡出去。\n\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.187 group 224.1.1.1 dev ens18\n\n\n1\n\n\n给vxlan0添加地址172.17.1.2/24，并把它拉起\n\nip addr add 172.17.1.2/24 dev vxlan0\nip link set vxlan0 up\n\n\n1\n2\n\n\n查看vxlan0的详细信息\n\n# ip -d link  show vxlan0\n22: vxlan0: <broadcast,multicast,up,lower_up> mtu 1450 qdisc noqueue state unknown mode default group default qlen 1000\n    link/ether 4e:92:72:79:59:ed brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535 \n    vxlan id 42 group 224.1.1.1 local 10.65.132.187 dev ens18 srcport 0 0 dstport 4789 ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535\n\n\n1\n2\n3\n4\n\n\n再看看fdb表，意思是，vxlan0封包的时候，默认会使用224.1.1.1作为vxlan包也就是外部udp的目的ip。\n\n# bridge fdb | grep vxlan0\n00:00:00:00:00:00 dev vxlan0 dst 224.1.1.1 via ens18 self permanent\n\n\n1\n2\n\n\n在node2上重复上述操作\n\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.188 group 224.1.1.1 dev ens18\n\nip addr add 172.17.1.3/24 dev vxlan0\nip link set vxlan0 up\n\n# ip -d link show vxlan0\n11: vxlan0: <broadcast,multicast,up,lower_up> mtu 1450 qdisc noqueue state unknown mode default group default qlen 1000\n    link/ether ba:d8:43:67:8d:fb brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535 \n    vxlan id 42 group 224.1.1.1 local 10.65.132.188 dev ens18 srcport 0 0 dstport 4789 ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 开始分析\n\n先使用tcpdump来监听node2中ens18网卡中来自node1的udp数据包，然后在node1上ping node2中vxlan0设备。\n\n可以看到是可以ping通的。\n\n# ping 172.17.1.3 -c 1\nping 172.17.1.3 (172.17.1.3) 56(84) bytes of data.\n64 bytes from 172.17.1.3: icmp_seq=1 ttl=64 time=0.807 ms\n\n--- 172.17.1.3 ping statistics ---\n1 packets transmitted, 1 received, 0% packet loss, time 0ms\nrtt min/avg/max/mdev = 0.807/0.807/0.807/0.000 ms\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n再来看看抓到的包：\n\n 1. 第一个数据包，可以看到node2收到了来自node1的 vxlan数据包，vni为42，目的地址是多播ip224.1.1.1，因为我们创建的vtep设备设置了该多播ip，所以会接收该数据包。且里面封装了arp数据包，需要将172.17.1.3的mac地址告诉172.17.1.2。\n 2. 第二个数据包可以看到回复了一个vxlan数据包，里面包含了arp应答包，将172.17.1.3的mac地址也就是vxlan0的地址回复过去。\n 3. 第三个数据包是node1 vxlan0根据对方的mac地址和node2的ip地址，直接单播发送包含了icmp数据包的vxlan数据包到node2\n 4. 第四个数据包时node2 vxlan0进行回复icmp，也是包裹在一个vxlan数据包中，发送到node1中。\n\n# tcpdump -i ens18 udp and host 10.65.132.187 -n\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type en10mb (ethernet), capture size 262144 bytes\n\n10:31:34.560469 ip 10.65.132.187.34062 > 224.1.1.1.vxlan: vxlan, flags [i] (0x08), vni 42\narp, request who-has 172.17.1.3 tell 172.17.1.2, length 28\n10:31:34.560616 ip 10.65.132.188.20835 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\narp, reply 172.17.1.3 is-at ba:d8:43:67:8d:fb, length 28\n10:31:34.560819 ip 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.2 > 172.17.1.3: icmp echo request, id 46810, seq 1, length 64\n10:31:34.560935 ip 10.65.132.188.62793 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.3 > 172.17.1.2: icmp echo reply, id 46810, seq 1, length 64\n10:31:39.661990 ip 10.65.132.188.20835 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\narp, request who-has 172.17.1.2 tell 172.17.1.3, length 28\n10:31:39.662329 ip 10.65.132.187.34062 > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\narp, reply 172.17.1.2 is-at 4e:92:72:79:59:ed, length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n再次ping node2的vxlan0设备，通过抓包可以看到，不需要发送arp报文了，是因为node1已经缓存了arp。\n\n第一个数据包目的ip不再是224.1.1.1多播地址了，而是node2的地址。是因为vxlan0也已经缓存到fdb表中。\n\n10:49:36.712777 ip 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.2 > 172.17.1.3: icmp echo request, id 41695, seq 1, length 64\n10:49:36.712973 ip 10.65.132.188.62793 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.3 > 172.17.1.2: icmp echo reply, id 41695, seq 1, length 64\n\n\n1\n2\n3\n4\n\n\n查看arp缓存\n\n# arp | grep vxlan0\n172.17.1.3               ether   ba:d8:43:67:8d:fb   c                     vxlan0\n\n\n1\n2\n\n\n查看fdb表，添加了node2中vxlan0的mac地址和node2地址的映射表项。\n\n# bridge fdb | grep vxlan0\n00:00:00:00:00:00 dev vxlan0 dst 224.1.1.1 via ens18 self permanent\nba:d8:43:67:8d:fb dev vxlan0 dst 10.65.132.188 self\n\n\n1\n2\n3\n\n\n\n# vxlan多播模式+桥接\n\n在vxlan的多播的基础上再加上桥接网络。\n\n\n# 通信过程\n\n桥接网络模拟及通信到宿主机过程可以参考手动实现docker容器bridge网络模型\n\n数据包达到网桥后，然后再转发到vxlan0中，接下来的流程也与上面将的多播是一致的。\n\n\n\n\n# 环境准备\n\n在node1上运行如下命令准备环境\n\n# 添加vtep设备\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.187 group 224.1.1.1 dev ens18\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set vxlan0 master bridge0\nip link set vxlan0 up\nip link set bridge0 up\n\n# 添加net1模拟容器\nip netns add net1\nip link add veth0 type veth peer name veth1\nip link set dev veth0 up\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n# 设置net1中网络配置\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n在node2中重复上面操作，将172.19.1.3/24绑定到另一个network namespace net3中\n\n# 添加vtep设备\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.188 group 224.1.1.1 dev ens18\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set vxlan0 master bridge0\nip link set vxlan0 up\nip link set bridge0 up\n\n# 添加net1模拟容器\nip netns add net3\nip link add veth0 type veth peer name veth1\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n# 设置net1中网络配置\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.1.3/24 dev veth0\nip netns exec net3 ip link set veth0 up\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n\n# 开始分析\n\n在node1的net1中ping node2中的net3，可以看到有回包，说明网络是通的。\n\n# ip netns exec net1 ping 172.19.1.3 -c 2\nping 172.19.1.3 (172.19.1.3) 56(84) bytes of data.\n64 bytes from 172.19.1.3: icmp_seq=1 ttl=64 time=0.992 ms\n64 bytes from 172.19.1.3: icmp_seq=2 ttl=64 time=0.605 ms\n\n\n1\n2\n3\n4\n\n\n通过监听node2的网卡ens18，抓到以下的包：\n\n 1. 首先是node1发送包含arp的udp包到多播地址224.1.1.1，因为node2是属于该多播地址，所以会接收该包，并通过vxlan0进行解包，最终拿到arp包，然后发送vxlan0的mac地址进行arp回包，也是通过封装到udp包中发送node1中，然后再通过vxlan0->bridge进入到net1中，net1中收到arp后，将node2的容器ip地址和mac地址缓存到arp中。\n\n 2. 并且在fdb表中添加一项，net3的的mac地址与node2的ip地址映射关系\n\n 3. 接下来是通过arp缓存找到mac地址并添加到icmp的ip包上，然后再将其封装到udp包中，udp的源ip是通过查询fdb表得到的，可以直接通过单播发送。\n\n7:15:47.595683 ip 10.65.132.187.34062 > 224.1.1.1.vxlan: vxlan, flags [i] (0x08), vni 42\narp, request who-has 172.19.1.3 tell 172.19.1.2, length 28\n17:15:47.595863 ip 10.65.132.188.20835 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\narp, reply 172.19.1.3 is-at 02:fd:f9:7f:61:a7, length 28\n17:15:47.596172 ip 10.65.132.187.42208 > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.19.1.2 > 172.19.1.3: icmp echo request, id 51397, seq 1, length 64\n17:15:47.596295 ip 10.65.132.188.22080 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.19.1.3 > 172.19.1.2: icmp echo reply, id 51397, seq 1, length 64\n17:15:48.596543 ip 10.65.132.187.42208 > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.19.1.2 > 172.19.1.3: icmp echo request, id 51397, seq 2, length 64\n17:15:48.596724 ip 10.65.132.188.22080 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.19.1.3 > 172.19.1.2: icmp echo reply, id 51397, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n可以看到net1中已经缓存了net3的ip地址与mac地址\n\n# node1\n# ip netns exec net1 arp \naddress                  hwtype  hwaddress           flags mask            iface\n172.19.1.3               ether   02:fd:f9:7f:61:a7   c                     veth0\n\n\n1\n2\n3\n4\n\n\nnet3中的mac地址和net1中的arp缓存是对应上的。\n\n# ip netns exec net3 ip -d link show veth0\n34: veth0@if33: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up mode default group default qlen 1000\n    link/ether 02:fd:f9:7f:61:a7 brd ff:ff:ff:ff:ff:ff link-netnsid 0 promiscuity 0 minmtu 68 maxmtu 65535 \n    veth addrgenmode eui64 numtxqueues 8 numrxqueues 8 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n\n\n查看fdb表，新增了net3的mac地址和node2的ip地址映射关系\n\n# bridge fdb | grep vxlan0\n02:fd:f9:7f:61:a7 dev vxlan0 dst 10.65.132.188 self\n\n\n1\n2\n\n\n\n# 巨人的肩膀\n\n * 《kubernetes网络权威指南》",charsets:{cjk:!0},lastUpdated:"2025/02/09, 23:47:02",lastUpdatedTimestamp:1739116022e3},{title:"使用hue创建ozzie的pyspark action workflow",frontmatter:{tags:["hue","python","大数据"],title:"使用hue创建ozzie的pyspark action workflow",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/aba491/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"介绍如何使用hue来创建ozzie来创建一个spark action的owrkflow",feed:{enable:!0},categories:["编程","其他"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215736.png"},{name:"twitter:title",content:"使用hue创建ozzie的pyspark action workflow"},{name:"twitter:description",content:"介绍如何使用hue来创建ozzie来创建一个spark action的owrkflow"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215736.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/02.%E4%BD%BF%E7%94%A8hue%E5%88%9B%E5%BB%BAozzie%E7%9A%84pyspark%20action%20workflow.html"},{property:"og:type",content:"article"},{property:"og:title",content:"使用hue创建ozzie的pyspark action workflow"},{property:"og:description",content:"介绍如何使用hue来创建ozzie来创建一个spark action的owrkflow"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215736.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/02.%E4%BD%BF%E7%94%A8hue%E5%88%9B%E5%BB%BAozzie%E7%9A%84pyspark%20action%20workflow.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"hue"},{property:"article:tag",content:"python"},{property:"article:tag",content:"大数据"},{itemprop:"name",content:"使用hue创建ozzie的pyspark action workflow"},{itemprop:"description",content:"介绍如何使用hue来创建ozzie来创建一个spark action的owrkflow"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/20220907215736.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/02.%E4%BD%BF%E7%94%A8hue%E5%88%9B%E5%BB%BAozzie%E7%9A%84pyspark%20action%20workflow.html",relativePath:"04.编程/09.其他/02.使用hue创建ozzie的pyspark action workflow.md",key:"v-7e9794a8",path:"/pages/aba491/",headersStr:null,content:'> hue是一个Apache Hadoop ui系统，本篇文章介绍如何使用hue创建一个ozzie的pyspark action的workflow, 该workflow仅包含一个spark action。注意，本文使用的是python语言的pyspark。\n\n 1. 编写一个python操作spark的程序。 demo.py\n\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.enableHiveSupport().appName(\n"demo").getOrCreate()\n\n# spark 的一些操作\n.......\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 2. 新建workflow\n\n\n\n> 传入需要运行的python脚本\n\n\n\n 3. 对该action 进行一些属性的配置。\n\n> 对spark进行设置，可以选择spark的运行模式。 默认使用的是spark1 的库去执行，如果使用的是spark2，则需要设置属性oozie.action.sharelib.for.spark=spark2 如图所示。\n\n\n\n> 进入2设置，进行一些变量的设置 oozie.libpath 需要使用到spark的一些jar包，填入路径jar包路径。\n\n\n\n 4. 该workflow已经设置成功，可以对其进行运行进行测试。',normalizedContent:'> hue是一个apache hadoop ui系统，本篇文章介绍如何使用hue创建一个ozzie的pyspark action的workflow, 该workflow仅包含一个spark action。注意，本文使用的是python语言的pyspark。\n\n 1. 编写一个python操作spark的程序。 demo.py\n\nfrom pyspark.sql import sparksession\n\nspark = sparksession.builder.enablehivesupport().appname(\n"demo").getorcreate()\n\n# spark 的一些操作\n.......\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 2. 新建workflow\n\n\n\n> 传入需要运行的python脚本\n\n\n\n 3. 对该action 进行一些属性的配置。\n\n> 对spark进行设置，可以选择spark的运行模式。 默认使用的是spark1 的库去执行，如果使用的是spark2，则需要设置属性oozie.action.sharelib.for.spark=spark2 如图所示。\n\n\n\n> 进入2设置，进行一些变量的设置 oozie.libpath 需要使用到spark的一些jar包，填入路径jar包路径。\n\n\n\n 4. 该workflow已经设置成功，可以对其进行运行进行测试。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"使用java开发logstash的filter插件",frontmatter:{title:"使用java开发logstash的filter插件",date:"2022-12-20T15:37:33.000Z",permalink:"/pages/7f16f6/",categories:["计算机","组件","其他"],tags:["组件","logstash","java"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"主要记录使用java开发logstash的filter插件的过程。",feed:{enable:!0},comment:!0,meta:[{name:"twitter:title",content:"使用java开发logstash的filter插件"},{name:"twitter:description",content:"主要记录使用java开发logstash的filter插件的过程。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/03.%E4%BD%BF%E7%94%A8java%E5%BC%80%E5%8F%91logstash%E7%9A%84filter%E6%8F%92%E4%BB%B6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"使用java开发logstash的filter插件"},{property:"og:description",content:"主要记录使用java开发logstash的filter插件的过程。"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/03.%E4%BD%BF%E7%94%A8java%E5%BC%80%E5%8F%91logstash%E7%9A%84filter%E6%8F%92%E4%BB%B6.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-12-20T15:37:33.000Z"},{property:"article:tag",content:"组件"},{property:"article:tag",content:"logstash"},{property:"article:tag",content:"java"},{itemprop:"name",content:"使用java开发logstash的filter插件"},{itemprop:"description",content:"主要记录使用java开发logstash的filter插件的过程。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/03.%E4%BD%BF%E7%94%A8java%E5%BC%80%E5%8F%91logstash%E7%9A%84filter%E6%8F%92%E4%BB%B6.html",relativePath:"04.编程/09.其他/03.使用java开发logstash的filter插件.md",key:"v-7accfee0",path:"/pages/7f16f6/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 准备开发环境",slug:"_1-准备开发环境",normalizedTitle:"1. 准备开发环境",charIndex:111},{level:2,title:"2. 编写 logstash java filter 插件",slug:"_2-编写-logstash-java-filter-插件",normalizedTitle:"2. 编写 logstash java filter 插件",charIndex:518},{level:3,title:"2.1 准备官方 demo",slug:"_2-1-准备官方-demo",normalizedTitle:"2.1 准备官方 demo",charIndex:552},{level:3,title:"2.2 开发 Filter 代码",slug:"_2-2-开发-filter-代码",normalizedTitle:"2.2 开发 filter 代码",charIndex:835},{level:2,title:"3. 单元测试",slug:"_3-单元测试",normalizedTitle:"3. 单元测试",charIndex:2129},{level:2,title:"4. 打包部署 Filter 插件",slug:"_4-打包部署-filter-插件",normalizedTitle:"4. 打包部署 filter 插件",charIndex:2368},{level:3,title:"4.1 元数据信息",slug:"_4-1-元数据信息",normalizedTitle:"4.1 元数据信息",charIndex:2390},{level:3,title:"4.2 打包任务",slug:"_4-2-打包任务",normalizedTitle:"4.2 打包任务",charIndex:2588},{level:3,title:"4.3 安装",slug:"_4-3-安装",normalizedTitle:"4.3 安装",charIndex:2659},{level:2,title:"5. 验证",slug:"_5-验证",normalizedTitle:"5. 验证",charIndex:3043},{level:2,title:"6. 相关链接",slug:"_6-相关链接",normalizedTitle:"6. 相关链接",charIndex:3700}],headersStr:"0. 前言 1. 准备开发环境 2. 编写 logstash java filter 插件 2.1 准备官方 demo 2.2 开发 Filter 代码 3. 单元测试 4. 打包部署 Filter 插件 4.1 元数据信息 4.2 打包任务 4.3 安装 5. 验证 6. 相关链接",content:'# 0. 前言\n\n在工作中遇到，logstash 中的 filter 中写了大量的解析逻辑，解析性能遇到瓶颈，所以希望将该部分的逻辑转换成 java 开发的插件，以提高解析速度。\n\n本文主要记录我开发插件的过程。\n\n\n# 1. 准备开发环境\n\n下载 logstash 源码\n\n直接可以去 logstash github 中选择自己使用的版本进行下载即可。\n\n构建 logstash\n\n将下载的 logstash 压缩包解压出来，进入 logstash 根目录下，当前路径下有 gradlew 和 gradlew.bat 两个脚本文件，前者是在 linux 下执行的，后者是在 windows 执行的脚本。\n\n假设当前环境是 windows，执行 gradlew.bat assemble 命令可以对当前模块进行构建。在这个过程中会去下载所有的依赖包到本地。等待构建完成，直至输出 BUILD SUCCESSFUL 代表构建成功。\n\n> gradlew.bat 脚本是对 gradle 的封装，在执行该命令时，会主动根据 gradle/wrapper/ 下的配置去下载 gradle 工具，然后再调用 gradle 进行构建模块\n\n\n# 2. 编写 logstash java filter 插件\n\n\n# 2.1 准备官方 demo\n\n下载 java 插件官方模板\n\n将 logstash-filter-java_filter_example 下载到本地使用，自定义开发的插件是基于该 example 进行修改的。\n\n构建插件\n\n在该项目的根目录下，创建 gradle.properties 文件，需要添加变量指定 logstash 下的 logstash-core 目录路径，使用绝对路径即可。\n\nLOGSTASH_CORE_PATH=<target_folder>/logstash-core\n\n\n1\n\n\n该变量是给 build.gradle 文件中使用的。\n\n\n# 2.2 开发 Filter 代码\n\n首先来看官方提供的 demo Filter 代码，代码路径在：src\\main\\java\\org\\logstashplugins\\JavaFilterExample.java，我们开发的插件基本是按照这个例子进行修改实现的。\n\n * 设置 pipeline 中的插件名称\n\n首先可以看到有一个注解 @LogstashPlugin(name = "java_filter_example") name 的值是指我们在 pipeline 中填写的插件名称。\n\n * 在 pipeline 中传参到插件中\n\n通过 PluginConfigSpec.stringSetting 定义变量\n\npublic static final PluginConfigSpec<String> SOURCE_CONFIG = PluginConfigSpec.stringSetting("source", "message");\n\n\n1\n\n\n再通过在构造方法中调用 get 方法即可获取到传入的值\n\nthis.sourceField = config.get(SOURCE_CONFIG);\n\n\n1\n\n\n并且需要将新增的字段添加到 configSchema 方法中并返回出去。\n\n@Override\npublic Collection<PluginConfigSpec<?>> configSchema() {\n\t// should return a list of all configuration options for this plugin\n\treturn Collections.singletonList(SOURCE_CONFIG);\n}\n\n\n1\n2\n3\n4\n5\n\n * filter 主体编码\n\n该插件的主体是 filter 方法，也就是数据的过滤走的 filter 方法，我们将想要做的解析规则实现在该方法中即可。\n\n可以看到该方法中有一个对 events 遍历的处理，每一个 Event 都是进来的每一条数据，然后对该条数据进行处理转换，最后再将转换好的 events 传出去。\n\n可以看到官方的案例是将传入的 message 字符串翻转。\n\n@Override\npublic Collection<Event> filter(Collection<Event> events, FilterMatchListener matchListener) {\n\tfor (Event e : events) {\n\t\tObject f = e.getField(sourceField);\n\t\tif (f instanceof String) {\n\t\t\te.setField(sourceField, StringUtils.reverse((String)f));\n\t\t\tmatchListener.filterMatched(e);\n\t\t}\n\t}\n\n\treturn events;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 3. 单元测试\n\n单测对插件来说至关重要，插件的规则转换流程、判断逻辑都非常多，各种类型的数据都可能导致插件出错，而插件验证需要编译、打包、安装再测试，流程较长，所以我们可以通过单测来减少以上流程的进行，在单测中就把所有的可能性都验证到，节省大量的时间。并且在后续迭代修改中，可以减少改动引发。\n\n建议可以使用 junit 的参数化单测方式，可以提高单测的效率和数量。这个需要在 build.gradle 文件中的 dependencies 添加支持参数化的库来支持。\n\n\n# 4. 打包部署 Filter 插件\n\n\n# 4.1 元数据信息\n\n我们需要在 build.gradle 文件中修改部分的插件元数据信息，像 description、authors 和 email 等字段都可以随意填写，以下字段需要注意：\n\n * group，需要和包名相同\n * pluginClass，需要和插件 Filter 的类名相同\n * pluginName，需要和 @LogstashPlugin 中的 name 相同\n\n\n# 4.2 打包任务\n\n通过执行 gradlew.bat gem 进行插件打包任务，最后会在插件根目下生成 .gem 的插件安装包文件。\n\n\n# 4.3 安装\n\n安装有在线安装和离线安装两种方式。\n\n> 注意：我们需要去官网下载可以直接使用的 logstash，而不能使用上面自己下载的 logstash 源码。\n\n在线安装\n\n在线安装会去访问 Elastic 的官网，所以需要是在线的环境。\n\n通过执行 logstash/bin 路径下的 logstash-plugin 命令进行安装，等待片刻即可安装成功。\n\nlogstash-plugin install /path/javaPlugin.gem\n\n\n1\n\n\n离线安装\n\n在某些场景下，环境是不能连接外网的，所以需要使用离线安装的方式。\n\n将生成的 gem 插件压缩到 zip 包中，然后再使用 logstash-plugin 命令进行安装。\n\nlogstash-plugin install file:///tmp/plugin.zip\n\n\n1\n\n\n\n# 5. 验证\n\n官方的插件 example 的功能是翻转字符串的功能，所以我们只需要验证该功能即可。\n\n 1. 创建一个 pipeline.conf\n\ninput {\n    # 输入一个字符串\n    generator { message => "Hello world!" count => 1 }\n}\n\nfilter {\n\t# 在插件中@LogstashPlugin配置的插件名称\n    java_filter_example {}\n}\n\noutput {\n    # 直接打印到控制台\n    stdout { }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n 2. 启动 logstash 加载上面的 pipeline.conf\n\nlogstash -f pipeline.conf\n\n\n1\n\n\n输出如下，可以看到 message 字段中的 Hello world!被翻转了。\n\n{\n\t"host" => {\n\t\t"name" => "4-sip0060"\n\t},\n\t"event" => {\n\t\t"original" => "Hello world!",\n\t\t"sequence" => 0\n\t},\n\t"@timestamp" => 2022-12-20T07:27:46.634166300Z,\n\t"@version" => "1",\n\t"message" => "!dlrow olleH"\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 6. 相关链接\n\n * How to write a Java filter plugin',normalizedContent:'# 0. 前言\n\n在工作中遇到，logstash 中的 filter 中写了大量的解析逻辑，解析性能遇到瓶颈，所以希望将该部分的逻辑转换成 java 开发的插件，以提高解析速度。\n\n本文主要记录我开发插件的过程。\n\n\n# 1. 准备开发环境\n\n下载 logstash 源码\n\n直接可以去 logstash github 中选择自己使用的版本进行下载即可。\n\n构建 logstash\n\n将下载的 logstash 压缩包解压出来，进入 logstash 根目录下，当前路径下有 gradlew 和 gradlew.bat 两个脚本文件，前者是在 linux 下执行的，后者是在 windows 执行的脚本。\n\n假设当前环境是 windows，执行 gradlew.bat assemble 命令可以对当前模块进行构建。在这个过程中会去下载所有的依赖包到本地。等待构建完成，直至输出 build successful 代表构建成功。\n\n> gradlew.bat 脚本是对 gradle 的封装，在执行该命令时，会主动根据 gradle/wrapper/ 下的配置去下载 gradle 工具，然后再调用 gradle 进行构建模块\n\n\n# 2. 编写 logstash java filter 插件\n\n\n# 2.1 准备官方 demo\n\n下载 java 插件官方模板\n\n将 logstash-filter-java_filter_example 下载到本地使用，自定义开发的插件是基于该 example 进行修改的。\n\n构建插件\n\n在该项目的根目录下，创建 gradle.properties 文件，需要添加变量指定 logstash 下的 logstash-core 目录路径，使用绝对路径即可。\n\nlogstash_core_path=<target_folder>/logstash-core\n\n\n1\n\n\n该变量是给 build.gradle 文件中使用的。\n\n\n# 2.2 开发 filter 代码\n\n首先来看官方提供的 demo filter 代码，代码路径在：src\\main\\java\\org\\logstashplugins\\javafilterexample.java，我们开发的插件基本是按照这个例子进行修改实现的。\n\n * 设置 pipeline 中的插件名称\n\n首先可以看到有一个注解 @logstashplugin(name = "java_filter_example") name 的值是指我们在 pipeline 中填写的插件名称。\n\n * 在 pipeline 中传参到插件中\n\n通过 pluginconfigspec.stringsetting 定义变量\n\npublic static final pluginconfigspec<string> source_config = pluginconfigspec.stringsetting("source", "message");\n\n\n1\n\n\n再通过在构造方法中调用 get 方法即可获取到传入的值\n\nthis.sourcefield = config.get(source_config);\n\n\n1\n\n\n并且需要将新增的字段添加到 configschema 方法中并返回出去。\n\n@override\npublic collection<pluginconfigspec<?>> configschema() {\n\t// should return a list of all configuration options for this plugin\n\treturn collections.singletonlist(source_config);\n}\n\n\n1\n2\n3\n4\n5\n\n * filter 主体编码\n\n该插件的主体是 filter 方法，也就是数据的过滤走的 filter 方法，我们将想要做的解析规则实现在该方法中即可。\n\n可以看到该方法中有一个对 events 遍历的处理，每一个 event 都是进来的每一条数据，然后对该条数据进行处理转换，最后再将转换好的 events 传出去。\n\n可以看到官方的案例是将传入的 message 字符串翻转。\n\n@override\npublic collection<event> filter(collection<event> events, filtermatchlistener matchlistener) {\n\tfor (event e : events) {\n\t\tobject f = e.getfield(sourcefield);\n\t\tif (f instanceof string) {\n\t\t\te.setfield(sourcefield, stringutils.reverse((string)f));\n\t\t\tmatchlistener.filtermatched(e);\n\t\t}\n\t}\n\n\treturn events;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 3. 单元测试\n\n单测对插件来说至关重要，插件的规则转换流程、判断逻辑都非常多，各种类型的数据都可能导致插件出错，而插件验证需要编译、打包、安装再测试，流程较长，所以我们可以通过单测来减少以上流程的进行，在单测中就把所有的可能性都验证到，节省大量的时间。并且在后续迭代修改中，可以减少改动引发。\n\n建议可以使用 junit 的参数化单测方式，可以提高单测的效率和数量。这个需要在 build.gradle 文件中的 dependencies 添加支持参数化的库来支持。\n\n\n# 4. 打包部署 filter 插件\n\n\n# 4.1 元数据信息\n\n我们需要在 build.gradle 文件中修改部分的插件元数据信息，像 description、authors 和 email 等字段都可以随意填写，以下字段需要注意：\n\n * group，需要和包名相同\n * pluginclass，需要和插件 filter 的类名相同\n * pluginname，需要和 @logstashplugin 中的 name 相同\n\n\n# 4.2 打包任务\n\n通过执行 gradlew.bat gem 进行插件打包任务，最后会在插件根目下生成 .gem 的插件安装包文件。\n\n\n# 4.3 安装\n\n安装有在线安装和离线安装两种方式。\n\n> 注意：我们需要去官网下载可以直接使用的 logstash，而不能使用上面自己下载的 logstash 源码。\n\n在线安装\n\n在线安装会去访问 elastic 的官网，所以需要是在线的环境。\n\n通过执行 logstash/bin 路径下的 logstash-plugin 命令进行安装，等待片刻即可安装成功。\n\nlogstash-plugin install /path/javaplugin.gem\n\n\n1\n\n\n离线安装\n\n在某些场景下，环境是不能连接外网的，所以需要使用离线安装的方式。\n\n将生成的 gem 插件压缩到 zip 包中，然后再使用 logstash-plugin 命令进行安装。\n\nlogstash-plugin install file:///tmp/plugin.zip\n\n\n1\n\n\n\n# 5. 验证\n\n官方的插件 example 的功能是翻转字符串的功能，所以我们只需要验证该功能即可。\n\n 1. 创建一个 pipeline.conf\n\ninput {\n    # 输入一个字符串\n    generator { message => "hello world!" count => 1 }\n}\n\nfilter {\n\t# 在插件中@logstashplugin配置的插件名称\n    java_filter_example {}\n}\n\noutput {\n    # 直接打印到控制台\n    stdout { }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n 2. 启动 logstash 加载上面的 pipeline.conf\n\nlogstash -f pipeline.conf\n\n\n1\n\n\n输出如下，可以看到 message 字段中的 hello world!被翻转了。\n\n{\n\t"host" => {\n\t\t"name" => "4-sip0060"\n\t},\n\t"event" => {\n\t\t"original" => "hello world!",\n\t\t"sequence" => 0\n\t},\n\t"@timestamp" => 2022-12-20t07:27:46.634166300z,\n\t"@version" => "1",\n\t"message" => "!dlrow olleh"\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 6. 相关链接\n\n * how to write a java filter plugin',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"分布式锁",frontmatter:{tags:["分布式","锁","python"],title:"分布式锁",date:"2022-09-21T10:09:01.000Z",permalink:"/pages/d91dfb/",author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文介绍了分布式锁遇到的问题及对应的解决方案",feed:{enable:!0},categories:["编程","其他"],comment:!0,meta:[{name:"twitter:title",content:"分布式锁"},{name:"twitter:description",content:"本文介绍了分布式锁遇到的问题及对应的解决方案"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/01.%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.html"},{property:"og:type",content:"article"},{property:"og:title",content:"分布式锁"},{property:"og:description",content:"本文介绍了分布式锁遇到的问题及对应的解决方案"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/01.%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-09-21T10:09:01.000Z"},{property:"article:tag",content:"分布式"},{property:"article:tag",content:"锁"},{property:"article:tag",content:"python"},{itemprop:"name",content:"分布式锁"},{itemprop:"description",content:"本文介绍了分布式锁遇到的问题及对应的解决方案"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/01.%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.html",relativePath:"04.编程/09.其他/01.分布式锁.md",key:"v-23857ed1",path:"/pages/d91dfb/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"数据库更新问题",slug:"数据库更新问题",normalizedTitle:"数据库更新问题",charIndex:34},{level:2,title:"超卖问题",slug:"超卖问题",normalizedTitle:"超卖问题",charIndex:1789},{level:2,title:"基于mysql的乐观锁机制实现",slug:"基于mysql的乐观锁机制实现",normalizedTitle:"基于mysql的乐观锁机制实现",charIndex:3022},{level:2,title:"基于mysql的悲观锁机制实现",slug:"基于mysql的悲观锁机制实现",normalizedTitle:"基于mysql的悲观锁机制实现",charIndex:4436},{level:2,title:"redis分布式锁",slug:"redis分布式锁",normalizedTitle:"redis分布式锁",charIndex:4593},{level:3,title:"分布式锁需要解决的问题",slug:"分布式锁需要解决的问题",normalizedTitle:"分布式锁需要解决的问题",charIndex:4607},{level:3,title:"抛出问题",slug:"抛出问题",normalizedTitle:"抛出问题",charIndex:4804},{level:3,title:"redis中原子操作setnx",slug:"redis中原子操作setnx",normalizedTitle:"redis中原子操作setnx",charIndex:7150},{level:3,title:"死锁问题",slug:"死锁问题",normalizedTitle:"死锁问题",charIndex:7832},{level:3,title:"py-redis-lock和redis-py",slug:"py-redis-lock和redis-py",normalizedTitle:"py-redis-lock和redis-py",charIndex:10238},{level:3,title:"redis的分布式锁优缺点",slug:"redis的分布式锁优缺点",normalizedTitle:"redis的分布式锁优缺点",charIndex:10307}],headersStr:"前言 数据库更新问题 超卖问题 基于mysql的乐观锁机制实现 基于mysql的悲观锁机制实现 redis分布式锁 分布式锁需要解决的问题 抛出问题 redis中原子操作setnx 死锁问题 py-redis-lock和redis-py redis的分布式锁优缺点",content:'# 前言\n\n本文介绍了分布式锁遇到的问题及对应的解决方案。\n\n\n# 数据库更新问题\n\n在数据库中创建一个商品表，包含id、name、count字段，这里使用的peewee来操作数据库。\n\nfrom peewee import *\n\ndb = SqliteDatabase(\'people.db\')\n\n\nclass Goods(Model):\n    id = IntegerField()\n    count = IntegerField()\n    name = CharField()\n\n    class Meta:\n        database = db  # This model uses the "people.db" database.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n初始化数据表中数据。给id=1的商品初始化商品数量为100\n\nID   NAME      COUNT\n1    clothes   100\n\n使用两个线程消费商品卖出的场景，每次消费数量为10，当商品数量充足时，商品数量减少10。因为程序可能会在任何地方暂停运行，我们使用time.Sleep来构造程序暂停的场景。\n\nimport time\n\ndef main():\n    # 卖出的数量\n    num = 10\n\n    goods = Goods.get(Goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        goods.count -= num\n        goods.save()\n\nif __name__ == \'__main__\':\n    import threading\n\n    t1 = threading.Thread(target=main)\n    t2 = threading.Thread(target=main)\n\n    t1.start()\n    t2.start()\n    t1.join()\n    t2.join()\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n运行后会发现，商品数量变成了90，这明显不符合我们的预期。两个线程都消费了10个，预期结果应该是80才对。\n\nID   NAME      COUNT\n1    clothes   90\n\n执行过程\n\n在t1线程查询到的goods的商品数量为100，保存在变量中，停止，然后t2线程开始查询，查询到的数量也是100，然后往下执行时，t1减10，调用save时是告诉数据库保存的数量为90，结束。t2线程也是100-10，save时，也是保存90。\n\n解决方案\n\n应该让数据库根据自己当前的值更新，而不是使用变量中的值进行更新。\n\n我们恢复商品的数量到100，然后修改代码如下，使用update来让数据库根据当前的值进行更新。\n\ndef main():\n    # 卖出的数量\n    num = 10\n\n    goods = Goods.get(Goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = Goods.update(count=Goods.count - num).where(Goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n运行结果符合我们的预期，商品数量变成了80。\n\nID   NAME      COUNT\n1    clothes   80\n\n\n# 超卖问题\n\n虽然解决了更新数量不一致的问题，依然没有解决商品超卖问题。商品数量依然是100，但是我们两个线程都想买99件。\n\ndef main():\n    # 卖出的数量\n    num = 99\n\n    goods = Goods.get(Goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = Goods.update(count=Goods.count - num).where(Goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n运行结果是，两个线程都成功买入，数据库表中的数量变成了-98。我们肯定期望一个线程买入成功，而另一个线程执行失败。\n\nID   NAME      COUNT\n1    clothes   -98\n\n加锁解决\n\n我们在买入之前，加一个锁，这样同时只能有一个用户在执行买入。\n\nimport threading\nR = threading.Lock()\n\ndef main():\n    # 卖出的数量\n    num = 99\n\n    R.acquire()\n    goods = Goods.get(Goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = Goods.update(count=Goods.count - num).where(Goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n\n    R.release()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n运行之后，可以看到库存为1件，只有一个线程更新成功，另一个更新失败。\n\n当前是同一个服务的两个线程中，可以拿到通一把锁，但是如果在微服务中，每一次请求因为负载均衡可能请求在不同的服务中，这两个服务甚至不在同一台服务器上，那么这个锁就失效了。\n\n这个时候需要使用分布式锁来解决该问题。 ‍\n\n\n# 基于mysql的乐观锁机制实现\n\n什么是乐观锁？\n\n乐观锁，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制，乐观锁适用于多读的应用类型，这样可以提高吞吐量\n\n实现\n\n从业务中实现乐观锁机制。\n\n在之前的Goods表中添加version字段\n\nclass Goods(Model):\n    id = IntegerField()\n    count = IntegerField()\n    name = CharField()\n    version = IntegerField()\n\n    class Meta:\n        database = db  # This model uses the "people.db" database.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n数据表如下：\n\nID   NAME      COUNT   VERSION\n1    clothes   100     1\n\n在更新条件中添加版本的判断，确认在更新库存数量时，是否有其他服务更改了该条记录，如果没有则进行更新。并且在更新库存时，给版本号+1，代表着该记录已被修改。\n\n如果没有更新成功，则一直重试，直至成功为止。\n\ndef main():\n    # 卖出的数量\n    num = 99\n\n    while True:\n        goods = Goods.get(Goods.id == 1)\n        time.sleep(random.randint(1, 3))\n        if goods.count < num:\n            print("商品数量不足")\n            break\n        else:\n            query = Goods.update(count=Goods.count - num, version=Goods.version + 1).where(Goods.id == 1,\n                                                                                           Goods.version == goods.version)\n            ok = query.execute()\n            if ok:\n                print("更新成功")\n                break\n            else:\n                print("更新失败")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n运行结果：\n\n更新成功\n更新失败\n商品数量不足\n\n\n1\n2\n3\n\n\n库存剩下1件，版本号更新为2，符合我们的预期。\n\nID   NAME      COUNT   VERSION\n1    clothes   1       2\n\n‍ 优点：\n\n 1. 简单\n 2. 不需要额外的组件\n\n缺点：\n\n并发高时，不断的对数据库进行查询，一样会增加数据库的压力。性能差。\n\n‍\n\n\n# 基于mysql的悲观锁机制实现\n\n悲观锁,就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。\n\n缺点：并发性不高，不建议使用\n\n\n# redis分布式锁\n\n\n# 分布式锁需要解决的问题\n\n 1. 互斥性，任何时刻只能有一个客户拥有锁，不能同时多个客户获取\n\n 2. 安全性，只有被持有该锁的用户删除，而不能被其他用户删除\n\n 3. 死锁，获取锁的客户单因为某些原因而宕机，而未能释放锁，其他客户端无法获取锁，需要有机制来避免该类问题的发生\n    \n    1. 代码异常，导致无法运行到release\n    2. 你的当前服务器网络问题-脑裂\n\n\n# 抛出问题\n\n我创建一个redis锁的类，使用acquire加锁，release解锁。\n\nclass Lock:\n    def __init__(self, name):\n        self.redis_client = redis.Redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n        if not self.redis_client.get(self.name):\n            self.redis_client.set(self.name, 1)\n            return True\n        else:\n            while True:\n                import time\n                time.sleep(1)\n                if self.redis_client.get(self.name):\n                    self.redis_client.set(self.name, 1)\n                    return True\n\n    def release(self):\n        self.redis_client.delete(self.name)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n在入口处加锁，在出口处释放锁，这样同时只有一个服务能够执行更新操作。\n\ndef main():\n    # 卖出的数量\n    num = 99\n    # 商品ID\n    goods_id = 1\n\n    lock = Lock("lock:goods_{}".format(goods_id))\n    lock.acquire()\n    goods = Goods.get(Goods.id == goods_id)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = Goods.update(count=Goods.count - num).where(Goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n    lock.release()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n运行之后，发现库存的数量是-98，没有达到预期的效果。\n\nID   NAME      COUNT\n1    clothes   -98\n\n我通过打日志的方式，在redis_client.get之后和release中打日志。\n\nclass Lock:\n    def __init__(self, name):\n        self.redis_client = redis.Redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n\n        if not self.redis_client.get(self.name):\n            print("acquire\\n")\n            self.redis_client.set(self.name, 1)\n            return True\n        else:\n            while True:\n                import time\n                time.sleep(1)\n                if self.redis_client.get(self.name):\n                    self.redis_client.set(self.name, 1)\n                    return True\n\n    def release(self):\n        print("release")\n        self.redis_client.delete(self.name)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n运行结果如下：\n\nacquireacquire\n\n更新成功\nrelease\n更新成功\nrelease\n\n\n1\n2\n3\n4\n5\n6\n\n\n在没有释放锁的时候，两个线程竟然都拿到锁了？\n\n因为，线程t1在执行redis_client.get(self.name)之后还没有redis_client.set(self.name, 1)时，线程t2也进来到这一步了，也就是两个线程同时在self.redis_client.get(self.name)和self.redis_client.set(self.name, 1)之间。\n\n我们需要保证get和set是原子性的，才能解决该问题。\n\n\n# redis中原子操作setnx\n\nredis中自带了一个原子性操作setnx，可以进行查询并更新。\n\nclass Lock:\n    def __init__(self, name):\n        self.redis_client = redis.Redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n#       # 如果不存在，设置值为1，返回1. 否则返回0. 原子操作。\n        if self.redis_client.setnx(self.name, 1):\n            return True\n        else:\n            while True:\n                import time\n                time.sleep(1)\n                if self.redis_client.setnx(self.name, 1):\n                    return True\n\n    def release(self):\n        self.redis_client.delete(self.name)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n运行后，库存数量为1，符合我们的预期。\n\nID   NAME      COUNT\n1    clothes   1\n\n\n# 死锁问题\n\n获取锁的客户单因为某些原因而宕机，而未能释放锁，其他客户端无法获取锁，需要有机制来避免该类问题的发生\n\n 1. 代码异常，导致无法运行到release\n 2. 断点\n\n‍ 解决方案：\n\n通过设置过期时间来解决，每次在拿锁时，给redis中对应的key设置一个过期时间，即使出现上面的问题，key也能自动被删除，解决死锁问题。\n\nclass Lock:\n    def __init__(self, name):\n        self.redis_client = redis.Redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n        if self.redis_client.set(self.name, 1, nx=True, ex=15):\n            return True\n        else:\n            while True:\n                import time\n                time.sleep(1)\n                if self.redis_client.set(self.name, 1, nx=True, ex=15):\n                    return True\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n但是会有新问题：\n\n * 当前线程如果在一段时间后没有执行完，当前的程序没有执行完，然后key过期\n * 不安全，另一个线程进来以后会将当前的key给删掉，另一个线程删掉了本该属于我设置的值。\n\n解决方案：\n\n如果当前线程没有执行完，那我的这个线程还应该在适当的时候去续租，将过期时间重新设置。一般是在快要过期的2/3的时候去续租。定时程序可以使用另一个线程去完成。\n\nclass Lock:\n    def __init__(self, name):\n        self.redis_client = redis.Redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n        if self.redis_client.set(self.name, 1, nx=True, ex=15):\n            # 启动一个线程然后去定时的刷新这个过期，这个操作最好也是使用lua脚本来完成。\n            return True\n        else:\n            while True:\n                import time\n                time.sleep(1)\n                if self.redis_client.set(self.name, 1, nx=True, ex=15):\n                    return True\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n‍ 如何防止我设置的值被其他的线程给删除掉?\n\n解决方法\n\n可以拿锁的时候生成一个ID，并将其设置redis中键对应的值，在删除的时候，判断从redis中拿出的值是否为该程序设置的ID，如果不是，则删除失败。\n\nclass Lock:\n    def __init__(self, name, id=None):\n        self.redis_client = redis.Redis(host="10.61.74.37")\n        self.name = name\n        self.id = id if id else str(uuid.uuid4())\n\n    def acquire(self):\n        if self.redis_client.set(self.name, self.id, nx=True, ex=15):\n            # 启动一个线程然后去定时的刷新这个过期，这个操作最好也是使用lua脚本来完成。\n            return True\n        else:\n            while True:\n                import time\n                time.sleep(1)\n                if self.redis_client.set(self.name, self.id, nx=True, ex=15):\n                    return True\n\n    def release(self):\n        val = str(self.redis_client.get(self.name), encoding="utf8")\n        if val == self.id:\n            self.redis_client.delete(self.name)\n        else:\n            print("不能删除自己的锁")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n‍ 但是还会有新的问题，上面的release方法，get和delete redis中key分成了两个步骤，还是有可能在两者之间中断，所以需要使用redis的lua脚本来实现两者的原子操作\n\n\n# py-redis-lock和redis-py\n\n该库是开源的分布式锁py实现库，解决了上面的问题。后面有空可以分析下该库的源码。\n\n\n# redis的分布式锁优缺点\n\n优点\n\n * 性能高\n * 简单\n * redis本身使用很频繁，不需要额外维护\n\n缺点\n\n * 依赖了第三方组件\n\n * 单机的redis挂掉的可能性相对较高，需要引入哨兵机制\n\n * redis的cluster的引入会导致刚才的redis的锁会有问题 - redlock\n\n‍\n\n‍',normalizedContent:'# 前言\n\n本文介绍了分布式锁遇到的问题及对应的解决方案。\n\n\n# 数据库更新问题\n\n在数据库中创建一个商品表，包含id、name、count字段，这里使用的peewee来操作数据库。\n\nfrom peewee import *\n\ndb = sqlitedatabase(\'people.db\')\n\n\nclass goods(model):\n    id = integerfield()\n    count = integerfield()\n    name = charfield()\n\n    class meta:\n        database = db  # this model uses the "people.db" database.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n初始化数据表中数据。给id=1的商品初始化商品数量为100\n\nid   name      count\n1    clothes   100\n\n使用两个线程消费商品卖出的场景，每次消费数量为10，当商品数量充足时，商品数量减少10。因为程序可能会在任何地方暂停运行，我们使用time.sleep来构造程序暂停的场景。\n\nimport time\n\ndef main():\n    # 卖出的数量\n    num = 10\n\n    goods = goods.get(goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        goods.count -= num\n        goods.save()\n\nif __name__ == \'__main__\':\n    import threading\n\n    t1 = threading.thread(target=main)\n    t2 = threading.thread(target=main)\n\n    t1.start()\n    t2.start()\n    t1.join()\n    t2.join()\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n运行后会发现，商品数量变成了90，这明显不符合我们的预期。两个线程都消费了10个，预期结果应该是80才对。\n\nid   name      count\n1    clothes   90\n\n执行过程\n\n在t1线程查询到的goods的商品数量为100，保存在变量中，停止，然后t2线程开始查询，查询到的数量也是100，然后往下执行时，t1减10，调用save时是告诉数据库保存的数量为90，结束。t2线程也是100-10，save时，也是保存90。\n\n解决方案\n\n应该让数据库根据自己当前的值更新，而不是使用变量中的值进行更新。\n\n我们恢复商品的数量到100，然后修改代码如下，使用update来让数据库根据当前的值进行更新。\n\ndef main():\n    # 卖出的数量\n    num = 10\n\n    goods = goods.get(goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = goods.update(count=goods.count - num).where(goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n运行结果符合我们的预期，商品数量变成了80。\n\nid   name      count\n1    clothes   80\n\n\n# 超卖问题\n\n虽然解决了更新数量不一致的问题，依然没有解决商品超卖问题。商品数量依然是100，但是我们两个线程都想买99件。\n\ndef main():\n    # 卖出的数量\n    num = 99\n\n    goods = goods.get(goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = goods.update(count=goods.count - num).where(goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n运行结果是，两个线程都成功买入，数据库表中的数量变成了-98。我们肯定期望一个线程买入成功，而另一个线程执行失败。\n\nid   name      count\n1    clothes   -98\n\n加锁解决\n\n我们在买入之前，加一个锁，这样同时只能有一个用户在执行买入。\n\nimport threading\nr = threading.lock()\n\ndef main():\n    # 卖出的数量\n    num = 99\n\n    r.acquire()\n    goods = goods.get(goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = goods.update(count=goods.count - num).where(goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n\n    r.release()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n运行之后，可以看到库存为1件，只有一个线程更新成功，另一个更新失败。\n\n当前是同一个服务的两个线程中，可以拿到通一把锁，但是如果在微服务中，每一次请求因为负载均衡可能请求在不同的服务中，这两个服务甚至不在同一台服务器上，那么这个锁就失效了。\n\n这个时候需要使用分布式锁来解决该问题。 ‍\n\n\n# 基于mysql的乐观锁机制实现\n\n什么是乐观锁？\n\n乐观锁，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制，乐观锁适用于多读的应用类型，这样可以提高吞吐量\n\n实现\n\n从业务中实现乐观锁机制。\n\n在之前的goods表中添加version字段\n\nclass goods(model):\n    id = integerfield()\n    count = integerfield()\n    name = charfield()\n    version = integerfield()\n\n    class meta:\n        database = db  # this model uses the "people.db" database.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n数据表如下：\n\nid   name      count   version\n1    clothes   100     1\n\n在更新条件中添加版本的判断，确认在更新库存数量时，是否有其他服务更改了该条记录，如果没有则进行更新。并且在更新库存时，给版本号+1，代表着该记录已被修改。\n\n如果没有更新成功，则一直重试，直至成功为止。\n\ndef main():\n    # 卖出的数量\n    num = 99\n\n    while true:\n        goods = goods.get(goods.id == 1)\n        time.sleep(random.randint(1, 3))\n        if goods.count < num:\n            print("商品数量不足")\n            break\n        else:\n            query = goods.update(count=goods.count - num, version=goods.version + 1).where(goods.id == 1,\n                                                                                           goods.version == goods.version)\n            ok = query.execute()\n            if ok:\n                print("更新成功")\n                break\n            else:\n                print("更新失败")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n运行结果：\n\n更新成功\n更新失败\n商品数量不足\n\n\n1\n2\n3\n\n\n库存剩下1件，版本号更新为2，符合我们的预期。\n\nid   name      count   version\n1    clothes   1       2\n\n‍ 优点：\n\n 1. 简单\n 2. 不需要额外的组件\n\n缺点：\n\n并发高时，不断的对数据库进行查询，一样会增加数据库的压力。性能差。\n\n‍\n\n\n# 基于mysql的悲观锁机制实现\n\n悲观锁,就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。\n\n缺点：并发性不高，不建议使用\n\n\n# redis分布式锁\n\n\n# 分布式锁需要解决的问题\n\n 1. 互斥性，任何时刻只能有一个客户拥有锁，不能同时多个客户获取\n\n 2. 安全性，只有被持有该锁的用户删除，而不能被其他用户删除\n\n 3. 死锁，获取锁的客户单因为某些原因而宕机，而未能释放锁，其他客户端无法获取锁，需要有机制来避免该类问题的发生\n    \n    1. 代码异常，导致无法运行到release\n    2. 你的当前服务器网络问题-脑裂\n\n\n# 抛出问题\n\n我创建一个redis锁的类，使用acquire加锁，release解锁。\n\nclass lock:\n    def __init__(self, name):\n        self.redis_client = redis.redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n        if not self.redis_client.get(self.name):\n            self.redis_client.set(self.name, 1)\n            return true\n        else:\n            while true:\n                import time\n                time.sleep(1)\n                if self.redis_client.get(self.name):\n                    self.redis_client.set(self.name, 1)\n                    return true\n\n    def release(self):\n        self.redis_client.delete(self.name)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n在入口处加锁，在出口处释放锁，这样同时只有一个服务能够执行更新操作。\n\ndef main():\n    # 卖出的数量\n    num = 99\n    # 商品id\n    goods_id = 1\n\n    lock = lock("lock:goods_{}".format(goods_id))\n    lock.acquire()\n    goods = goods.get(goods.id == goods_id)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = goods.update(count=goods.count - num).where(goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n    lock.release()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n运行之后，发现库存的数量是-98，没有达到预期的效果。\n\nid   name      count\n1    clothes   -98\n\n我通过打日志的方式，在redis_client.get之后和release中打日志。\n\nclass lock:\n    def __init__(self, name):\n        self.redis_client = redis.redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n\n        if not self.redis_client.get(self.name):\n            print("acquire\\n")\n            self.redis_client.set(self.name, 1)\n            return true\n        else:\n            while true:\n                import time\n                time.sleep(1)\n                if self.redis_client.get(self.name):\n                    self.redis_client.set(self.name, 1)\n                    return true\n\n    def release(self):\n        print("release")\n        self.redis_client.delete(self.name)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n运行结果如下：\n\nacquireacquire\n\n更新成功\nrelease\n更新成功\nrelease\n\n\n1\n2\n3\n4\n5\n6\n\n\n在没有释放锁的时候，两个线程竟然都拿到锁了？\n\n因为，线程t1在执行redis_client.get(self.name)之后还没有redis_client.set(self.name, 1)时，线程t2也进来到这一步了，也就是两个线程同时在self.redis_client.get(self.name)和self.redis_client.set(self.name, 1)之间。\n\n我们需要保证get和set是原子性的，才能解决该问题。\n\n\n# redis中原子操作setnx\n\nredis中自带了一个原子性操作setnx，可以进行查询并更新。\n\nclass lock:\n    def __init__(self, name):\n        self.redis_client = redis.redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n#       # 如果不存在，设置值为1，返回1. 否则返回0. 原子操作。\n        if self.redis_client.setnx(self.name, 1):\n            return true\n        else:\n            while true:\n                import time\n                time.sleep(1)\n                if self.redis_client.setnx(self.name, 1):\n                    return true\n\n    def release(self):\n        self.redis_client.delete(self.name)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n运行后，库存数量为1，符合我们的预期。\n\nid   name      count\n1    clothes   1\n\n\n# 死锁问题\n\n获取锁的客户单因为某些原因而宕机，而未能释放锁，其他客户端无法获取锁，需要有机制来避免该类问题的发生\n\n 1. 代码异常，导致无法运行到release\n 2. 断点\n\n‍ 解决方案：\n\n通过设置过期时间来解决，每次在拿锁时，给redis中对应的key设置一个过期时间，即使出现上面的问题，key也能自动被删除，解决死锁问题。\n\nclass lock:\n    def __init__(self, name):\n        self.redis_client = redis.redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n        if self.redis_client.set(self.name, 1, nx=true, ex=15):\n            return true\n        else:\n            while true:\n                import time\n                time.sleep(1)\n                if self.redis_client.set(self.name, 1, nx=true, ex=15):\n                    return true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n但是会有新问题：\n\n * 当前线程如果在一段时间后没有执行完，当前的程序没有执行完，然后key过期\n * 不安全，另一个线程进来以后会将当前的key给删掉，另一个线程删掉了本该属于我设置的值。\n\n解决方案：\n\n如果当前线程没有执行完，那我的这个线程还应该在适当的时候去续租，将过期时间重新设置。一般是在快要过期的2/3的时候去续租。定时程序可以使用另一个线程去完成。\n\nclass lock:\n    def __init__(self, name):\n        self.redis_client = redis.redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n        if self.redis_client.set(self.name, 1, nx=true, ex=15):\n            # 启动一个线程然后去定时的刷新这个过期，这个操作最好也是使用lua脚本来完成。\n            return true\n        else:\n            while true:\n                import time\n                time.sleep(1)\n                if self.redis_client.set(self.name, 1, nx=true, ex=15):\n                    return true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n‍ 如何防止我设置的值被其他的线程给删除掉?\n\n解决方法\n\n可以拿锁的时候生成一个id，并将其设置redis中键对应的值，在删除的时候，判断从redis中拿出的值是否为该程序设置的id，如果不是，则删除失败。\n\nclass lock:\n    def __init__(self, name, id=none):\n        self.redis_client = redis.redis(host="10.61.74.37")\n        self.name = name\n        self.id = id if id else str(uuid.uuid4())\n\n    def acquire(self):\n        if self.redis_client.set(self.name, self.id, nx=true, ex=15):\n            # 启动一个线程然后去定时的刷新这个过期，这个操作最好也是使用lua脚本来完成。\n            return true\n        else:\n            while true:\n                import time\n                time.sleep(1)\n                if self.redis_client.set(self.name, self.id, nx=true, ex=15):\n                    return true\n\n    def release(self):\n        val = str(self.redis_client.get(self.name), encoding="utf8")\n        if val == self.id:\n            self.redis_client.delete(self.name)\n        else:\n            print("不能删除自己的锁")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n‍ 但是还会有新的问题，上面的release方法，get和delete redis中key分成了两个步骤，还是有可能在两者之间中断，所以需要使用redis的lua脚本来实现两者的原子操作\n\n\n# py-redis-lock和redis-py\n\n该库是开源的分布式锁py实现库，解决了上面的问题。后面有空可以分析下该库的源码。\n\n\n# redis的分布式锁优缺点\n\n优点\n\n * 性能高\n * 简单\n * redis本身使用很频繁，不需要额外维护\n\n缺点\n\n * 依赖了第三方组件\n\n * 单机的redis挂掉的可能性相对较高，需要引入哨兵机制\n\n * redis的cluster的引入会导致刚才的redis的锁会有问题 - redlock\n\n‍\n\n‍',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"count的性能优化",frontmatter:{title:"count的性能优化",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/19cfb6/",tags:["性能问题","sql","clickhouse"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"遇到的sql查询语句中发现的count性能优化的问题",feed:{enable:!0},categories:["编程","其他"],comment:!0,meta:[{name:"twitter:title",content:"count的性能优化"},{name:"twitter:description",content:"遇到的sql查询语句中发现的count性能优化的问题"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/20.count%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.html"},{property:"og:type",content:"article"},{property:"og:title",content:"count的性能优化"},{property:"og:description",content:"遇到的sql查询语句中发现的count性能优化的问题"},{property:"og:url",content:"https://www.zhengwenfeng.com/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/20.count%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"性能问题"},{property:"article:tag",content:"sql"},{property:"article:tag",content:"clickhouse"},{itemprop:"name",content:"count的性能优化"},{itemprop:"description",content:"遇到的sql查询语句中发现的count性能优化的问题"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/20.count%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.html",relativePath:"04.编程/09.其他/20.count的性能优化.md",key:"v-48a6492a",path:"/pages/19cfb6/",headers:[{level:2,title:"问题",slug:"问题",normalizedTitle:"问题",charIndex:2},{level:2,title:"定位问题",slug:"定位问题",normalizedTitle:"定位问题",charIndex:77},{level:2,title:"查询分析",slug:"查询分析",normalizedTitle:"查询分析",charIndex:227}],headersStr:"问题 定位问题 查询分析",content:"# 问题\n\n今天测试给我提了BUG，发现某个查询接口超时了，超时时间为1分钟。\n\n目前的用的数据库是clickhouse，数据量大概在20亿左右\n\n\n# 定位问题\n\n我通过调试将查询数据的语句打印出来，查询语句放在数据库中执行，发现几秒就查询完成了，这个时候我就奇了怪了，后面我再仔细看接口的代码，跟踪调试后发现，除了会查询数据之外，还会执行查询数据量的语句。\n\n我将查询数量的语句打印出来，执行该语句，发现是超过1分钟的，看来是定位到问题了。\n\n\n# 查询分析\n\n语句大概是下面这样的，大概有30多张表，也就是需要union30多张表\n\nselect\n    count(*)\nfrom\n    (\n        select\n            a_field,\n            b_field,\n            c_field,\n            d_field,\n            e_field,\n            f_field\n        from\n            A\n        union\n        all\n        select\n            a_field,\n            b_field,\n            c_field,\n            d_field,\n            e_field,\n            f_field\n        from\n            B\n    )\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n这条语句是通过将多个表union成一个大表，然后再count求数量。\n\n问题显而易见，为啥我们要构造一张这么大的表在内存中再count数量，直接count每张表的数量再相加不就是了。优化语句如下：\n\nselect\n    count(cnt)\nfrom\n    (\n        select\n            count() as cnt\n        from\n            A\n        union\n        all\n        select\n            count() as cnt\n        from\n            B\n    )\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n将该语句放在数据库查询，秒级返回，直接从1分钟优化到1秒钟",normalizedContent:"# 问题\n\n今天测试给我提了bug，发现某个查询接口超时了，超时时间为1分钟。\n\n目前的用的数据库是clickhouse，数据量大概在20亿左右\n\n\n# 定位问题\n\n我通过调试将查询数据的语句打印出来，查询语句放在数据库中执行，发现几秒就查询完成了，这个时候我就奇了怪了，后面我再仔细看接口的代码，跟踪调试后发现，除了会查询数据之外，还会执行查询数据量的语句。\n\n我将查询数量的语句打印出来，执行该语句，发现是超过1分钟的，看来是定位到问题了。\n\n\n# 查询分析\n\n语句大概是下面这样的，大概有30多张表，也就是需要union30多张表\n\nselect\n    count(*)\nfrom\n    (\n        select\n            a_field,\n            b_field,\n            c_field,\n            d_field,\n            e_field,\n            f_field\n        from\n            a\n        union\n        all\n        select\n            a_field,\n            b_field,\n            c_field,\n            d_field,\n            e_field,\n            f_field\n        from\n            b\n    )\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n这条语句是通过将多个表union成一个大表，然后再count求数量。\n\n问题显而易见，为啥我们要构造一张这么大的表在内存中再count数量，直接count每张表的数量再相加不就是了。优化语句如下：\n\nselect\n    count(cnt)\nfrom\n    (\n        select\n            count() as cnt\n        from\n            a\n        union\n        all\n        select\n            count() as cnt\n        from\n            b\n    )\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n将该语句放在数据库查询，秒级返回，直接从1分钟优化到1秒钟",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"读书笔记:如何阅读一本书",frontmatter:{title:"读书笔记:如何阅读一本书",date:"2022-10-21T20:52:34.000Z",permalink:"/pages/8bdb8d/",categories:["读书破万卷"],tags:["读书"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"本文是我阅读完《如何阅读一本书》的读后感，作者主要是将阅读分为了四个层次：基础阅读、检视阅读、分析阅读和主题阅读，并讲解这几个层次该如何去做，能够更好的帮助我们阅读，让我们从中收获到更多",feed:{enable:!0},comment:!0,meta:[{name:"twitter:title",content:"读书笔记:如何阅读一本书"},{name:"twitter:description",content:"本文是我阅读完《如何阅读一本书》的读后感，作者主要是将阅读分为了四个层次：基础阅读、检视阅读、分析阅读和主题阅读，并讲解这几个层次该如何去做，能够更好的帮助我们阅读，让我们从中收获到更多"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/05.%E8%AF%BB%E4%B9%A6%E7%A0%B4%E4%B8%87%E5%8D%B7/01.%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E6%9C%AC%E4%B9%A6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"读书笔记:如何阅读一本书"},{property:"og:description",content:"本文是我阅读完《如何阅读一本书》的读后感，作者主要是将阅读分为了四个层次：基础阅读、检视阅读、分析阅读和主题阅读，并讲解这几个层次该如何去做，能够更好的帮助我们阅读，让我们从中收获到更多"},{property:"og:url",content:"https://www.zhengwenfeng.com/05.%E8%AF%BB%E4%B9%A6%E7%A0%B4%E4%B8%87%E5%8D%B7/01.%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E6%9C%AC%E4%B9%A6.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-10-21T20:52:34.000Z"},{property:"article:tag",content:"读书"},{itemprop:"name",content:"读书笔记:如何阅读一本书"},{itemprop:"description",content:"本文是我阅读完《如何阅读一本书》的读后感，作者主要是将阅读分为了四个层次：基础阅读、检视阅读、分析阅读和主题阅读，并讲解这几个层次该如何去做，能够更好的帮助我们阅读，让我们从中收获到更多"}],readingShow:"top"},regularPath:"/05.%E8%AF%BB%E4%B9%A6%E7%A0%B4%E4%B8%87%E5%8D%B7/01.%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E6%9C%AC%E4%B9%A6.html",relativePath:"05.读书破万卷/01.如何阅读一本书.md",key:"v-38488cef",path:"/pages/8bdb8d/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"主动阅读",slug:"主动阅读",normalizedTitle:"主动阅读",charIndex:104},{level:2,title:"阅读的目标 ：为获得资讯而读，以及为求得理解而读",slug:"阅读的目标-为获得资讯而读-以及为求得理解而读",normalizedTitle:"阅读的目标 ：为获得资讯而读，以及为求得理解而读",charIndex:603},{level:2,title:"真正的阅读",slug:"真正的阅读",normalizedTitle:"真正的阅读",charIndex:705},{level:2,title:"指导型的学习，以及自我发现型的学习",slug:"指导型的学习-以及自我发现型的学习",normalizedTitle:"指导型的学习，以及自我发现型的学习",charIndex:750},{level:2,title:"阅读是跟着已为缺席的来势在学习",slug:"阅读是跟着已为缺席的来势在学习",normalizedTitle:"阅读是跟着已为缺席的来势在学习",charIndex:883},{level:2,title:"四个层次",slug:"四个层次",normalizedTitle:"四个层次",charIndex:38},{level:2,title:"略读",slug:"略读",normalizedTitle:"略读",charIndex:1149},{level:2,title:"阅读速度",slug:"阅读速度",normalizedTitle:"阅读速度",charIndex:1404},{level:2,title:"培养阅读的习惯",slug:"培养阅读的习惯",normalizedTitle:"培养阅读的习惯",charIndex:1551},{level:2,title:"分析阅读的规则",slug:"分析阅读的规则",normalizedTitle:"分析阅读的规则",charIndex:1977},{level:2,title:"辅助阅读",slug:"辅助阅读",normalizedTitle:"辅助阅读",charIndex:3312},{level:2,title:"阅读好书的重要性",slug:"阅读好书的重要性",normalizedTitle:"阅读好书的重要性",charIndex:3689}],headersStr:"前言 主动阅读 阅读的目标 ：为获得资讯而读，以及为求得理解而读 真正的阅读 指导型的学习，以及自我发现型的学习 阅读是跟着已为缺席的来势在学习 四个层次 略读 阅读速度 培养阅读的习惯 分析阅读的规则 辅助阅读 阅读好书的重要性",content:'# 前言\n\n本文是我阅读完《如何阅读一本书》的读后感，作者主要是将阅读分为了四个层次：基础阅读、检视阅读、分析阅读和主题阅读，并讲解这几个层次该如何去做，能够更好的帮助我们阅读，让我们从中收获到更多\n\n\n# 主动阅读\n\n作者提倡我们需要主动读书，这样我们才能对书中知识有更好的探索并收获到的会更多。\n\n像在我们阅读资讯信息的时候，不仅仅只需要知道了某件事的发生，还需要理解它发生的背后逻辑及原理进行联想，将自己以前的知识进行关联起来。这就是主动的阅读。\n\n并且我们再主动阅读时会保持大脑的思考并保持清醒的状态，那么平时昏昏欲睡的人都只是在被动的接收知识，所以注意力才无法集中起来。\n\n问题来了，我们该如何做到主动阅读呢？答案是带着问题去阅读：\n\n * 这本书在讲什么？\n * 作者仔细说了什么，如何说的，找出对应的想法、声明及论点\n * 这本书有道理嘛？是全部有道理？还是部分有道理？\n * 这本书跟自己有什么关系？自己可以学到什么？对自己有什么启示？\n\n在阅读的过程中提出除了上面几个基础的问题之外，还需要自己去提出问题，并不断的去从书寻找并回答问题。只有这样经过思考才能做到主动阅读。\n\n作者还提到了做笔记的必要性，这也是主动阅读的一个方式：\n\n * 能让自己的保持清醒\n * 是一个主动思考的过程并用言语给表达出来。\n * 将自己的感想写出来，让自己更好的理解作者的思想，并展开自己的联想。\n\n\n# 阅读的目标 ：为获得资讯而读，以及为求得理解而读\n\n我们是为了获取到作者输出的知识而读书，而不是为了读书而读书，如果读完这本书，没有理解到作者想要表达的东西，自身没有改变，那么则纯粹的浪费时间。\n\n\n# 真正的阅读\n\n不借助外力，通过自己不断的思考去阅读，从模糊的理解到更清楚的理解。\n\n\n# 指导型的学习，以及自我发现型的学习\n\n无论是指导型学习还是自我发现型学习都可以是主动的，不论是哪一种 方式，只有真正学习到的人才是主动的学习者。\n\n在指导型的学习过程中，虽然我们是被动的接收知识，看起来毫不费力，但是一样还是需要经过自己的思考才能有所获得。\n\n\n# 阅读是跟着已为缺席的来势在学习\n\n有老师时，可以回答你的问题，节省自己思考的时间，而阅读书本时，必须经过自己的思考与分析才可能有答案。\n\n\n# 四个层次\n\n作者将阅读分为四个层次：\n\n * 基础阅读，就是最基础的阅读，能认字就行，经历了九年义务教育基本就能做到。\n * 检视阅读，就是在一定的时间之内，抓住一本书的重点。\n * 分析阅读，是全盘的阅读、完整的阅读。\n * 主题阅读，阅读者通过读很多的书，然后列举这些书之间的相关之处。这种方式是最主动、也是最花力气的阅读。\n\n作者整本书主要是围绕这四个层次进行讲解分析的。\n\n\n# 略读\n\n> 你脑中的目标是要发现这本书值不值得多花时间仔细阅读。其次，就算你决定了不再多花时间仔细阅读这本书，略读也能告诉你许多跟这本书有关的事。\n\n这是略读的目标，我们通过略读可以节省时间，排除一些垃圾书。\n\n那么我们改如何进行略读呢？有以下几个方法：\n\n * 先看书名页，然后如果有序就先看序。\n * 研究目录页。\n * 如果书中附有索引，也要检阅一下。\n * 如果那是本包着书衣的新书，不妨读一下出版者的介绍。\n * 从目录页中挑选几个跟主题相关的篇章查看。\n * 将全数翻一遍，随意看个几段。\n\n\n# 阅读速度\n\n我们在检视阅读时，是需要快速地阅读的，在不值得我们花时间的地方读快一点，这个时候我们时候需要知道我们在阅读中寻找什么，这样我们才能对不同的内容使用不同的速度来进行阅读。\n\n如何提升阅读速度：将手指指向文字往后移动下去，眼睛跟着手指看下去，强迫自己的眼睛跟着手部的动作移动。\n\n\n# 培养阅读的习惯\n\n> 我们谈到一个有技术的人时，并不是在说他知道该如何去做那件事，而是他已经养成去做那件事的习惯了。\n\n当我们养成习惯后，我就能够自然的按照规则去做那件事情，有技术的人也是通过不断的训练将规则养成了习惯。\n\n我们将阅读培养成习惯后，可以提高阅读的能力与速度，最后会像走路与吃饭一样的自然。\n\n> 你一定要学会忘掉那些分开的步骤，才能表现出整体的动作，而每一个单一的步骤都还要确实表现得很好。但是，为了要忘掉这些单一的动作，一开始你必须先分别学会每一个单一的动作。只有这样，你才能将所有的动作连结起来，变成一个优秀的滑雪高手。\n\n阅读是需要多个步骤结合起来的，我们需要不断的练习锻炼单个步骤，将这些步骤变成习惯后逐渐忘记，然后自然的将所有的连接起来，最终成为一个阅读高手。这让我想到了倚天屠龙记中的张三丰教张无忌太极时的场景，先是教张无忌每一个动作，熟练之后逐渐忘记，最终将太极融会贯通，当时不太懂，现在发现这里有异曲同工之妙。\n\n\n# 分析阅读的规则\n\n> 依照书本的种类与主题作分类。\n\n不同种类的书籍的目的是不同的，比如理论性的作品是教你这是什么，而实用性的作用在教你如何去做你想做的事情。\n\n将书籍的分类并不简单，我们可以通过书名、前言和书中主题内容来区分。\n\n不同种类的书籍也需要使用的是不同的方法阅读。\n\n> 用最简短的句子说出整本书在谈些什么。\n\n如果我们知道了这本书在谈什么，我们就能揣测出作者想要干什么，并能发现这本书的主题和重点。\n\n通过给自己或他人讲述这本书说的什么，可以验证自己是否对本书整体内容有一个详细的了解。\n\n> 按照顺序与关系，列出全书的重要部分。将全书的纲要拟出来之后，再将各个部分的纲要也一一列出。\n\n心中要对书中的整体架构有一个了解，才能从多个方面去看待这本书。\n\n> 找出作者在问的问题，或作者想要解决的问题。\n\n作者写书时，肯定是带着问题或者想要解决一个问题去写的。找出这些问题能够更好的为上面两条服务。\n\n> 诠释作者使用的关键字，与作者达成共识。\n\n相同的单字会呈现出不同的意义，比如我们在谈"阅读"时，可能是为娱乐而阅读，可能是为获得咨询而阅读，也可能是为追求理解力而阅读。我们需要和作者保持一致理解，才能有共同的思想。如果我们对字句毫不用心，自然无法跟作者达成共识，也就一无所获。\n\n我们可以通过上下文中已经理解的语句在帮助自己来推敲出我们不理解的那个字的意思。\n\n> 从最重要的句子中抓出作者的重要主旨。\n\n找出语句的主旨后，需要使用自己的话语来说来验证自己到底有没有理解透彻。也可以通过到某个例子或者事情来说明主旨来验证。\n\n> 找出作者的论述，重新架构这些论述的前因后果，以明白作者的主张。\n\n> 确定作者已经解决了哪些问题，还有哪些是未解决的。在未解决的问题中，定哪些是作者认为自己无法解决的问题。\n\n> 在你说出“我同意”，“我不同意”，或“我暂缓评论”之前，你一定要能肯定地说：“我了解了。”\n\n在我们评论之前，一定是在自己已经理解的基础之上，这是对对方的基本礼貌。在我们不清楚的时候便同意对方，是愚蠢的，如果不清楚还不同意对方的，则是无礼的。只有完全理解了，才有评头论足的资格。\n\n> 当你不同意作者的观点时，要理性地表达自己的意见，不要无理地辩驳或争论。\n\n我们需要把谈话当做学习，这是一个互相学习和头脑风暴的过程，从中获取到知识，这才是目的，而不是无意义的争吵。\n\n> 尊重知识与个人观点的不同，在作任何评断之前，都要找出理论基础\n\n作者提出满足和作者辩论资格的三个规则：\n\n * 读者一定要完整的了解这本书\n * 读者不要争强好胜或盲目反驳\n * 将知识上的不同意见看做是大体上可以解决的问题\n\n我们在阅读一本书时如果有不同的意见，可以有纪律的进行辩论：\n\n * 在争辩的过程中不要带有自己的情绪，否则就不是在说理了。\n * 在争辩时需要先将前提条件或者假设条件提出来，这个是你后面所有判断的基础，你也要接受对方的假设条件，即使你们的看法完全相反，但是也需要接受。\n * 在争辩时，需要站在对方的角度去思考，这样才能是意见的交流，而不是无意义的争吵。\n\n我们在反驳作者问题的时候，一定要拿出依据来证明自己的论点才对对方的尊重。\n\n\n# 辅助阅读\n\n对于辅助阅读，建议先尽自己所能的通过内在阅读去将一本书，如果还有不懂的则需要寻找外在的帮助。\n\n对于导读，建议是在读完一本书之后再去阅读，这是因为：\n\n * 导读不一定是对的，因为这个是别人读完书之后自己的思考\n * 即使是对的，也不是一定是全面的，可能导读这也会有遗漏\n * 看导读也会限制自己的理解，并且跟着导读者的角度去思考，但没有自己的思考。\n\n这么做的话，也是有好处的：\n\n * 帮助我们诠释语句，并找出共识与主旨。\n * 自我读书的一种补充，在阅读完之后产生的问答，可以帮助你解答与理解。\n\n对于摘要的作用：\n\n * 在阅读一本书之后，可以唤醒自己的记忆\n * 在主题阅读时，可以通过摘要相关联起来。\n\n对于工具书的使用，我们需要知道自己想要找什么，哪一种工具有我们想要找的内容，并如何使用他们快速查找到你想要找的资料。\n\n\n# 阅读好书的重要性\n\n> 如果你所读的书都在你的能力范围之内，你就没法提升自己的阅读能力。你必须能操纵超越你能力的书，或像我们所说的，阅读超越你头脑的书。只有那样的书能帮助你的思想增长，除非你能增长心智，否则你学不到东西。\n\n我们需要通过检视阅读来排除掉那些坏书，才能节省时间读更多的好书。',normalizedContent:'# 前言\n\n本文是我阅读完《如何阅读一本书》的读后感，作者主要是将阅读分为了四个层次：基础阅读、检视阅读、分析阅读和主题阅读，并讲解这几个层次该如何去做，能够更好的帮助我们阅读，让我们从中收获到更多\n\n\n# 主动阅读\n\n作者提倡我们需要主动读书，这样我们才能对书中知识有更好的探索并收获到的会更多。\n\n像在我们阅读资讯信息的时候，不仅仅只需要知道了某件事的发生，还需要理解它发生的背后逻辑及原理进行联想，将自己以前的知识进行关联起来。这就是主动的阅读。\n\n并且我们再主动阅读时会保持大脑的思考并保持清醒的状态，那么平时昏昏欲睡的人都只是在被动的接收知识，所以注意力才无法集中起来。\n\n问题来了，我们该如何做到主动阅读呢？答案是带着问题去阅读：\n\n * 这本书在讲什么？\n * 作者仔细说了什么，如何说的，找出对应的想法、声明及论点\n * 这本书有道理嘛？是全部有道理？还是部分有道理？\n * 这本书跟自己有什么关系？自己可以学到什么？对自己有什么启示？\n\n在阅读的过程中提出除了上面几个基础的问题之外，还需要自己去提出问题，并不断的去从书寻找并回答问题。只有这样经过思考才能做到主动阅读。\n\n作者还提到了做笔记的必要性，这也是主动阅读的一个方式：\n\n * 能让自己的保持清醒\n * 是一个主动思考的过程并用言语给表达出来。\n * 将自己的感想写出来，让自己更好的理解作者的思想，并展开自己的联想。\n\n\n# 阅读的目标 ：为获得资讯而读，以及为求得理解而读\n\n我们是为了获取到作者输出的知识而读书，而不是为了读书而读书，如果读完这本书，没有理解到作者想要表达的东西，自身没有改变，那么则纯粹的浪费时间。\n\n\n# 真正的阅读\n\n不借助外力，通过自己不断的思考去阅读，从模糊的理解到更清楚的理解。\n\n\n# 指导型的学习，以及自我发现型的学习\n\n无论是指导型学习还是自我发现型学习都可以是主动的，不论是哪一种 方式，只有真正学习到的人才是主动的学习者。\n\n在指导型的学习过程中，虽然我们是被动的接收知识，看起来毫不费力，但是一样还是需要经过自己的思考才能有所获得。\n\n\n# 阅读是跟着已为缺席的来势在学习\n\n有老师时，可以回答你的问题，节省自己思考的时间，而阅读书本时，必须经过自己的思考与分析才可能有答案。\n\n\n# 四个层次\n\n作者将阅读分为四个层次：\n\n * 基础阅读，就是最基础的阅读，能认字就行，经历了九年义务教育基本就能做到。\n * 检视阅读，就是在一定的时间之内，抓住一本书的重点。\n * 分析阅读，是全盘的阅读、完整的阅读。\n * 主题阅读，阅读者通过读很多的书，然后列举这些书之间的相关之处。这种方式是最主动、也是最花力气的阅读。\n\n作者整本书主要是围绕这四个层次进行讲解分析的。\n\n\n# 略读\n\n> 你脑中的目标是要发现这本书值不值得多花时间仔细阅读。其次，就算你决定了不再多花时间仔细阅读这本书，略读也能告诉你许多跟这本书有关的事。\n\n这是略读的目标，我们通过略读可以节省时间，排除一些垃圾书。\n\n那么我们改如何进行略读呢？有以下几个方法：\n\n * 先看书名页，然后如果有序就先看序。\n * 研究目录页。\n * 如果书中附有索引，也要检阅一下。\n * 如果那是本包着书衣的新书，不妨读一下出版者的介绍。\n * 从目录页中挑选几个跟主题相关的篇章查看。\n * 将全数翻一遍，随意看个几段。\n\n\n# 阅读速度\n\n我们在检视阅读时，是需要快速地阅读的，在不值得我们花时间的地方读快一点，这个时候我们时候需要知道我们在阅读中寻找什么，这样我们才能对不同的内容使用不同的速度来进行阅读。\n\n如何提升阅读速度：将手指指向文字往后移动下去，眼睛跟着手指看下去，强迫自己的眼睛跟着手部的动作移动。\n\n\n# 培养阅读的习惯\n\n> 我们谈到一个有技术的人时，并不是在说他知道该如何去做那件事，而是他已经养成去做那件事的习惯了。\n\n当我们养成习惯后，我就能够自然的按照规则去做那件事情，有技术的人也是通过不断的训练将规则养成了习惯。\n\n我们将阅读培养成习惯后，可以提高阅读的能力与速度，最后会像走路与吃饭一样的自然。\n\n> 你一定要学会忘掉那些分开的步骤，才能表现出整体的动作，而每一个单一的步骤都还要确实表现得很好。但是，为了要忘掉这些单一的动作，一开始你必须先分别学会每一个单一的动作。只有这样，你才能将所有的动作连结起来，变成一个优秀的滑雪高手。\n\n阅读是需要多个步骤结合起来的，我们需要不断的练习锻炼单个步骤，将这些步骤变成习惯后逐渐忘记，然后自然的将所有的连接起来，最终成为一个阅读高手。这让我想到了倚天屠龙记中的张三丰教张无忌太极时的场景，先是教张无忌每一个动作，熟练之后逐渐忘记，最终将太极融会贯通，当时不太懂，现在发现这里有异曲同工之妙。\n\n\n# 分析阅读的规则\n\n> 依照书本的种类与主题作分类。\n\n不同种类的书籍的目的是不同的，比如理论性的作品是教你这是什么，而实用性的作用在教你如何去做你想做的事情。\n\n将书籍的分类并不简单，我们可以通过书名、前言和书中主题内容来区分。\n\n不同种类的书籍也需要使用的是不同的方法阅读。\n\n> 用最简短的句子说出整本书在谈些什么。\n\n如果我们知道了这本书在谈什么，我们就能揣测出作者想要干什么，并能发现这本书的主题和重点。\n\n通过给自己或他人讲述这本书说的什么，可以验证自己是否对本书整体内容有一个详细的了解。\n\n> 按照顺序与关系，列出全书的重要部分。将全书的纲要拟出来之后，再将各个部分的纲要也一一列出。\n\n心中要对书中的整体架构有一个了解，才能从多个方面去看待这本书。\n\n> 找出作者在问的问题，或作者想要解决的问题。\n\n作者写书时，肯定是带着问题或者想要解决一个问题去写的。找出这些问题能够更好的为上面两条服务。\n\n> 诠释作者使用的关键字，与作者达成共识。\n\n相同的单字会呈现出不同的意义，比如我们在谈"阅读"时，可能是为娱乐而阅读，可能是为获得咨询而阅读，也可能是为追求理解力而阅读。我们需要和作者保持一致理解，才能有共同的思想。如果我们对字句毫不用心，自然无法跟作者达成共识，也就一无所获。\n\n我们可以通过上下文中已经理解的语句在帮助自己来推敲出我们不理解的那个字的意思。\n\n> 从最重要的句子中抓出作者的重要主旨。\n\n找出语句的主旨后，需要使用自己的话语来说来验证自己到底有没有理解透彻。也可以通过到某个例子或者事情来说明主旨来验证。\n\n> 找出作者的论述，重新架构这些论述的前因后果，以明白作者的主张。\n\n> 确定作者已经解决了哪些问题，还有哪些是未解决的。在未解决的问题中，定哪些是作者认为自己无法解决的问题。\n\n> 在你说出“我同意”，“我不同意”，或“我暂缓评论”之前，你一定要能肯定地说：“我了解了。”\n\n在我们评论之前，一定是在自己已经理解的基础之上，这是对对方的基本礼貌。在我们不清楚的时候便同意对方，是愚蠢的，如果不清楚还不同意对方的，则是无礼的。只有完全理解了，才有评头论足的资格。\n\n> 当你不同意作者的观点时，要理性地表达自己的意见，不要无理地辩驳或争论。\n\n我们需要把谈话当做学习，这是一个互相学习和头脑风暴的过程，从中获取到知识，这才是目的，而不是无意义的争吵。\n\n> 尊重知识与个人观点的不同，在作任何评断之前，都要找出理论基础\n\n作者提出满足和作者辩论资格的三个规则：\n\n * 读者一定要完整的了解这本书\n * 读者不要争强好胜或盲目反驳\n * 将知识上的不同意见看做是大体上可以解决的问题\n\n我们在阅读一本书时如果有不同的意见，可以有纪律的进行辩论：\n\n * 在争辩的过程中不要带有自己的情绪，否则就不是在说理了。\n * 在争辩时需要先将前提条件或者假设条件提出来，这个是你后面所有判断的基础，你也要接受对方的假设条件，即使你们的看法完全相反，但是也需要接受。\n * 在争辩时，需要站在对方的角度去思考，这样才能是意见的交流，而不是无意义的争吵。\n\n我们在反驳作者问题的时候，一定要拿出依据来证明自己的论点才对对方的尊重。\n\n\n# 辅助阅读\n\n对于辅助阅读，建议先尽自己所能的通过内在阅读去将一本书，如果还有不懂的则需要寻找外在的帮助。\n\n对于导读，建议是在读完一本书之后再去阅读，这是因为：\n\n * 导读不一定是对的，因为这个是别人读完书之后自己的思考\n * 即使是对的，也不是一定是全面的，可能导读这也会有遗漏\n * 看导读也会限制自己的理解，并且跟着导读者的角度去思考，但没有自己的思考。\n\n这么做的话，也是有好处的：\n\n * 帮助我们诠释语句，并找出共识与主旨。\n * 自我读书的一种补充，在阅读完之后产生的问答，可以帮助你解答与理解。\n\n对于摘要的作用：\n\n * 在阅读一本书之后，可以唤醒自己的记忆\n * 在主题阅读时，可以通过摘要相关联起来。\n\n对于工具书的使用，我们需要知道自己想要找什么，哪一种工具有我们想要找的内容，并如何使用他们快速查找到你想要找的资料。\n\n\n# 阅读好书的重要性\n\n> 如果你所读的书都在你的能力范围之内，你就没法提升自己的阅读能力。你必须能操纵超越你能力的书，或像我们所说的，阅读超越你头脑的书。只有那样的书能帮助你的思想增长，除非你能增长心智，否则你学不到东西。\n\n我们需要通过检视阅读来排除掉那些坏书，才能节省时间读更多的好书。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"初识 MCP Server",frontmatter:{title:"初识 MCP Server",date:"2025-05-01T16:05:29.000Z",permalink:"/pages/92e280/",categories:["AI"],tags:["AI"],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"MCP 全称为 Model Context Protocol，是一个大模型智能体与外部工具或者数据源的交互协议。也就是说，智能体可以通过该协议去调用所以支持该协议的服务，来增强智能体的能力。在没有 MCP 时，不同的智能体都需要对不同的外部工具做单独的适配才能调用，也就是都用自己独有的协议，有 MCP 后也就是统一了外部调用协议，减轻了智能体的开发成本，也可以快速接入不同的外部服务。本文主要是简单认识下 MCP，并利用 MCP 来调用本地文件系统和数据库来完成案例。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17460888546831746088854424.png"},{name:"twitter:title",content:"初识 MCP Server"},{name:"twitter:description",content:"MCP 全称为 Model Context Protocol，是一个大模型智能体与外部工具或者数据源的交互协议。也就是说，智能体可以通过该协议去调用所以支持该协议的服务，来增强智能体的能力。在没有 MCP 时，不同的智能体都需要对不同的外部工具做单独的适配才能调用，也就是都用自己独有的协议，有 MCP 后也就是统一了外部调用协议，减轻了智能体的开发成本，也可以快速接入不同的外部服务。本文主要是简单认识下 MCP，并利用 MCP 来调用本地文件系统和数据库来完成案例。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17460888546831746088854424.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/06.AI/01.%E5%88%9D%E8%AF%86%20MCP%20Server.html"},{property:"og:type",content:"article"},{property:"og:title",content:"初识 MCP Server"},{property:"og:description",content:"MCP 全称为 Model Context Protocol，是一个大模型智能体与外部工具或者数据源的交互协议。也就是说，智能体可以通过该协议去调用所以支持该协议的服务，来增强智能体的能力。在没有 MCP 时，不同的智能体都需要对不同的外部工具做单独的适配才能调用，也就是都用自己独有的协议，有 MCP 后也就是统一了外部调用协议，减轻了智能体的开发成本，也可以快速接入不同的外部服务。本文主要是简单认识下 MCP，并利用 MCP 来调用本地文件系统和数据库来完成案例。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17460888546831746088854424.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/06.AI/01.%E5%88%9D%E8%AF%86%20MCP%20Server.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2025-05-01T16:05:29.000Z"},{property:"article:tag",content:"AI"},{itemprop:"name",content:"初识 MCP Server"},{itemprop:"description",content:"MCP 全称为 Model Context Protocol，是一个大模型智能体与外部工具或者数据源的交互协议。也就是说，智能体可以通过该协议去调用所以支持该协议的服务，来增强智能体的能力。在没有 MCP 时，不同的智能体都需要对不同的外部工具做单独的适配才能调用，也就是都用自己独有的协议，有 MCP 后也就是统一了外部调用协议，减轻了智能体的开发成本，也可以快速接入不同的外部服务。本文主要是简单认识下 MCP，并利用 MCP 来调用本地文件系统和数据库来完成案例。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/tenqaz/BLOG-CDN@main/17460888546831746088854424.png"}],readingShow:"top"},regularPath:"/06.AI/01.%E5%88%9D%E8%AF%86%20MCP%20Server.html",relativePath:"06.AI/01.初识 MCP Server.md",key:"v-602416af",path:"/pages/92e280/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"准备工作",slug:"准备工作",normalizedTitle:"准备工作",charIndex:252},{level:2,title:"通过大模型操作本地文件",slug:"通过大模型操作本地文件",normalizedTitle:"通过大模型操作本地文件",charIndex:376},{level:2,title:"通过大模型来完成postgres的查询",slug:"通过大模型来完成postgres的查询",normalizedTitle:"通过大模型来完成postgres的查询",charIndex:675},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:896}],headersStr:"简介 准备工作 通过大模型操作本地文件 通过大模型来完成postgres的查询 总结",content:"# 简介\n\nMCP 全称为 Model Context Protocol，是一个大模型智能体与外部工具或者数据源的交互协议。也就是说，智能体可以通过该协议去调用所以支持该协议的服务，来增强智能体的能力。\n\n在没有 MCP 时，不同的智能体都需要对不同的外部工具做单独的适配才能调用，也就是都用自己独有的协议，有 MCP 后也就是统一了外部调用协议，减轻了智能体的开发成本，也可以快速接入不同的外部服务。\n\n\n\n本文主要是简单认识下 MCP，并利用 MCP 来调用本地文件系统和数据库来完成案例。\n\n\n# 准备工作\n\n本文使用的是CherryStduio来作为大模型的客户端。\n\n然后再去阿里云百炼上申请免费的大模型的额度，拿到 API KEY\n\n最后将将 API KEY 配置到 CherryStudio 中，就可以使用大模型进行对话了。\n\n\n\n\n# 通过大模型操作本地文件\n\n首先需要配置支持本地文件系统的 MCP Server，这里选择是的desktop-commander\n\n在页面中找到服务运行的命令\n\n然后填写到 CherryStudio 中，点击保存即可\n\n进入到对话页面，选择使用的大模型，然后再选择上面添加好的desktop-commander服务，就可以进行对话了。\n\n在对话中，让大模型帮忙在桌面上创建一个文件，可以看到客户端分别调用了desck-commander服务中的两个方法：create_directory和write_file\n\n在看向桌面发现了文件hello.txt，并打开发现内容和我们对话中的内容一致。\n\n\n# 通过大模型来完成postgres的查询\n\n首先需要提前准备好一个postgres数据库，数据如下：\n\n然后我们选择是的server-postgres作为我们的postgres MCP Server，找到服务运行的命令。\n\n\n\n将命令配置到 CherryStudio 中，点击保存即可\n\n在对话框中选择我们配置到server-postgres服务，然后就可以进行对话了。\n\n现在可以来对话中数据库的操作，让它帮我们查询表以及表中数据。\n\n\n# 总结\n\nAI的发展趋势是越来越快，而MCP的出现，使得AI可以更加方便的与外部服务进行交互，从而实现更加智能的应用。",normalizedContent:"# 简介\n\nmcp 全称为 model context protocol，是一个大模型智能体与外部工具或者数据源的交互协议。也就是说，智能体可以通过该协议去调用所以支持该协议的服务，来增强智能体的能力。\n\n在没有 mcp 时，不同的智能体都需要对不同的外部工具做单独的适配才能调用，也就是都用自己独有的协议，有 mcp 后也就是统一了外部调用协议，减轻了智能体的开发成本，也可以快速接入不同的外部服务。\n\n\n\n本文主要是简单认识下 mcp，并利用 mcp 来调用本地文件系统和数据库来完成案例。\n\n\n# 准备工作\n\n本文使用的是cherrystduio来作为大模型的客户端。\n\n然后再去阿里云百炼上申请免费的大模型的额度，拿到 api key\n\n最后将将 api key 配置到 cherrystudio 中，就可以使用大模型进行对话了。\n\n\n\n\n# 通过大模型操作本地文件\n\n首先需要配置支持本地文件系统的 mcp server，这里选择是的desktop-commander\n\n在页面中找到服务运行的命令\n\n然后填写到 cherrystudio 中，点击保存即可\n\n进入到对话页面，选择使用的大模型，然后再选择上面添加好的desktop-commander服务，就可以进行对话了。\n\n在对话中，让大模型帮忙在桌面上创建一个文件，可以看到客户端分别调用了desck-commander服务中的两个方法：create_directory和write_file\n\n在看向桌面发现了文件hello.txt，并打开发现内容和我们对话中的内容一致。\n\n\n# 通过大模型来完成postgres的查询\n\n首先需要提前准备好一个postgres数据库，数据如下：\n\n然后我们选择是的server-postgres作为我们的postgres mcp server，找到服务运行的命令。\n\n\n\n将命令配置到 cherrystudio 中，点击保存即可\n\n在对话框中选择我们配置到server-postgres服务，然后就可以进行对话了。\n\n现在可以来对话中数据库的操作，让它帮我们查询表以及表中数据。\n\n\n# 总结\n\nai的发展趋势是越来越快，而mcp的出现，使得ai可以更加方便的与外部服务进行交互，从而实现更加智能的应用。",charsets:{cjk:!0},lastUpdated:"2025/06/15, 00:16:07",lastUpdatedTimestamp:1749917767e3},{title:"关于",frontmatter:{title:"关于",date:"2019-12-25T14:27:01.000Z",permalink:"/about/",sidebar:!1,article:!1,author:{name:"zhengwenfeng",link:"https://github.com/zhengwenfeng"},description:"工作年限: 5年\n职业: 软件开发工程师\n目前: 在某厂搬砖中~",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"关于"},{name:"twitter:description",content:"工作年限: 5年\n职业: 软件开发工程师\n目前: 在某厂搬砖中~"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/08.%E5%85%B3%E4%BA%8E/01.%E5%85%B3%E4%BA%8E.html"},{property:"og:type",content:"article"},{property:"og:title",content:"关于"},{property:"og:description",content:"工作年限: 5年\n职业: 软件开发工程师\n目前: 在某厂搬砖中~"},{property:"og:url",content:"https://www.zhengwenfeng.com/08.%E5%85%B3%E4%BA%8E/01.%E5%85%B3%E4%BA%8E.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2019-12-25T14:27:01.000Z"},{itemprop:"name",content:"关于"},{itemprop:"description",content:"工作年限: 5年\n职业: 软件开发工程师\n目前: 在某厂搬砖中~"}],readingShow:"top"},regularPath:"/08.%E5%85%B3%E4%BA%8E/01.%E5%85%B3%E4%BA%8E.html",relativePath:"08.关于/01.关于.md",key:"v-c5fbc8ae",path:"/about/",headers:[{level:2,title:"关于博主",slug:"关于博主",normalizedTitle:"关于博主",charIndex:2},{level:3,title:"技能清单",slug:"技能清单",normalizedTitle:"技能清单",charIndex:54},{level:3,title:"✉️ 联系",slug:"联系",normalizedTitle:"✉️ 联系",charIndex:159},{level:2,title:"关于本站",slug:"关于本站",normalizedTitle:"关于本站",charIndex:396},{level:3,title:"博客历程",slug:"博客历程",normalizedTitle:"博客历程",charIndex:425}],headersStr:"关于博主 技能清单 ✉️ 联系 关于本站 博客历程",content:"# 关于博主\n\n * 工作年限: 5年\n * 职业: 软件开发工程师\n * 目前: 在某厂搬砖中~\n\n\n# 技能清单\n\n * 编程语言: python/go\n * web框架: django/flask/gin\n * 数据库: mysql/redis/mongo/es\n * 容器技术: docker/k8s\n\n\n# ✉️ 联系\n\n * WeChat or QQ: {{ QQ }}\n * Email: zhengwenfeng37@gmail.com\n * GitHub: https://github.com/tenqaz\n * CSDN: https://blog.csdn.net/qq_22918243\n * 微博：https://weibo.com/u/3983876297\n * Twitter(X)：https://twitter.com/wenfeng_zheng\n\n\n# 关于本站\n\n用来记录本人学习、思考及生活的的博客\n\n\n# 博客历程\n\n * 2023-01-15\n\n> 添加了waline的评论系统，方便讨论交流问题。\n\n * 2022-08-07\n\n> 决定选用vuepress作为个人博客的技术框架，并开始学习搭建。",normalizedContent:"# 关于博主\n\n * 工作年限: 5年\n * 职业: 软件开发工程师\n * 目前: 在某厂搬砖中~\n\n\n# 技能清单\n\n * 编程语言: python/go\n * web框架: django/flask/gin\n * 数据库: mysql/redis/mongo/es\n * 容器技术: docker/k8s\n\n\n# ✉️ 联系\n\n * wechat or qq: {{ qq }}\n * email: zhengwenfeng37@gmail.com\n * github: https://github.com/tenqaz\n * csdn: https://blog.csdn.net/qq_22918243\n * 微博：https://weibo.com/u/3983876297\n * twitter(x)：https://twitter.com/wenfeng_zheng\n\n\n# 关于本站\n\n用来记录本人学习、思考及生活的的博客\n\n\n# 博客历程\n\n * 2023-01-15\n\n> 添加了waline的评论系统，方便讨论交流问题。\n\n * 2022-08-07\n\n> 决定选用vuepress作为个人博客的技术框架，并开始学习搭建。",charsets:{cjk:!0},lastUpdated:"2025/02/09, 23:47:02",lastUpdatedTimestamp:1739116022e3},{title:"网站",frontmatter:{title:"网站",permalink:"/pages/beb6c0bd8a66cea6/",date:"2020-04-19T11:33:04.000Z",article:!1,author:{name:"xugaoyi",link:"https://github.com/xugaoyi"},description:"k8s k8s中文官网\nvuepress-theme-vdoing 一款优秀的博客主题\n技术文章摘录\n代码片段 快速查看某一门技术的代码片段",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"网站"},{name:"twitter:description",content:"k8s k8s中文官网\nvuepress-theme-vdoing 一款优秀的博客主题\n技术文章摘录\n代码片段 快速查看某一门技术的代码片段"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/09.%E6%9B%B4%E5%A4%9A/01.%E6%94%B6%E8%97%8F.html"},{property:"og:type",content:"article"},{property:"og:title",content:"网站"},{property:"og:description",content:"k8s k8s中文官网\nvuepress-theme-vdoing 一款优秀的博客主题\n技术文章摘录\n代码片段 快速查看某一门技术的代码片段"},{property:"og:url",content:"https://www.zhengwenfeng.com/09.%E6%9B%B4%E5%A4%9A/01.%E6%94%B6%E8%97%8F.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2020-04-19T11:33:04.000Z"},{itemprop:"name",content:"网站"},{itemprop:"description",content:"k8s k8s中文官网\nvuepress-theme-vdoing 一款优秀的博客主题\n技术文章摘录\n代码片段 快速查看某一门技术的代码片段"}],readingShow:"top"},regularPath:"/09.%E6%9B%B4%E5%A4%9A/01.%E6%94%B6%E8%97%8F.html",relativePath:"09.更多/01.收藏.md",key:"v-fe55c380",path:"/pages/beb6c0bd8a66cea6/",headers:[{level:2,title:"文档",slug:"文档",normalizedTitle:"文档",charIndex:12},{level:2,title:"golang",slug:"golang",normalizedTitle:"golang",charIndex:103},{level:2,title:"博客",slug:"博客",normalizedTitle:"博客",charIndex:61},{level:2,title:"社区",slug:"社区",normalizedTitle:"社区",charIndex:324},{level:2,title:"技巧",slug:"技巧",normalizedTitle:"技巧",charIndex:476},{level:2,title:"视频",slug:"视频",normalizedTitle:"视频",charIndex:564},{level:2,title:"算法",slug:"算法",normalizedTitle:"算法",charIndex:727},{level:2,title:"工具",slug:"工具",normalizedTitle:"工具",charIndex:747},{level:2,title:"娱乐",slug:"娱乐",normalizedTitle:"娱乐",charIndex:886}],headersStr:"文档 golang 博客 社区 技巧 视频 算法 工具 娱乐",content:"# 个人收藏夹\n\n\n# 文档\n\n * k8s k8s中文官网\n * vuepress-theme-vdoing 一款优秀的博客主题\n * 技术文章摘录\n * 代码片段 快速查看某一门技术的代码片段\n\n\n# golang\n\n * hotexamples golang代码示例网站\n\n\n# 博客\n\n * 阮一峰的网络日志\n * 韦世东的技术专栏\n * IT码农\n * 明哥\n * 崔庆才\n * 酷壳\n * 王登科-DK博客\n * 二丫讲梵\n * Crayonの博客\n * Tushar's Blog 一个国外python程序员的博客，感觉不错\n * 初探云原生\n * simpleprogrammer 《软技能-代码之外的生存指南》作者的博客\n\n\n# 社区\n\n * Github 程序员同性交友社区\n * 掘金 一个帮助开发者成长的社区\n * 简书 有很多频道的创作社区\n * 思否 解决技术问题的社区\n * stack overflow 同上，外网的\n * InfoQ 促进软件开发及相关领域知识与创新的传播\n * V2EX 创意工作者们的社区\n\n\n# 技巧\n\n * Google 趋势 查看某项技术或关键字的热度趋势，可用于分析某项技术的发展前景，或对比某两项技术的热度。\n * 百度指数 同上，但百度的数据仅限国内。\n\n\n# 视频\n\n * bilibili B站，上面很多免费教学视频\n * 慕课网 实战视频教程\n * 妙味课堂 比较系统的前端入门视频教程\n * 中国大学MOOC 涵盖计算机、外语、心理学等专业免费课程\n * 终身教育平台 涵盖生活、兴趣、职场、技能、老年、学历等免费课程\n * egghead 质量还不错的短视频教程，外网\n\n\n# 算法\n\n * leetcode\n\n\n# 工具\n\n * 微信markdown编辑器\n * ossinsight 可以看到github上用户或者仓库的数据指标\n * feeddd 微信公众号的RSS订阅源\n * ChatGPT 聊天智能AI服务，可以自动写代码。\n * corrector 一款免费的中文纠错服务\n\n\n# 娱乐\n\n * 中文播客榜\n * 异常教程 工具破解网站",normalizedContent:"# 个人收藏夹\n\n\n# 文档\n\n * k8s k8s中文官网\n * vuepress-theme-vdoing 一款优秀的博客主题\n * 技术文章摘录\n * 代码片段 快速查看某一门技术的代码片段\n\n\n# golang\n\n * hotexamples golang代码示例网站\n\n\n# 博客\n\n * 阮一峰的网络日志\n * 韦世东的技术专栏\n * it码农\n * 明哥\n * 崔庆才\n * 酷壳\n * 王登科-dk博客\n * 二丫讲梵\n * crayonの博客\n * tushar's blog 一个国外python程序员的博客，感觉不错\n * 初探云原生\n * simpleprogrammer 《软技能-代码之外的生存指南》作者的博客\n\n\n# 社区\n\n * github 程序员同性交友社区\n * 掘金 一个帮助开发者成长的社区\n * 简书 有很多频道的创作社区\n * 思否 解决技术问题的社区\n * stack overflow 同上，外网的\n * infoq 促进软件开发及相关领域知识与创新的传播\n * v2ex 创意工作者们的社区\n\n\n# 技巧\n\n * google 趋势 查看某项技术或关键字的热度趋势，可用于分析某项技术的发展前景，或对比某两项技术的热度。\n * 百度指数 同上，但百度的数据仅限国内。\n\n\n# 视频\n\n * bilibili b站，上面很多免费教学视频\n * 慕课网 实战视频教程\n * 妙味课堂 比较系统的前端入门视频教程\n * 中国大学mooc 涵盖计算机、外语、心理学等专业免费课程\n * 终身教育平台 涵盖生活、兴趣、职场、技能、老年、学历等免费课程\n * egghead 质量还不错的短视频教程，外网\n\n\n# 算法\n\n * leetcode\n\n\n# 工具\n\n * 微信markdown编辑器\n * ossinsight 可以看到github上用户或者仓库的数据指标\n * feeddd 微信公众号的rss订阅源\n * chatgpt 聊天智能ai服务，可以自动写代码。\n * corrector 一款免费的中文纠错服务\n\n\n# 娱乐\n\n * 中文播客榜\n * 异常教程 工具破解网站",charsets:{cjk:!0},lastUpdated:"2025/02/09, 23:47:02",lastUpdatedTimestamp:1739116022e3},{title:"友链",frontmatter:{title:"友链",date:"2022-10-30T20:28:03.000Z",permalink:"/friends",categories:["更多"],tags:[null],author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"desc: 一个专注互联网技术分享的个人独立博客。\n  avatar: https://blog.wenfxl.com/images/logo.png\n  link: https://blog.wenfxl.com/\n:::",article:!1,comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"友链"},{name:"twitter:description",content:"desc: 一个专注互联网技术分享的个人独立博客。\n  avatar: https://blog.wenfxl.com/images/logo.png\n  link: https://blog.wenfxl.com/\n:::"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/09.%E6%9B%B4%E5%A4%9A/02.%E5%8F%8B%E9%93%BE.html"},{property:"og:type",content:"article"},{property:"og:title",content:"友链"},{property:"og:description",content:"desc: 一个专注互联网技术分享的个人独立博客。\n  avatar: https://blog.wenfxl.com/images/logo.png\n  link: https://blog.wenfxl.com/\n:::"},{property:"og:url",content:"https://www.zhengwenfeng.com/09.%E6%9B%B4%E5%A4%9A/02.%E5%8F%8B%E9%93%BE.html"},{property:"og:site_name",content:"zhengwenfeng"},{property:"article:published_time",content:"2022-10-30T20:28:03.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"友链"},{itemprop:"description",content:"desc: 一个专注互联网技术分享的个人独立博客。\n  avatar: https://blog.wenfxl.com/images/logo.png\n  link: https://blog.wenfxl.com/\n:::"}],readingShow:"top"},regularPath:"/09.%E6%9B%B4%E5%A4%9A/02.%E5%8F%8B%E9%93%BE.html",relativePath:"09.更多/02.友链.md",key:"v-67feae3c",path:"/friends/",headers:[{level:2,title:"友链申请",slug:"友链申请",normalizedTitle:"友链申请",charIndex:1954}],headersStr:"友链申请",content:"郑文峰的博客\n\n朝闻道,夕死可矣\n\nEvan's blog\n\n积跬步以至千里，喜欢学习喜欢你。\n\n二丫讲梵\n\n💻学习📝记录🔗分享\n\n麋鹿鲁哟\n\n大道至简，知易行难。\n\nCrayonの博客\n\n程序猿 && 二次猿\n\nCase of Xeon\n\nWelcome inside\n\n肥猫博客\n\n技术改变生活\n\nmqray's blog\n\n明日复明日，明日何其多？\n\n汐塔魔法屋\n\n欢迎旅行者，来到这个平凡但又记载了许多故事的小屋\n\n芈渡\n\n开发日常\n\n轩灵博客\n\n一个专注互联网技术分享的个人独立博客。\n\n- name: 郑文峰的博客\n  desc: '朝闻道,夕死可矣'\n  avatar: https://www.zhengwenfeng.com/img/me.jpg\n  link: https://www.zhengwenfeng.com\n  bgColor: '#f8f9fa'\n- name: Evan's blog # 昵称\n  desc: 积跬步以至千里，喜欢学习喜欢你。 # 介绍\n  avatar: https://cdn.jsdelivr.net/gh/xugaoyi/image_store/blog/20200103123203.jpg # 头像\n  link: https://xugaoyi.com/  # 链接\n  bgColor: '#f8f9fa'\n- name: 二丫讲梵\n  desc: '💻学习📝记录🔗分享'\n  avatar: https://wiki.eryajf.net/img/logo.png\n  link: https://wiki.eryajf.net\n  bgColor: '#f8f9fa'\n- name: 麋鹿鲁哟\n  desc: '大道至简，知易行难。'\n  avatar: https://pic.cnblogs.com/avatar/1273193/20190806180831.png\n  link: https://www.cnblogs.com/miluluyo/\n  bgColor: '#f8f9fa'\n- name: Crayonの博客\n  desc: '程序猿 && 二次猿'\n  avatar: http://sucrayon.top/images/avatar.jpg\n  link: http://sucrayon.top/\n  bgColor: '#f8f9fa'\n- name: Case of Xeon\n  desc: 'Welcome inside'\n  avatar: https://hexo.chensmallx.top/img/avator.jpg\n  link: https://hexo.chensmallx.top/\n  bgColor: '#f8f9fa'\n- name: 肥猫博客\n  desc: 技术改变生活\n  avatar: http://blog.mryxh.cn/favicon.ico\n  link: http://blog.mryxh.cn/\n  bgColor: '#f8f9fa'\n- name: mqray's blog\n  desc: 明日复明日，明日何其多？\n  avatar: https://mqrayblog.cn/img/avatar.png\n  link: https://mqrayblog.cn/\n- name: 汐塔魔法屋\n  desc: 欢迎旅行者，来到这个平凡但又记载了许多故事的小屋\n  avatar: https://blog.storical.space/images/icon.png\n  link: https://blog.storical.space/\n- name: 芈渡\n  desc: 开发日常\n  avatar: https://www.lllomh.com/static/images/photos.jpg\n  link: https://www.lllomh.com/\n- name: 轩灵博客\n  desc: 一个专注互联网技术分享的个人独立博客。\n  avatar: https://blog.wenfxl.com/images/logo.png\n  link: https://blog.wenfxl.com/\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n\n\n\n# 友链申请\n\n申请前记得先添加本站哦~\n\n * 方法一\n\n与我 联系 或者 在本页面评论区留言您的友链信息，格式：(点击代码块右上角一键复制)\n\n- name: 郑文峰的博客 # 昵称\n  desc:  朝闻道,夕死可矣 # 介绍\n  avatar: https://www.zhengwenfeng.com/img/me.jpg # 头像\n  link: https://www.zhengwenfeng.com  # 链接\n\n\n1\n2\n3\n4\n\n * 方法二\n\nfork本项目,在docs/更多/友链.md文件中，新增自己的友链，然后提交PR即可。",normalizedContent:"郑文峰的博客\n\n朝闻道,夕死可矣\n\nevan's blog\n\n积跬步以至千里，喜欢学习喜欢你。\n\n二丫讲梵\n\n💻学习📝记录🔗分享\n\n麋鹿鲁哟\n\n大道至简，知易行难。\n\ncrayonの博客\n\n程序猿 && 二次猿\n\ncase of xeon\n\nwelcome inside\n\n肥猫博客\n\n技术改变生活\n\nmqray's blog\n\n明日复明日，明日何其多？\n\n汐塔魔法屋\n\n欢迎旅行者，来到这个平凡但又记载了许多故事的小屋\n\n芈渡\n\n开发日常\n\n轩灵博客\n\n一个专注互联网技术分享的个人独立博客。\n\n- name: 郑文峰的博客\n  desc: '朝闻道,夕死可矣'\n  avatar: https://www.zhengwenfeng.com/img/me.jpg\n  link: https://www.zhengwenfeng.com\n  bgcolor: '#f8f9fa'\n- name: evan's blog # 昵称\n  desc: 积跬步以至千里，喜欢学习喜欢你。 # 介绍\n  avatar: https://cdn.jsdelivr.net/gh/xugaoyi/image_store/blog/20200103123203.jpg # 头像\n  link: https://xugaoyi.com/  # 链接\n  bgcolor: '#f8f9fa'\n- name: 二丫讲梵\n  desc: '💻学习📝记录🔗分享'\n  avatar: https://wiki.eryajf.net/img/logo.png\n  link: https://wiki.eryajf.net\n  bgcolor: '#f8f9fa'\n- name: 麋鹿鲁哟\n  desc: '大道至简，知易行难。'\n  avatar: https://pic.cnblogs.com/avatar/1273193/20190806180831.png\n  link: https://www.cnblogs.com/miluluyo/\n  bgcolor: '#f8f9fa'\n- name: crayonの博客\n  desc: '程序猿 && 二次猿'\n  avatar: http://sucrayon.top/images/avatar.jpg\n  link: http://sucrayon.top/\n  bgcolor: '#f8f9fa'\n- name: case of xeon\n  desc: 'welcome inside'\n  avatar: https://hexo.chensmallx.top/img/avator.jpg\n  link: https://hexo.chensmallx.top/\n  bgcolor: '#f8f9fa'\n- name: 肥猫博客\n  desc: 技术改变生活\n  avatar: http://blog.mryxh.cn/favicon.ico\n  link: http://blog.mryxh.cn/\n  bgcolor: '#f8f9fa'\n- name: mqray's blog\n  desc: 明日复明日，明日何其多？\n  avatar: https://mqrayblog.cn/img/avatar.png\n  link: https://mqrayblog.cn/\n- name: 汐塔魔法屋\n  desc: 欢迎旅行者，来到这个平凡但又记载了许多故事的小屋\n  avatar: https://blog.storical.space/images/icon.png\n  link: https://blog.storical.space/\n- name: 芈渡\n  desc: 开发日常\n  avatar: https://www.lllomh.com/static/images/photos.jpg\n  link: https://www.lllomh.com/\n- name: 轩灵博客\n  desc: 一个专注互联网技术分享的个人独立博客。\n  avatar: https://blog.wenfxl.com/images/logo.png\n  link: https://blog.wenfxl.com/\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n\n\n\n# 友链申请\n\n申请前记得先添加本站哦~\n\n * 方法一\n\n与我 联系 或者 在本页面评论区留言您的友链信息，格式：(点击代码块右上角一键复制)\n\n- name: 郑文峰的博客 # 昵称\n  desc:  朝闻道,夕死可矣 # 介绍\n  avatar: https://www.zhengwenfeng.com/img/me.jpg # 头像\n  link: https://www.zhengwenfeng.com  # 链接\n\n\n1\n2\n3\n4\n\n * 方法二\n\nfork本项目,在docs/更多/友链.md文件中，新增自己的友链，然后提交pr即可。",charsets:{cjk:!0},lastUpdated:"2025/02/09, 23:47:02",lastUpdatedTimestamp:1739116022e3},{title:"归档",frontmatter:{archivesPage:!0,title:"归档",permalink:"/archives/",article:!1,description:"",meta:[{name:"twitter:title",content:"归档"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/@pages/archivesPage.html"},{property:"og:type",content:"article"},{property:"og:title",content:"归档"},{property:"og:description",content:""},{property:"og:url",content:"https://www.zhengwenfeng.com/@pages/archivesPage.html"},{property:"og:site_name",content:"zhengwenfeng"},{itemprop:"name",content:"归档"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-31af7045",path:"/archives/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/08/09, 07:53:30",lastUpdatedTimestamp:166000281e4},{title:"标签",frontmatter:{tagsPage:!0,title:"标签",permalink:"/tags/",article:!1,description:"",meta:[{name:"twitter:title",content:"标签"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/@pages/tagsPage.html"},{property:"og:type",content:"article"},{property:"og:title",content:"标签"},{property:"og:description",content:""},{property:"og:url",content:"https://www.zhengwenfeng.com/@pages/tagsPage.html"},{property:"og:site_name",content:"zhengwenfeng"},{itemprop:"name",content:"标签"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/@pages/tagsPage.html",relativePath:"@pages/tagsPage.md",key:"v-36a595c5",path:"/tags/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/08/09, 07:53:30",lastUpdatedTimestamp:166000281e4},{title:"Home",frontmatter:{home:!0,heroText:"郑文峰的博客",tagline:"朝闻道,夕死可矣。",hideRightBar:!1,description:"技术博客，专注于后端学习与总结，python,go,redis,k8s,mysql,kafka,flask,django,tornado,git,github,markdown等技术类文章",meta:[{name:"image",content:"https://www.zhengwenfeng.com/img/panda-waving.png"},{name:"twitter:title",content:"郑文峰的博客"},{name:"twitter:description",content:"技术博客，专注于后端学习与总结，python,go,redis,k8s,mysql,kafka,flask,django,tornado,git,github,markdown等技术类文章"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://www.zhengwenfeng.com/img/panda-waving.png"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/"},{property:"og:type",content:"website"},{property:"og:title",content:"郑文峰的博客"},{property:"og:description",content:"技术博客，专注于后端学习与总结，python,go,redis,k8s,mysql,kafka,flask,django,tornado,git,github,markdown等技术类文章"},{property:"og:image",content:"https://www.zhengwenfeng.com/img/panda-waving.png"},{property:"og:url",content:"https://www.zhengwenfeng.com/"},{property:"og:site_name",content:"zhengwenfeng"},{itemprop:"name",content:"郑文峰的博客"},{itemprop:"description",content:"技术博客，专注于后端学习与总结，python,go,redis,k8s,mysql,kafka,flask,django,tornado,git,github,markdown等技术类文章"},{itemprop:"image",content:"https://www.zhengwenfeng.com/img/panda-waving.png"}],readingShow:"top"},regularPath:"/",relativePath:"index.md",key:"v-1e8d1344",path:"/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/10/31, 21:57:05",lastUpdatedTimestamp:1667224625e3},{title:"分类",frontmatter:{categoriesPage:!0,title:"分类",permalink:"/categories/",article:!1,description:"",meta:[{name:"twitter:title",content:"分类"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.zhengwenfeng.com/@pages/categoriesPage.html"},{property:"og:type",content:"article"},{property:"og:title",content:"分类"},{property:"og:description",content:""},{property:"og:url",content:"https://www.zhengwenfeng.com/@pages/categoriesPage.html"},{property:"og:site_name",content:"zhengwenfeng"},{itemprop:"name",content:"分类"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/@pages/categoriesPage.html",relativePath:"@pages/categoriesPage.md",key:"v-5cc30ba5",path:"/categories/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/08/09, 07:53:30",lastUpdatedTimestamp:166000281e4}],themeConfig:{nav:[{text:"首页",link:"/"},{text:"专题",items:[{text:"Go语言高性能编程",link:"/go_performance/"},{text:"Bug 通缉令",link:"/bug_hunt/"}]},{text:"分类",link:"/categories/"},{text:"标签",link:"/tags/"},{text:"归档",link:"/archives/"},{text:"关于",link:"/about/"},{text:"我的工具",items:[{text:"导航",link:"https://nav.zhengwenfeng.com/"},{text:"代码片段",link:"https://ref.zhengwenfeng.com/"}]},{text:"更多",link:"/more/",items:[{text:"收藏",link:"/pages/beb6c0bd8a66cea6/"},{text:"友链",link:"/friends/"},{text:"外部页面",items:[{text:"开往",link:"https://www.travellings.cn/go.html"}]}]}],sidebarDepth:3,logo:"/img/me.jpg",repo:"tenqaz/tenqaz.github.io",searchMaxSuggestions:10,lastUpdated:"上次更新",docsDir:"docs",editLinks:!1,searchPlaceholder:"按下 𝑺 搜索",sidebar:{"/00.目录页/":[["01.Go语言高性能编程.md","Go语言高性能编程","/go_performance/"],["02.Bug 通缉令.md","Bug 通缉令","/bug_hunt/"]],catalogue:{"Go语言高性能编程":"/go_performance/","Bug 通缉令":"/bug_hunt/"},"/01.云原生/":[{title:"docker",collapsable:!0,children:[["06.docker/01.容器的本质.md","容器的本质","/pages/f3cf17/"],["06.docker/02.docker容器.md","docker容器","/pages/39f36e/"],["06.docker/03.手动实现docker容器bridge网络模型.md","手动实现docker容器bridge网络模型","/pages/d3768c/"],["06.docker/04.docker容器单机网络.md","docker容器单机网络","/pages/0ddeb7/"]]},{title:"k8s",collapsable:!0,children:[["07.k8s/03.k8s之pod.md","k8s之Pod","/pages/2b547f/"],["07.k8s/04.k8s之deployment.md","k8s之Deployment","/pages/d73c88/"],["07.k8s/05.k8s之service.md","k8s之Service","/pages/1f860b/"],["07.k8s/06.k8s之ConfigMap和Secret.md","k8s之ConfigMap和Secret","/pages/ff8188/"],["07.k8s/07.k8s之Job和CronJob.md","k8s之Job和CronJob","/pages/c96905/"],["07.k8s/08.k8s之DaemonSet.md","k8s之DaemonSet","/pages/92bee4/"],["07.k8s/09.k8s之PV、PVC和StorageClass.md","k8s之PV、PVC和StorageClass","/pages/095c75/"],["07.k8s/10.k8s之StatefulSet.md","k8s之StatefulSet","/pages/d178a2/"],["07.k8s/11.使用kubeadm安装k8s.md","使用kubeadm安装k8s","/pages/9e17c8/"],["07.k8s/12.pod中将代码与运行环境分离.md","pod中将代码与运行环境分离","/pages/27987d/"],["07.k8s/13.django后端服务、logstash和flink接入VictoriaMetrics指标监控.md","django后端服务、logstash和flink接入VictoriaMetrics指标监控","/pages/b1b4a3/"],["07.k8s/14.理解flannel的三种容器网络方案原理.md","理解flannel的三种容器网络方案原理","/pages/d9d0ce/"],["07.k8s/15.理解calico容器网络通信方案原理.md","理解calico容器网络通信方案原理","/pages/f0f725/"],["07.k8s/16.kubernetes service如何通过iptables转发.md","kubernetes service如何通过iptables转发","/pages/b3955c/"],["07.k8s/17.kube-proxy源码分析.md","kube-proxy源码分析","/pages/6e0045/"]]}],"/02.Bug 通缉令/":[["01.一次服务升级时pg表DDL执行超时失败.md","一次服务升级时pg表DDL执行超时失败","/pages/cf65ba/"],["02.服务启动时出现 OOM.md","服务启动时出现 OOM","/pages/de98b1/"]],"/03.中间件/":[{title:"kafka",collapsable:!0,children:[["01.kafka/01.listener和advertised.listeners的作用.md","kafka中listener和advertised.listeners的作用","/pages/fa114f/"]]},{title:"mysql",collapsable:!0,children:[["03.mysql/01.mysql之日志.md","mysql之日志","/pages/2d69c7/"],["03.mysql/02.mysql之MVCC原理.md","mysql之MVCC原理","/pages/0d8f4a/"]]},{title:"redis",collapsable:!0,children:[["05.redis/01.redis之五种基本数据类型.md","redis之五种基本数据类型","/pages/2bbeb3/"],["05.redis/02.redis之持久化.md","redis之持久化","/pages/4c6b13/"],["05.redis/03. redis之主从库同步.md","redis之主从库同步","/pages/8072eb/"],["05.redis/04. redis之哨兵机制.md","redis之哨兵机制","/pages/ffee9e/"],["05.redis/05. redis之分片集群.md","redis之分片集群","/pages/1c2914/"],["05.redis/06. redis之缓存.md","redis之缓存","/pages/0d7b25/"]]},{title:"logstash",collapsable:!0,children:[["06.logstash/01.pulsar阻塞导致logstash无法接入日志.md","pulsar阻塞导致logstash无法接入日志","/pages/adedbd/"]]}],"/04.编程/":[{title:"python",collapsable:!0,children:[{title:"基础",collapsable:!0,children:[["01.python/01.基础/01.python迭代器与生成器.md","python迭代器与生成器","/pages/e31b06/"],["01.python/01.基础/02.python元编程.md","python元编程","/pages/5fa368/"],["01.python/01.基础/03.python垃圾回收机制.md","python垃圾回收机制","/pages/78c648/"],["01.python/01.基础/04.python上下文管理器.md","python上下文管理器","/pages/a6b804/"],["01.python/01.基础/05.python装饰器的使用方法.md","python装饰器的使用方法","/pages/7434f1/"],["01.python/01.基础/06.使用python实现单例模式的三种方式.md","使用python实现单例模式的三种方式","/pages/33b8d0/"],["01.python/01.基础/07.python中import原理.md","python中import原理","/pages/d8fd49/"]]},{title:"第三方库",collapsable:!0,children:[["01.python/02.第三方库/01.使用ddt实现unittest的参数化测试.md","使用ddt实现unittest的参数化测试","/pages/8d9ab9/"],["01.python/02.第三方库/02.ddt源码分析.md","ddt源码分析","/pages/069c65/"],["01.python/02.第三方库/03.django-apschedule定时任务异常停止.md","django-apschedule定时任务异常停止","/pages/ec5110/"]]},{title:"django",collapsable:!0,children:[["01.python/06.django/01.django celery 结合使用.md","django celery 结合使用","/pages/853501/"],["01.python/06.django/02.django rest_framework使用jwt.md","django rest_framework使用jwt","/pages/25eafd/"],["01.python/06.django/03.django rest_framework Authentication.md","django rest_framework Authentication","/pages/626675/"],["01.python/06.django/04.django rest_framework异常处理.md","django rest_framework异常处理","/pages/070fec/"],["01.python/06.django/05.django rest_framework 自定义文档.md","django rest_framework 自定义文档","/pages/c3af6a/"],["01.python/06.django/06.django压缩文件下载.md","django压缩文件下载","/pages/f2738b/"],["01.python/06.django/07.django rest_framework使用pytest单元测试.md","django rest_framework使用pytest单元测试","/pages/c28126/"],["01.python/06.django/08.django restframework choice 自定义输出数据.md","django restframework choice 自定义输出数据","/pages/b90015/"],["01.python/06.django/09.django Filtering 使用.md","django Filtering 使用","/pages/cfdb5f/"],["01.python/06.django/10.django viewset 和 Router 配合使用时报的错.md","django viewset 和 Router 配合使用时报的错","/pages/e75ceb/"],["01.python/06.django/11.django model的序列化.md","django model的序列化","/pages/acdd50/"],["01.python/06.django/12.django中使用AbStractUser.md","django中使用AbStractUser","/pages/382755/"],["01.python/06.django/13.django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users.md","django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users","/pages/060c51/"],["01.python/06.django/14.django 中 media配置.md","django 中 media配置","/pages/de01e2/"],["01.python/06.django/15.django 外键引用自身和on_delete参数.md","django 外键引用自身和on_delete参数","/pages/b422bd/"],["01.python/06.django/16.django 警告 while time zone support is active.md","django 警告 while time zone support is active","/pages/f0d816/"],["01.python/06.django/17.django rest_framework 分页.md","django rest_framework 分页","/pages/cb262f/"],["01.python/06.django/18.django-prometheus使用及源码分析.md","django-prometheus使用及源码分析","/pages/4b0adb/"]]},{title:"flask",collapsable:!0,children:[["01.python/07.flask/01.Flask使用flask_socketio实现websocket.md","Flask使用flask_socketio实现websocket","/pages/b71dc2/"],["01.python/07.flask/02.flask结合mongo.md","flask结合mongo","/pages/c59edf/"]]},{title:"tornado",collapsable:!0,children:[["01.python/08.tornado/01.tornado 文件上传.md","tornado 文件上传","/pages/4c38f5/"],["01.python/08.tornado/02.tornado 使用jwt完成用户异步认证.md","tornado 使用jwt完成用户异步认证","/pages/c24905/"],["01.python/08.tornado/03.tornado 用户密码 bcrypt加密.md","tornado 用户密码 bcrypt加密","/pages/22f35b/"],["01.python/08.tornado/04.tornado 结合wtforms使用表单操作.md","tornado 结合wtforms使用表单操作","/pages/7ac01f/"],["01.python/08.tornado/05.tornado finish和write区别.md","tornado finish和write区别","/pages/d18657/"],["01.python/08.tornado/06.tornado 使用peewee-async 完成异步orm数据库操作.md","tornado 使用peewee-async 完成异步orm数据库操作","/pages/113ab1/"]]},{title:"其他",collapsable:!0,children:[["01.python/09.其他/01.python简单使用grpc.md","python简单使用grpc","/pages/f9d78c/"],["01.python/09.其他/02.pyspark streaming简介 和 消费 kafka示例.md","pyspark streaming简介 和 消费 kafka示例","/pages/72664a/"],["01.python/09.其他/03.基于pre-commit的Python代码规范落地实践.md","基于pre-commit的Python代码规范落地实践","/pages/7f6078/"]]}]},{title:"go语言",collapsable:!0,children:[["02.go语言/01.go简单使用grpc.md","go简单使用grpc","/pages/87014e/"],["02.go语言/02. gin中validator模块的源码分析.md","gin中validator模块的源码分析","/pages/c41003/"],["02.go语言/03.优化gin表单的错误提示信息.md","优化gin表单的错误提示信息","/pages/cf9a4d/"],["02.go语言/04.go中如何处理error.md","go中如何处理error","/pages/d93df5/"],["02.go语言/05.tcp缓存引起的日志丢失.md","tcp缓存引起的日志丢失","/pages/36b0b2/"],["02.go语言/06.使用etcd分布式锁导致的协程泄露与死锁问题.md","使用etcd分布式锁导致的协程泄露与死锁问题","/pages/91d2d9/"],{title:"go语言高性能编程",collapsable:!0,children:[["02.go语言/07.go语言高性能编程/01.Go协程池深度解析：原理、实现与最佳实践.md","Go协程池深度解析：原理、实现与最佳实践","/pages/d2c214/"],["02.go语言/07.go语言高性能编程/02.Go语言Interface Boxing原理与性能优化指南.md","Go语言Interface Boxing原理与性能优化指南","/pages/49057b/"],["02.go语言/07.go语言高性能编程/03.Go语言遍历性能深度解析：从原理到优化实践.md","Go语言遍历性能深度解析：从原理到优化实践","/pages/88360d/"],["02.go语言/07.go语言高性能编程/04.Go语言零拷贝技术完全指南.md","Go语言零拷贝技术完全指南","/pages/4f7497/"],["02.go语言/07.go语言高性能编程/05.Go语言不可变数据共享：无锁并发编程实践.md","Go语言不可变数据共享：无锁并发编程实践","/pages/b03207/"],["02.go语言/07.go语言高性能编程/06.Go语言内存预分配完全指南.md","Go语言内存预分配完全指南","/pages/d7dbc7/"],["02.go语言/07.go语言高性能编程/07.Go语言原子操作完全指南.md","Go语言原子操作完全指南","/pages/821b25/"],["02.go语言/07.go语言高性能编程/08.Go语言堆栈分配与逃逸分析深度解析.md","Go语言堆栈分配与逃逸分析深度解析","/pages/c19d45/"],["02.go语言/07.go语言高性能编程/09.Go语言空结构体：零内存消耗的高效编程.md","Go语言空结构体：零内存消耗的高效编程","/pages/df4833/"],["02.go语言/07.go语言高性能编程/10.Go语言高性能编程之结构体内存对齐.md","Go语言结构体内存对齐完全指南","/pages/13969e/"],["02.go语言/07.go语言高性能编程/11.Go语言字符串拼接性能对比与优化指南.md","Go语言字符串拼接性能对比与优化指南","/pages/d4c8eb/"],["02.go语言/07.go语言高性能编程/12.Go语言延迟初始化(Lazy Initialization)最佳实践.md","Go语言延迟初始化(Lazy Initialization)最佳实践","/pages/f9a2a3/"],["02.go语言/07.go语言高性能编程/13.Go语言高效IO缓冲技术详解.md","Go语言高效IO缓冲技术详解","/pages/d8ed61/"]]}]},{title:"linux",collapsable:!0,children:[["03.linux/01.快速了解iptables.md","快速了解iptables","/pages/72ba9a/"],["03.linux/02.理解Linux TunTap设备.md","理解Linux TunTap设备","/pages/143447/"],["03.linux/03.理解VXLAN网络.md","理解VXLAN网络","/pages/8a4b28/"],["03.linux/04.理解Linux IPIP隧道.md","理解Linux IPIP隧道","/pages/c128e7/"]]},{title:"其他",collapsable:!0,children:[["09.其他/01.分布式锁.md","分布式锁","/pages/d91dfb/"],["09.其他/02.使用hue创建ozzie的pyspark action workflow.md","使用hue创建ozzie的pyspark action workflow","/pages/aba491/"],["09.其他/03.使用java开发logstash的filter插件.md","使用java开发logstash的filter插件","/pages/7f16f6/"],["09.其他/20.count的性能优化.md","count的性能优化","/pages/19cfb6/"]]}],"/05.读书破万卷/":[["01.如何阅读一本书.md","读书笔记:如何阅读一本书","/pages/8bdb8d/"]],"/06.AI/":[["01.初识 MCP Server.md","初识 MCP Server","/pages/92e280/"]],"/08.关于/":[["01.关于.md","关于","/about/"]],"/09.更多/":[["01.收藏.md","网站","/pages/beb6c0bd8a66cea6/"],["02.友链.md","友链","/friends"]]},author:{name:"zhengwenfeng",link:"https://www.zhengwenfeng.com"},blogger:{avatar:"/img/me.jpg",name:"zhengwenfeng",slogan:"穷则变，变则通，通则久"},social:{icons:[{iconClass:"icon-youjian",title:"发邮件",link:"mailto:326695231@qq.com"},{iconClass:"icon-github",title:"GitHub",link:"https://github.com/tenqaz"},{iconClass:"icon-rss",title:"RSS订阅",link:"https://www.zhengwenfeng.com/rss.xml"}]},footer:{createYear:2022,copyrightInfo:'zhengwenfeng | <a href="https://github.com/tenqaz/tenqaz.github.io/master/LICENSE" target="_blank">MIT License</a>'},extendFrontmatter:{author:{name:"zhengwenfeng",link:"https://github.com/tenqaz"},description:"",comment:!0,feed:{enable:!0}},htmlModules:{homeSidebarB:'<div style="padding: 0.95rem">\n    <p style="\n      color: var(--textColor);\n      opacity: 0.9;\n      font-size: 20px;\n      font-weight: bold;\n      margin: 0 0 8px 0;\n    ">公众号</p>\n    <img src="https://open.weixin.qq.com/qr/code?username=gh_15e3ec18b681"  style="width:100%;" />\n    编程黑洞，扫码或者搜索关注\n    </p>\n    </div>'}}};var wl=t(126),El=t(127),xl=t(21);var Al={computed:{$filterPosts(){return this.$site.pages.filter(n=>{const{frontmatter:{pageComponent:e,article:t,home:r}}=n;return!(e||!1===t||!0===r)})},$sortPosts(){return(n=this.$filterPosts).sort((n,e)=>{const t=n.frontmatter.sticky,r=e.frontmatter.sticky;return t&&r?t==r?Object(xl.a)(n,e):t-r:t&&!r?-1:!t&&r?1:Object(xl.a)(n,e)}),n;var n},$sortPostsByDate(){return(n=this.$filterPosts).sort((n,e)=>Object(xl.a)(n,e)),n;var n},$groupPosts(){return function(n){const e={},t={};for(let r=0,o=n.length;r<o;r++){const{frontmatter:{categories:o,tags:a}}=n[r];"array"===Object(xl.n)(o)&&o.forEach(t=>{t&&(e[t]||(e[t]=[]),e[t].push(n[r]))}),"array"===Object(xl.n)(a)&&a.forEach(e=>{e&&(t[e]||(t[e]=[]),t[e].push(n[r]))})}return{categories:e,tags:t}}(this.$sortPosts)},$categoriesAndTags(){return function(n){const e=[],t=[];for(let t in n.categories)e.push({key:t,length:n.categories[t].length});for(let e in n.tags)t.push({key:e,length:n.tags[e].length});return{categories:e,tags:t}}(this.$groupPosts)}}};Ht.component(wl.default),Ht.component(El.default);function Bl(n){return n.toString().padStart(2,"0")}t(279);Ht.component("Badge",()=>Promise.all([t.e(0),t.e(3)]).then(t.bind(null,472))),Ht.component("CodeBlock",()=>Promise.resolve().then(t.bind(null,126))),Ht.component("CodeGroup",()=>Promise.resolve().then(t.bind(null,127)));t(280);var zl=t(125),jl=t.n(zl),Tl=t(46);let Cl,Sl,Pl;var Il;"valine"===(Il="waline")?t.e(116).then(t.t.bind(null,358,7)).then(n=>Sl=n.default):"gitalk"===Il?Promise.all([t.e(0),t.e(115)]).then(t.t.bind(null,359,7)).then(()=>t.e(114).then(t.t.bind(null,360,7))).then(n=>Cl=n.default):"waline"===Il&&t.e(5).then(t.t.bind(null,361,7)).then(n=>Pl=n.default);function ql(n,e){const t={};return Reflect.ownKeys(n).forEach(r=>{if("string"==typeof n[r])try{t[r]=jl.a.render(n[r],e)}catch(e){console.warn(`Comment config option error at key named "${r}"`),console.warn("More info: "+e.message),t[r]=n[r]}else t[r]=n[r]}),t}console.log(`How to use "waline" in ${Tl.name}@v${Tl.version}:`,Tl.homepage);const Dl={gitalk:{render(n,e){const t=document.createElement("div");t.id=e;document.querySelector("main.page").appendChild(t);new Cl(ql({serverURL:"https://comment.zhengwenfeng.com/"},{frontmatter:n})).render(e)},clear(n){const e=document.querySelector("#"+n);return e&&e.remove(),!0}},valine:{render(n,e){const t=document.createElement("div");t.id=e;document.querySelector("main.page").appendChild(t),new Sl({...ql({serverURL:"https://comment.zhengwenfeng.com/"},{frontmatter:n}),el:"#"+e})},clear(n){const e=document.querySelector("#"+n);return e&&e.remove(),!0}},waline:{render(n,e){const t=document.createElement("div");t.id=e;document.querySelector("main.page").appendChild(t),new Pl({...ql({serverURL:"https://comment.zhengwenfeng.com/"},{frontmatter:n}),el:"#"+e})},clear(n){const e=document.querySelector("#"+n);return e&&e.remove(),!0}}},Nl="vuepress-plugin-comment";let Ol=null;function Rl(n){let e={serverURL:"https://comment.zhengwenfeng.com/"}.el||Nl;return e.startsWith("#")&&(e=e.slice(1)),console.log(e),Dl.waline.clear(e)}function Fl(n){return!1!==n.comment&&!1!==n.comments}function Ll(n){clearTimeout(Ol);if(!document.querySelector("main.page"))return void(Ol=setTimeout(()=>Ll(n),200));let e={serverURL:"https://comment.zhengwenfeng.com/"}.el||Nl;return e.startsWith("#")&&(e=e.slice(1)),Dl.waline.render(n,e)}var Ul={mounted(){Ol=setTimeout(()=>{const n={to:{},from:{},...this.$frontmatter};Rl()&&Fl(n)&&Ll(n)},1e3),this.$router.afterEach((n,e)=>{if(n&&e&&n.path===e.path)return;const t={to:n,from:e,...this.$frontmatter};Rl()&&Fl(t)&&Ll(t)})}},Ml=Object(bl.a)(Ul,(function(){return(0,this._self._c)("div")}),[],!1,null,null,null).exports,Gl={name:"ReadingProgress",data:()=>({readingTop:0,readingHeight:1,progressStyle:null,transform:void 0,running:!1}),watch:{$readingShow(){this.progressStyle=this.getProgressStyle(),this.$readingShow&&window.addEventListener("scroll",this.base)}},mounted(){this.transform=this.getTransform(),this.progressStyle=this.getProgressStyle(),this.$readingShow&&window.addEventListener("scroll",this.base)},beforeDestroy(){this.$readingShow&&window.removeEventListener("scroll",this.base)},methods:{base(){this.running||(this.running=!0,requestAnimationFrame(this.getReadingBase))},getReadingBase(){this.readingHeight=this.getReadingHeight()-this.getScreenHeight(),this.readingTop=this.getReadingTop(),this.progressStyle=this.getProgressStyle(),this.running=!1},getReadingHeight:()=>Math.max(document.body.scrollHeight,document.body.offsetHeight,0),getScreenHeight:()=>Math.max(window.innerHeight,document.documentElement.clientHeight,0),getReadingTop:()=>Math.max(window.pageYOffset,document.documentElement.scrollTop,0),getTransform(){const n=document.createElement("div");return["transform","-webkit-transform","-moz-transform","-o-transform","-ms-transform"].find(e=>e in n.style)||void 0},getProgressStyle(){const n=this.readingTop/this.readingHeight;switch(this.$readingShow){case"top":case"bottom":return this.transform?`${this.transform}: scaleX(${n})`:`width: ${100*n}%`;case"left":case"right":return this.transform?`${this.transform}: scaleY(${n})`:`height: ${100*n}%`;default:return null}}}},Vl=(t(285),Object(bl.a)(Gl,(function(){var n=this._self._c;return n("ClientOnly",[this.$readingShow?n("div",{staticClass:"reading-progress",class:this.$readingShow},[n("div",{staticClass:"progress",style:this.progressStyle})]):this._e()])}),[],!1,null,"3640397f",null).exports),$l=[({Vue:n,options:e,router:t,siteData:r})=>{},({Vue:n,options:e,router:t,siteData:r})=>{r.pages.map(n=>{const{frontmatter:{date:e,author:t}}=n;"string"==typeof e&&"Z"===e.charAt(e.length-1)&&(n.frontmatter.date=function(n){n instanceof Date||(n=new Date(n));return`${n.getUTCFullYear()}-${Bl(n.getUTCMonth()+1)}-${Bl(n.getUTCDate())} ${Bl(n.getUTCHours())}:${Bl(n.getUTCMinutes())}:${Bl(n.getUTCSeconds())}`}(e)),t?n.author=t:r.themeConfig.author&&(n.author=r.themeConfig.author)}),n.mixin(Al)},{},({Vue:n})=>{n.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},{},({Vue:n})=>{n.component("Comment",Ml)},({router:n})=>{"undefined"!=typeof window&&function(){var n=document.createElement("script"),e=window.location.protocol.split(":")[0];n.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(n,t)}()},({router:n})=>{"undefined"!=typeof window&&(window._hmt=window._hmt||[],function(){var n=document.createElement("script");n.src="https://hm.baidu.com/hm.js?7c28cc47ffa100de44e976f816b0b294";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(n,e)}(),n.afterEach((function(n){_hmt.push(["_trackPageview",n.fullPath])})))},({Vue:n})=>{n.component(Vl.name,Vl),n.mixin({computed:{$readingShow(){return this.$page.frontmatter.readingShow}}})}],Wl=["Comment","ReadingProgress"];class Hl extends class{constructor(){this.store=new Ht({data:{state:{}}})}$get(n){return this.store.state[n]}$set(n,e){Ht.set(this.store.state,n,e)}$emit(...n){this.store.$emit(...n)}$on(...n){this.store.$on(...n)}}{}Object.assign(Hl.prototype,{getPageAsyncComponent:ii,getLayoutAsyncComponent:li,getAsyncComponent:ci,getVueComponent:pi});var Zl={install(n){const e=new Hl;n.$vuepress=e,n.prototype.$vuepress=e}};function Kl(n,e){const t=e.toLowerCase();return n.options.routes.some(n=>n.path.toLowerCase()===t)}var Xl={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(n){const e=this.pageKey||this.$parent.$page.key;return ui("pageKey",e),Ht.component(e)||Ht.component(e,ii(e)),Ht.component(e)?n(e):n("")}},Jl={functional:!0,props:{slotKey:String,required:!0},render:(n,{props:e,slots:t})=>n("div",{class:["content__"+e.slotKey]},t()[e.slotKey])},Yl={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Ql=(t(286),t(287),Object(bl.a)(Yl,(function(){var n=this._self._c;return n("span",[n("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[n("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),n("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),n("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),nc={functional:!0,render(n,{parent:e,children:t}){if(e._isMounted)return t;e.$once("hook:mounted",()=>{e.$forceUpdate()})}};Ht.config.productionTip=!1,Ht.use($s),Ht.use(Zl),Ht.mixin(function(n,e,t=Ht){!function(n){n.locales&&Object.keys(n.locales).forEach(e=>{n.locales[e].path=e});Object.freeze(n)}(e),t.$vuepress.$set("siteData",e);const r=new(n(t.$vuepress.$get("siteData"))),o=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(r)),a={};return Object.keys(o).reduce((n,e)=>(e.startsWith("$")&&(n[e]=o[e].get),n),a),{computed:a}}(n=>class{setPage(n){this.__page=n}get $site(){return n}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:n={}}=this.$site;let e,t;for(const r in n)"/"===r?t=n[r]:0===this.$page.path.indexOf(r)&&(e=n[r]);return e||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:n}=this.$page.frontmatter;return"string"==typeof n&&n}get $title(){const n=this.$page,{metaTitle:e}=this.$page.frontmatter;if("string"==typeof e)return e;const t=this.$siteTitle,r=n.frontmatter.home?null:n.frontmatter.title||n.title;return t?r?r+" | "+t:t:r||"VuePress"}get $description(){const n=function(n){if(n){const e=n.filter(n=>"description"===n.name)[0];if(e)return e.content}}(this.$page.frontmatter.meta);return n||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(n,e){for(let t=0;t<n.length;t++){const r=n[t];if(r.path.toLowerCase()===e.toLowerCase())return r}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},kl)),Ht.component("Content",Xl),Ht.component("ContentSlotsDistributor",Jl),Ht.component("OutboundLink",Ql),Ht.component("ClientOnly",nc),Ht.component("Layout",li("Layout")),Ht.component("NotFound",li("NotFound")),Ht.prototype.$withBase=function(n){const e=this.$site.base;return"/"===n.charAt(0)?e+n.slice(1):n},window.__VUEPRESS__={version:"1.9.5",hash:"c31a666"},async function(n){const e="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:kl.routerBase||kl.base,t=new $s({base:e,mode:"history",fallback:!1,routes:yl,scrollBehavior:(n,e,t)=>t||(n.hash?!Ht.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(n.hash)}:{x:0,y:0})});!function(n){n.beforeEach((e,t,r)=>{if(Kl(n,e.path))r();else if(/(\/|\.html)$/.test(e.path))if(/\/$/.test(e.path)){const t=e.path.replace(/\/$/,"")+".html";Kl(n,t)?r(t):r()}else r();else{const t=e.path+"/",o=e.path+".html";Kl(n,o)?r(o):Kl(n,t)?r(t):r()}})}(t);const r={};try{await Promise.all($l.filter(n=>"function"==typeof n).map(e=>e({Vue:Ht,options:r,router:t,siteData:kl,isServer:n})))}catch(n){console.error(n)}return{app:new Ht(Object.assign(r,{router:t,render:n=>n("div",{attrs:{id:"app"}},[n("RouterView",{ref:"layout"}),n("div",{class:"global-ui"},Wl.map(e=>n(e)))])})),router:t}}(!1).then(({app:n,router:e})=>{e.onReady(()=>{n.$mount("#app")})})}]);